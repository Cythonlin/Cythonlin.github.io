<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cythonlin.github.io</id>
    <title>Cython_lin</title>
    <updated>2021-02-05T14:22:04.334Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cythonlin.github.io"/>
    <link rel="self" href="https://cythonlin.github.io/atom.xml"/>
    <logo>https://cythonlin.github.io/images/avatar.png</logo>
    <icon>https://cythonlin.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Cython_lin</rights>
    <entry>
        <title type="html"><![CDATA[PR => Alias & Linux瑞士军刀]]></title>
        <id>https://cythonlin.github.io/post/pr-greater-del-alias-and-linux-rui-shi-jun-dao/</id>
        <link href="https://cythonlin.github.io/post/pr-greater-del-alias-and-linux-rui-shi-jun-dao/">
        </link>
        <updated>2021-02-04T16:08:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="介绍">介绍</h1>
<h2 id="前文">前文</h2>
<p>前面文章介绍了Windows Terminal 以及 WSL2<br>
二者各有用途，但是用了一段时间发现，都不太方便 &quot;Sim-Bash&quot;<br>
因为 Windows Terminal 的底层调用其实还是 PowerShell的命令。。<br>
只不过 只是PowerShell（下面用简称PS来介绍）的命令全部都做了一层Alias操作。<br>
此Alias有具体的语法，与Linux不一样的，但是意思差不多，就是给命令起别名。</p>
<p>就是因为PS这个别名，使得我们用Scoop安装的Linux同名命令冲突，并且用不了。</p>
<h2 id="同名命令介绍">同名命令介绍</h2>
<p>比如 ls 这个命令， PS用的 其他命令（类似dir）起个ls 这个别名<br>
使得使用 ls 就可以像 Linux的Bash那样简单。<br>
但是！！！！</p>
<pre><code>PS的命令参数 和  Bash的命令参数是不一样的。。。
PS的 ls 命令 列举隐藏文件参数是 :   -h
Bash的 ls 命令 列举隐藏文件参数是 :   -a
</code></pre>
<p>这就是 PS的命令不方便之处， ls只是个例子，还有很多其他命令有同样的问题。<br>
Windows Terminal 就是用 PS “挂羊头卖狗肉” 罢了。。。</p>
<h2 id="解决办法">解决办法</h2>
<p>我唯一想到的就是，删除所有PS命令的别名，一切命令由Scoop重新下载（很简单，后面说军刀）<br>
然后按照这个思路寻找，找到可用的解决办法：</p>
<h3 id="创建windows-powershell-profile配置文件">创建Windows PowerShell profile配置文件:</h3>
<pre><code>New-Item -Type file -Force $profile
</code></pre>
<p>创建的此文件默认位置为：（我的用户名是 lin ）</p>
<pre><code>C:\Users\lin\Documents\WindowsPowerShell
</code></pre>
<p>新的空文件，写入如下代码：</p>
<pre><code>Get-Alias | ForEach-Object { 
    if ($_.Name -ne &quot;cd&quot;)
    {
        Remove-Item -Path (&quot;Alias:\&quot; + $_.Name) -Force -ErrorAction &quot;SilentlyContinue&quot; 
    }
} 
</code></pre>
<p>此行命令意思就是清除所有PS 命令的别名。<br>
（这个语句我学习加了一个条件 和 截获异常的语句）<br>
如果不排除 cd 这个命令， 我们后续安装的模块是 没有cd这个安装包的。<br>
因为 cd 是 LinuxBash 内建命令。 Windows无法安装， 即使我们安装了Bash, 也没有 cd。<br>
所以，cd我们只能用ps自带的cd, 这是没办法的事情，  其余的命令别名就可以全删了。</p>
<p>至此，重新代开 Terminal。</p>
<h3 id="遇到的问题">遇到的问题</h3>
<p>那就是每次打开新的Terminal 都会加载 上面Windows PowerShell profile这个配置文件里面的命令。可能是有缓存之类的信息，所以会发生文件不存在（就是类似空文件异常）<br>
于是，查PowerShell的异常处理语句如上代码后追加 -ErrorAction &quot;SilentlyContinue 即可。</p>
<h1 id="scoop-linux瑞士军刀-busybox">Scoop + Linux瑞士军刀-busybox</h1>
<p><a href="https://www.cklin.top/post/pr-greater-windows-terminal-ge-xing-hua-pei-zhi/">-&gt;Scoop的安装教程见这里寻找</a></p>
<p>既然上文已删除了所有PS别名，那我们就需要下载我们要用的各种 Linux命令了， 比如 ls ps kill<br>
各种常用 Linux命令。 不需要一个一个去手动 Scoop install 工具包， 只需一句：</p>
<pre><code>scoop install busybox
</code></pre>
<p>如此一来，我们就把 Windows Terminal 的各种蹩脚别名的PS命令 替换成了 Linux Bash命令！</p>
<h1 id="结束语">结束语</h1>
<p>我并非吐槽PS命令，因为它可能有它专门的用途。<br>
而是我更熟悉于 Linux 的 Bash 命令而已。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PR => MusicBee & VST]]></title>
        <id>https://cythonlin.github.io/post/pr-greater-musicbee-and-winamp-and-vst/</id>
        <link href="https://cythonlin.github.io/post/pr-greater-musicbee-and-winamp-and-vst/">
        </link>
        <updated>2021-01-29T04:58:49.000Z</updated>
        <content type="html"><![CDATA[<h1 id="musicbee">MusicBee</h1>
<h3 id="musicbee-皮肤">MusicBee 皮肤</h3>
<pre><code>Dark -&gt; Bee78
</code></pre>
<h3 id="musicbee-2">MusicBee</h3>
<h1 id="musicbee安装vst插槽">MusicBee安装VST插槽</h1>
<p>注：MusicBee不能直接安装VST插件， 需要官网安装一个VST插槽。用此插槽才可以安装其他VST插件<br>
<a href="https://getmusicbee.com/addons/plugins/16/vst-effects-support/">VST插槽下载地址</a></p>
<h3 id="安装插槽">安装插槽</h3>
<pre><code>Preference -&gt; Plugins -&gt; Add Plugins -&gt; 插槽下载的位置
</code></pre>
<h1 id="使用vst插槽安装vst插件">使用VST插槽安装VST插件</h1>
<h2 id="正常dll文件安装方式">正常DLL文件安装方式</h2>
<p><a href="https://freevstplugins.net/?s=NT+Pitch">VST插件下载地址</a><br>
注：MusicBee对VST插件支持很不友好，看了一大堆选了几个适合我这种初级选手能用的：</p>
<pre><code>3D_Panner_2.0
wL_niceNwide
Ceres (1)
cs12-156
</code></pre>
<p>下载后直接解压，将解压文件夹直接放到 music的plugins目录下即可（需重启MusicBee）</p>
<h2 id="痛苦安装方式只用通过这种方式才能安装到pitch-shift类插件">痛苦安装方式（只用通过这种方式才能安装到Pitch Shift类插件）</h2>
<p>这里提到一个超级老牌player -&gt;  Winamp...   ，现在应该没人用了。 或者都用Foobar2000了。<br>
Winamp 我看论坛都是 2000年左右的评论。。。可知它的插件也特别旧了。  但是它的插件特别多。<br>
可惜大多数放在 MusicBee上不好用或者崩溃。但没办法，还得用。</p>
<h3 id="为什么这里要提到winamp">为什么这里要提到Winamp</h3>
<p>因为MusicBee有个选项（从Winamp导入插件）<br>
而 Winamp的插件大多数都是 EXE格式的， 需要识别 Winamp的安装路径，并且安装到Winamp路径下。<br>
（其实EXE安装完也就是 DLL文件， 只不过它只能是这种方式。）<br>
所以 Winamp 只是个过渡的工具人。。。</p>
<h3 id="winamp插件地址">Winamp插件地址</h3>
<p><a href="https://winampheritage.com/plugins/DSP-Effect-5">Winamp插件</a><br>
拾到可用的插件 take it easy 可以改变 Pitch<br>
但是试过一段时间很遗憾，会让 MusicBee 宕掉。</p>
<h1 id="最后一根救命稻草-pitchshifterv101">最后一根救命稻草 pitchShifter.V1.01</h1>
<p><a href="https://github.com/kawaCat/pitchShifter-Vst/releases">pitchShifter地址</a><br>
这个就用不到 Winmap了， 直接移动到 MusicBee 的 Plugins中即可</p>
<h1 id="总结">总结</h1>
<p>找的很辛苦，普通的VST插件很好找， PITCH shift 这种的真的难找。<br>
即使找到了，MusicBee有些也各种不支持，不兼容，宕掉。</p>
<h2 id="最终插件合集">最终插件合集：</h2>
<pre><code>3D_Panner_2.0
wL_niceNwide
Ceres (1)
cs12-156

pitchShifter       （灵魂）
</code></pre>
<p>为何我如此执着音乐的变调，因为对于我来说，每一个Key都是一首新音乐！</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PR => U&P]]></title>
        <id>https://cythonlin.github.io/post/pr-greater-uandp/</id>
        <link href="https://cythonlin.github.io/post/pr-greater-uandp/">
        </link>
        <updated>2021-01-19T08:45:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="google">Google</h1>
<pre><code>96@
</code></pre>
<h1 id="github">Github</h1>
<pre><code>Cy
ha-
http://cythonlin.github.io/
</code></pre>
<h1 id="vultr">Vultr</h1>
<pre><code>Cy
</code></pre>
<h1 id="kaggle">Kaggle</h1>
<pre><code>cy
</code></pre>
<h1 id="microsoft">MicroSoft</h1>
<pre><code>96@ / si
</code></pre>
<h1 id="nvidia">Nvidia</h1>
<pre><code>96@
</code></pre>
<h1 id="anaconda">Anaconda</h1>
<pre><code>ha_
</code></pre>
<h1 id="七牛">七牛</h1>
<pre><code>96@
</code></pre>
<h1 id="ynote">YNote</h1>
<pre><code>96@
</code></pre>
<h1 id="coding-pages">Coding Pages</h1>
<pre><code>96@ / Jxxxxxxxxxxxxxx.       （末尾多个英文标点 句号）
https://cythonlin.coding.net
</code></pre>
<h1 id="postman">Postman</h1>
<pre><code>96@
</code></pre>
<h1 id="bd">BD</h1>
<pre><code>18/13
</code></pre>
<h1 id="docker">Docker</h1>
<pre><code>ha
</code></pre>
<h1 id="极算">极算</h1>
<pre><code>18
</code></pre>
<h1 id="neo4j">Neo4j</h1>
<pre><code>neo4j / zxc
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PR => Windows Terminal]]></title>
        <id>https://cythonlin.github.io/post/pr-greater-windows-terminal-ge-xing-hua-pei-zhi/</id>
        <link href="https://cythonlin.github.io/post/pr-greater-windows-terminal-ge-xing-hua-pei-zhi/">
        </link>
        <updated>2021-01-18T09:41:15.000Z</updated>
        <content type="html"><![CDATA[<h1 id="快捷键">快捷键</h1>
<p>搜索功能</p>
<pre><code>ctrl + shift + p
</code></pre>
<p>搜索文本</p>
<pre><code>ctrl + shift + f
</code></pre>
<p>編輯配置文件</p>
<pre><code>ctrl + '       (回車旁邊的符號 ')
</code></pre>
<p>橫向拆分窗口（下面action中，自定義配置）</p>
<pre><code>ctrl + +號
</code></pre>
<p>垂直拆分窗口（下面actrion中，自定義配置）</p>
<pre><code>ctrl + -號
</code></pre>
<p>關閉拆分的窗口（下面action中，自定義配置）</p>
<pre><code>ctrl + w
</code></pre>
<p>配置文件（ctrl + ' 后，全部内容整體替換即可）</p>
<pre><code>    // To view the default settings, hold &quot;alt&quot; while clicking on the &quot;Settings&quot; button.
    // For documentation on these settings, see: https://aka.ms/terminal-documentation

    {
        // 官方设置指南?
        &quot;$schema&quot;: &quot;https://aka.ms/terminal-profiles-schema&quot;,

        // 一些globals设置
        &quot;theme&quot;: &quot;dark&quot;, // 窗口主题
        &quot;initialRows&quot;: 25,
        &quot;initialCols&quot;: 100,

        &quot;defaultProfile&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;,

        &quot;profiles&quot;: {

            &quot;defaults&quot;: {
                // Put settings here that you want to apply to all profiles
                &quot;colorScheme&quot;: &quot;Seafoam Pastel&quot;,
                &quot;useAcrylic&quot;: true,
                &quot;acrylicOpacity&quot;: 0.55,
                &quot;cursorShape&quot;: &quot;vintage&quot;,
                &quot;cursorHeight&quot;: 60,
                &quot;cursorColor&quot;: &quot;#B00C11&quot;,
                &quot;fontFace&quot;: &quot;YaHei Consolas Hybrid&quot;,
                &quot;fontSize&quot;: 18
            },

            &quot;list&quot;: [{
                    // Make changes here to the powershell.exe profile
                    &quot;guid&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;,
                    &quot;name&quot;: &quot;Windows PowerShell&quot;,
                    &quot;commandline&quot;: &quot;powershell.exe&quot;,
                    &quot;hidden&quot;: false
                },
                {
                    // Make changes here to the cmd.exe profile
                    &quot;guid&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa6101}&quot;,
                    &quot;name&quot;: &quot;cmd&quot;,
                    &quot;commandline&quot;: &quot;cmd.exe&quot;,
                    &quot;hidden&quot;: false
                },
                {
                    &quot;guid&quot;: &quot;{b453ae62-4e3d-5e58-b989-0a998ec441b8}&quot;,
                    &quot;hidden&quot;: false,
                    &quot;name&quot;: &quot;Azure Cloud Shell&quot;,
                    &quot;source&quot;: &quot;Windows.Terminal.Azure&quot;
                }
            ]
        },

        // Add custom color schemes to this array
        &quot;schemes&quot;: [
    {
    &quot;name&quot;: &quot;Seafoam Pastel&quot;,
    &quot;black&quot;: &quot;#000000&quot;,
    &quot;red&quot;: &quot;#ff7092&quot;,
    &quot;green&quot;: &quot;#00fbac&quot;,
    &quot;yellow&quot;: &quot;#fffa6a&quot;,
    &quot;blue&quot;: &quot;#00bfff&quot;,
    &quot;purple&quot;: &quot;#df95ff&quot;,
    &quot;cyan&quot;: &quot;#86cbfe&quot;,
    &quot;white&quot;: &quot;#ffffff&quot;,
    &quot;brightBlack&quot;: &quot;#000000&quot;,
    &quot;brightRed&quot;: &quot;#ff8aa4&quot;,
    &quot;brightGreen&quot;: &quot;#21f6bc&quot;,
    &quot;brightYellow&quot;: &quot;#fff787&quot;,
    &quot;brightBlue&quot;: &quot;#1bccfd&quot;,
    &quot;brightPurple&quot;: &quot;#e6aefe&quot;,
    &quot;brightCyan&quot;: &quot;#99d6fc&quot;,
    &quot;brightWhite&quot;: &quot;#ffffff&quot;,
    &quot;background&quot;: &quot;#332a57&quot;,
    &quot;foreground&quot;: &quot;#e5e5e5&quot;
    }
    ],

        // Add any keybinding overrides to this array.
        // To unbind a default keybinding, set the command to &quot;unbound&quot;
        &quot;keybindings&quot;: [],
        &quot;actions&quot;:
        [
            // Copy and paste are bound to Ctrl+Shift+C and Ctrl+Shift+V in your defaults.json.
            // These two lines additionally bind them to Ctrl+C and Ctrl+V.
            // To learn more about selection, visit https://aka.ms/terminal-selection
            { &quot;command&quot;: {&quot;action&quot;: &quot;copy&quot;, &quot;singleLine&quot;: false }, &quot;keys&quot;: &quot;ctrl+c&quot; },
            { &quot;command&quot;: &quot;paste&quot;, &quot;keys&quot;: &quot;ctrl+v&quot; },

            // Press Ctrl+Shift+F to open the search box
            { &quot;command&quot;: &quot;find&quot;, &quot;keys&quot;: &quot;ctrl+f&quot; },
            // settings
            { &quot;command&quot;: &quot;openSettings&quot;, &quot;keys&quot;: &quot;ctrl+'&quot; },
            // Press Alt+Shift+D to open a new pane.
            // - &quot;split&quot;: &quot;auto&quot; makes this pane open in the direction that provides the most surface area.
            // - &quot;splitMode&quot;: &quot;duplicate&quot; makes the new pane use the focused pane's profile.
            // To learn more about panes, visit https://aka.ms/terminal-panes
            { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;auto&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; }, &quot;keys&quot;: &quot;alt+shift+d&quot; },
            { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;vertical&quot; }, &quot;keys&quot;: &quot;ctrl+plus&quot; },
            { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;horizontal&quot; }, &quot;keys&quot;: &quot;ctrl+-&quot; },
            { &quot;command&quot;: &quot;closePane&quot;, &quot;keys&quot;: &quot;ctrl+w&quot; }
        ]
    }
</code></pre>
<h1 id="wsl2附着在选项卡">WSL2(附着在选项卡)</h1>
<ol>
<li>
<p>启用WSL(用PowerShell替代手动启用),（可稍后重启，继续下面）</p>
<pre><code> dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
</code></pre>
</li>
<li>
<p>启用虚拟机功能（这部结束后，需要重启）</p>
<pre><code> dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
</code></pre>
</li>
<li>
<p>下载 X64 WSL2 更新包，并双击安装<br>
<a href="https://docs.microsoft.com/zh-cn/windows/wsl/install-win10#step-4---download-the-linux-kernel-update-package">WSL2更新包地址</a></p>
</li>
<li>
<p>将WSL2设置为默认版本</p>
<pre><code> wsl --set-default-version 2
</code></pre>
</li>
<li>
<p>MIcrosoft Store 安装 Ubuntu20 LTS</p>
</li>
<li>
<p>可以在 Windows Terminal 选项卡打开，也可直接打开Ubuntu</p>
</li>
<li>
<p>Win Terminal 输入 wsl 即可进入 Ubuntu,</p>
</li>
<li>
<p>换源</p>
<pre><code>cp -a /etc/apt/sources.list /etc/apt/sources.list.bak

 sudo sed -i &quot;s@http://.*archive.ubuntu.com@http://mirrors.huaweicloud.com@g&quot; /etc/apt/sources.list
 sudo sed -i &quot;s@http://.*security.ubuntu.com@http://mirrors.huaweicloud.com@g&quot; /etc/apt/sources.list
 
 sudo apt-get update
</code></pre>
</li>
</ol>
<h2 id="查看wsl版本信息与运行状态">查看WSL版本信息与运行状态</h2>
<pre><code>wsl -l -v
</code></pre>
<h1 id="安装scoop并非sqoop">安装Scoop(并非Sqoop...)</h1>
<h3 id="作用">作用</h3>
<pre><code>主要用在 单个纯 Windows Terminal  去安装 Linux工具使用。
但我发现 Win Terminal 的一些基础命令 还是没Linux好用（比如 ls无选项看不到隐藏文件）

所以我最后选择了 Win Terminal + WSL2 并用
所以Scoop这项就可以不用了
</code></pre>
<h3 id="流程">流程</h3>
<p>因为用Powershell命令，会访问到raw.githubusercontent.com，所以先修改DNS</p>
<pre><code>C:\Windows\System32\drivers\etc
    199.232.68.133 raw.githubusercontent.com
ipconfig /flushdns
</code></pre>
<p>用Powershell命令正式安装Scoop:</p>
<pre><code>Set-ExecutionPolicy RemoteSigned -scope CurrentUser
iwr -useb get.scoop.sh | iex
</code></pre>
<p>静待Scoop安装完成， 用Scoop安装 Unix工具：</p>
<pre><code>scoop install sudo
</code></pre>
<p>加速 Scoop的下载</p>
<pre><code>scoop install aria2
</code></pre>
<p>Scoop 使用 Git 更新它自身，所以安一个Git 是需要的。</p>
<pre><code>scoop install git
</code></pre>
<p>卸载语法</p>
<pre><code>scoop uninstall  xxxx
</code></pre>
<h1 id="三方桌面程序">三方桌面程序</h1>
<p>Winstep Xtreme 18.0+ (含 workshelf + NextStart)</p>
<h1 id="三方-file-explorer">三方 File Explorer</h1>
<p>RX 文件管理器</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PY => 音声合成]]></title>
        <id>https://cythonlin.github.io/post/py-greater-yin-sheng-he-cheng/</id>
        <link href="https://cythonlin.github.io/post/py-greater-yin-sheng-he-cheng/">
        </link>
        <updated>2020-10-12T12:20:17.000Z</updated>
        <content type="html"><![CDATA[<h1 id="背景">背景</h1>
<p>音声合成 基于 很久之前写的文章 <a href="https://www.cklin.top/post/py-greater-yin-sheng-fen-chi/">音声分离</a><br>
一些 Light Music 的 Electronic Drum 太吵了。<br>
于是突发奇想，如何  N v 1 分离出 Drum 并且 Drop</p>
<h1 id="音声分离更新为5stems-16khz-model">音声分离（更新为5stems-16kHz Model）</h1>
<p>2stems (vocals / accompaniment)</p>
<pre><code>spleeter separate  -o audio_output -i audio_example.mp3
</code></pre>
<p>4stems (vocals / bass / drums / other )</p>
<pre><code>spleeter separate -o audio_output -p spleeter:4stems  -i audio_example.mp3
</code></pre>
<p>5stems (vocals / bass / drums / piano / other)</p>
<pre><code>spleeter separate -o audio_output -p spleeter:5stems-16kHz -i audio_example.mp3
</code></pre>
<p>这次用的是 5stems预训练模型， 得到了如下5个文件：</p>
<pre><code>bass.wav
drums.wav
other.wav
piano.wav
vocals.wav
</code></pre>
<h1 id="寻找解决方案">寻找解决方案</h1>
<p>最开始不知道从何搜起，后来直接索性Github贴了一个 <a href="https://github.com/deezer/spleeter/issues/506">Question Issues</a>。<br>
有人给出stack的<a href="https://stackoverflow.com/questions/14498539/how-to-overlay-downmix-two-audio-files-using-ffmpeg">解决方案</a>， 个人简化使用如下：</p>
<pre><code>ffmpeg -i other.wav -i vocals.wav -i bass.wav -i piano.wav -filter_complex amix=inputs=4:duration=longest output.mp3
</code></pre>
<h1 id="结果">结果</h1>
<p>最终成功把 Electronic Drum 声 Drop。<br>
唯一美中不足的就是，5个Stems预训练模型分的不够细致, Github Wiki最新方案的就是5stems~</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PY => K8S（未完待续）]]></title>
        <id>https://cythonlin.github.io/post/py-greater-k8s/</id>
        <link href="https://cythonlin.github.io/post/py-greater-k8s/">
        </link>
        <updated>2020-10-06T22:18:23.000Z</updated>
        <content type="html"><![CDATA[<h1 id="安装">安装</h1>
<p>官档： <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/</a><br>
官档中的镜像时Google的，需要换成阿里源。</p>
<h3 id="ubuntu">Ubuntu</h3>
<pre><code>apt-get update &amp;&amp; apt-get install -y apt-transport-https

curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 

cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF

apt-get update
apt-get install -y kubelet kubeadm kubectl
</code></pre>
<h3 id="centos">CentOS</h3>
<pre><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

setenforce 0
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet &amp;&amp; systemctl start kubelet</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PY => Github-Cli]]></title>
        <id>https://cythonlin.github.io/post/py-greater-github-cli-quan-tao/</id>
        <link href="https://cythonlin.github.io/post/py-greater-github-cli-quan-tao/">
        </link>
        <updated>2020-10-03T01:53:58.000Z</updated>
        <content type="html"><![CDATA[<h1 id="下载">下载</h1>
<p>选个OS版本（我用的Win）：<a href="https://github.com/cli/cli/releases">https://github.com/cli/cli/releases  </a></p>
<h1 id="列出配置">列出配置</h1>
<pre><code>git config --list
</code></pre>
<p>由于我github2个号切换，导致，push的时候有403错误混淆，<br>
所以删除了家目录的 .gitconfig(应该是这个有些记不清了)</p>
<h1 id="设置代理">设置代理</h1>
<p>为了加速clone，这里先设置，若没有PROXY, 那此步可略过</p>
<pre><code>git config --global http.proxy &quot;socks5://127.0.0.1:7890&quot;
git config --global https.proxy &quot;socks5://127.0.0.1:7890&quot;
</code></pre>
<p>清除代理也很简单</p>
<pre><code>git config --global --unset http.proxy
git config --global --unset https.proxy
</code></pre>
<h1 id="设置ssh-key">设置SSH Key</h1>
<h3 id="说明">说明</h3>
<pre><code>如果你不习惯用SSH，而是习惯用HTTP的方式，那这步可省
</code></pre>
<h3 id="生成密钥命令">生成密钥命令</h3>
<pre><code>ssh-keygen
</code></pre>
<p>进入用户家目录，把id_rsa.pub公钥复制出来<br>
粘贴到-&gt; <a href="https://github.com/settings/ssh/">https://github.com/settings/ssh/new</a></p>
<h1 id="登录">登录</h1>
<pre><code>gh auth login
</code></pre>
<p>提前声明，遇到选项，都是用上下箭头选择<br>
第1个选项： 选择Github.com（也就是个人用户）<br>
第2个选项：选择 Login with a web browser<br>
Command中会给一串代码，复制代码-&gt;CMD回车-&gt;自动跳转到Web-&gt;粘贴代码-&gt;确认-&gt;确认授权</p>
<pre><code>这里也可以选择使用 Token 代替 web browser。但是这种方式需要生成一个Token
生成URL如下：
:  -&gt;   https://github.com/settings/tokens

点击 Generate bew token ，新建一个新 token：
    注意： 需要把 repo的所有权限勾上
               外加一个admin:org下面的  read:org  选项
    温馨提示：  read:org  必须勾上，不然创建失败。
</code></pre>
<p>第3个选项：选择SSH（HTTPS也可以）</p>
<h3 id="查看登录状态">查看登录状态</h3>
<pre><code>gh auth status
</code></pre>
<h3 id="退出登录">退出登录</h3>
<pre><code>gh auth logout
</code></pre>
<h1 id="仓库">仓库</h1>
<h3 id="创建仓库">创建仓库</h3>
<pre><code>gh repo create my-gh
    -&gt; Public
    -&gt; xxx  in your current directory（Y/N） y   (回车默认就是yes，下同)
    -&gt; Create a local project directory for xxx （Y/N）y
</code></pre>
<h3 id="查看远程权限">查看远程权限</h3>
<pre><code>git remote -v
    origin  https://github.com/Cythonlin/my-gh.git (fetch)
    origin  https://github.com/Cythonlin/my-gh.git (push)
</code></pre>
<h3 id="克隆">克隆</h3>
<pre><code>gh repo clone gin-gonic/gin
cd gin
git remote -v
    origin  https://github.com/gin-gonic/gin.git (fetch)
    origin  https://github.com/gin-gonic/gin.git (push)
    # 我们可以发现，这分支并不是我们的自己的
    # 所以我们可以 fork 下来
</code></pre>
<h3 id="fork">fork</h3>
<p>fork 指的是，把克隆到自己的仓库，作为上游（upstream）项目，然后自己就可自由同步它</p>
<pre><code>cd gin  # 上面已经进此路径，这步可省
gh repo fork
    -&gt; Would you like to add a remote for the fork? (Y/n) 回车yes
</code></pre>
<p>上面是先clone,然后进入路径，再fork<br>
如果事先未clone， 也可以用gh repo fork + 用户名/仓库名， 直接 fork+clone一步到位</p>
<pre><code># 这就不需要像上面先 cd进入clone的目录下再fork了，这种方式直接fork即可
gh repo fork pytorch/pytorch
</code></pre>
<h1 id="gist">Gist</h1>
<p>gist是github分享数据内容的平台 -&gt; <a href="https://gist.github.com/">https://gist.github.com/</a><br>
上面的地址可以分享公有/私有的文件，创建上传后，Github会跳转生成一个链接，来给我们使用</p>
<h3 id="github-cli实现gist">github-cli实现Gist</h3>
<p>默认是私有的，命令如下：</p>
<pre><code>gh gist create 1.txt
</code></pre>
<p>公有命令如下：</p>
<pre><code>gh gist create 1.txt --public
</code></pre>
<p>二者都会生成个URL，即可访问。<br>
也可以一个gist中存2个文件：</p>
<pre><code>gh gist create 1.txt 2.txt
</code></pre>
<h3 id="修改-gist共享的文件参数为生成url的尾部路径参数">修改 Gist共享的文件，参数为生成url的尾部路径参数</h3>
<pre><code>gh gist edit 5ff497631f0cc1e0a4463079a6a9eeff
</code></pre>
<h3 id="列出-上传过的gist文件-public代表公有文件-secret私有-不加参数代表所有">列出 上传过的Gist文件, --public代表公有文件，--secret私有, 不加参数代表所有</h3>
<pre><code>gh gist list
gh gist list --secret  
gh gist list --public
</code></pre>
<h1 id="pr-pull-request">PR (Pull Request）</h1>
<h2 id="pr概念">PR概念</h2>
<p>&quot;我fork了你们的代码，现在我发送一个请求，请你们回收我的代码&quot;😂</p>
<h2 id="pr流程">PR流程</h2>
<ol>
<li>fork别人仓库（先fork在clone， 前面已经提到 gh 可以直接fork一步到位了）</li>
<li>切换分支（也可以在 master 下），add,commit,push 修改代码。</li>
<li>在你fork后的仓库主页点击右上角的 Compare &amp; pull request 提交合并申请</li>
<li>等待别人合并你的请求</li>
</ol>
<h2 id="实验流程">实验流程</h2>
<h3 id="一-用当前的号去-fork另一个号另外那个也是自己的号方便做实验的仓库">一、用当前的号，去 fork另一个号（另外那个也是自己的号方便做实验）的仓库。</h3>
<pre><code>gh repo fork hacker-lin/bio2bioes
cd bio2bioes
</code></pre>
<h3 id="二-创建切换分支addcommitpushadd">二、 创建+切换分支+add+commit+push+add</h3>
<pre><code>git checkout -b dev
echo 111 &gt; 1.txt
git add . &amp;&amp; git commit -m &quot;my_test&quot; 
到这里即可，先不要push（下面PR创建的过程，会自动帮我们push，这里push我试了会出错）
</code></pre>
<h3 id="三-用github-cli命令-代替-点击compare-pull-request-按钮提交合并申请">三、用GitHUB-Cli命令 代替 点击Compare &amp; pull request 按钮提交合并申请</h3>
<p>创建PR</p>
<pre><code>gh pr create
     -&gt; Where should we push the 'dev' branch # 选第一个
     -&gt; Title  # 随便写个  some update
     -&gt; Body # 直接 回车 跳过就行。
     -&gt; What's next? # 选 Submit  提交即可 
</code></pre>
<p>列出提交的PR</p>
<pre><code>gh pr list 
# 执行后，你会发现 PR信息， # 后面的数字记住下面Closed和diff用得到
</code></pre>
<p>Merge PR</p>
<pre><code>gh pr merge
    -&gt; What merge method would you like to use # Create a merge commit即可
</code></pre>
<p>Closed PR</p>
<pre><code>gh pr close 3
# 这个3 就是上面 gh pr list 的结果
</code></pre>
<p>比较 PR 信息</p>
<pre><code>gh pr diff 3
# 最下面是最新的
</code></pre>
<p>查看 PR 详细信息</p>
<pre><code>gh pr status
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GO => 交换元素的四种方式]]></title>
        <id>https://cythonlin.github.io/post/go-greater-jiao-huan-yuan-su-de-si-chong-fang-shi/</id>
        <link href="https://cythonlin.github.io/post/go-greater-jiao-huan-yuan-su-de-si-chong-fang-shi/">
        </link>
        <updated>2020-09-29T04:22:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="python-and-go">Python and Go</h1>
<p>下面代码，除了数据声明与定义，其他Py 和 Go 的语法都是一摸一样的（主要强调 异或方式）<br>
a := 1<br>
b := 3</p>
<h3 id="方式0">方式0</h3>
<pre><code>c := 0
c = a
a = b
b = c
</code></pre>
<h3 id="方式1">方式1</h3>
<pre><code>a,b = b,a
</code></pre>
<h3 id="方式2">方式2</h3>
<pre><code>a = a + b
b = a - b
a = a - b
</code></pre>
<h3 id="方式3-注必须是整形-py也一样">方式3 （注：必须是整形， Py也一样）</h3>
<pre><code>a = a ^ b
b = a ^ b
a = a ^ b

fmt.Println(a)
fmt.Println(b)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[RS => 推荐系统（三）离线召回与排序 ]]></title>
        <id>https://cythonlin.github.io/post/rs-greater-tui-jian-xi-tong-san-chi-xian-zhao-hui-yu-pai-xu/</id>
        <link href="https://cythonlin.github.io/post/rs-greater-tui-jian-xi-tong-san-chi-xian-zhao-hui-yu-pai-xu/">
        </link>
        <updated>2020-09-29T04:21:44.000Z</updated>
        <content type="html"><![CDATA[<h1 id="召回设计">召回设计</h1>
<h3 id="召回排序流程">召回排序流程</h3>
<h4 id="匿名用户">匿名用户：</h4>
<pre><code>通常使用用户冷启动方案，区别在于user_id为匿名用户手机识别号(黑马头条不允许匿名用户)
所有只正针对于登录用户：
</code></pre>
<h4 id="用户冷启动前期点击行为较少情况">用户冷启动（前期点击行为较少情况）</h4>
<p>非个性化推荐<br>
热门召回：自定义热门规则，根据当前时间段热点定期更新维护人点文章库<br>
新文章召回：为了提高新文章的曝光率，建立新文章库，进行推荐<br>
个性化推荐：<br>
基于内容的协同过滤在线召回：基于用户实时兴趣画像相似的召回结果用于首页的个性化推荐</p>
<h4 id="后期离线部分用户点击行为较多用户画像完善">后期离线部分（用户点击行为较多，用户画像完善）</h4>
<p>建立用户长期兴趣画像（详细）：包括用户各个维度的兴趣特征<br>
训练排序模型<br>
LR模型、FTRL、Wide&amp;Deep<br>
离线部分的召回：<br>
基于模型协同过滤推荐离线召回：ALS<br>
基于内容的离线召回：或者称基于用户画像的召回</p>
<h3 id="召回表设计与模型召回">召回表设计与模型召回</h3>
<h4 id="召回表设计">召回表设计</h4>
<p>我们的召回方式有很多种。<br>
多路召回结果存储模型召回 与 内容召回的结果 需要进行相应频道推荐合并。<br>
方案：基于模型与基于内容的召回结果存入同一张表，避免多张表进行读取处理<br>
由于HBASE有多个版本数据功能存在的支持<br>
TTL=&gt;7776000, VERSIONS=&gt;999999<br>
如下：<br>
create 'cb_recall', {NAME=&gt;'als', TTL=&gt;7776000, VERSIONS=&gt;999999}<br>
alter 'cb_recall', {NAME=&gt;'content', TTL=&gt;7776000, VERSIONS=&gt;999999}<br>
alter 'cb_recall', {NAME=&gt;'online', TTL=&gt;7776000, VERSIONS=&gt;999999}</p>
<pre><code># 例子（多版本）：
put 'cb_recall', 'recall:user:5', 'als:1',[45,3,5,10]
put 'cb_recall', 'recall:user:5', 'als:1',[289,11,65,52,109,8]
put 'cb_recall', 'recall:user:5', 'als:2',[1,2,3,4,5,6,7,8,9,10]
put 'cb_recall', 'recall:user:2', 'content:1',[45,3,5,10,289,11,65,52,109,8]
put 'cb_recall', 'recall:user:2', 'content:2',[1,2,3,4,5,6,7,8,9,10]


hbase(main):084:0&gt; desc 'cb_recall'
Table cb_recall is ENABLED                                                                             
cb_recall                                                                                              
COLUMN FAMILIES DESCRIPTION                                                                            
{NAME =&gt; 'als', VERSIONS =&gt; '999999', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'false'
, KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; 
'7776000 SECONDS (90 DAYS)', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', CACHE
_INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS_ON_
OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'}                    
{NAME =&gt; 'content', VERSIONS =&gt; '999999', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'fa
lse', KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL
          =&gt; '7776000 SECONDS (90 DAYS)', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', C
ACHE_INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS
_ON_OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'}                
{NAME =&gt; 'online', VERSIONS =&gt; '999999', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'fal
se', KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL 
=&gt; '7776000 SECONDS (90 DAYS)', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', CA
CHE_INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS_
ON_OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'}                 
3 row(s)	
</code></pre>
<p>（几乎不用）在HIVE用户数据数据库下建立HIVE外部表,若hbase表有修改，则进行HIVE 表删除更新<br>
create external table cb_recall_hbase(<br>
user_id STRING comment &quot;userID&quot;,<br>
als map&lt;string, ARRAY<BIGINT>&gt; comment &quot;als recall&quot;,<br>
content map&lt;string, ARRAY<BIGINT>&gt; comment &quot;content recall&quot;,<br>
online map&lt;string, ARRAY<BIGINT>&gt; comment &quot;online recall&quot;)<br>
COMMENT &quot;user recall table&quot;<br>
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'<br>
WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,als:,content:,online:&quot;)<br>
TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;cb_recall&quot;);</p>
<h4 id="增加一个历史召回结果表">增加一个历史召回结果表</h4>
<pre><code>create 'history_recall', {NAME=&gt;'channel', TTL=&gt;7776000, VERSIONS=&gt;999999}

put 'history_recall', 'recall:user:5', 'als:1',[1,2,3]
put 'history_recall', 'recall:user:5', 'als:1',[4,5,6,7]
put 'history_recall', 'recall:user:5', 'als:1',[8,9,10]
</code></pre>
<p>为什么增加历史召回表？<br>
1、直接在存储召回结果部分进行过滤，比之后排序过滤，节省排序时间<br>
2、防止Redis缓存没有消耗完，造成重复推荐，从源头进行过滤</p>
<h3 id="基于模型召回集合计算">基于模型召回集合计算</h3>
<h4 id="als模型推荐实现">ALS模型推荐实现</h4>
<p>步骤：<br>
1、数据类型转换,clicked以及用户ID与文章ID处理<br>
2、ALS模型训练以及推荐<br>
3、推荐结果解析处理<br>
4、推荐结果存储<br>
数据类型转换,clicked( bool 转 int)<br>
ur.spark.sql(&quot;use profile&quot;)<br>
user_article_click = ur.spark.sql(&quot;select * from user_article_basic&quot;).<br>
select(['user_id', 'article_id', 'clicked'])<br>
# 更换类型<br>
def change_types(row):<br>
return row.user_id, row.article_id, int(row.clicked)</p>
<pre><code>user_article_click = user_article_click.rdd.map(change_types).toDF(['user_id', 'article_id', 'clicked'])
</code></pre>
<p>这步处理结果格式如下：<br>
user_id	article_id	clicked<br>
0<br>
1<br>
用户ID与文章ID处理，编程ID索引（原用户ID和文章ID是长字符串，ALS模型不能处理，要重新编排ID索引）<br>
from pyspark.ml.feature import StringIndexer<br>
from pyspark.ml import Pipeline<br>
# 用户和文章ID超过ALS最大整数值，需要使用StringIndexer进行转换<br>
user_id_indexer = StringIndexer(inputCol='user_id', outputCol='als_user_id')<br>
article_id_indexer = StringIndexer(inputCol='article_id', outputCol='als_article_id')<br>
pip = Pipeline(stages=[user_id_indexer, article_id_indexer])<br>
pip_fit = pip.fit(user_article_click)<br>
als_user_article_click = pip_fit.transform(user_article_click)<br>
ALS 模型训练与推荐（ALS模型需要输出用户ID列，文章ID列以及点击列）<br>
from pyspark.ml.recommendation import ALS<br>
# 模型训练和推荐默认每个用户固定文章个数<br>
als = ALS(userCol='als_user_id', itemCol='als_article_id', ratingCol='clicked', checkpointInterval=1)<br>
model = als.fit(als_user_article_click)<br>
recall_res = model.recommendForAllUsers(100)<br>
结果：<br>
als_user_id	recommendations<br>
1			[[article_id, 分数]]</p>
<h4 id="推荐结果处理">推荐结果处理</h4>
<p>通过StringIndexer变换后的下标知道原来的和用户ID<br>
# recall_res得到需要使用StringIndexer变换后的下标<br>
# 保存原来的下表映射关系<br>
refection_user = als_user_article_click.groupBy(['user_id']).max('als_user_id').withColumnRenamed(<br>
'max(als_user_id)', 'als_user_id')<br>
refection_article = als_user_article_click.groupBy(['article_id']).max('als_article_id').withColumnRenamed(<br>
'max(als_article_id)', 'als_article_id')</p>
<pre><code># Join推荐结果与 refection_user映射关系表
# +-----------+--------------------+-------------------+
# | als_user_id | recommendations | user_id |
# +-----------+--------------------+-------------------+
# | 8 | [[163, 0.91328144]... | 2 |
 # | 0 | [[145, 0.653115], ... | 1106476833370537984 |
 
recall_res = recall_res.join(refection_user, on=['als_user_id'], how='left').select(
['als_user_id', 'recommendations', 'user_id'])
</code></pre>
<p>对推荐文章ID后处理：得到推荐列表,获取推荐列表中的ID索引<br>
# Join推荐结果与 refection_article映射关系表<br>
# +-----------+-------+----------------+<br>
# | als_user_id | user_id | als_article_id |<br>
# +-----------+-------+----------------+<br>
# | 8 | 2 | [163, 0.91328144] |<br>
# | 8 | 2 | [132, 0.91328144] |<br>
import pyspark.sql.functions as F<br>
recall_res = recall_res.withColumn('als_article_id', F.explode('recommendations')).drop('recommendations')</p>
<pre><code># +-----------+-------+--------------+
# | als_user_id | user_id | als_article_id |
# +-----------+-------+--------------+
# | 8 | 2 | 163 |
# | 8 | 2 | 132 |
def _article_id(row):
	return row.als_user_id, row.user_id, row.als_article_id[0]
</code></pre>
<p>进行索引对应文章ID获取<br>
als_recall = recall_res.rdd.map(_article_id).toDF(['als_user_id', 'user_id', 'als_article_id'])<br>
als_recall = als_recall.join(refection_article, on=['als_article_id'], how='left').select(<br>
['user_id', 'article_id'])<br>
# 得到每个用户ID 对应推荐文章<br>
# +-------------------+----------+<br>
# | user_id |				 article_id |<br>
# +-------------------+----------+<br>
# | 1106476833370537984 |   44075 |<br>
# | 1 | 					 44075 |<br>
获取每个文章对应的频道，推荐给用户时按照频道存储:<br>
ur.spark.sql(&quot;use toutiao&quot;)<br>
news_article_basic = ur.spark.sql(&quot;select article_id, channel_id from news_article_basic&quot;)</p>
<pre><code>als_recall = als_recall.join(news_article_basic, on=['article_id'], how='left')
als_recall = als_recall.groupBy(['user_id', 'channel_id']).agg(F.collect_list('article_id')).withColumnRenamed(
                    'collect_list(article_id)', 'article_list')

als_recall = als_recall.dropna()
</code></pre>
<h4 id="召回结果存储">召回结果存储</h4>
<p>HBASE表设计概览：<br>
put 'cb_recall', 'recall:user:5', 'als:1',[45,3,5,10,289,11,65,52,109,8]<br>
put 'cb_recall', 'recall:user:5', 'als:2',[1,2,3,4,5,6,7,8,9,10]<br>
存储代码如下：<br>
def save_offline_recall_hbase(partition):<br>
&quot;&quot;&quot;离线模型召回结果存储<br>
&quot;&quot;&quot;<br>
import happybase<br>
pool = happybase.ConnectionPool(size=10, host='hadoop-master', port=9090)<br>
for row in partition:<br>
with pool.connection() as conn:<br>
# 获取历史看过的该频道文章<br>
history_table = conn.table('history_recall')<br>
# 多个版本<br>
data = history_table.cells('reco:his:{}'.format(row.user_id).encode(),<br>
'channel:{}'.format(row.channel_id).encode())</p>
<pre><code>            history = []
            if len(data) &gt;= 2:
                for l in data[:-1]:
                    history.extend(eval(l))
            else:
                history = []

            # 过滤reco_article与history
            reco_res = list(set(row.article_list) - set(history))

            if reco_res:

                table = conn.table('cb_recall')
                # 默认放在推荐频道
                table.put('recall:user:{}'.format(row.user_id).encode(),
                          {'als:{}'.format(row.channel_id).encode(): str(reco_res).encode()})

                # 放入历史推荐过文章
                history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(),
                                  {'channel:{}'.format(row.channel_id): str(reco_res).encode()})
            conn.close()

als_recall.foreachPartition(save_offline_recall_hbase)
</code></pre>
<h3 id="离线用户基于内容召回集">离线用户基于内容召回集</h3>
<p>目标<br>
知道离线内容召回的概念<br>
知道如何进行内容召回计算存储规则<br>
应用<br>
应用spark完成离线用户基于内容的协同过滤推荐</p>
<h4 id="基于内容召回实现文章向量之前已经弄好了">基于内容召回实现（文章向量之前已经弄好了）</h4>
<p>过滤用户点击的文章<br>
# 基于内容相似召回（画像召回）<br>
ur.spark.sql(&quot;use profile&quot;)<br>
user_article_basic = self.spark.sql(&quot;select * from user_article_basic&quot;)<br>
user_article_basic = user_article_basic.filter(&quot;clicked=True&quot;)</p>
<pre><code>def save_content_filter_history_to__recall(partition):
    &quot;&quot;&quot;计算每个用户的每个操作文章的相似文章，过滤之后，写入content召回表当中（支持不同时间戳版本）
    &quot;&quot;&quot;
    import happybase
    pool = happybase.ConnectionPool(size=10, host='hadoop-master')

    # 进行为相似文章获取
    with pool.connection() as conn:

        # key:   article_id,    column:  similar:article_id
        similar_table = conn.table('article_similar')
        # 循环partition
        for row in partition:
            # 获取相似文章结果表
            similar_article = similar_table.row(str(row.article_id).encode(),
                                                columns=[b'similar'])
            # 相似文章相似度排序过滤，召回不需要太大的数据， 百个，千
            _srt = sorted(similar_article.items(), key=lambda item: item[1], reverse=True)
            if _srt:
                # 每次行为推荐10篇文章
                reco_article = [int(i[0].split(b':')[1]) for i in _srt][:10]

                # 获取历史看过的该频道文章
                history_table = conn.table('history_recall')
                # 多个版本
                data = history_table.cells('reco:his:{}'.format(row.user_id).encode(),
                                           'channel:{}'.format(row.channel_id).encode())

                history = []
                if len(data) &gt;= 2:
                    for l in data[:-1]:
                        history.extend(eval(l))
                else:
                    history = []

                # 过滤reco_article与history
                reco_res = list(set(reco_article) - set(history))

                # 进行推荐，放入基于内容的召回表当中以及历史看过的文章表当中
                if reco_res:
                    # content_table = conn.table('cb_content_recall')
                    content_table = conn.table('cb_recall')
                    content_table.put(&quot;recall:user:{}&quot;.format(row.user_id).encode(),
                                      {'content:{}'.format(row.channel_id).encode(): str(reco_res).encode()})

                    # 放入历史推荐过文章
                    history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(),
                                      {'channel:{}'.format(row.channel_id).encode(): str(reco_res).encode()})

        conn.close()

user_article_basic.foreachPartition(save_content_filter_history_to__recall)
</code></pre>
<h3 id="离线用户召回定时更新">离线用户召回定时更新</h3>
<h4 id="定时更新代码">定时更新代码</h4>
<pre><code>import os
import sys
# 如果当前代码文件运行测试需要加入修改路径，否则后面的导包出现问题
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(BASE_DIR))
from pyspark.ml.feature import StringIndexer
from pyspark.ml import Pipeline

from pyspark.ml.recommendation import ALS
from offline import SparkSessionBase
from datetime import datetime
import time
import numpy as np


class UpdateRecall(SparkSessionBase):

    SPARK_APP_NAME = &quot;updateRecall&quot;
    ENABLE_HIVE_SUPPORT = True

    def __init__(self, number):

        self.spark = self._create_spark_session()
        self.N = number

    def update_als_recall(self):
        &quot;&quot;&quot;
        更新基于模型（ALS）的协同过滤召回集
        :return:
        &quot;&quot;&quot;
        # 读取用户行为基本表
        self.spark.sql(&quot;use profile&quot;)
        user_article_click = self.spark.sql(&quot;select * from user_article_basic&quot;).\
            select(['user_id', 'article_id', 'clicked'])

        # 更换类型
        def change_types(row):
            return row.user_id, row.article_id, int(row.clicked)

        user_article_click = user_article_click.rdd.map(change_types).toDF(['user_id', 'article_id', 'clicked'])
        # 用户和文章ID超过ALS最大整数值，需要使用StringIndexer进行转换
        user_id_indexer = StringIndexer(inputCol='user_id', outputCol='als_user_id')
        article_id_indexer = StringIndexer(inputCol='article_id', outputCol='als_article_id')
        pip = Pipeline(stages=[user_id_indexer, article_id_indexer])
        pip_fit = pip.fit(user_article_click)
        als_user_article_click = pip_fit.transform(user_article_click)

        # 模型训练和推荐默认每个用户固定文章个数
        als = ALS(userCol='als_user_id', itemCol='als_article_id', ratingCol='clicked', checkpointInterval=1)
        model = als.fit(als_user_article_click)
        recall_res = model.recommendForAllUsers(self.N)

        # recall_res得到需要使用StringIndexer变换后的下标
        # 保存原来的下表映射关系
        refection_user = als_user_article_click.groupBy(['user_id']).max('als_user_id').withColumnRenamed(
            'max(als_user_id)', 'als_user_id')
        refection_article = als_user_article_click.groupBy(['article_id']).max('als_article_id').withColumnRenamed(
            'max(als_article_id)', 'als_article_id')

        # Join推荐结果与 refection_user映射关系表
        # +-----------+--------------------+-------------------+
        # | als_user_id | recommendations | user_id |
        # +-----------+--------------------+-------------------+
        # | 8 | [[163, 0.91328144]... | 2 |
        #        | 0 | [[145, 0.653115], ... | 1106476833370537984 |
        recall_res = recall_res.join(refection_user, on=['als_user_id'], how='left').select(
            ['als_user_id', 'recommendations', 'user_id'])

        # Join推荐结果与 refection_article映射关系表
        # +-----------+-------+----------------+
        # | als_user_id | user_id | als_article_id |
        # +-----------+-------+----------------+
        # | 8 | 2 | [163, 0.91328144] |
        # | 8 | 2 | [132, 0.91328144] |
        import pyspark.sql.functions as F
        recall_res = recall_res.withColumn('als_article_id', F.explode('recommendations')).drop('recommendations')

        # +-----------+-------+--------------+
        # | als_user_id | user_id | als_article_id |
        # +-----------+-------+--------------+
        # | 8 | 2 | 163 |
        # | 8 | 2 | 132 |
        def _article_id(row):
            return row.als_user_id, row.user_id, row.als_article_id[0]

        als_recall = recall_res.rdd.map(_article_id).toDF(['als_user_id', 'user_id', 'als_article_id'])
        als_recall = als_recall.join(refection_article, on=['als_article_id'], how='left').select(
            ['user_id', 'article_id'])
        # 得到每个用户ID 对应推荐文章
        # +-------------------+----------+
        # | user_id | article_id |
        # +-------------------+----------+
        # | 1106476833370537984 | 44075 |
        # | 1 | 44075 |
        # 分组统计每个用户，推荐列表
        # als_recall = als_recall.groupby('user_id').agg(F.collect_list('article_id')).withColumnRenamed(
        #     'collect_list(article_id)', 'article_list')
        self.spark.sql(&quot;use toutiao&quot;)
        news_article_basic = self.spark.sql(&quot;select article_id, channel_id from news_article_basic&quot;)
        als_recall = als_recall.join(news_article_basic, on=['article_id'], how='left')
        als_recall = als_recall.groupBy(['user_id', 'channel_id']).agg(F.collect_list('article_id')).withColumnRenamed(
            'collect_list(article_id)', 'article_list')
        als_recall = als_recall.dropna()

        # 存储
        def save_offline_recall_hbase(partition):
            &quot;&quot;&quot;离线模型召回结果存储
            &quot;&quot;&quot;
            import happybase
            pool = happybase.ConnectionPool(size=10, host='hadoop-master', port=9090)
            for row in partition:
                with pool.connection() as conn:
                    # 获取历史看过的该频道文章
                    history_table = conn.table('history_recall')
                    # 多个版本
                    data = history_table.cells('reco:his:{}'.format(row.user_id).encode(),
                                               'channel:{}'.format(row.channel_id).encode())

                    history = []
                    if len(data) &gt;= 2:
                        for l in data[:-1]:
                            history.extend(eval(l))
                    else:
                        history = []

                    # 过滤reco_article与history
                    reco_res = list(set(row.article_list) - set(history))

                    if reco_res:

                        table = conn.table('cb_recall')
                        # 默认放在推荐频道
                        table.put('recall:user:{}'.format(row.user_id).encode(),
                                  {'als:{}'.format(row.channel_id).encode(): str(reco_res).encode()})
                        conn.close()

                        # 放入历史推荐过文章
                        history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(),
                                          {'channel:{}'.format(row.channel_id): str(reco_res).encode()})
                    conn.close()

        als_recall.foreachPartition(save_offline_recall_hbase)

    def update_content_recall(self):
        &quot;&quot;&quot;
        更新基于内容（画像）的推荐召回集, word2vec相似
        :return:
        &quot;&quot;&quot;
        # 基于内容相似召回（画像召回）
        ur.spark.sql(&quot;use profile&quot;)
        user_article_basic = self.spark.sql(&quot;select * from user_article_basic&quot;)
        user_article_basic = user_article_basic.filter(&quot;clicked=True&quot;)

        def save_content_filter_history_to__recall(partition):
            &quot;&quot;&quot;计算每个用户的每个操作文章的相似文章，过滤之后，写入content召回表当中（支持不同时间戳版本）
            &quot;&quot;&quot;
            import happybase
            pool = happybase.ConnectionPool(size=10, host='hadoop-master')

            # 进行为相似文章获取
            with pool.connection() as conn:

                # key:   article_id,    column:  similar:article_id
                similar_table = conn.table('article_similar')
                # 循环partition
                for row in partition:
                    # 获取相似文章结果表
                    similar_article = similar_table.row(str(row.article_id).encode(),
                                                        columns=[b'similar'])
                    # 相似文章相似度排序过滤，召回不需要太大的数据， 百个，千
                    _srt = sorted(similar_article.items(), key=lambda item: item[1], reverse=True)
                    if _srt:
                        # 每次行为推荐10篇文章
                        reco_article = [int(i[0].split(b':')[1]) for i in _srt][:10]

                        # 获取历史看过的该频道文章
                        history_table = conn.table('history_recall')
                        # 多个版本
                        data = history_table.cells('reco:his:{}'.format(row.user_id).encode(),
                                                   'channel:{}'.format(row.channel_id).encode())

                        history = []
                            if len(_history_data) &gt; 1:
                                for l in _history_data:
                                    history.extend(l)

                        # 过滤reco_article与history
                        reco_res = list(set(reco_article) - set(history))

                        # 进行推荐，放入基于内容的召回表当中以及历史看过的文章表当中
                        if reco_res:
                            # content_table = conn.table('cb_content_recall')
                            content_table = conn.table('cb_recall')
                            content_table.put(&quot;recall:user:{}&quot;.format(row.user_id).encode(),
                                              {'content:{}'.format(row.channel_id).encode(): str(reco_res).encode()})

                            # 放入历史推荐过文章
                            history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(),
                                              {'channel:{}'.format(row.channel_id).encode(): str(reco_res).encode()})

                conn.close()

        user_article_basic.foreachPartition(save_content_filter_history_to__recall)


if __name__ == '__main__':
    ur = UpdateRecall(500)
    ur.update_als_recall()
    ur.update_content_recall()
</code></pre>
<p>定时更新代码，在main.py和update.py中添加以下代码：<br>
from offline.update_recall import UpdateRecall<br>
from schedule.update_profile import update_user_profile, update_article_profile, update_recall</p>
<pre><code>def update_recall():
    &quot;&quot;&quot;
    更新用户的召回集
    :return:
    &quot;&quot;&quot;
    udp = UpdateRecall(200)
    udp.update_als_recall()
    udp.update_content_recall()
</code></pre>
<p>main中添加<br>
scheduler.add_job(update_recall, trigger='interval', hour=3)</p>
<h1 id="排序设计">排序设计</h1>
<h3 id="排序模型">排序模型</h3>
<p>宽模型 + 特征⼯程<br>
LR/MLR + 非ID类特征(⼈⼯离散/GBDT/FM)<br>
spark 中可以直接使用<br>
宽模型 + 深模型<br>
wide&amp;deep,DeepFM<br>
使用TensorFlow进行训练<br>
深模型：<br>
DNN + 特征embedding<br>
使用TensorFlow进行训练</p>
<h3 id="特征处理原则">特征处理原则</h3>
<p>离散数据<br>
one-hot编码<br>
连续数据<br>
归一化<br>
图片/文本<br>
文章标签/关键词提取<br>
embedding</p>
<h3 id="优化训练方式">优化训练方式</h3>
<p>使用Batch SGD优化<br>
加入正则化防止过拟合</p>
<h3 id="spark-lr-进行预估">spark LR 进行预估</h3>
<p>目的：通过LR模型进行CTR预估<br>
步骤：<br>
1、需要通过spark读取HIVE外部表，需要新的sparksession配置<br>
增加HBASE配置<br>
2、读取用户点击行为表，与用户画像和文章画像，构造训练样本<br>
3、LR模型进行训练<br>
4、LR模型预测、结果评估</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PY => HBase]]></title>
        <id>https://cythonlin.github.io/post/py-greater-hbase/</id>
        <link href="https://cythonlin.github.io/post/py-greater-hbase/">
        </link>
        <updated>2020-09-29T04:21:09.000Z</updated>
        <content type="html"><![CDATA[<h1 id="报错">报错</h1>
<p>若list 或其他命令 有如下错误：<br>
ERROR: org.apache.hadoop.hbase.PleaseHoldException: Master is initializing<br>
则使用如下命令：<br>
cd $HBASE_HOME/bin<br>
./hbase zkcli<br>
ls /<br>
rmr /hbase<br>
ls /<br>
退出 zookeeper cli， 删除hdfs中的 /hbase<br>
hdfs dfs -rm -r /hbase<br>
然后重启hbase:<br>
cd $HBASE_HOME/bin<br>
./stop-hbase.sh<br>
./start-hbase.sh<br>
若stop hbase的时候出现 ..... 停止不掉， 则：<br>
cd $HBASE_HOME/bin<br>
./hbase-daemons.sh stop regionserver</p>
<pre><code># ./start-hbase.sh
# kill -9 pid来终止hbase的进程
</code></pre>
<h1 id="hbase命令">HBase命令</h1>
<p>https://blog.csdn.net/vbirdbest/article/details/88236575</p>
]]></content>
    </entry>
</feed>