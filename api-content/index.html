{"posts":[{"title":"PR => Cheat.sh","content":"å›å¿† ç”±äºScoopå¯¹cheat.shæ”¯æŒä¸å‹å¥½ï¼Œæˆ‘å°±åˆæŠŠWSL2åŠ äº†è¿›æ¥ =&gt; WSL2+ZSH åŒæ—¶ä¹Ÿæ›´æ–°äº†æœ€æ–°çš„ä¸€æ¬¡ WTçš„é…ç½®æ–‡ä»¶ï¼Œå¦‚ä¸‹ï¼š // To view the default settings, hold &quot;alt&quot; while clicking on the &quot;Settings&quot; button. // For documentation on these settings, see: https://aka.ms/terminal-documentation { // å®˜æ–¹è®¾ç½®æŒ‡å—? &quot;$schema&quot;: &quot;https://aka.ms/terminal-profiles-schema&quot;, // ä¸€äº›globalsè®¾ç½® &quot;theme&quot;: &quot;dark&quot;, // çª—å£ä¸»é¢˜ // &quot;initialRows&quot;: 25, // &quot;initialCols&quot;: 100, &quot;launchMode&quot;: &quot;maximized&quot;, // å…¨å± // è®¾ç½®é»˜è®¤ç»ˆç«¯ // &quot;defaultProfile&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, // &quot;defaultProfile&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa610}1&quot;, &quot;defaultProfile&quot;: &quot;{574e775e-4f2a-5b96-ac1e-a2962a402336}&quot;, &quot;profiles&quot;: { &quot;defaults&quot;: { // Put settings here that you want to apply to all profiles &quot;colorScheme&quot;: &quot;Seafoam Pastel&quot;, &quot;useAcrylic&quot;: true, &quot;acrylicOpacity&quot;: 0.55, &quot;cursorShape&quot;: &quot;vintage&quot;, &quot;cursorHeight&quot;: 60, &quot;cursorColor&quot;: &quot;#B00C11&quot;, &quot;fontFace&quot;: &quot;Hack Nerd Font&quot;, &quot;fontSize&quot;: 18 }, &quot;list&quot;: [ { &quot;guid&quot;: &quot;{07b52e3e-de2c-5db4-bd2d-ba144ed6c273}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;UBT&quot;, &quot;source&quot;: &quot;Windows.Terminal.Wsl&quot;, &quot;startingDirectory&quot;: &quot;d:&quot; }, { &quot;guid&quot;: &quot;{e05f1426-9e28-4be3-8f2b-3e2b48eae4a8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;CON&quot;, &quot;commandline&quot;: &quot;%windir%//System32//cmd.exe \\&quot;\\/K\\&quot; D:/miniconda/Scripts/activate.bat D:/miniconda&quot;, &quot;startingDirectory&quot;: &quot;d:&quot; }, { &quot;guid&quot;: &quot;{574e775e-4f2a-5b96-ac1e-a2962a402336}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;PS7&quot;, &quot;source&quot;: &quot;Windows.Terminal.PowershellCore&quot;, &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;commandline&quot;: &quot;C://Program Files//PowerShell//7//pwsh.exe /nologo&quot;, // /nologo è¡¨ç¤ºåˆ é™¤ banner }, { // Make changes here to the cmd.exe profile &quot;guid&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa6101}&quot;, &quot;name&quot;: &quot;cmd&quot;, &quot;commandline&quot;: &quot;cmd.exe&quot;, &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;hidden&quot;: false }, { // Make changes here to the powershell.exe profile &quot;guid&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, &quot;name&quot;: &quot;PS5&quot;, &quot;commandline&quot;: &quot;PowerShell.exe /nologo&quot;, // /nologo è¡¨ç¤ºåˆ é™¤ banner &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;hidden&quot;: false }, // { // // Make changes here to the powershell.exe profile // &quot;guid&quot;: &quot;{7c0b0203-de8d-490d-9183-a9e245a83be1}&quot;, // &quot;name&quot;: &quot;PWSH&quot;, // &quot;commandline&quot;: &quot;C://Program Files//PowerShell//7//pwsh.exe /nologo&quot;, // /nologo è¡¨ç¤ºåˆ é™¤ banner // &quot;startingDirectory&quot;: &quot;d:&quot;, // &quot;hidden&quot;: false // }, { &quot;guid&quot;: &quot;{b453ae62-4e3d-5e58-b989-0a998ec441b8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;AWS&quot;, &quot;source&quot;: &quot;Windows.Terminal.Azure&quot; } // { // &quot;guid&quot;: &quot;{e05f1426-9e28-4be3-8f2b-3e2b48eae4a8}&quot;, // &quot;hidden&quot;: false, // &quot;name&quot;: &quot;ssh&quot;, // &quot;commandline&quot;: &quot;ssh root@127.0.0.1 -p 22&quot; // } ] }, // Add custom color schemes to this array &quot;schemes&quot;: [ { &quot;name&quot;: &quot;Seafoam Pastel&quot;, &quot;black&quot;: &quot;#000000&quot;, &quot;red&quot;: &quot;#ff7092&quot;, &quot;green&quot;: &quot;#00fbac&quot;, &quot;yellow&quot;: &quot;#fffa6a&quot;, &quot;blue&quot;: &quot;#00bfff&quot;, &quot;purple&quot;: &quot;#df95ff&quot;, &quot;cyan&quot;: &quot;#86cbfe&quot;, &quot;white&quot;: &quot;#ffffff&quot;, &quot;brightBlack&quot;: &quot;#000000&quot;, &quot;brightRed&quot;: &quot;#ff8aa4&quot;, &quot;brightGreen&quot;: &quot;#21f6bc&quot;, &quot;brightYellow&quot;: &quot;#fff787&quot;, &quot;brightBlue&quot;: &quot;#1bccfd&quot;, &quot;brightPurple&quot;: &quot;#e6aefe&quot;, &quot;brightCyan&quot;: &quot;#99d6fc&quot;, &quot;brightWhite&quot;: &quot;#ffffff&quot;, &quot;background&quot;: &quot;#332a57&quot;, &quot;foreground&quot;: &quot;#e5e5e5&quot; } ], // Add any keybinding overrides to this array. // To unbind a default keybinding, set the command to &quot;unbound&quot; &quot;keybindings&quot;: [], &quot;actions&quot;: [ // Copy and paste are bound to Ctrl+Shift+C and Ctrl+Shift+V in your defaults.json. // These two lines additionally bind them to Ctrl+C and Ctrl+V. // To learn more about selection, visit https://aka.ms/terminal-selection { &quot;command&quot;: {&quot;action&quot;: &quot;copy&quot;, &quot;singleLine&quot;: false }, &quot;keys&quot;: &quot;ctrl+c&quot; }, { &quot;command&quot;: &quot;paste&quot;, &quot;keys&quot;: &quot;ctrl+v&quot; }, // Press Ctrl+Shift+F to open the search box { &quot;command&quot;: &quot;find&quot;, &quot;keys&quot;: &quot;ctrl+f&quot; }, // settings { &quot;command&quot;: &quot;openSettings&quot;, &quot;keys&quot;: &quot;ctrl+'&quot; }, // Press Alt+Shift+D to open a new pane. // - &quot;split&quot;: &quot;auto&quot; makes this pane open in the direction that provides the most surface area. // - &quot;splitMode&quot;: &quot;duplicate&quot; makes the new pane use the focused pane's profile. // To learn more about panes, visit https://aka.ms/terminal-panes { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;auto&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; }, &quot;keys&quot;: &quot;alt+shift+d&quot; }, { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;vertical&quot; }, &quot;keys&quot;: &quot;ctrl+plus&quot; }, { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;horizontal&quot; }, &quot;keys&quot;: &quot;ctrl+-&quot; }, { &quot;command&quot;: &quot;closePane&quot;, &quot;keys&quot;: &quot;ctrl+w&quot; } ] } Cheat.sh -&gt; cheat.sh For Curl(å¯ä»¥ç”¨ä¸‹é¢Terminalä»£æ›¿) ç±»ä¼¼å¦‚ä¸‹è¯­æ³•ï¼š curl cht.sh/python/string+time Client windowsä¸‹è½½åˆ°æœ¬åœ°ä½¿ç”¨: scoop install cht ä½†æ˜¯è¿™ç§æ–¹å¼ä¸å¤ªè¡Œï¼Œå› ä¸ºæ˜¯scoopä¸‹è½½çš„æ˜¯ cht.exe è€Œé cht.sh å³ä½¿ä¸‹åˆ°äº†cht.shã€‚ BusyBoxæ˜¯ dashï¼Œè€Œé bashï¼Œä¸æ”¯æŒæ‰§è¡Œ.shè„šæœ¬ å³ä½¿ç”¨äº†çœŸçš„bashï¼ˆgit bash, gow è¿™äº›å·¥å…·ï¼Œä¹Ÿç¼ºä¾èµ–ï¼‰å¹¶ä¸”ä¸æ˜¯åœ¨powershellè¿è¡Œã€‚ æ‰€ä»¥æˆ‘è¿˜æ˜¯æ”¾å¼ƒäº†å·¥å…·åŒ–çš„æ–¹å¼ï¼Œ è¿˜æ˜¯ç”¨ curläº† For Pycharm Plugins cheat.sh code snippets æ–¹å¼1ï¼šä½¿ç”¨é¢æ¿ è°ƒå‡ºé¢æ¿å¿«æ·é”® alt + p alt + p åœ¨é¢æ¿ä¸­è¾“å…¥è¯­å¥æµ‹è¯•ï¼š string time å’Œ time string ä¸¤ä¸ªå•è¯é¡ºåºæ˜¯ä¸åŒçš„ï¼Œä½†æ˜¯å´æœ‰ä¸åŒçš„è¯­å¥å— æ–¹å¼2ï¼šç›´æ¥åœ¨å†™ä»£ç  ä»£ç ä¸­ç›´æ¥å†™ï¼š string time é€‰ä¸­æ­¤ä»£ç  string time æŒ‰ç»„åˆé”®å¤åˆ¶ç”Ÿæˆçš„ä»£ç å— alt + c ç„¶åå…¨éƒ¨æ¾æ‰‹å†å¤åˆ¶ç”Ÿæˆçš„ä»£ç å—(ç›´æ¥ä¸€ä¸ªå•sé”®å³å¯) s For Sublime sublimeè¿™æ–¹é¢é…ç½®æ–‡æ¡£æ¬ ç¼ºï¼Œç¼ºå¿«æ·é”® ","link":"https://cythonlin.github.io/post/ide-greater-cheatsh/"},{"title":"PR => Powershell 7","content":"PS7 ä¸»è¦æ–°å¢åŠŸèƒ½ &amp; åå° &amp;&amp; || ç®¡é“ æ‰¾åˆ°PS5é…ç½®æ–‡ä»¶ # åˆ—å‡ºPS5é…ç½®æ–‡ä»¶ locate PowerShell_profile.ps1 # æ‰“å¼€é…ç½®æ–‡ä»¶ sublime C:\\Users\\lin\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 ä¿®æ”¹PS5é…ç½®ä¸ºå¦‚ä¸‹å†…å®¹ ä¸»è¦å°±æ˜¯ iex å’Œ irm ä¸¤æ¡åˆ«åå‘½ä»¤æ·»åŠ å›æ¥ï¼Œä¸‹é¢è¦ç”¨åˆ° Get-Alias | ForEach-Object { if ($_.Name -ne &quot;cd&quot; -and $_.Name -ne &quot;start&quot; -and $_.Name -ne &quot;iex&quot; -and $_.Name -ne &quot;irm&quot;) { Remove-Item -Path (&quot;Alias:\\&quot; + $_.Name) -Force -ErrorAction &quot;SilentlyContinue&quot; } } Invoke-Expression (oh-my-posh --init --shell pwsh --config &quot;C:\\Users\\lin\\lin.omp.json&quot;) Write-Color -Text &quot; __ __ ___ &quot; -Color Cyan Write-Color -Text &quot; /\\ \\__/\\ \\ /\\_ \\ __ &quot; -Color Cyan Write-Color -Text &quot; ___ __ __\\ \\ ,_\\ \\ \\___ ___ ___ \\//\\ \\ /\\_\\ ___ &quot; -Color red Write-Color -Text &quot; /'___\\/\\ \\/\\ \\\\ \\ \\/\\ \\ _ \\\\ / __\\\\ /' _ \\\\ \\ \\ \\ \\/\\ \\ /' _ \\\\ &quot; -Color yellow Write-Color -Text &quot; /\\ \\__/\\ \\ \\_\\ \\\\ \\ \\_\\ \\ \\ \\ \\/\\ \\\\ \\/\\ \\/\\ \\ \\_\\ \\_\\ \\ \\/\\ \\/\\ \\ &quot; -Color green Write-Color -Text &quot; \\ \\____\\\\/\\____ \\\\ \\__\\\\ \\_\\ \\_\\ \\____/\\ \\_\\ \\_\\ /\\____\\\\ \\_\\ \\_\\ \\_\\&quot; -Color blue Write-Color -Text &quot; \\/____/ \\\\___// \\\\/__/ \\/_/\\/_/\\/___/ \\/_/\\/_/ \\/____/ \\/_/\\/_/\\/_/&quot; -Color Magenta Write-Color -Text &quot; /\\___/ &quot; -Color Cyan Write-Color -Text &quot; \\/__/ &quot; -Color Cyan Write-Color -Text &quot; &quot; function new_clear{ Clear-Host Write-Color -Text &quot; __ __ ___ &quot; -Color Cyan Write-Color -Text &quot; /\\ \\__/\\ \\ /\\_ \\ __ &quot; -Color Cyan Write-Color -Text &quot; ___ __ __\\ \\ ,_\\ \\ \\___ ___ ___ \\//\\ \\ /\\_\\ ___ &quot; -Color red Write-Color -Text &quot; /'___\\/\\ \\/\\ \\\\ \\ \\/\\ \\ _ \\\\ / __\\\\ /' _ \\\\ \\ \\ \\ \\/\\ \\ /' _ \\\\ &quot; -Color yellow Write-Color -Text &quot; /\\ \\__/\\ \\ \\_\\ \\\\ \\ \\_\\ \\ \\ \\ \\/\\ \\\\ \\/\\ \\/\\ \\ \\_\\ \\_\\ \\ \\/\\ \\/\\ \\ &quot; -Color green Write-Color -Text &quot; \\ \\____\\\\/\\____ \\\\ \\__\\\\ \\_\\ \\_\\ \\____/\\ \\_\\ \\_\\ /\\____\\\\ \\_\\ \\_\\ \\_\\&quot; -Color blue Write-Color -Text &quot; \\/____/ \\\\___// \\\\/__/ \\/_/\\/_/\\/___/ \\/_/\\/_/ \\/____/ \\/_/\\/_/\\/_/&quot; -Color Magenta Write-Color -Text &quot; /\\___/ &quot; -Color Cyan Write-Color -Text &quot; \\/__/ &quot; -Color Cyan Write-Color -Text &quot; &quot; } Set-Alias clear new_clear Set-Alias cls clear ä¸‹è½½PS7å®‰è£…åŒ… iex &quot;&amp; { $(irm https://aka.ms/install-powershell.ps1) } -UseMSI&quot; æ–°å»ºPS7é…ç½®æ–‡ä»¶ æ³¨ï¼šç®¡ç†å‘˜èº«ä»½è¿è¡Œ cd &quot;C:/Program Files/PowerShell/7&quot; notepad profile.ps1 æŠŠä¸Šé¢PS5ä¸€æ¨¡ä¸€æ ·çš„å†…å®¹å¤åˆ¶è¿›æ¥ ç•¥ ä¿å­˜ï¼Œé€€å‡º ä½¿ç”¨PS7å‘½ä»¤è¡Œé‡æ–°å®‰è£…é¢œè‰²å­—ä½“ Install-Module -Name PSWriteColor -Scope CurrentUser é‡æ–°ä¿®æ”¹Terminal é…ç½®æ–‡ä»¶ # åˆ—å‡ºé…ç½®æ–‡ä»¶ locate settings.json | grep -i windowsterminal # æ‰“å¼€é…ç½®æ–‡ä»¶ sublime C:\\Users\\lin\\AppData\\Local\\Packages\\Microsoft.WindowsTerminal_8wekyb3d8bbwe\\LocalState\\settings.json å°†settings.jsoné‡æ–°ç²˜å…¥å¦‚ä¸‹å†…å®¹ // To view the default settings, hold &quot;alt&quot; while clicking on the &quot;Settings&quot; button. // For documentation on these settings, see: https://aka.ms/terminal-documentation { // å®˜æ–¹è®¾ç½®æŒ‡å—? &quot;$schema&quot;: &quot;https://aka.ms/terminal-profiles-schema&quot;, // ä¸€äº›globalsè®¾ç½® &quot;theme&quot;: &quot;dark&quot;, // çª—å£ä¸»é¢˜ // &quot;initialRows&quot;: 25, // &quot;initialCols&quot;: 100, &quot;launchMode&quot;: &quot;maximized&quot;, // å…¨å± // è®¾ç½®é»˜è®¤ç»ˆç«¯ // &quot;defaultProfile&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, // &quot;defaultProfile&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa610}1&quot;, &quot;defaultProfile&quot;: &quot;{574e775e-4f2a-5b96-ac1e-a2962a402336}&quot;, &quot;profiles&quot;: { &quot;defaults&quot;: { // Put settings here that you want to apply to all profiles &quot;colorScheme&quot;: &quot;Seafoam Pastel&quot;, &quot;useAcrylic&quot;: true, &quot;acrylicOpacity&quot;: 0.55, &quot;cursorShape&quot;: &quot;vintage&quot;, &quot;cursorHeight&quot;: 60, &quot;cursorColor&quot;: &quot;#B00C11&quot;, &quot;fontFace&quot;: &quot;Hack Nerd Font&quot;, &quot;fontSize&quot;: 18 }, &quot;list&quot;: [{ // Make changes here to the powershell.exe profile &quot;guid&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, &quot;name&quot;: &quot;PS5&quot;, &quot;commandline&quot;: &quot;PowerShell.exe /nologo&quot;, // /nologo è¡¨ç¤ºåˆ é™¤ banner &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;hidden&quot;: false }, // { // // Make changes here to the powershell.exe profile // &quot;guid&quot;: &quot;{7c0b0203-de8d-490d-9183-a9e245a83be1}&quot;, // &quot;name&quot;: &quot;PWSH&quot;, // &quot;commandline&quot;: &quot;C://Program Files//PowerShell//7//pwsh.exe /nologo&quot;, // /nologo è¡¨ç¤ºåˆ é™¤ banner // &quot;startingDirectory&quot;: &quot;d:&quot;, // &quot;hidden&quot;: false // }, { // Make changes here to the cmd.exe profile &quot;guid&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa6101}&quot;, &quot;name&quot;: &quot;cmd&quot;, &quot;commandline&quot;: &quot;cmd.exe&quot;, &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;hidden&quot;: false }, { &quot;guid&quot;: &quot;{b453ae62-4e3d-5e58-b989-0a998ec441b8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Azure Cloud Shell&quot;, &quot;source&quot;: &quot;Windows.Terminal.Azure&quot; }, // { // &quot;guid&quot;: &quot;{07b52e3e-de2c-5db4-bd2d-ba144ed6c273}&quot;, // &quot;hidden&quot;: false, // &quot;name&quot;: &quot;Ubuntu-20.04&quot;, // &quot;startingDirectory&quot;: &quot;d:&quot;, // &quot;source&quot;: &quot;Windows.Terminal.Wsl&quot; // }, // { // &quot;guid&quot;: &quot;{e05f1426-9e28-4be3-8f2b-3e2b48eae4a8}&quot;, // &quot;hidden&quot;: false, // &quot;name&quot;: &quot;ssh&quot;, // &quot;commandline&quot;: &quot;ssh root@127.0.0.1 -p 22&quot; // }, { &quot;guid&quot;: &quot;{e05f1426-9e28-4be3-8f2b-3e2b48eae4a8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Conda&quot;, &quot;commandline&quot;: &quot;%windir%//System32//cmd.exe \\&quot;\\/K\\&quot; D:/miniconda/Scripts/activate.bat D:/miniconda&quot;, &quot;startingDirectory&quot;: &quot;d:&quot; }, { &quot;guid&quot;: &quot;{574e775e-4f2a-5b96-ac1e-a2962a402336}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;PS7&quot;, &quot;source&quot;: &quot;Windows.Terminal.PowershellCore&quot;, &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;commandline&quot;: &quot;C://Program Files//PowerShell//7//pwsh.exe /nologo&quot;, // /nologo è¡¨ç¤ºåˆ é™¤ banner } ] }, // Add custom color schemes to this array &quot;schemes&quot;: [ { &quot;name&quot;: &quot;Seafoam Pastel&quot;, &quot;black&quot;: &quot;#000000&quot;, &quot;red&quot;: &quot;#ff7092&quot;, &quot;green&quot;: &quot;#00fbac&quot;, &quot;yellow&quot;: &quot;#fffa6a&quot;, &quot;blue&quot;: &quot;#00bfff&quot;, &quot;purple&quot;: &quot;#df95ff&quot;, &quot;cyan&quot;: &quot;#86cbfe&quot;, &quot;white&quot;: &quot;#ffffff&quot;, &quot;brightBlack&quot;: &quot;#000000&quot;, &quot;brightRed&quot;: &quot;#ff8aa4&quot;, &quot;brightGreen&quot;: &quot;#21f6bc&quot;, &quot;brightYellow&quot;: &quot;#fff787&quot;, &quot;brightBlue&quot;: &quot;#1bccfd&quot;, &quot;brightPurple&quot;: &quot;#e6aefe&quot;, &quot;brightCyan&quot;: &quot;#99d6fc&quot;, &quot;brightWhite&quot;: &quot;#ffffff&quot;, &quot;background&quot;: &quot;#332a57&quot;, &quot;foreground&quot;: &quot;#e5e5e5&quot; } ], // Add any keybinding overrides to this array. // To unbind a default keybinding, set the command to &quot;unbound&quot; &quot;keybindings&quot;: [], &quot;actions&quot;: [ // Copy and paste are bound to Ctrl+Shift+C and Ctrl+Shift+V in your defaults.json. // These two lines additionally bind them to Ctrl+C and Ctrl+V. // To learn more about selection, visit https://aka.ms/terminal-selection { &quot;command&quot;: {&quot;action&quot;: &quot;copy&quot;, &quot;singleLine&quot;: false }, &quot;keys&quot;: &quot;ctrl+c&quot; }, { &quot;command&quot;: &quot;paste&quot;, &quot;keys&quot;: &quot;ctrl+v&quot; }, // Press Ctrl+Shift+F to open the search box { &quot;command&quot;: &quot;find&quot;, &quot;keys&quot;: &quot;ctrl+f&quot; }, // settings { &quot;command&quot;: &quot;openSettings&quot;, &quot;keys&quot;: &quot;ctrl+'&quot; }, // Press Alt+Shift+D to open a new pane. // - &quot;split&quot;: &quot;auto&quot; makes this pane open in the direction that provides the most surface area. // - &quot;splitMode&quot;: &quot;duplicate&quot; makes the new pane use the focused pane's profile. // To learn more about panes, visit https://aka.ms/terminal-panes { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;auto&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; }, &quot;keys&quot;: &quot;alt+shift+d&quot; }, { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;vertical&quot; }, &quot;keys&quot;: &quot;ctrl+plus&quot; }, { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;horizontal&quot; }, &quot;keys&quot;: &quot;ctrl+-&quot; }, { &quot;command&quot;: &quot;closePane&quot;, &quot;keys&quot;: &quot;ctrl+w&quot; } ] } æœ¬æ¬¡ settings.jsonä¸»è¦å¯¹ Terminalåšäº†å¦‚ä¸‹ä¿®æ”¹ çª—å£å¼€å¯ä¸ºå…¨å± -&gt; launchMode åŠ å…¥PS7 é»˜è®¤ç»ˆç«¯è®¾ä¸ºPS7 -&gt; defaultProfile Powershell5 æ”¹åä¸º PS5 åŠ äº†ä¸€äº›åå°ä¾¿æ·åŠŸèƒ½ï¼Œæ•´ä½“profile.ps1æ–‡ä»¶å¦‚ä¸‹ï¼š æ³¨ï¼šè¿™é‡ŒåŠ äº† gsudoçš„é…ç½®ï¼Œå› æ­¤éœ€è¦ï¼Œå…ˆå®‰è£… gsudo Get-Alias | ForEach-Object { if ($_.Name -ne &quot;cd&quot; ` -and $_.Name -ne &quot;start&quot; ` -and $_.Name -ne &quot;iex&quot; ` -and $_.Name -ne &quot;irm&quot; ` -and $_.Name -ne &quot;select&quot; ` ) ` { Remove-Item -Path (&quot;Alias:\\&quot; + $_.Name) -Force -ErrorAction &quot;SilentlyContinue&quot; } } Invoke-Expression (oh-my-posh --init --shell pwsh --config &quot;C:\\Users\\lin\\lin.omp.json&quot;) Write-Color -Text &quot; __ __ ___ &quot; -Color Cyan Write-Color -Text &quot; /\\ \\__/\\ \\ /\\_ \\ __ &quot; -Color Cyan Write-Color -Text &quot; ___ __ __\\ \\ ,_\\ \\ \\___ ___ ___ \\//\\ \\ /\\_\\ ___ &quot; -Color red Write-Color -Text &quot; /'___\\/\\ \\/\\ \\\\ \\ \\/\\ \\ _ \\\\ / __\\\\ /' _ \\\\ \\ \\ \\ \\/\\ \\ /' _ \\\\ &quot; -Color yellow Write-Color -Text &quot; /\\ \\__/\\ \\ \\_\\ \\\\ \\ \\_\\ \\ \\ \\ \\/\\ \\\\ \\/\\ \\/\\ \\ \\_\\ \\_\\ \\ \\/\\ \\/\\ \\ &quot; -Color green Write-Color -Text &quot; \\ \\____\\\\/\\____ \\\\ \\__\\\\ \\_\\ \\_\\ \\____/\\ \\_\\ \\_\\ /\\____\\\\ \\_\\ \\_\\ \\_\\&quot; -Color blue Write-Color -Text &quot; \\/____/ \\\\___// \\\\/__/ \\/_/\\/_/\\/___/ \\/_/\\/_/ \\/____/ \\/_/\\/_/\\/_/&quot; -Color Magenta Write-Color -Text &quot; /\\___/ &quot; -Color Cyan Write-Color -Text &quot; \\/__/ &quot; -Color Cyan Write-Color -Text &quot; &quot; function new_clear{ Clear-Host Write-Color -Text &quot; __ __ ___ &quot; -Color Cyan Write-Color -Text &quot; /\\ \\__/\\ \\ /\\_ \\ __ &quot; -Color Cyan Write-Color -Text &quot; ___ __ __\\ \\ ,_\\ \\ \\___ ___ ___ \\//\\ \\ /\\_\\ ___ &quot; -Color red Write-Color -Text &quot; /'___\\/\\ \\/\\ \\\\ \\ \\/\\ \\ _ \\\\ / __\\\\ /' _ \\\\ \\ \\ \\ \\/\\ \\ /' _ \\\\ &quot; -Color yellow Write-Color -Text &quot; /\\ \\__/\\ \\ \\_\\ \\\\ \\ \\_\\ \\ \\ \\ \\/\\ \\\\ \\/\\ \\/\\ \\ \\_\\ \\_\\ \\ \\/\\ \\/\\ \\ &quot; -Color green Write-Color -Text &quot; \\ \\____\\\\/\\____ \\\\ \\__\\\\ \\_\\ \\_\\ \\____/\\ \\_\\ \\_\\ /\\____\\\\ \\_\\ \\_\\ \\_\\&quot; -Color blue Write-Color -Text &quot; \\/____/ \\\\___// \\\\/__/ \\/_/\\/_/\\/___/ \\/_/\\/_/ \\/____/ \\/_/\\/_/\\/_/&quot; -Color Magenta Write-Color -Text &quot; /\\___/ &quot; -Color Cyan Write-Color -Text &quot; \\/__/ &quot; -Color Cyan Write-Color -Text &quot; &quot; } function rjobs{ get-job | remove-job -force } function stops{ get-job | stop-job } function stop{ stop-job @args } function fg{ wait-job @args } Set-Alias jobs job function rjob{ remove-job @args } Set-Alias clear new_clear Set-Alias cls clear Set-Alias sudo gsudo ","link":"https://cythonlin.github.io/post/pr-greater-powershell-7/"},{"title":"PR => Oh-my-Posh3+Banner","content":"é€‰ç”¨å…¼å®¹å­—ä½“ å®‰è£…å­—ä½“ è¿™é‡Œç”¨Nerdå­—ä½“ï¼Œå¯ä»¥åšåˆ°å…¼å®¹ =&gt; Nerdå®˜ç½‘ï¼Œéšä¾¿æŒ‘ä¸€ä¸ªä¸‹è½½ æˆ‘è¿™é‡Œé€‰çš„ Hackï¼Œ =&gt;ä¸‹è½½åŒ…åœ°å€ ä¸‹è½½zipè§£å‹ï¼Œ æŠŠæ‰€æœ‰å­—ä½“é€‰ä¸­ï¼Œ å³é”® ï¼ˆä¸ºæ‰€æœ‰ç”¨æˆ·å®‰è£…ï¼‰ã€‚ ç»™Windows Terminalè®¾ç½®é»˜è®¤å­—ä½“ ctrl + ' è°ƒå‡ºé…ç½®æ–‡ä»¶ æˆ–è€… ç”¨sublimeæ›´æ–¹ä¾¿æ“ä½œ // æŸ¥å‡ºæ–‡ä»¶æ‰€åœ¨ä½ç½® locate settings.json | grep -i terminal sublime æ–‡ä»¶ æœç´¢å…³é”®è¯ fontFaceæ‰€åœ¨è¡Œ, ä¿®æ”¹ä¸ºï¼š &quot;fontFace&quot;: &quot;Hack Nerd Font&quot;, Oh my Posh3 å®‰è£… æ–¹å¼1ï¼š scoop install https://github.com/JanDeDobbeleer/oh-my-posh3/releases/latest/download/oh-my-posh.json æ–¹å¼2ï¼š scoop install oh-my-posh3 æ›´æ–° scoop update oh-my-posh ç”Ÿæˆé…ç½®æ–‡ä»¶ Invoke-Expression (oh-my-posh --init --shell pwsh --config &quot;$(scoop prefix oh-my-posh)/themes/jandedobbeleer.omp.json&quot;) æŸ¥çœ‹è‡ªå¸¦é…ç½®æ–‡ä»¶ä½ç½® locate jandedobbeleer.omp.json æŠŠåŸé…ç½®æ–‡ä»¶copyä¸€ä»½ç»™homeç›®å½•ï¼Œåä¸ºlin.omp.json cp C:\\Users\\lin\\scoop\\apps\\oh-my-posh\\3.85.2\\themes\\jandedobbeleer.omp.json C:\\Users\\lin\\lin.omp.json ä½¿ç”¨è‡ªå·±çš„é…ç½®æ–‡ä»¶ï¼Œå¹¶æŠŠå®ƒå†™å…¥åˆ°psé…ç½®æ–‡ä»¶ä¸­ Invoke-Expression (oh-my-posh --init --shell pwsh --config &quot;C:\\Users\\lin\\lin.omp.json&quot;) æ‰“å¼€lin.omp.jsonï¼Œcopyå…¥å¦‚ä¸‹å†…å®¹ { &quot;$schema&quot;: &quot;https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh3/main/themes/schema.json&quot;, &quot;blocks&quot;: [ { &quot;type&quot;: &quot;prompt&quot;, &quot;alignment&quot;: &quot;left&quot;, &quot;segments&quot;: [ { &quot;type&quot;: &quot;session&quot;, &quot;style&quot;: &quot;powerline&quot;, &quot;foreground&quot;: &quot;#000000&quot;, &quot;background&quot;: &quot;#00FFFF&quot;, &quot;trailing_diamond&quot;: &quot;\\uE0B0&quot; }, { &quot;type&quot;: &quot;path&quot;, &quot;style&quot;: &quot;powerline&quot;, &quot;leading_diamond&quot;: &quot;\\uE0B0&quot;, &quot;trailing_diamond&quot;: &quot;\\uE0B0&quot;, &quot;powerline_symbol&quot;: &quot;\\uE0B0&quot;, &quot;foreground&quot;: &quot;#000000&quot;, &quot;background&quot;: &quot;#00FF00&quot;, &quot;properties&quot;: { &quot;prefix&quot;: &quot; \\uE5FF &quot;, &quot;style&quot;: &quot;folder&quot; } }, { &quot;type&quot;: &quot;git&quot;, &quot;style&quot;: &quot;powerline&quot;, &quot;powerline_symbol&quot;: &quot;\\uE0B0&quot;, &quot;foreground&quot;: &quot;#193549&quot;, &quot;background&quot;: &quot;#fffb38&quot;, &quot;properties&quot;: { &quot;display_stash_count&quot;: true, &quot;display_upstream_icon&quot;: true } }, { &quot;type&quot;: &quot;root&quot;, &quot;style&quot;: &quot;powerline&quot;, &quot;powerline_symbol&quot;: &quot;\\uE0B0&quot;, &quot;foreground&quot;: &quot;#193549&quot;, &quot;background&quot;: &quot;#ffff66&quot; }, { &quot;type&quot;: &quot;exit&quot;, &quot;style&quot;: &quot;powerline&quot;, &quot;foreground&quot;: &quot;#ffffff&quot;, &quot;background&quot;: &quot;#0000FF&quot;, &quot;leading_diamond&quot;: &quot;\\uE0B0&quot;, &quot;trailing_diamond&quot;: &quot;\\uE0B0&quot;, &quot;powerline_symbol&quot;: &quot;\\uE0B0&quot;, &quot;properties&quot;: { &quot;display_exit_code&quot;: false, &quot;always_enabled&quot;: true, &quot;error_color&quot;: &quot;#FF0000&quot;, &quot;color_background&quot;: true, &quot;success_icon&quot;:&quot;ğŸ˜„&quot;, &quot;error_icon&quot;: &quot;ğŸ˜­&quot; } } ] } ], &quot;final_space&quot;: true } Terminal Banner å®‰è£…è‰²å½©æ¨¡å— Install-Module -Name PSWriteColor -Scope CurrentUser é¢œè‰²å•è¯ï¼Œä¸ºä¸‹é¢ -Color å‡†å¤‡ Black DarkBlue, DarkCyan, DarkRed, DarkMagenta, Gray, DarkGray, Blue, Green, Cyan, Red, Magenta, YellowWhite å»æ­¤ç½‘ç«™æŠŠæ–‡æœ¬è½¬ASCII Art =&gt; è¿™é‡Œæˆ‘é€‰ç”¨çš„æ˜¯ ASCII Shadow ç¤ºä¾‹0ï¼š é—æ†¾çš„æ˜¯ï¼Œåªæœ‰è¿™ä¸ªç¤ºä¾‹0èƒ½ç”¨ï¼Œä¸‹é¢åœ¨PSä¸­ä¸èƒ½ç”¨ï¼Œä¸è¿‡ä»¥åå¯èƒ½ç”¨å¾—åˆ° __ __ ___ /\\ \\__/\\ \\ /\\_ \\ __ __ __ __\\ \\ ,_\\ \\ \\___ ___ ___ \\//\\ \\ /\\_\\ ___ /'___\\/\\ \\/\\ \\\\ \\ \\/\\ \\ _ \\\\ / __\\\\ /' _ \\\\ \\ \\ \\ \\/\\ \\ /' _ \\\\ /\\ \\__/\\ \\ \\_\\ \\\\ \\ \\_\\ \\ \\ \\ \\/\\ \\ \\ \\/\\ \\/\\ \\ \\_\\ \\_\\ \\ \\/\\ \\/\\ \\ \\ \\____\\\\/\\____ \\\\ \\__\\\\ \\_\\ \\_\\ \\____/\\ \\_\\ \\_\\ /\\____\\\\ \\_\\ \\_\\ \\_\\ \\/____/ \\\\___// \\\\/__/ \\/_/\\/_/\\/___/ \\/_/\\/_/ \\/____/ \\/_/\\/_/\\/_/ /\\___/ \\/__/ ç¤ºä¾‹1ï¼š â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â•â• â•šâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â•šâ•â• â•šâ•â• â•šâ•â• â•šâ•â• â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â• â•šâ•â•â•â• ç¤ºä¾‹2ï¼š â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ ç¤ºä¾‹3ï¼š â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ å†™å…¥PSé…ç½®æ–‡ä»¶ sublime C:\\Users\\lin\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 Get-Alias | ForEach-Object { if ($_.Name -ne &quot;cd&quot;) { Remove-Item -Path (&quot;Alias:\\&quot; + $_.Name) -Force -ErrorAction &quot;SilentlyContinue&quot; } } Invoke-Expression (oh-my-posh --init --shell pwsh --config &quot;C:\\Users\\lin\\lin.omp.json&quot;) Write-Color -Text &quot; __ __ ___ &quot; -Color Cyan Write-Color -Text &quot; /\\ \\__/\\ \\ /\\_ \\ __ &quot; -Color Cyan Write-Color -Text &quot; ___ __ __\\ \\ ,_\\ \\ \\___ ___ ___ \\//\\ \\ /\\_\\ ___ &quot; -Color red Write-Color -Text &quot; /'___\\/\\ \\/\\ \\\\ \\ \\/\\ \\ _ \\\\ / __\\\\ /' _ \\\\ \\ \\ \\ \\/\\ \\ /' _ \\\\ &quot; -Color yellow Write-Color -Text &quot; /\\ \\__/\\ \\ \\_\\ \\\\ \\ \\_\\ \\ \\ \\ \\/\\ \\\\ \\/\\ \\/\\ \\ \\_\\ \\_\\ \\ \\/\\ \\/\\ \\ &quot; -Color green Write-Color -Text &quot; \\ \\____\\\\/\\____ \\\\ \\__\\\\ \\_\\ \\_\\ \\____/\\ \\_\\ \\_\\ /\\____\\\\ \\_\\ \\_\\ \\_\\&quot; -Color blue Write-Color -Text &quot; \\/____/ \\\\___// \\\\/__/ \\/_/\\/_/\\/___/ \\/_/\\/_/ \\/____/ \\/_/\\/_/\\/_/&quot; -Color Magenta Write-Color -Text &quot; /\\___/ &quot; -Color Cyan Write-Color -Text &quot; \\/__/ &quot; -Color Cyan Write-Color -Text &quot; &quot; function new_clear{ Clear-Host Write-Color -Text &quot; __ __ ___ &quot; -Color Cyan Write-Color -Text &quot; /\\ \\__/\\ \\ /\\_ \\ __ &quot; -Color Cyan Write-Color -Text &quot; ___ __ __\\ \\ ,_\\ \\ \\___ ___ ___ \\//\\ \\ /\\_\\ ___ &quot; -Color red Write-Color -Text &quot; /'___\\/\\ \\/\\ \\\\ \\ \\/\\ \\ _ \\\\ / __\\\\ /' _ \\\\ \\ \\ \\ \\/\\ \\ /' _ \\\\ &quot; -Color yellow Write-Color -Text &quot; /\\ \\__/\\ \\ \\_\\ \\\\ \\ \\_\\ \\ \\ \\ \\/\\ \\\\ \\/\\ \\/\\ \\ \\_\\ \\_\\ \\ \\/\\ \\/\\ \\ &quot; -Color green Write-Color -Text &quot; \\ \\____\\\\/\\____ \\\\ \\__\\\\ \\_\\ \\_\\ \\____/\\ \\_\\ \\_\\ /\\____\\\\ \\_\\ \\_\\ \\_\\&quot; -Color blue Write-Color -Text &quot; \\/____/ \\\\___// \\\\/__/ \\/_/\\/_/\\/___/ \\/_/\\/_/ \\/____/ \\/_/\\/_/\\/_/&quot; -Color Magenta Write-Color -Text &quot; /\\___/ &quot; -Color Cyan Write-Color -Text &quot; \\/__/ &quot; -Color Cyan Write-Color -Text &quot; &quot; } Set-Alias clear new_clear Set-Alias cls clear Banner å¦ä¸€ç§è§£å†³æ€è·¯ scoop install figlet figlet &quot;Cython lin&quot; ","link":"https://cythonlin.github.io/post/pr-greater-oh-my-posh3/"},{"title":"PR => Terminal åº”ç”¨","content":"README ä»¥åè‹¥å‘ç° Windowsåº”ç”¨ç¨‹åºæˆ–åŠŸèƒ½ å¯ç”¨Terminalå‘½ä»¤ä»£æ›¿ä¸”ä¾¿æ·å®ç°ï¼Œåˆ™è®°è½½äºæ­¤ã€‚ Everything å‘½ä»¤è¡Œ - ES ä¸‹è½½åœ°å€ï¼š ESç‚¹æ­¤ä¸‹è½½ æ„å›¾ è™½ç„¶ Everythingå›¾å½¢ç•Œé¢å·¥å…·å·²ç»å¾ˆå‡ºè‰²äº†ã€‚ä½†æˆ‘ä¾ç„¶å¿˜ä¸æ‰ Linux çš„ locate å‘½ä»¤ æ•…æœ‰æ„å°† Everythingçš„å‘½ä»¤è¡Œå·¥å…· es æ›¿ä»£ locate ä½¿ç”¨æ–¹å¼ ä¸‹è½½zip è§£å‹ å°† es.exe æ”¹åä¸º locate.exe (Linuxçš„locateå‘½ä»¤ä½¿ç”¨ä¹ æƒ¯ï¼Œè‹¥æ— æ­¤ä¹ æƒ¯ï¼Œåˆ™è·³è¿‡æ­¤æ­¥) å°†æ­¤è§£å‹è·¯å¾„åŠ å…¥åˆ°ç¯å¢ƒå˜é‡ locate xxx ES å¸¸ç”¨è¯­æ³•å‚æ•° æˆ‘çœ‹äº†çœ‹ ESæ–‡æ¡£ï¼ŒæŠ½å–äº†ä¸€äº›ä¸ªäººè®¤ä¸ºå¥½ç”¨çš„å‚æ•°ã€‚ -rï¼šæ­£åˆ™ -sï¼šä»¥å…¨è·¯å¾„æ’åºï¼ˆæ¯çº§è·¯å¾„éƒ½ä¼šæ’åºï¼Œ ä¸¾ä¸ªä¾‹å­å°±å’Œå¤šçº§åˆ†ç»„æ’åºåŸç†å·®ä¸å¤šï¼‰ -sizeï¼šæ–‡ä»¶å¤§å° -dmï¼šä¿®æ”¹æ—¥æœŸ -highlightï¼šå…³é”®è¯é«˜äº® è§£é‡Šçš„å¾ˆæ¸…æ¥šäº†ï¼Œè¿™é‡Œæ‹¿æ­£åˆ™ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œ å› ä¸ºesåŒ¹é…åŸåˆ™æ˜¯åŒ…å«åŸåˆ™ã€‚ åªè¦å«æœ‰ï¼Œå°±ä¼šåˆ—ä¸¾å‡ºæ¥ï¼Œå¾ˆå®½æŸ”ã€‚è¿™é‡Œæˆ‘ä»¬å†™ä¸€ä¸ªä¸¥æ ¼åŒ¹é…çš„æ­£åˆ™ï¼š locate -r ^test.py$ ä¿å­˜é…ç½®åˆ°æ–‡ä»¶ï¼ˆ es.exe åŒç›®å½•ä¸‹ es.iniï¼‰ä¸­ï¼Œä¸€åŠ³æ°¸é€¸ï¼š -save-settings locate -size -dm -sizecolor 0x0d -dmcolor 0x0b -s -highlight -save-settings æ¸…é™¤é…ç½®ï¼š-clear-settings locate -clear-settings ä¸ªäººè®¤ä¸º ES å‘½ä»¤è¡Œçš„ä¸€äº›ä¼˜åŠ¿ everythingçš„å›¾å½¢ç•Œé¢ä¸€äº›é«˜çº§åŠŸèƒ½éƒ½åœ¨å·¥å…·æ ï¼Œæˆ‘æ˜¯å‡ ä¹ä¸ç”¨ã€‚æ„Ÿè§‰éº»çƒ¦ã€‚ä¸å¦‚å‘½ä»¤æ¥çš„ç®€æ´ã€‚ æ­£å¦‚å‰å‡ ç¯‡æ–‡ç« æ‰€è®²ï¼ŒæŠŠPSæ‰“é€ æˆ Sim-Linuxï¼Œ æ‰€ä»¥æˆ‘å¯ä»¥ä½¿ç”¨ grep ç­‰å‘½ä»¤ã€‚ è¿™æ ·æˆ‘å°±å¯ä»¥ä½¿ç”¨ ESæœç´¢å‘½ä»¤ + grep ç­‰åš å¤šå…³é”®è¯ ç²¾ç»†æŸ¥æ‰¾ï¼ˆeverythingå›¾å½¢é«˜çº§åŠŸèƒ½åº”è¯¥ä¹Ÿæœ‰ï¼‰ ","link":"https://cythonlin.github.io/post/pr-greater-terminal-ying-yong/"},{"title":"PR => Alias & Linuxç‘å£«å†›åˆ€","content":"ä»‹ç» å‰æ–‡ å‰é¢æ–‡ç« ä»‹ç»äº†Windows Terminal ä»¥åŠ WSL2 äºŒè€…å„æœ‰ç”¨é€”ï¼Œä½†æ˜¯ç”¨äº†ä¸€æ®µæ—¶é—´å‘ç°ï¼Œéƒ½ä¸å¤ªæ–¹ä¾¿ &quot;Sim-Bash&quot; å› ä¸º Windows Terminal çš„åº•å±‚è°ƒç”¨å…¶å®è¿˜æ˜¯ PowerShellçš„å‘½ä»¤ã€‚ã€‚ åªä¸è¿‡ åªæ˜¯PowerShellï¼ˆä¸‹é¢ç”¨ç®€ç§°PSæ¥ä»‹ç»ï¼‰çš„å‘½ä»¤å…¨éƒ¨éƒ½åšäº†ä¸€å±‚Aliasæ“ä½œã€‚ æ­¤Aliasæœ‰å…·ä½“çš„è¯­æ³•ï¼Œä¸Linuxä¸ä¸€æ ·çš„ï¼Œä½†æ˜¯æ„æ€å·®ä¸å¤šï¼Œå°±æ˜¯ç»™å‘½ä»¤èµ·åˆ«åã€‚ å°±æ˜¯å› ä¸ºPSè¿™ä¸ªåˆ«åï¼Œä½¿å¾—æˆ‘ä»¬ç”¨Scoopå®‰è£…çš„LinuxåŒåå‘½ä»¤å†²çªï¼Œå¹¶ä¸”ç”¨ä¸äº†ã€‚ åŒåå‘½ä»¤ä»‹ç» æ¯”å¦‚ ls è¿™ä¸ªå‘½ä»¤ï¼Œ PSç”¨çš„ å…¶ä»–å‘½ä»¤ï¼ˆç±»ä¼¼dirï¼‰èµ·ä¸ªls è¿™ä¸ªåˆ«å ä½¿å¾—ä½¿ç”¨ ls å°±å¯ä»¥åƒ Linuxçš„Bashé‚£æ ·ç®€å•ã€‚ ä½†æ˜¯ï¼ï¼ï¼ï¼ PSçš„å‘½ä»¤å‚æ•° å’Œ Bashçš„å‘½ä»¤å‚æ•°æ˜¯ä¸ä¸€æ ·çš„ã€‚ã€‚ã€‚ PSçš„ ls å‘½ä»¤ åˆ—ä¸¾éšè—æ–‡ä»¶å‚æ•°æ˜¯ : -h Bashçš„ ls å‘½ä»¤ åˆ—ä¸¾éšè—æ–‡ä»¶å‚æ•°æ˜¯ : -a è¿™å°±æ˜¯ PSçš„å‘½ä»¤ä¸æ–¹ä¾¿ä¹‹å¤„ï¼Œ lsåªæ˜¯ä¸ªä¾‹å­ï¼Œè¿˜æœ‰å¾ˆå¤šå…¶ä»–å‘½ä»¤æœ‰åŒæ ·çš„é—®é¢˜ã€‚ Windows Terminal å°±æ˜¯ç”¨ PS â€œæŒ‚ç¾Šå¤´å–ç‹—è‚‰â€ ç½¢äº†ã€‚ã€‚ã€‚ è§£å†³åŠæ³• æˆ‘å”¯ä¸€æƒ³åˆ°çš„å°±æ˜¯ï¼Œåˆ é™¤æ‰€æœ‰PSå‘½ä»¤çš„åˆ«åï¼Œä¸€åˆ‡å‘½ä»¤ç”±Scoopé‡æ–°ä¸‹è½½ï¼ˆå¾ˆç®€å•ï¼Œåé¢è¯´å†›åˆ€ï¼‰ ç„¶åæŒ‰ç…§è¿™ä¸ªæ€è·¯å¯»æ‰¾ï¼Œæ‰¾åˆ°å¯ç”¨çš„è§£å†³åŠæ³•ï¼š åˆ›å»ºWindows PowerShell profileé…ç½®æ–‡ä»¶: New-Item -Type file -Force $profile åˆ›å»ºçš„æ­¤æ–‡ä»¶é»˜è®¤ä½ç½®ä¸ºï¼šï¼ˆæˆ‘çš„ç”¨æˆ·åæ˜¯ lin ï¼‰ C:\\Users\\lin\\Documents\\WindowsPowerShell å†™å…¥å¦‚ä¸‹ä»£ç ï¼Œæ–‡ä»¶æ˜¯(Microsoft.PowerShell_profile.ps1)ï¼š Get-Alias | ForEach-Object { if ($_.Name -ne &quot;cd&quot;) { Remove-Item -Path (&quot;Alias:\\&quot; + $_.Name) -Force -ErrorAction &quot;SilentlyContinue&quot; } } æ­¤è¡Œå‘½ä»¤æ„æ€å°±æ˜¯æ¸…é™¤æ‰€æœ‰PS å‘½ä»¤çš„åˆ«åã€‚ ï¼ˆè¿™ä¸ªè¯­å¥æˆ‘å­¦ä¹ åŠ äº†ä¸€ä¸ªæ¡ä»¶ å’Œ æˆªè·å¼‚å¸¸çš„è¯­å¥ï¼‰ å¦‚æœä¸æ’é™¤ cd è¿™ä¸ªå‘½ä»¤ï¼Œ æˆ‘ä»¬åç»­å®‰è£…çš„æ¨¡å—æ˜¯ æ²¡æœ‰cdè¿™ä¸ªå®‰è£…åŒ…çš„ã€‚ å› ä¸º cd æ˜¯ LinuxBash å†…å»ºå‘½ä»¤ã€‚ Windowsæ— æ³•å®‰è£…ï¼Œ å³ä½¿æˆ‘ä»¬å®‰è£…äº†Bash, ä¹Ÿæ²¡æœ‰ cdã€‚ æ‰€ä»¥ï¼Œcdæˆ‘ä»¬åªèƒ½ç”¨psè‡ªå¸¦çš„cd, è¿™æ˜¯æ²¡åŠæ³•çš„äº‹æƒ…ï¼Œ å…¶ä½™çš„å‘½ä»¤åˆ«åå°±å¯ä»¥å…¨åˆ äº†ã€‚ è‡³æ­¤ï¼Œé‡æ–°ä»£å¼€ Terminalã€‚ é‡åˆ°çš„é—®é¢˜ é‚£å°±æ˜¯æ¯æ¬¡æ‰“å¼€æ–°çš„Terminal éƒ½ä¼šåŠ è½½ ä¸Šé¢Windows PowerShell profileè¿™ä¸ªé…ç½®æ–‡ä»¶é‡Œé¢çš„å‘½ä»¤ã€‚å¯èƒ½æ˜¯æœ‰ç¼“å­˜ä¹‹ç±»çš„ä¿¡æ¯ï¼Œæ‰€ä»¥ä¼šå‘ç”Ÿæ–‡ä»¶ä¸å­˜åœ¨ï¼ˆå°±æ˜¯ç±»ä¼¼ç©ºæ–‡ä»¶å¼‚å¸¸ï¼‰ äºæ˜¯ï¼ŒæŸ¥PowerShellçš„å¼‚å¸¸å¤„ç†è¯­å¥å¦‚ä¸Šä»£ç åè¿½åŠ  -ErrorAction &quot;SilentlyContinue å³å¯ã€‚ Scoop + Linuxç‘å£«å†›åˆ€-busybox -&gt;Scoopçš„å®‰è£…æ•™ç¨‹è§è¿™é‡Œå¯»æ‰¾ æ—¢ç„¶ä¸Šæ–‡å·²åˆ é™¤äº†æ‰€æœ‰PSåˆ«åï¼Œé‚£æˆ‘ä»¬å°±éœ€è¦ä¸‹è½½æˆ‘ä»¬è¦ç”¨çš„å„ç§ Linuxå‘½ä»¤äº†ï¼Œ æ¯”å¦‚ ls ps kill å„ç§å¸¸ç”¨ Linuxå‘½ä»¤ã€‚ ä¸éœ€è¦ä¸€ä¸ªä¸€ä¸ªå»æ‰‹åŠ¨ Scoop install å·¥å…·åŒ…ï¼Œ åªéœ€ä¸€å¥ï¼š scoop install busybox å¦‚æ­¤ä¸€æ¥ï¼Œæˆ‘ä»¬å°±æŠŠ Windows Terminal çš„å„ç§è¹©è„šåˆ«åçš„PSå‘½ä»¤ æ›¿æ¢æˆäº† Linux Bashå‘½ä»¤ï¼ ç»“æŸè¯­ æˆ‘å¹¶éåæ§½PSå‘½ä»¤ï¼Œå› ä¸ºå®ƒå¯èƒ½æœ‰å®ƒä¸“é—¨çš„ç”¨é€”ã€‚ è€Œæ˜¯æˆ‘æ›´ç†Ÿæ‚‰äº Linux çš„ Bash å‘½ä»¤è€Œå·²ã€‚ ","link":"https://cythonlin.github.io/post/pr-greater-del-alias-and-linux-rui-shi-jun-dao/"},{"title":"PR => MusicBee & VST","content":"MusicBee MusicBee çš®è‚¤ Dark -&gt; Bee78 MusicBee éŸ³è´¨é…ç½® é¦–å…ˆè¦è®¾ç½®ä¸€ä¸‹æ‰¬å£°å™¨å±æ€§ å³é”®æ’­æ”¾ä¸‹é¢çš„ â€œæ‰¬å£°å™¨â€ å±æ€§ -&gt; é«˜çº§ (æŠŠä¸‹é¢2ä¸ªé€‰é¡¹éƒ½ æ‰“ä¸Š âˆš) -&gt; å…è®¸åº”ç”¨ç¨‹åºç‹¬å æ§åˆ¶è¯¥è®¾å¤‡ -&gt; ç»™ä¸ç‹¬å æ¨¡å¼åº”ç”¨ç¨‹åºä¼˜å…ˆ ç„¶åé…ç½®MusicBee é¦–é€‰é¡¹ -&gt; æ’­æ”¾å™¨ -&gt; è¾“å‡º -&gt; é€‰æ‹© WSAAPI (Shared) ï¼ï¼ï¼ï¼ï¼ï¼ï¼è¿™ä¸ªè‡³å…³é‡è¦ï¼Œå¿…é¡»æ˜¯ Shared -&gt; ä½¿ç”¨32ä½è¾“å‡º+ç«‹ä½“å£°æ··éŸ³è‡³5.1+é‡æ–°é‡‡æ ·åˆ° 192Kï¼ˆè¿™å‡ ä¸ªä½œç”¨ä¸å¤ªæ˜æ˜¾ï¼‰ ç„¶åè°ƒæ§éŸ³é‡ï¼ˆæ¯”è¾ƒé‡è¦ï¼‰ï¼š MusicBee çš„ å†…éƒ¨éŸ³é‡ è°ƒåˆ°æœ€ä½ï¼ˆä½†æ˜¯ä¸è¦è°ƒæ²¡ï¼‰ã€‚ Windowsæ‰¬å£°å™¨éŸ³é‡è°ƒé«˜ã€‚ MusicBeeå®‰è£…VSTæ’æ§½ æ³¨ï¼šMusicBeeä¸èƒ½ç›´æ¥å®‰è£…VSTæ’ä»¶ï¼Œ éœ€è¦å®˜ç½‘å®‰è£…ä¸€ä¸ªVSTæ’æ§½ã€‚ç”¨æ­¤æ’æ§½æ‰å¯ä»¥å®‰è£…å…¶ä»–VSTæ’ä»¶ VSTæ’æ§½ä¸‹è½½åœ°å€ å®‰è£…æ’æ§½ Preference -&gt; Plugins -&gt; Add Plugins -&gt; æ’æ§½ä¸‹è½½çš„ä½ç½® ä½¿ç”¨VSTæ’æ§½å®‰è£…VSTæ’ä»¶ æ­£å¸¸DLLæ–‡ä»¶å®‰è£…æ–¹å¼ VSTæ’ä»¶ä¸‹è½½åœ°å€ æ³¨ï¼šMusicBeeå¯¹VSTæ’ä»¶æ”¯æŒå¾ˆä¸å‹å¥½ï¼Œçœ‹äº†ä¸€å¤§å †é€‰äº†å‡ ä¸ªé€‚åˆæˆ‘è¿™ç§åˆçº§é€‰æ‰‹èƒ½ç”¨çš„ï¼š 3D_Panner_2.0 wL_niceNwide Ceres (1) cs12-156 ä¸‹è½½åç›´æ¥è§£å‹ï¼Œå°†è§£å‹æ–‡ä»¶å¤¹ç›´æ¥æ”¾åˆ° musicçš„pluginsç›®å½•ä¸‹å³å¯ï¼ˆéœ€é‡å¯MusicBeeï¼‰ ç—›è‹¦å®‰è£…æ–¹å¼ï¼ˆåªç”¨é€šè¿‡è¿™ç§æ–¹å¼æ‰èƒ½å®‰è£…åˆ°Pitch Shiftç±»æ’ä»¶ï¼‰ è¿™é‡Œæåˆ°ä¸€ä¸ªè¶…çº§è€ç‰Œplayer -&gt; Winamp... ï¼Œç°åœ¨åº”è¯¥æ²¡äººç”¨äº†ã€‚ æˆ–è€…éƒ½ç”¨Foobar2000äº†ã€‚ Winamp æˆ‘çœ‹è®ºå›éƒ½æ˜¯ 2000å¹´å·¦å³çš„è¯„è®ºã€‚ã€‚ã€‚å¯çŸ¥å®ƒçš„æ’ä»¶ä¹Ÿç‰¹åˆ«æ—§äº†ã€‚ ä½†æ˜¯å®ƒçš„æ’ä»¶ç‰¹åˆ«å¤šã€‚ å¯æƒœå¤§å¤šæ•°æ”¾åœ¨ MusicBeeä¸Šä¸å¥½ç”¨æˆ–è€…å´©æºƒã€‚ä½†æ²¡åŠæ³•ï¼Œè¿˜å¾—ç”¨ã€‚ ä¸ºä»€ä¹ˆè¿™é‡Œè¦æåˆ°Winamp å› ä¸ºMusicBeeæœ‰ä¸ªé€‰é¡¹ï¼ˆä»Winampå¯¼å…¥æ’ä»¶ï¼‰ è€Œ Winampçš„æ’ä»¶å¤§å¤šæ•°éƒ½æ˜¯ EXEæ ¼å¼çš„ï¼Œ éœ€è¦è¯†åˆ« Winampçš„å®‰è£…è·¯å¾„ï¼Œå¹¶ä¸”å®‰è£…åˆ°Winampè·¯å¾„ä¸‹ã€‚ ï¼ˆå…¶å®EXEå®‰è£…å®Œä¹Ÿå°±æ˜¯ DLLæ–‡ä»¶ï¼Œ åªä¸è¿‡å®ƒåªèƒ½æ˜¯è¿™ç§æ–¹å¼ã€‚ï¼‰ æ‰€ä»¥ Winamp åªæ˜¯ä¸ªè¿‡æ¸¡çš„å·¥å…·äººã€‚ã€‚ã€‚ Winampæ’ä»¶åœ°å€ Winampæ’ä»¶ æ‹¾åˆ°å¯ç”¨çš„æ’ä»¶ take it easy å¯ä»¥æ”¹å˜ Pitch ä½†æ˜¯è¯•è¿‡ä¸€æ®µæ—¶é—´å¾ˆé—æ†¾ï¼Œä¼šè®© MusicBee å®•æ‰ã€‚ æœ€åä¸€æ ¹æ•‘å‘½ç¨»è‰ pitchShifter.V1.01 pitchShifteråœ°å€ è¿™ä¸ªå°±ç”¨ä¸åˆ° Winmapäº†ï¼Œ ç›´æ¥ç§»åŠ¨åˆ° MusicBee çš„ Pluginsä¸­å³å¯ æ€»ç»“ æ‰¾çš„å¾ˆè¾›è‹¦ï¼Œæ™®é€šçš„VSTæ’ä»¶å¾ˆå¥½æ‰¾ï¼Œ PITCH shift è¿™ç§çš„çœŸçš„éš¾æ‰¾ã€‚ å³ä½¿æ‰¾åˆ°äº†ï¼ŒMusicBeeæœ‰äº›ä¹Ÿå„ç§ä¸æ”¯æŒï¼Œä¸å…¼å®¹ï¼Œå®•æ‰ã€‚ æœ€ç»ˆæ’ä»¶åˆé›†ï¼š 3D_Panner_2.0 wL_niceNwide Ceres (1) cs12-156 pitchShifter ï¼ˆçµé­‚ï¼‰ ä¸ºä½•æˆ‘å¦‚æ­¤æ‰§ç€éŸ³ä¹çš„å˜è°ƒï¼Œå› ä¸ºå¯¹äºæˆ‘æ¥è¯´ï¼Œæ¯ä¸€ä¸ªKeyéƒ½æ˜¯ä¸€é¦–æ–°éŸ³ä¹ï¼ ","link":"https://cythonlin.github.io/post/pr-greater-musicbee-and-winamp-and-vst/"},{"title":"PR => U&P","content":"Google 96@ Github Cy ha- http://cythonlin.github.io/ Vultr Cy Kaggle cy MicroSoft 96@ / si Nvidia 96@ Anaconda ha_ ä¸ƒç‰› 96@ YNote 96@ Coding Pages 96@ / Jxxxxxxxxxxxxxx. ï¼ˆæœ«å°¾å¤šä¸ªè‹±æ–‡æ ‡ç‚¹ å¥å·ï¼‰ https://cythonlin.coding.net Postman 96@ BD 18/13 Docker ha æç®— 18 Neo4j neo4j / zxc ","link":"https://cythonlin.github.io/post/pr-greater-uandp/"},{"title":"PR => Terminal+WSL+ZSH+Docker","content":"å¿«æ·é”® æœç´¢åŠŸèƒ½ ctrl + shift + p æœç´¢æ–‡æœ¬ ctrl + shift + f ç·¨è¼¯é…ç½®æ–‡ä»¶ ctrl + ' (å›è»Šæ—é‚Šçš„ç¬¦è™Ÿ ') æ©«å‘æ‹†åˆ†çª—å£ï¼ˆä¸‹é¢actionä¸­ï¼Œè‡ªå®šç¾©é…ç½®ï¼‰ ctrl + +è™Ÿ å‚ç›´æ‹†åˆ†çª—å£ï¼ˆä¸‹é¢actrionä¸­ï¼Œè‡ªå®šç¾©é…ç½®ï¼‰ ctrl + -è™Ÿ é—œé–‰æ‹†åˆ†çš„çª—å£ï¼ˆä¸‹é¢actionä¸­ï¼Œè‡ªå®šç¾©é…ç½®ï¼‰ ctrl + w é…ç½®æ–‡ä»¶ï¼ˆctrl + ' åï¼Œå…¨éƒ¨å†…å®¹æ•´é«”æ›¿æ›å³å¯ï¼‰ // To view the default settings, hold &quot;alt&quot; while clicking on the &quot;Settings&quot; button. // For documentation on these settings, see: https://aka.ms/terminal-documentation { // å®˜æ–¹è®¾ç½®æŒ‡å—? &quot;$schema&quot;: &quot;https://aka.ms/terminal-profiles-schema&quot;, // ä¸€äº›globalsè®¾ç½® &quot;theme&quot;: &quot;dark&quot;, // çª—å£ä¸»é¢˜ &quot;initialRows&quot;: 25, &quot;initialCols&quot;: 100, // è®¾ç½®é»˜è®¤ç»ˆç«¯ &quot;defaultProfile&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, // &quot;defaultProfile&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa610}1&quot;, &quot;profiles&quot;: { &quot;defaults&quot;: { // Put settings here that you want to apply to all profiles &quot;colorScheme&quot;: &quot;Seafoam Pastel&quot;, &quot;useAcrylic&quot;: true, &quot;acrylicOpacity&quot;: 0.55, &quot;cursorShape&quot;: &quot;vintage&quot;, &quot;cursorHeight&quot;: 60, &quot;cursorColor&quot;: &quot;#B00C11&quot;, &quot;fontFace&quot;: &quot;YaHei Consolas Hybrid&quot;, &quot;fontSize&quot;: 18 }, &quot;list&quot;: [{ // Make changes here to the powershell.exe profile &quot;guid&quot;: &quot;{61c54bbd-c2c6-5271-96e7-009a87ff44bf}&quot;, &quot;name&quot;: &quot;PS&quot;, &quot;commandline&quot;: &quot;powershell.exe /nologo&quot;, // /nologo è¡¨ç¤ºåˆ é™¤ banner &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;hidden&quot;: false }, { // Make changes here to the cmd.exe profile &quot;guid&quot;: &quot;{0caa0dad-35be-5f56-a8ff-afceeeaa6101}&quot;, &quot;name&quot;: &quot;cmd&quot;, &quot;commandline&quot;: &quot;cmd.exe&quot;, &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;hidden&quot;: false }, { &quot;guid&quot;: &quot;{b453ae62-4e3d-5e58-b989-0a998ec441b8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Azure Cloud Shell&quot;, &quot;source&quot;: &quot;Windows.Terminal.Azure&quot; }, { &quot;guid&quot;: &quot;{07b52e3e-de2c-5db4-bd2d-ba144ed6c273}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Ubuntu-20.04&quot;, &quot;startingDirectory&quot;: &quot;d:&quot;, &quot;source&quot;: &quot;Windows.Terminal.Wsl&quot; }, // { // &quot;guid&quot;: &quot;{e05f1426-9e28-4be3-8f2b-3e2b48eae4a8}&quot;, // &quot;hidden&quot;: false, // &quot;name&quot;: &quot;ssh&quot;, // &quot;commandline&quot;: &quot;ssh root@127.0.0.1 -p 22&quot; // }, { &quot;guid&quot;: &quot;{e05f1426-9e28-4be3-8f2b-3e2b48eae4a8}&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Conda&quot;, &quot;commandline&quot;: &quot;%windir%//System32//cmd.exe \\&quot;\\/K\\&quot; D:/miniconda/Scripts/activate.bat D:/miniconda&quot;, &quot;startingDirectory&quot;: &quot;d:&quot; }, ] }, // Add custom color schemes to this array &quot;schemes&quot;: [ { &quot;name&quot;: &quot;Seafoam Pastel&quot;, &quot;black&quot;: &quot;#000000&quot;, &quot;red&quot;: &quot;#ff7092&quot;, &quot;green&quot;: &quot;#00fbac&quot;, &quot;yellow&quot;: &quot;#fffa6a&quot;, &quot;blue&quot;: &quot;#00bfff&quot;, &quot;purple&quot;: &quot;#df95ff&quot;, &quot;cyan&quot;: &quot;#86cbfe&quot;, &quot;white&quot;: &quot;#ffffff&quot;, &quot;brightBlack&quot;: &quot;#000000&quot;, &quot;brightRed&quot;: &quot;#ff8aa4&quot;, &quot;brightGreen&quot;: &quot;#21f6bc&quot;, &quot;brightYellow&quot;: &quot;#fff787&quot;, &quot;brightBlue&quot;: &quot;#1bccfd&quot;, &quot;brightPurple&quot;: &quot;#e6aefe&quot;, &quot;brightCyan&quot;: &quot;#99d6fc&quot;, &quot;brightWhite&quot;: &quot;#ffffff&quot;, &quot;background&quot;: &quot;#332a57&quot;, &quot;foreground&quot;: &quot;#e5e5e5&quot; } ], // Add any keybinding overrides to this array. // To unbind a default keybinding, set the command to &quot;unbound&quot; &quot;keybindings&quot;: [], &quot;actions&quot;: [ // Copy and paste are bound to Ctrl+Shift+C and Ctrl+Shift+V in your defaults.json. // These two lines additionally bind them to Ctrl+C and Ctrl+V. // To learn more about selection, visit https://aka.ms/terminal-selection { &quot;command&quot;: {&quot;action&quot;: &quot;copy&quot;, &quot;singleLine&quot;: false }, &quot;keys&quot;: &quot;ctrl+c&quot; }, { &quot;command&quot;: &quot;paste&quot;, &quot;keys&quot;: &quot;ctrl+v&quot; }, // Press Ctrl+Shift+F to open the search box { &quot;command&quot;: &quot;find&quot;, &quot;keys&quot;: &quot;ctrl+f&quot; }, // settings { &quot;command&quot;: &quot;openSettings&quot;, &quot;keys&quot;: &quot;ctrl+'&quot; }, // Press Alt+Shift+D to open a new pane. // - &quot;split&quot;: &quot;auto&quot; makes this pane open in the direction that provides the most surface area. // - &quot;splitMode&quot;: &quot;duplicate&quot; makes the new pane use the focused pane's profile. // To learn more about panes, visit https://aka.ms/terminal-panes { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;auto&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; }, &quot;keys&quot;: &quot;alt+shift+d&quot; }, { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;vertical&quot; }, &quot;keys&quot;: &quot;ctrl+plus&quot; }, { &quot;command&quot;: { &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;horizontal&quot; }, &quot;keys&quot;: &quot;ctrl+-&quot; }, { &quot;command&quot;: &quot;closePane&quot;, &quot;keys&quot;: &quot;ctrl+w&quot; } ] } å®‰è£…Scoop(å¹¶éSqoop...) ä½œç”¨ ä¸»è¦ç”¨åœ¨ å•ä¸ªçº¯ Windows Terminal å»å®‰è£… Linuxå·¥å…·ä½¿ç”¨ã€‚ ä½†æˆ‘å‘ç° Win Terminal çš„ä¸€äº›åŸºç¡€å‘½ä»¤ è¿˜æ˜¯æ²¡Linuxå¥½ç”¨ï¼ˆæ¯”å¦‚ lsæ— é€‰é¡¹çœ‹ä¸åˆ°éšè—æ–‡ä»¶ï¼‰ æ‰€ä»¥æˆ‘æœ€åé€‰æ‹©äº† Win Terminal + WSL2 å¹¶ç”¨ æ‰€ä»¥Scoopè¿™é¡¹å°±å¯ä»¥ä¸ç”¨äº† æµç¨‹ å› ä¸ºç”¨Powershellå‘½ä»¤ï¼Œä¼šè®¿é—®åˆ°raw.githubusercontent.comï¼Œæ‰€ä»¥å…ˆä¿®æ”¹DNS C:\\Windows\\System32\\drivers\\etc 199.232.68.133 raw.githubusercontent.com ipconfig /flushdns ç”¨Powershellå‘½ä»¤æ­£å¼å®‰è£…Scoop: Set-ExecutionPolicy RemoteSigned -scope CurrentUser Invoke-Expression (New-Object System.Net.WebClient).DownloadString('https://get.scoop.sh') æ›´æ–°å¯èƒ½ä¼šå‡ºç°çš„BUG å®‰è£…åº”è¯¥æ˜¯æ²¡é—®é¢˜çš„ï¼Œä¸è¿‡ä»¥åä½¿ç”¨çš„è¿‡ç¨‹ä¸­å¯èƒ½ä¼šé‡åˆ°æ›´æ–°çš„BUGã€‚ cd C:/Users/lin/scoop/apps/ åˆ é™¤è¿™ä¸ªç›®å½•ä¸‹çš„ scoopç›®å½• rm -rf scoop ç„¶åé‡æ–°å®‰è£… scoop(æ³¨æ„ï¼Œåˆ é™¤çš„è¿™ä¸ªscoopæ˜¯scoopå†…éƒ¨çš„æ–‡ä»¶å¤¹) Invoke-Expression (New-Object System.Net.WebClient).DownloadString('https://get.scoop.sh') ç»™scoopæ·»åŠ è½¯ä»¶åº“(bucket) åˆ—å‡ºå¯ç”¨çš„è½¯ä»¶åº“(è¿™ç§è½¯ä»¶åº“ä¼šæŠŠä¸€äº›å¸¦æœ‰GUIçš„è½¯ä»¶æ”¾åœ¨é‡Œé¢)ï¼š scoop bucket known æ·»åŠ è½¯ä»¶åº“(è¿™ä¸ªæ˜¯å®˜æ–¹çš„) scoop bucket add extras å®‰è£… deluge(ä¸‹è½½torrentç”¨çš„) scoop install deluge æ·»åŠ è‡ªå®šä¹‰è½¯ä»¶åº“ -&gt;å®˜æ–¹æ•™ç¨‹ åŠ é€Ÿ Scoopçš„ä¸‹è½½ scoop install aria2 Scoop ä½¿ç”¨ Git æ›´æ–°å®ƒè‡ªèº«ï¼Œæ‰€ä»¥å®‰ä¸€ä¸ªGit æ˜¯éœ€è¦çš„ã€‚ scoop install git å¸è½½è¯­æ³• scoop uninstall xxxx ä¸‰æ–¹æ¡Œé¢ç¨‹åº Winstep Xtreme 17.0+ (å« workshelf + NextStart) å¸è½½NextStart everythingæœåˆ  nextstart æ³¨å†Œè¡¨ HKEY_CURRENT_USER-&gt; SOFTWARE-&gt; WinSTEP2000-&gt; æŠŠè¿™é‡Œé¢çš„ Nextstart å’Œ Shared æ•´ä½“åˆ é™¤ å¹¶ä¸”æŠŠ workshelfé‡Œé¢çš„ METARCode é¡¹çš„å€¼ åˆ æ‰ ä¸‰æ–¹ File Explorer RX æ–‡ä»¶ç®¡ç†å™¨ WSL2(é™„ç€åœ¨é€‰é¡¹å¡) å¯ç”¨WSL(ç”¨PowerShellæ›¿ä»£æ‰‹åŠ¨å¯ç”¨),ï¼ˆå¯ç¨åé‡å¯ï¼Œç»§ç»­ä¸‹é¢ï¼‰ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart å¯ç”¨è™šæ‹ŸæœºåŠŸèƒ½ï¼ˆè¿™éƒ¨ç»“æŸåï¼Œéœ€è¦é‡å¯ï¼‰ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart ä¸‹è½½ X64 WSL2 æ›´æ–°åŒ…ï¼Œå¹¶åŒå‡»å®‰è£… WSL2æ›´æ–°åŒ…åœ°å€ å°†WSL2è®¾ç½®ä¸ºé»˜è®¤ç‰ˆæœ¬ wsl --set-default-version 2 MIcrosoft Store å®‰è£… Ubuntu20 LTS å¯ä»¥åœ¨ Windows Terminal é€‰é¡¹å¡æ‰“å¼€ï¼Œä¹Ÿå¯ç›´æ¥æ‰“å¼€Ubuntu Win Terminal è¾“å…¥ wsl å³å¯è¿›å…¥ Ubuntu, æ¢æº cp -a /etc/apt/sources.list /etc/apt/sources.list.bak sudo sed -i &quot;s@http://.*archive.ubuntu.com@http://mirrors.huaweicloud.com@g&quot; /etc/apt/sources.list sudo sed -i &quot;s@http://.*security.ubuntu.com@http://mirrors.huaweicloud.com@g&quot; /etc/apt/sources.list sudo apt-get update æŸ¥çœ‹WSLç‰ˆæœ¬ä¿¡æ¯ä¸è¿è¡ŒçŠ¶æ€ wsl -l -v ZSH+Oh-my-zsh ZSH å®‰è£…ZSH sudo apt install zsh æŸ¥çœ‹ç‰ˆæœ¬ï¼š zsh --version å°†ZSHè®¾ä¸ºé»˜è®¤shell: chsh -s $(which zsh) é€€å‡ºå½“å‰ç”¨æˆ·linï¼Œé‡æ–°ç™»å½•ï¼Œå¹¶æŸ¥çœ‹å½“å‰æ‰€ç”¨shellï¼š echo $SHELL Oh-my-zsh å®‰è£…oh-my-zsh sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; è®¾ç½®ä¸»é¢˜ï¼šæ‰“å¼€oh-my-zshé…ç½®æ–‡ä»¶ï¼š vi ~/.zshrc ä¿®æ”¹å¦‚ä¸‹ï¼š ZSH_THEME=&quot;agnoster&quot; æ¿€æ´»ï¼š source ~/.zshrc ç»™winå·²æœ‰çš„Sublimeå’Œlocateè®¾ç½®ç¯å¢ƒå˜é‡ vi ~/.zshrc export PATH=&quot;$PATH:/mnt/d/ide/Sublime/sublime.exe&quot; export PATH=&quot;$PATH:/mnt/e/download/Everything-1.4.1.986.x86/ES-1.1.0.18/locate.exe&quot; alias sublime=sublime.exe alias locate=locate.exe æ¿€æ´»ZSHé…ç½®æ–‡ä»¶ï¼š source ~/.zshrc å¦‚ä½•åœ¨Powershellä¸­æ‰“å¼€ Ubuntu å‘½ä»¤ä¸ºï¼š wsl NOTEï¼šwslå’Œä» WTçš„å³ä¸Šè§’é€‰æ‹©Ubuntuæ˜¯ä¸€ä¸ªæ•ˆæœ ç‰¹åˆ«æ³¨æ„ï¼šä¸è¦ç”¨bashå‘½ä»¤äº†ï¼Œå› ä¸ºæˆ‘ä»¬WSLå·²ç»æŠŠBashæ¢æˆäº†ZSH Docker æ–¹å¼1ï¼šç›´æ¥ç”¨WSL2çš„è™šæ‹Ÿæœºå®‰è£…Docker curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh æ­¤è¿‡ç¨‹ä¸­ä¼šå‡ºç° sleep 20ï¼Œ å¹¶æ¨èä½ ä½¿ç”¨æ–¹å¼2ï¼Œä½†æ˜¯æˆ‘åä¸æƒ³ä½¿ç”¨æ–¹å¼2 æ‰€ä»¥ï¼Œåªéœ€ç­‰20ç§’ï¼Œä¾¿å¯æˆåŠŸé€šè¿‡æ–¹å¼1æ¥å®‰è£… Note: æ­¤æœŸé—´ä¸è¦æŒ‰Ctrl + C, å¦åˆ™ä¼šé€€å‡ºæ–¹å¼1çš„å®‰è£… æ–¹å¼2ï¼šDocker Desktop for windows https://www.docker.com/products/docker-desktop æŸ¥çœ‹DockeræœåŠ¡ sudo service docker start sudo service docker status sudo service docker stop ä½¿ç”¨Docker sudo docker run hello-world Dockerè¯­æ³•ä¸ªäººç¬”è®° =&gt; Dockerè¯­æ³• ","link":"https://cythonlin.github.io/post/pr-greater-windows-terminal-ge-xing-hua-pei-zhi/"},{"title":"PY => éŸ³å£°åˆæˆ","content":"èƒŒæ™¯ éŸ³å£°åˆæˆ åŸºäº å¾ˆä¹…ä¹‹å‰å†™çš„æ–‡ç«  éŸ³å£°åˆ†ç¦» ä¸€äº› Light Music çš„ Electronic Drum å¤ªåµäº†ã€‚ äºæ˜¯çªå‘å¥‡æƒ³ï¼Œå¦‚ä½• N v 1 åˆ†ç¦»å‡º Drum å¹¶ä¸” Drop éŸ³å£°åˆ†ç¦»ï¼ˆæ›´æ–°ä¸º5stems-16kHz Modelï¼‰ 2stems (vocals / accompaniment) spleeter separate -o audio_output -i audio_example.mp3 4stems (vocals / bass / drums / other ) spleeter separate -o audio_output -p spleeter:4stems -i audio_example.mp3 5stems (vocals / bass / drums / piano / other) spleeter separate -o audio_output -p spleeter:5stems-16kHz -i audio_example.mp3 è¿™æ¬¡ç”¨çš„æ˜¯ 5stemsé¢„è®­ç»ƒæ¨¡å‹ï¼Œ å¾—åˆ°äº†å¦‚ä¸‹5ä¸ªæ–‡ä»¶ï¼š bass.wav drums.wav other.wav piano.wav vocals.wav å¯»æ‰¾è§£å†³æ–¹æ¡ˆ æœ€å¼€å§‹ä¸çŸ¥é“ä»ä½•æœèµ·ï¼Œåæ¥ç›´æ¥ç´¢æ€§Githubè´´äº†ä¸€ä¸ª Question Issuesã€‚ æœ‰äººç»™å‡ºstackçš„è§£å†³æ–¹æ¡ˆï¼Œ ä¸ªäººç®€åŒ–ä½¿ç”¨å¦‚ä¸‹ï¼š ffmpeg -i other.wav -i vocals.wav -i bass.wav -i piano.wav -filter_complex amix=inputs=4:duration=longest output.mp3 ç»“æœ æœ€ç»ˆæˆåŠŸæŠŠ Electronic Drum å£° Dropã€‚ å”¯ä¸€ç¾ä¸­ä¸è¶³çš„å°±æ˜¯ï¼Œ5ä¸ªStemsé¢„è®­ç»ƒæ¨¡å‹åˆ†çš„ä¸å¤Ÿç»†è‡´, Github Wikiæœ€æ–°æ–¹æ¡ˆçš„å°±æ˜¯5stems~ ","link":"https://cythonlin.github.io/post/py-greater-yin-sheng-he-cheng/"},{"title":"PY => Github-Cli","content":"ä¸‹è½½ é€‰ä¸ªOSç‰ˆæœ¬ï¼ˆæˆ‘ç”¨çš„Winï¼‰ï¼šhttps://github.com/cli/cli/releases åˆ—å‡ºé…ç½® git config --list ç”±äºæˆ‘github2ä¸ªå·åˆ‡æ¢ï¼Œå¯¼è‡´ï¼Œpushçš„æ—¶å€™æœ‰403é”™è¯¯æ··æ·†ï¼Œ æ‰€ä»¥åˆ é™¤äº†å®¶ç›®å½•çš„ .gitconfig(åº”è¯¥æ˜¯è¿™ä¸ªæœ‰äº›è®°ä¸æ¸…äº†) è®¾ç½®ä»£ç† ä¸ºäº†åŠ é€Ÿcloneï¼Œè¿™é‡Œå…ˆè®¾ç½®ï¼Œè‹¥æ²¡æœ‰PROXY, é‚£æ­¤æ­¥å¯ç•¥è¿‡ git config --global http.proxy &quot;socks5://127.0.0.1:7890&quot; git config --global https.proxy &quot;socks5://127.0.0.1:7890&quot; æ¸…é™¤ä»£ç†ä¹Ÿå¾ˆç®€å• git config --global --unset http.proxy git config --global --unset https.proxy è®¾ç½®SSH Key è¯´æ˜ å¦‚æœä½ ä¸ä¹ æƒ¯ç”¨SSHï¼Œè€Œæ˜¯ä¹ æƒ¯ç”¨HTTPçš„æ–¹å¼ï¼Œé‚£è¿™æ­¥å¯çœ ç”Ÿæˆå¯†é’¥å‘½ä»¤ ssh-keygen è¿›å…¥ç”¨æˆ·å®¶ç›®å½•ï¼ŒæŠŠid_rsa.pubå…¬é’¥å¤åˆ¶å‡ºæ¥ ç²˜è´´åˆ°-&gt; https://github.com/settings/ssh/new ç™»å½• gh auth login æå‰å£°æ˜ï¼Œé‡åˆ°é€‰é¡¹ï¼Œéƒ½æ˜¯ç”¨ä¸Šä¸‹ç®­å¤´é€‰æ‹© ç¬¬1ä¸ªé€‰é¡¹ï¼š é€‰æ‹©Github.comï¼ˆä¹Ÿå°±æ˜¯ä¸ªäººç”¨æˆ·ï¼‰ ç¬¬2ä¸ªé€‰é¡¹ï¼šé€‰æ‹© Login with a web browser Commandä¸­ä¼šç»™ä¸€ä¸²ä»£ç ï¼Œå¤åˆ¶ä»£ç -&gt;CMDå›è½¦-&gt;è‡ªåŠ¨è·³è½¬åˆ°Web-&gt;ç²˜è´´ä»£ç -&gt;ç¡®è®¤-&gt;ç¡®è®¤æˆæƒ è¿™é‡Œä¹Ÿå¯ä»¥é€‰æ‹©ä½¿ç”¨ Token ä»£æ›¿ web browserã€‚ä½†æ˜¯è¿™ç§æ–¹å¼éœ€è¦ç”Ÿæˆä¸€ä¸ªToken ç”ŸæˆURLå¦‚ä¸‹ï¼š : -&gt; https://github.com/settings/tokens ç‚¹å‡» Generate bew token ï¼Œæ–°å»ºä¸€ä¸ªæ–° tokenï¼š æ³¨æ„ï¼š éœ€è¦æŠŠ repoçš„æ‰€æœ‰æƒé™å‹¾ä¸Š å¤–åŠ ä¸€ä¸ªadmin:orgä¸‹é¢çš„ read:org é€‰é¡¹ æ¸©é¦¨æç¤ºï¼š read:org å¿…é¡»å‹¾ä¸Šï¼Œä¸ç„¶åˆ›å»ºå¤±è´¥ã€‚ ç¬¬3ä¸ªé€‰é¡¹ï¼šé€‰æ‹©SSHï¼ˆHTTPSä¹Ÿå¯ä»¥ï¼‰ æŸ¥çœ‹ç™»å½•çŠ¶æ€ gh auth status é€€å‡ºç™»å½• gh auth logout ä»“åº“ åˆ›å»ºä»“åº“ gh repo create my-gh -&gt; Public -&gt; xxx in your current directoryï¼ˆY/Nï¼‰ y (å›è½¦é»˜è®¤å°±æ˜¯yesï¼Œä¸‹åŒ) -&gt; Create a local project directory for xxx ï¼ˆY/Nï¼‰y æŸ¥çœ‹è¿œç¨‹æƒé™ git remote -v origin https://github.com/Cythonlin/my-gh.git (fetch) origin https://github.com/Cythonlin/my-gh.git (push) å…‹éš† gh repo clone gin-gonic/gin cd gin git remote -v origin https://github.com/gin-gonic/gin.git (fetch) origin https://github.com/gin-gonic/gin.git (push) # æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œè¿™åˆ†æ”¯å¹¶ä¸æ˜¯æˆ‘ä»¬çš„è‡ªå·±çš„ # æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ fork ä¸‹æ¥ fork fork æŒ‡çš„æ˜¯ï¼ŒæŠŠå…‹éš†åˆ°è‡ªå·±çš„ä»“åº“ï¼Œä½œä¸ºä¸Šæ¸¸ï¼ˆupstreamï¼‰é¡¹ç›®ï¼Œç„¶åè‡ªå·±å°±å¯è‡ªç”±åŒæ­¥å®ƒ cd gin # ä¸Šé¢å·²ç»è¿›æ­¤è·¯å¾„ï¼Œè¿™æ­¥å¯çœ gh repo fork -&gt; Would you like to add a remote for the fork? (Y/n) å›è½¦yes ä¸Šé¢æ˜¯å…ˆclone,ç„¶åè¿›å…¥è·¯å¾„ï¼Œå†fork å¦‚æœäº‹å…ˆæœªcloneï¼Œ ä¹Ÿå¯ä»¥ç”¨gh repo fork + ç”¨æˆ·å/ä»“åº“åï¼Œ ç›´æ¥ fork+cloneä¸€æ­¥åˆ°ä½ # è¿™å°±ä¸éœ€è¦åƒä¸Šé¢å…ˆ cdè¿›å…¥cloneçš„ç›®å½•ä¸‹å†forkäº†ï¼Œè¿™ç§æ–¹å¼ç›´æ¥forkå³å¯ gh repo fork pytorch/pytorch Gist gistæ˜¯githubåˆ†äº«æ•°æ®å†…å®¹çš„å¹³å° -&gt; https://gist.github.com/ ä¸Šé¢çš„åœ°å€å¯ä»¥åˆ†äº«å…¬æœ‰/ç§æœ‰çš„æ–‡ä»¶ï¼Œåˆ›å»ºä¸Šä¼ åï¼ŒGithubä¼šè·³è½¬ç”Ÿæˆä¸€ä¸ªé“¾æ¥ï¼Œæ¥ç»™æˆ‘ä»¬ä½¿ç”¨ github-cliå®ç°Gist é»˜è®¤æ˜¯ç§æœ‰çš„ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š gh gist create 1.txt å…¬æœ‰å‘½ä»¤å¦‚ä¸‹ï¼š gh gist create 1.txt --public äºŒè€…éƒ½ä¼šç”Ÿæˆä¸ªURLï¼Œå³å¯è®¿é—®ã€‚ ä¹Ÿå¯ä»¥ä¸€ä¸ªgistä¸­å­˜2ä¸ªæ–‡ä»¶ï¼š gh gist create 1.txt 2.txt ä¿®æ”¹ Gistå…±äº«çš„æ–‡ä»¶ï¼Œå‚æ•°ä¸ºç”Ÿæˆurlçš„å°¾éƒ¨è·¯å¾„å‚æ•° gh gist edit 5ff497631f0cc1e0a4463079a6a9eeff åˆ—å‡º ä¸Šä¼ è¿‡çš„Gistæ–‡ä»¶, --publicä»£è¡¨å…¬æœ‰æ–‡ä»¶ï¼Œ--secretç§æœ‰, ä¸åŠ å‚æ•°ä»£è¡¨æ‰€æœ‰ gh gist list gh gist list --secret gh gist list --public PR (Pull Requestï¼‰ PRæ¦‚å¿µ &quot;æˆ‘forkäº†ä½ ä»¬çš„ä»£ç ï¼Œç°åœ¨æˆ‘å‘é€ä¸€ä¸ªè¯·æ±‚ï¼Œè¯·ä½ ä»¬å›æ”¶æˆ‘çš„ä»£ç &quot;ğŸ˜‚ PRæµç¨‹ forkåˆ«äººä»“åº“ï¼ˆå…ˆforkåœ¨cloneï¼Œ å‰é¢å·²ç»æåˆ° gh å¯ä»¥ç›´æ¥forkä¸€æ­¥åˆ°ä½äº†ï¼‰ åˆ‡æ¢åˆ†æ”¯ï¼ˆä¹Ÿå¯ä»¥åœ¨ master ä¸‹ï¼‰ï¼Œadd,commit,push ä¿®æ”¹ä»£ç ã€‚ åœ¨ä½ forkåçš„ä»“åº“ä¸»é¡µç‚¹å‡»å³ä¸Šè§’çš„ Compare &amp; pull request æäº¤åˆå¹¶ç”³è¯· ç­‰å¾…åˆ«äººåˆå¹¶ä½ çš„è¯·æ±‚ å®éªŒæµç¨‹ ä¸€ã€ç”¨å½“å‰çš„å·ï¼Œå» forkå¦ä¸€ä¸ªå·ï¼ˆå¦å¤–é‚£ä¸ªä¹Ÿæ˜¯è‡ªå·±çš„å·æ–¹ä¾¿åšå®éªŒï¼‰çš„ä»“åº“ã€‚ gh repo fork hacker-lin/bio2bioes cd bio2bioes äºŒã€ åˆ›å»º+åˆ‡æ¢åˆ†æ”¯+add+commit+push+add git checkout -b dev echo 111 &gt; 1.txt git add . &amp;&amp; git commit -m &quot;my_test&quot; åˆ°è¿™é‡Œå³å¯ï¼Œå…ˆä¸è¦pushï¼ˆä¸‹é¢PRåˆ›å»ºçš„è¿‡ç¨‹ï¼Œä¼šè‡ªåŠ¨å¸®æˆ‘ä»¬pushï¼Œè¿™é‡Œpushæˆ‘è¯•äº†ä¼šå‡ºé”™ï¼‰ ä¸‰ã€ç”¨GitHUB-Cliå‘½ä»¤ ä»£æ›¿ ç‚¹å‡»Compare &amp; pull request æŒ‰é’®æäº¤åˆå¹¶ç”³è¯· åˆ›å»ºPR gh pr create -&gt; Where should we push the 'dev' branch # é€‰ç¬¬ä¸€ä¸ª -&gt; Title # éšä¾¿å†™ä¸ª some update -&gt; Body # ç›´æ¥ å›è½¦ è·³è¿‡å°±è¡Œã€‚ -&gt; What's next? # é€‰ Submit æäº¤å³å¯ åˆ—å‡ºæäº¤çš„PR gh pr list # æ‰§è¡Œåï¼Œä½ ä¼šå‘ç° PRä¿¡æ¯ï¼Œ # åé¢çš„æ•°å­—è®°ä½ä¸‹é¢Closedå’Œdiffç”¨å¾—åˆ° Merge PR gh pr merge -&gt; What merge method would you like to use # Create a merge commitå³å¯ Closed PR gh pr close 3 # è¿™ä¸ª3 å°±æ˜¯ä¸Šé¢ gh pr list çš„ç»“æœ æ¯”è¾ƒ PR ä¿¡æ¯ gh pr diff 3 # æœ€ä¸‹é¢æ˜¯æœ€æ–°çš„ æŸ¥çœ‹ PR è¯¦ç»†ä¿¡æ¯ gh pr status ","link":"https://cythonlin.github.io/post/py-greater-github-cli-quan-tao/"},{"title":"GO => äº¤æ¢å…ƒç´ çš„å››ç§æ–¹å¼","content":"Python and Go ä¸‹é¢ä»£ç ï¼Œé™¤äº†æ•°æ®å£°æ˜ä¸å®šä¹‰ï¼Œå…¶ä»–Py å’Œ Go çš„è¯­æ³•éƒ½æ˜¯ä¸€æ‘¸ä¸€æ ·çš„ï¼ˆä¸»è¦å¼ºè°ƒ å¼‚æˆ–æ–¹å¼ï¼‰ a := 1 b := 3 æ–¹å¼0 c := 0 c = a a = b b = c æ–¹å¼1 a,b = b,a æ–¹å¼2 a = a + b b = a - b a = a - b æ–¹å¼3 ï¼ˆæ³¨ï¼šå¿…é¡»æ˜¯æ•´å½¢ï¼Œ Pyä¹Ÿä¸€æ ·ï¼‰ a = a ^ b b = a ^ b a = a ^ b fmt.Println(a) fmt.Println(b) ","link":"https://cythonlin.github.io/post/go-greater-jiao-huan-yuan-su-de-si-chong-fang-shi/"},{"title":"RS => æ¨èç³»ç»Ÿï¼ˆä¸‰ï¼‰ç¦»çº¿å¬å›ä¸æ’åº ","content":"å¬å›è®¾è®¡ å¬å›æ’åºæµç¨‹ åŒ¿åç”¨æˆ·ï¼š é€šå¸¸ä½¿ç”¨ç”¨æˆ·å†·å¯åŠ¨æ–¹æ¡ˆï¼ŒåŒºåˆ«åœ¨äºuser_idä¸ºåŒ¿åç”¨æˆ·æ‰‹æœºè¯†åˆ«å·(é»‘é©¬å¤´æ¡ä¸å…è®¸åŒ¿åç”¨æˆ·) æ‰€æœ‰åªæ­£é’ˆå¯¹äºç™»å½•ç”¨æˆ·ï¼š ç”¨æˆ·å†·å¯åŠ¨ï¼ˆå‰æœŸç‚¹å‡»è¡Œä¸ºè¾ƒå°‘æƒ…å†µï¼‰ éä¸ªæ€§åŒ–æ¨è çƒ­é—¨å¬å›ï¼šè‡ªå®šä¹‰çƒ­é—¨è§„åˆ™ï¼Œæ ¹æ®å½“å‰æ—¶é—´æ®µçƒ­ç‚¹å®šæœŸæ›´æ–°ç»´æŠ¤äººç‚¹æ–‡ç« åº“ æ–°æ–‡ç« å¬å›ï¼šä¸ºäº†æé«˜æ–°æ–‡ç« çš„æ›å…‰ç‡ï¼Œå»ºç«‹æ–°æ–‡ç« åº“ï¼Œè¿›è¡Œæ¨è ä¸ªæ€§åŒ–æ¨èï¼š åŸºäºå†…å®¹çš„ååŒè¿‡æ»¤åœ¨çº¿å¬å›ï¼šåŸºäºç”¨æˆ·å®æ—¶å…´è¶£ç”»åƒç›¸ä¼¼çš„å¬å›ç»“æœç”¨äºé¦–é¡µçš„ä¸ªæ€§åŒ–æ¨è åæœŸç¦»çº¿éƒ¨åˆ†ï¼ˆç”¨æˆ·ç‚¹å‡»è¡Œä¸ºè¾ƒå¤šï¼Œç”¨æˆ·ç”»åƒå®Œå–„ï¼‰ å»ºç«‹ç”¨æˆ·é•¿æœŸå…´è¶£ç”»åƒï¼ˆè¯¦ç»†ï¼‰ï¼šåŒ…æ‹¬ç”¨æˆ·å„ä¸ªç»´åº¦çš„å…´è¶£ç‰¹å¾ è®­ç»ƒæ’åºæ¨¡å‹ LRæ¨¡å‹ã€FTRLã€Wide&amp;Deep ç¦»çº¿éƒ¨åˆ†çš„å¬å›ï¼š åŸºäºæ¨¡å‹ååŒè¿‡æ»¤æ¨èç¦»çº¿å¬å›ï¼šALS åŸºäºå†…å®¹çš„ç¦»çº¿å¬å›ï¼šæˆ–è€…ç§°åŸºäºç”¨æˆ·ç”»åƒçš„å¬å› å¬å›è¡¨è®¾è®¡ä¸æ¨¡å‹å¬å› å¬å›è¡¨è®¾è®¡ æˆ‘ä»¬çš„å¬å›æ–¹å¼æœ‰å¾ˆå¤šç§ã€‚ å¤šè·¯å¬å›ç»“æœå­˜å‚¨æ¨¡å‹å¬å› ä¸ å†…å®¹å¬å›çš„ç»“æœ éœ€è¦è¿›è¡Œç›¸åº”é¢‘é“æ¨èåˆå¹¶ã€‚ æ–¹æ¡ˆï¼šåŸºäºæ¨¡å‹ä¸åŸºäºå†…å®¹çš„å¬å›ç»“æœå­˜å…¥åŒä¸€å¼ è¡¨ï¼Œé¿å…å¤šå¼ è¡¨è¿›è¡Œè¯»å–å¤„ç† ç”±äºHBASEæœ‰å¤šä¸ªç‰ˆæœ¬æ•°æ®åŠŸèƒ½å­˜åœ¨çš„æ”¯æŒ TTL=&gt;7776000, VERSIONS=&gt;999999 å¦‚ä¸‹ï¼š create 'cb_recall', {NAME=&gt;'als', TTL=&gt;7776000, VERSIONS=&gt;999999} alter 'cb_recall', {NAME=&gt;'content', TTL=&gt;7776000, VERSIONS=&gt;999999} alter 'cb_recall', {NAME=&gt;'online', TTL=&gt;7776000, VERSIONS=&gt;999999} # ä¾‹å­ï¼ˆå¤šç‰ˆæœ¬ï¼‰ï¼š put 'cb_recall', 'recall:user:5', 'als:1',[45,3,5,10] put 'cb_recall', 'recall:user:5', 'als:1',[289,11,65,52,109,8] put 'cb_recall', 'recall:user:5', 'als:2',[1,2,3,4,5,6,7,8,9,10] put 'cb_recall', 'recall:user:2', 'content:1',[45,3,5,10,289,11,65,52,109,8] put 'cb_recall', 'recall:user:2', 'content:2',[1,2,3,4,5,6,7,8,9,10] hbase(main):084:0&gt; desc 'cb_recall' Table cb_recall is ENABLED cb_recall COLUMN FAMILIES DESCRIPTION {NAME =&gt; 'als', VERSIONS =&gt; '999999', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'false' , KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; '7776000 SECONDS (90 DAYS)', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', CACHE _INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS_ON_ OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'} {NAME =&gt; 'content', VERSIONS =&gt; '999999', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'fa lse', KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; '7776000 SECONDS (90 DAYS)', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', C ACHE_INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS _ON_OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'} {NAME =&gt; 'online', VERSIONS =&gt; '999999', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'fal se', KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; '7776000 SECONDS (90 DAYS)', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', CA CHE_INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS_ ON_OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'} 3 row(s) ï¼ˆå‡ ä¹ä¸ç”¨ï¼‰åœ¨HIVEç”¨æˆ·æ•°æ®æ•°æ®åº“ä¸‹å»ºç«‹HIVEå¤–éƒ¨è¡¨,è‹¥hbaseè¡¨æœ‰ä¿®æ”¹ï¼Œåˆ™è¿›è¡ŒHIVE è¡¨åˆ é™¤æ›´æ–° create external table cb_recall_hbase( user_id STRING comment &quot;userID&quot;, als map&lt;string, ARRAY&gt; comment &quot;als recall&quot;, content map&lt;string, ARRAY&gt; comment &quot;content recall&quot;, online map&lt;string, ARRAY&gt; comment &quot;online recall&quot;) COMMENT &quot;user recall table&quot; STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,als:,content:,online:&quot;) TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;cb_recall&quot;); å¢åŠ ä¸€ä¸ªå†å²å¬å›ç»“æœè¡¨ create 'history_recall', {NAME=&gt;'channel', TTL=&gt;7776000, VERSIONS=&gt;999999} put 'history_recall', 'recall:user:5', 'als:1',[1,2,3] put 'history_recall', 'recall:user:5', 'als:1',[4,5,6,7] put 'history_recall', 'recall:user:5', 'als:1',[8,9,10] ä¸ºä»€ä¹ˆå¢åŠ å†å²å¬å›è¡¨ï¼Ÿ 1ã€ç›´æ¥åœ¨å­˜å‚¨å¬å›ç»“æœéƒ¨åˆ†è¿›è¡Œè¿‡æ»¤ï¼Œæ¯”ä¹‹åæ’åºè¿‡æ»¤ï¼ŒèŠ‚çœæ’åºæ—¶é—´ 2ã€é˜²æ­¢Redisç¼“å­˜æ²¡æœ‰æ¶ˆè€—å®Œï¼Œé€ æˆé‡å¤æ¨èï¼Œä»æºå¤´è¿›è¡Œè¿‡æ»¤ åŸºäºæ¨¡å‹å¬å›é›†åˆè®¡ç®— ALSæ¨¡å‹æ¨èå®ç° æ­¥éª¤ï¼š 1ã€æ•°æ®ç±»å‹è½¬æ¢,clickedä»¥åŠç”¨æˆ·IDä¸æ–‡ç« IDå¤„ç† 2ã€ALSæ¨¡å‹è®­ç»ƒä»¥åŠæ¨è 3ã€æ¨èç»“æœè§£æå¤„ç† 4ã€æ¨èç»“æœå­˜å‚¨ æ•°æ®ç±»å‹è½¬æ¢,clicked( bool è½¬ int) ur.spark.sql(&quot;use profile&quot;) user_article_click = ur.spark.sql(&quot;select * from user_article_basic&quot;). select(['user_id', 'article_id', 'clicked']) # æ›´æ¢ç±»å‹ def change_types(row): return row.user_id, row.article_id, int(row.clicked) user_article_click = user_article_click.rdd.map(change_types).toDF(['user_id', 'article_id', 'clicked']) è¿™æ­¥å¤„ç†ç»“æœæ ¼å¼å¦‚ä¸‹ï¼š user_id article_id clicked 0 1 ç”¨æˆ·IDä¸æ–‡ç« IDå¤„ç†ï¼Œç¼–ç¨‹IDç´¢å¼•ï¼ˆåŸç”¨æˆ·IDå’Œæ–‡ç« IDæ˜¯é•¿å­—ç¬¦ä¸²ï¼ŒALSæ¨¡å‹ä¸èƒ½å¤„ç†ï¼Œè¦é‡æ–°ç¼–æ’IDç´¢å¼•ï¼‰ from pyspark.ml.feature import StringIndexer from pyspark.ml import Pipeline # ç”¨æˆ·å’Œæ–‡ç« IDè¶…è¿‡ALSæœ€å¤§æ•´æ•°å€¼ï¼Œéœ€è¦ä½¿ç”¨StringIndexerè¿›è¡Œè½¬æ¢ user_id_indexer = StringIndexer(inputCol='user_id', outputCol='als_user_id') article_id_indexer = StringIndexer(inputCol='article_id', outputCol='als_article_id') pip = Pipeline(stages=[user_id_indexer, article_id_indexer]) pip_fit = pip.fit(user_article_click) als_user_article_click = pip_fit.transform(user_article_click) ALS æ¨¡å‹è®­ç»ƒä¸æ¨èï¼ˆALSæ¨¡å‹éœ€è¦è¾“å‡ºç”¨æˆ·IDåˆ—ï¼Œæ–‡ç« IDåˆ—ä»¥åŠç‚¹å‡»åˆ—ï¼‰ from pyspark.ml.recommendation import ALS # æ¨¡å‹è®­ç»ƒå’Œæ¨èé»˜è®¤æ¯ä¸ªç”¨æˆ·å›ºå®šæ–‡ç« ä¸ªæ•° als = ALS(userCol='als_user_id', itemCol='als_article_id', ratingCol='clicked', checkpointInterval=1) model = als.fit(als_user_article_click) recall_res = model.recommendForAllUsers(100) ç»“æœï¼š als_user_id recommendations 1 [[article_id, åˆ†æ•°]] æ¨èç»“æœå¤„ç† é€šè¿‡StringIndexerå˜æ¢åçš„ä¸‹æ ‡çŸ¥é“åŸæ¥çš„å’Œç”¨æˆ·ID # recall_reså¾—åˆ°éœ€è¦ä½¿ç”¨StringIndexerå˜æ¢åçš„ä¸‹æ ‡ # ä¿å­˜åŸæ¥çš„ä¸‹è¡¨æ˜ å°„å…³ç³» refection_user = als_user_article_click.groupBy(['user_id']).max('als_user_id').withColumnRenamed( 'max(als_user_id)', 'als_user_id') refection_article = als_user_article_click.groupBy(['article_id']).max('als_article_id').withColumnRenamed( 'max(als_article_id)', 'als_article_id') # Joinæ¨èç»“æœä¸ refection_useræ˜ å°„å…³ç³»è¡¨ # +-----------+--------------------+-------------------+ # | als_user_id | recommendations | user_id | # +-----------+--------------------+-------------------+ # | 8 | [[163, 0.91328144]... | 2 | # | 0 | [[145, 0.653115], ... | 1106476833370537984 | recall_res = recall_res.join(refection_user, on=['als_user_id'], how='left').select( ['als_user_id', 'recommendations', 'user_id']) å¯¹æ¨èæ–‡ç« IDåå¤„ç†ï¼šå¾—åˆ°æ¨èåˆ—è¡¨,è·å–æ¨èåˆ—è¡¨ä¸­çš„IDç´¢å¼• # Joinæ¨èç»“æœä¸ refection_articleæ˜ å°„å…³ç³»è¡¨ # +-----------+-------+----------------+ # | als_user_id | user_id | als_article_id | # +-----------+-------+----------------+ # | 8 | 2 | [163, 0.91328144] | # | 8 | 2 | [132, 0.91328144] | import pyspark.sql.functions as F recall_res = recall_res.withColumn('als_article_id', F.explode('recommendations')).drop('recommendations') # +-----------+-------+--------------+ # | als_user_id | user_id | als_article_id | # +-----------+-------+--------------+ # | 8 | 2 | 163 | # | 8 | 2 | 132 | def _article_id(row): return row.als_user_id, row.user_id, row.als_article_id[0] è¿›è¡Œç´¢å¼•å¯¹åº”æ–‡ç« IDè·å– als_recall = recall_res.rdd.map(_article_id).toDF(['als_user_id', 'user_id', 'als_article_id']) als_recall = als_recall.join(refection_article, on=['als_article_id'], how='left').select( ['user_id', 'article_id']) # å¾—åˆ°æ¯ä¸ªç”¨æˆ·ID å¯¹åº”æ¨èæ–‡ç«  # +-------------------+----------+ # | user_id | article_id | # +-------------------+----------+ # | 1106476833370537984 | 44075 | # | 1 | 44075 | è·å–æ¯ä¸ªæ–‡ç« å¯¹åº”çš„é¢‘é“ï¼Œæ¨èç»™ç”¨æˆ·æ—¶æŒ‰ç…§é¢‘é“å­˜å‚¨: ur.spark.sql(&quot;use toutiao&quot;) news_article_basic = ur.spark.sql(&quot;select article_id, channel_id from news_article_basic&quot;) als_recall = als_recall.join(news_article_basic, on=['article_id'], how='left') als_recall = als_recall.groupBy(['user_id', 'channel_id']).agg(F.collect_list('article_id')).withColumnRenamed( 'collect_list(article_id)', 'article_list') als_recall = als_recall.dropna() å¬å›ç»“æœå­˜å‚¨ HBASEè¡¨è®¾è®¡æ¦‚è§ˆï¼š put 'cb_recall', 'recall:user:5', 'als:1',[45,3,5,10,289,11,65,52,109,8] put 'cb_recall', 'recall:user:5', 'als:2',[1,2,3,4,5,6,7,8,9,10] å­˜å‚¨ä»£ç å¦‚ä¸‹ï¼š def save_offline_recall_hbase(partition): &quot;&quot;&quot;ç¦»çº¿æ¨¡å‹å¬å›ç»“æœå­˜å‚¨ &quot;&quot;&quot; import happybase pool = happybase.ConnectionPool(size=10, host='hadoop-master', port=9090) for row in partition: with pool.connection() as conn: # è·å–å†å²çœ‹è¿‡çš„è¯¥é¢‘é“æ–‡ç«  history_table = conn.table('history_recall') # å¤šä¸ªç‰ˆæœ¬ data = history_table.cells('reco:his:{}'.format(row.user_id).encode(), 'channel:{}'.format(row.channel_id).encode()) history = [] if len(data) &gt;= 2: for l in data[:-1]: history.extend(eval(l)) else: history = [] # è¿‡æ»¤reco_articleä¸history reco_res = list(set(row.article_list) - set(history)) if reco_res: table = conn.table('cb_recall') # é»˜è®¤æ”¾åœ¨æ¨èé¢‘é“ table.put('recall:user:{}'.format(row.user_id).encode(), {'als:{}'.format(row.channel_id).encode(): str(reco_res).encode()}) # æ”¾å…¥å†å²æ¨èè¿‡æ–‡ç«  history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(), {'channel:{}'.format(row.channel_id): str(reco_res).encode()}) conn.close() als_recall.foreachPartition(save_offline_recall_hbase) ç¦»çº¿ç”¨æˆ·åŸºäºå†…å®¹å¬å›é›† ç›®æ ‡ çŸ¥é“ç¦»çº¿å†…å®¹å¬å›çš„æ¦‚å¿µ çŸ¥é“å¦‚ä½•è¿›è¡Œå†…å®¹å¬å›è®¡ç®—å­˜å‚¨è§„åˆ™ åº”ç”¨ åº”ç”¨sparkå®Œæˆç¦»çº¿ç”¨æˆ·åŸºäºå†…å®¹çš„ååŒè¿‡æ»¤æ¨è åŸºäºå†…å®¹å¬å›å®ç°ï¼ˆæ–‡ç« å‘é‡ä¹‹å‰å·²ç»å¼„å¥½äº†ï¼‰ è¿‡æ»¤ç”¨æˆ·ç‚¹å‡»çš„æ–‡ç«  # åŸºäºå†…å®¹ç›¸ä¼¼å¬å›ï¼ˆç”»åƒå¬å›ï¼‰ ur.spark.sql(&quot;use profile&quot;) user_article_basic = self.spark.sql(&quot;select * from user_article_basic&quot;) user_article_basic = user_article_basic.filter(&quot;clicked=True&quot;) def save_content_filter_history_to__recall(partition): &quot;&quot;&quot;è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„æ¯ä¸ªæ“ä½œæ–‡ç« çš„ç›¸ä¼¼æ–‡ç« ï¼Œè¿‡æ»¤ä¹‹åï¼Œå†™å…¥contentå¬å›è¡¨å½“ä¸­ï¼ˆæ”¯æŒä¸åŒæ—¶é—´æˆ³ç‰ˆæœ¬ï¼‰ &quot;&quot;&quot; import happybase pool = happybase.ConnectionPool(size=10, host='hadoop-master') # è¿›è¡Œä¸ºç›¸ä¼¼æ–‡ç« è·å– with pool.connection() as conn: # key: article_id, column: similar:article_id similar_table = conn.table('article_similar') # å¾ªç¯partition for row in partition: # è·å–ç›¸ä¼¼æ–‡ç« ç»“æœè¡¨ similar_article = similar_table.row(str(row.article_id).encode(), columns=[b'similar']) # ç›¸ä¼¼æ–‡ç« ç›¸ä¼¼åº¦æ’åºè¿‡æ»¤ï¼Œå¬å›ä¸éœ€è¦å¤ªå¤§çš„æ•°æ®ï¼Œ ç™¾ä¸ªï¼Œåƒ _srt = sorted(similar_article.items(), key=lambda item: item[1], reverse=True) if _srt: # æ¯æ¬¡è¡Œä¸ºæ¨è10ç¯‡æ–‡ç«  reco_article = [int(i[0].split(b':')[1]) for i in _srt][:10] # è·å–å†å²çœ‹è¿‡çš„è¯¥é¢‘é“æ–‡ç«  history_table = conn.table('history_recall') # å¤šä¸ªç‰ˆæœ¬ data = history_table.cells('reco:his:{}'.format(row.user_id).encode(), 'channel:{}'.format(row.channel_id).encode()) history = [] if len(data) &gt;= 2: for l in data[:-1]: history.extend(eval(l)) else: history = [] # è¿‡æ»¤reco_articleä¸history reco_res = list(set(reco_article) - set(history)) # è¿›è¡Œæ¨èï¼Œæ”¾å…¥åŸºäºå†…å®¹çš„å¬å›è¡¨å½“ä¸­ä»¥åŠå†å²çœ‹è¿‡çš„æ–‡ç« è¡¨å½“ä¸­ if reco_res: # content_table = conn.table('cb_content_recall') content_table = conn.table('cb_recall') content_table.put(&quot;recall:user:{}&quot;.format(row.user_id).encode(), {'content:{}'.format(row.channel_id).encode(): str(reco_res).encode()}) # æ”¾å…¥å†å²æ¨èè¿‡æ–‡ç«  history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(), {'channel:{}'.format(row.channel_id).encode(): str(reco_res).encode()}) conn.close() user_article_basic.foreachPartition(save_content_filter_history_to__recall) ç¦»çº¿ç”¨æˆ·å¬å›å®šæ—¶æ›´æ–° å®šæ—¶æ›´æ–°ä»£ç  import os import sys # å¦‚æœå½“å‰ä»£ç æ–‡ä»¶è¿è¡Œæµ‹è¯•éœ€è¦åŠ å…¥ä¿®æ”¹è·¯å¾„ï¼Œå¦åˆ™åé¢çš„å¯¼åŒ…å‡ºç°é—®é¢˜ BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) sys.path.insert(0, os.path.join(BASE_DIR)) from pyspark.ml.feature import StringIndexer from pyspark.ml import Pipeline from pyspark.ml.recommendation import ALS from offline import SparkSessionBase from datetime import datetime import time import numpy as np class UpdateRecall(SparkSessionBase): SPARK_APP_NAME = &quot;updateRecall&quot; ENABLE_HIVE_SUPPORT = True def __init__(self, number): self.spark = self._create_spark_session() self.N = number def update_als_recall(self): &quot;&quot;&quot; æ›´æ–°åŸºäºæ¨¡å‹ï¼ˆALSï¼‰çš„ååŒè¿‡æ»¤å¬å›é›† :return: &quot;&quot;&quot; # è¯»å–ç”¨æˆ·è¡Œä¸ºåŸºæœ¬è¡¨ self.spark.sql(&quot;use profile&quot;) user_article_click = self.spark.sql(&quot;select * from user_article_basic&quot;).\\ select(['user_id', 'article_id', 'clicked']) # æ›´æ¢ç±»å‹ def change_types(row): return row.user_id, row.article_id, int(row.clicked) user_article_click = user_article_click.rdd.map(change_types).toDF(['user_id', 'article_id', 'clicked']) # ç”¨æˆ·å’Œæ–‡ç« IDè¶…è¿‡ALSæœ€å¤§æ•´æ•°å€¼ï¼Œéœ€è¦ä½¿ç”¨StringIndexerè¿›è¡Œè½¬æ¢ user_id_indexer = StringIndexer(inputCol='user_id', outputCol='als_user_id') article_id_indexer = StringIndexer(inputCol='article_id', outputCol='als_article_id') pip = Pipeline(stages=[user_id_indexer, article_id_indexer]) pip_fit = pip.fit(user_article_click) als_user_article_click = pip_fit.transform(user_article_click) # æ¨¡å‹è®­ç»ƒå’Œæ¨èé»˜è®¤æ¯ä¸ªç”¨æˆ·å›ºå®šæ–‡ç« ä¸ªæ•° als = ALS(userCol='als_user_id', itemCol='als_article_id', ratingCol='clicked', checkpointInterval=1) model = als.fit(als_user_article_click) recall_res = model.recommendForAllUsers(self.N) # recall_reså¾—åˆ°éœ€è¦ä½¿ç”¨StringIndexerå˜æ¢åçš„ä¸‹æ ‡ # ä¿å­˜åŸæ¥çš„ä¸‹è¡¨æ˜ å°„å…³ç³» refection_user = als_user_article_click.groupBy(['user_id']).max('als_user_id').withColumnRenamed( 'max(als_user_id)', 'als_user_id') refection_article = als_user_article_click.groupBy(['article_id']).max('als_article_id').withColumnRenamed( 'max(als_article_id)', 'als_article_id') # Joinæ¨èç»“æœä¸ refection_useræ˜ å°„å…³ç³»è¡¨ # +-----------+--------------------+-------------------+ # | als_user_id | recommendations | user_id | # +-----------+--------------------+-------------------+ # | 8 | [[163, 0.91328144]... | 2 | # | 0 | [[145, 0.653115], ... | 1106476833370537984 | recall_res = recall_res.join(refection_user, on=['als_user_id'], how='left').select( ['als_user_id', 'recommendations', 'user_id']) # Joinæ¨èç»“æœä¸ refection_articleæ˜ å°„å…³ç³»è¡¨ # +-----------+-------+----------------+ # | als_user_id | user_id | als_article_id | # +-----------+-------+----------------+ # | 8 | 2 | [163, 0.91328144] | # | 8 | 2 | [132, 0.91328144] | import pyspark.sql.functions as F recall_res = recall_res.withColumn('als_article_id', F.explode('recommendations')).drop('recommendations') # +-----------+-------+--------------+ # | als_user_id | user_id | als_article_id | # +-----------+-------+--------------+ # | 8 | 2 | 163 | # | 8 | 2 | 132 | def _article_id(row): return row.als_user_id, row.user_id, row.als_article_id[0] als_recall = recall_res.rdd.map(_article_id).toDF(['als_user_id', 'user_id', 'als_article_id']) als_recall = als_recall.join(refection_article, on=['als_article_id'], how='left').select( ['user_id', 'article_id']) # å¾—åˆ°æ¯ä¸ªç”¨æˆ·ID å¯¹åº”æ¨èæ–‡ç«  # +-------------------+----------+ # | user_id | article_id | # +-------------------+----------+ # | 1106476833370537984 | 44075 | # | 1 | 44075 | # åˆ†ç»„ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·ï¼Œæ¨èåˆ—è¡¨ # als_recall = als_recall.groupby('user_id').agg(F.collect_list('article_id')).withColumnRenamed( # 'collect_list(article_id)', 'article_list') self.spark.sql(&quot;use toutiao&quot;) news_article_basic = self.spark.sql(&quot;select article_id, channel_id from news_article_basic&quot;) als_recall = als_recall.join(news_article_basic, on=['article_id'], how='left') als_recall = als_recall.groupBy(['user_id', 'channel_id']).agg(F.collect_list('article_id')).withColumnRenamed( 'collect_list(article_id)', 'article_list') als_recall = als_recall.dropna() # å­˜å‚¨ def save_offline_recall_hbase(partition): &quot;&quot;&quot;ç¦»çº¿æ¨¡å‹å¬å›ç»“æœå­˜å‚¨ &quot;&quot;&quot; import happybase pool = happybase.ConnectionPool(size=10, host='hadoop-master', port=9090) for row in partition: with pool.connection() as conn: # è·å–å†å²çœ‹è¿‡çš„è¯¥é¢‘é“æ–‡ç«  history_table = conn.table('history_recall') # å¤šä¸ªç‰ˆæœ¬ data = history_table.cells('reco:his:{}'.format(row.user_id).encode(), 'channel:{}'.format(row.channel_id).encode()) history = [] if len(data) &gt;= 2: for l in data[:-1]: history.extend(eval(l)) else: history = [] # è¿‡æ»¤reco_articleä¸history reco_res = list(set(row.article_list) - set(history)) if reco_res: table = conn.table('cb_recall') # é»˜è®¤æ”¾åœ¨æ¨èé¢‘é“ table.put('recall:user:{}'.format(row.user_id).encode(), {'als:{}'.format(row.channel_id).encode(): str(reco_res).encode()}) conn.close() # æ”¾å…¥å†å²æ¨èè¿‡æ–‡ç«  history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(), {'channel:{}'.format(row.channel_id): str(reco_res).encode()}) conn.close() als_recall.foreachPartition(save_offline_recall_hbase) def update_content_recall(self): &quot;&quot;&quot; æ›´æ–°åŸºäºå†…å®¹ï¼ˆç”»åƒï¼‰çš„æ¨èå¬å›é›†, word2vecç›¸ä¼¼ :return: &quot;&quot;&quot; # åŸºäºå†…å®¹ç›¸ä¼¼å¬å›ï¼ˆç”»åƒå¬å›ï¼‰ ur.spark.sql(&quot;use profile&quot;) user_article_basic = self.spark.sql(&quot;select * from user_article_basic&quot;) user_article_basic = user_article_basic.filter(&quot;clicked=True&quot;) def save_content_filter_history_to__recall(partition): &quot;&quot;&quot;è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„æ¯ä¸ªæ“ä½œæ–‡ç« çš„ç›¸ä¼¼æ–‡ç« ï¼Œè¿‡æ»¤ä¹‹åï¼Œå†™å…¥contentå¬å›è¡¨å½“ä¸­ï¼ˆæ”¯æŒä¸åŒæ—¶é—´æˆ³ç‰ˆæœ¬ï¼‰ &quot;&quot;&quot; import happybase pool = happybase.ConnectionPool(size=10, host='hadoop-master') # è¿›è¡Œä¸ºç›¸ä¼¼æ–‡ç« è·å– with pool.connection() as conn: # key: article_id, column: similar:article_id similar_table = conn.table('article_similar') # å¾ªç¯partition for row in partition: # è·å–ç›¸ä¼¼æ–‡ç« ç»“æœè¡¨ similar_article = similar_table.row(str(row.article_id).encode(), columns=[b'similar']) # ç›¸ä¼¼æ–‡ç« ç›¸ä¼¼åº¦æ’åºè¿‡æ»¤ï¼Œå¬å›ä¸éœ€è¦å¤ªå¤§çš„æ•°æ®ï¼Œ ç™¾ä¸ªï¼Œåƒ _srt = sorted(similar_article.items(), key=lambda item: item[1], reverse=True) if _srt: # æ¯æ¬¡è¡Œä¸ºæ¨è10ç¯‡æ–‡ç«  reco_article = [int(i[0].split(b':')[1]) for i in _srt][:10] # è·å–å†å²çœ‹è¿‡çš„è¯¥é¢‘é“æ–‡ç«  history_table = conn.table('history_recall') # å¤šä¸ªç‰ˆæœ¬ data = history_table.cells('reco:his:{}'.format(row.user_id).encode(), 'channel:{}'.format(row.channel_id).encode()) history = [] if len(_history_data) &gt; 1: for l in _history_data: history.extend(l) # è¿‡æ»¤reco_articleä¸history reco_res = list(set(reco_article) - set(history)) # è¿›è¡Œæ¨èï¼Œæ”¾å…¥åŸºäºå†…å®¹çš„å¬å›è¡¨å½“ä¸­ä»¥åŠå†å²çœ‹è¿‡çš„æ–‡ç« è¡¨å½“ä¸­ if reco_res: # content_table = conn.table('cb_content_recall') content_table = conn.table('cb_recall') content_table.put(&quot;recall:user:{}&quot;.format(row.user_id).encode(), {'content:{}'.format(row.channel_id).encode(): str(reco_res).encode()}) # æ”¾å…¥å†å²æ¨èè¿‡æ–‡ç«  history_table.put(&quot;reco:his:{}&quot;.format(row.user_id).encode(), {'channel:{}'.format(row.channel_id).encode(): str(reco_res).encode()}) conn.close() user_article_basic.foreachPartition(save_content_filter_history_to__recall) if __name__ == '__main__': ur = UpdateRecall(500) ur.update_als_recall() ur.update_content_recall() å®šæ—¶æ›´æ–°ä»£ç ï¼Œåœ¨main.pyå’Œupdate.pyä¸­æ·»åŠ ä»¥ä¸‹ä»£ç ï¼š from offline.update_recall import UpdateRecall from schedule.update_profile import update_user_profile, update_article_profile, update_recall def update_recall(): &quot;&quot;&quot; æ›´æ–°ç”¨æˆ·çš„å¬å›é›† :return: &quot;&quot;&quot; udp = UpdateRecall(200) udp.update_als_recall() udp.update_content_recall() mainä¸­æ·»åŠ  scheduler.add_job(update_recall, trigger='interval', hour=3) æ’åºè®¾è®¡ æ’åºæ¨¡å‹ å®½æ¨¡å‹ + ç‰¹å¾â¼¯ç¨‹ LR/MLR + éIDç±»ç‰¹å¾(â¼ˆâ¼¯ç¦»æ•£/GBDT/FM) spark ä¸­å¯ä»¥ç›´æ¥ä½¿ç”¨ å®½æ¨¡å‹ + æ·±æ¨¡å‹ wide&amp;deep,DeepFM ä½¿ç”¨TensorFlowè¿›è¡Œè®­ç»ƒ æ·±æ¨¡å‹ï¼š DNN + ç‰¹å¾embedding ä½¿ç”¨TensorFlowè¿›è¡Œè®­ç»ƒ ç‰¹å¾å¤„ç†åŸåˆ™ ç¦»æ•£æ•°æ® one-hotç¼–ç  è¿ç»­æ•°æ® å½’ä¸€åŒ– å›¾ç‰‡/æ–‡æœ¬ æ–‡ç« æ ‡ç­¾/å…³é”®è¯æå– embedding ä¼˜åŒ–è®­ç»ƒæ–¹å¼ ä½¿ç”¨Batch SGDä¼˜åŒ– åŠ å…¥æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ spark LR è¿›è¡Œé¢„ä¼° ç›®çš„ï¼šé€šè¿‡LRæ¨¡å‹è¿›è¡ŒCTRé¢„ä¼° æ­¥éª¤ï¼š 1ã€éœ€è¦é€šè¿‡sparkè¯»å–HIVEå¤–éƒ¨è¡¨ï¼Œéœ€è¦æ–°çš„sparksessioné…ç½® å¢åŠ HBASEé…ç½® 2ã€è¯»å–ç”¨æˆ·ç‚¹å‡»è¡Œä¸ºè¡¨ï¼Œä¸ç”¨æˆ·ç”»åƒå’Œæ–‡ç« ç”»åƒï¼Œæ„é€ è®­ç»ƒæ ·æœ¬ 3ã€LRæ¨¡å‹è¿›è¡Œè®­ç»ƒ 4ã€LRæ¨¡å‹é¢„æµ‹ã€ç»“æœè¯„ä¼° ","link":"https://cythonlin.github.io/post/rs-greater-tui-jian-xi-tong-san-chi-xian-zhao-hui-yu-pai-xu/"},{"title":"PY => HBase","content":"æŠ¥é”™ è‹¥list æˆ–å…¶ä»–å‘½ä»¤ æœ‰å¦‚ä¸‹é”™è¯¯ï¼š ERROR: org.apache.hadoop.hbase.PleaseHoldException: Master is initializing åˆ™ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š cd $HBASE_HOME/bin ./hbase zkcli ls / rmr /hbase ls / é€€å‡º zookeeper cliï¼Œ åˆ é™¤hdfsä¸­çš„ /hbase hdfs dfs -rm -r /hbase ç„¶åé‡å¯hbase: cd $HBASE_HOME/bin ./stop-hbase.sh ./start-hbase.sh è‹¥stop hbaseçš„æ—¶å€™å‡ºç° ..... åœæ­¢ä¸æ‰ï¼Œ åˆ™ï¼š cd $HBASE_HOME/bin ./hbase-daemons.sh stop regionserver # ./start-hbase.sh # kill -9 pidæ¥ç»ˆæ­¢hbaseçš„è¿›ç¨‹ HBaseå‘½ä»¤ https://blog.csdn.net/vbirdbest/article/details/88236575 ","link":"https://cythonlin.github.io/post/py-greater-hbase/"},{"title":"RS => æ¨èç³»ç»Ÿï¼ˆäºŒï¼‰ç¦»çº¿ç”»åƒæ„å»º ","content":"æ–‡ç« ç¦»çº¿ç”»åƒæ„å»º Sparké…ç½®åŸºç±»æŠ½å– from pyspark import SparkConf from pyspark.sql import SparkSession import os class SparkSessionBase(object): SPARK_APP_NAME = None SPARK_URL = &quot;yarn&quot; SPARK_EXECUTOR_MEMORY = &quot;2g&quot; SPARK_EXECUTOR_CORES = 2 SPARK_EXECUTOR_INSTANCES = 2 ENABLE_HIVE_SUPPORT = False def _create_spark_session(self): conf = SparkConf() # åˆ›å»ºspark configå¯¹è±¡ config = ( (&quot;spark.app.name&quot;, self.SPARK_APP_NAME), # è®¾ç½®å¯åŠ¨çš„sparkçš„appåç§°ï¼Œæ²¡æœ‰æä¾›ï¼Œå°†éšæœºäº§ç”Ÿä¸€ä¸ªåç§° (&quot;spark.executor.memory&quot;, self.SPARK_EXECUTOR_MEMORY), # è®¾ç½®è¯¥appå¯åŠ¨æ—¶å ç”¨çš„å†…å­˜ç”¨é‡ï¼Œé»˜è®¤2g (&quot;spark.master&quot;, self.SPARK_URL), # spark masterçš„åœ°å€ (&quot;spark.executor.cores&quot;, self.SPARK_EXECUTOR_CORES), # è®¾ç½®spark executorä½¿ç”¨çš„CPUæ ¸å¿ƒæ•°ï¼Œé»˜è®¤æ˜¯1æ ¸å¿ƒ (&quot;spark.executor.instances&quot;, self.SPARK_EXECUTOR_INSTANCES), (&quot;hive.metastore.uris&quot;, &quot;thrift://localhost:9083&quot;), ) conf.setAll(config) # åˆ©ç”¨configå¯¹è±¡ï¼Œåˆ›å»ºspark session if self.ENABLE_HIVE_SUPPORT: return SparkSession.builder.config(conf=conf).enableHiveSupport().getOrCreate() else: return SparkSession.builder.config(conf=conf).getOrCreate() ä¸»åº”ç”¨å¯¼å…¥åŸºç±» # pip install pyspark # pip install findspark import findspark findspark.init() import os import sys # å¦‚æœå½“å‰ä»£ç æ–‡ä»¶è¿è¡Œæµ‹è¯•éœ€è¦åŠ å…¥ä¿®æ”¹è·¯å¾„ï¼Œé¿å…å‡ºç°åå¯¼åŒ…é—®é¢˜ BASE_DIR = os.path.dirname(os.path.dirname(os.getcwd())) sys.path.insert(0, os.path.join(BASE_DIR)) print(BASE_DIR) PYSPARK_PYTHON = &quot;/miniconda2/envs/reco_sys/bin/python&quot; # å½“å­˜åœ¨å¤šä¸ªç‰ˆæœ¬æ—¶ï¼Œä¸æŒ‡å®šå¾ˆå¯èƒ½ä¼šå¯¼è‡´å‡ºé”™ os.environ[&quot;PYSPARK_PYTHON&quot;] = PYSPARK_PYTHON os.environ[&quot;PYSPARK_DRIVER_PYTHON&quot;] = PYSPARK_PYTHON from offline import SparkSessionBase class OriginArticleData(SparkSessionBase): SPARK_APP_NAME = &quot;mergeArticle&quot; SPARK_URL = &quot;yarn&quot; ENABLE_HIVE_SUPPORT = True def __init__(self): self.spark = self._create_spark_session() oa = OriginArticleData() # oaå°±æ˜¯å¸¦æœ‰é…ç½®çš„ sparkSessionçš„å®ä¾‹åŒ–å¯¹è±¡ æ–‡ç«  è¡¨ åˆå¹¶ æ–‡ç« åŸºæœ¬ä¿¡æ¯è¡¨+æ–‡ç« å†…å®¹è¡¨+é¢‘é“è¡¨ï¼š titlce_content = oa.spark.sql(&quot;select a.article_id, a.channel_id, a.title, b.content from news_article_basic a inner join news_article_content b on a.article_id=b.article_id) å› ä¸ºå¾—åˆ°çš„æ˜¯ DFç±»å‹ï¼Œæƒ³è¦ç”¨SQLï¼Œå¯ä»¥æŠŠDFæ³¨å†Œä¸ºä¸´æ—¶è¡¨ titlce_content.registerTempTable('temptable') å†æŠŠ é¢‘é“è¡¨ çš„ é¢‘é“å åˆå¹¶è¿›æ¥ channel_title_content = oa.spark.sql(&quot;select t.*, n.channel_name from temptable t left join news_channel n on t.channel_id=n.channel_id&quot;) æ–‡ç«  å­—æ®µ åˆå¹¶ å°† æ–‡ç« æ ‡é¢˜+æ–‡ç« å†…å®¹+æ–‡ç« é¢‘é“ çš„åˆ—ï¼Œæ‹¼æ¥æˆä¸€ä¸ªå¤§å­—ç¬¦ä¸² import pyspark.sql.functions as F import gc # å¢åŠ channelçš„åå­—ï¼Œåé¢ä¼šä½¿ç”¨ basic_content.registerTempTable(&quot;temparticle&quot;) channel_basic_content = oa.spark.sql( &quot;select t.*, n.channel_name from temparticle t left join news_channel n on t.channel_id=n.channel_id&quot; ) # åˆ©ç”¨concat_wsæ–¹æ³•ï¼Œå°†å¤šåˆ—æ•°æ®åˆå¹¶ä¸ºä¸€ä¸ªé•¿æ–‡æœ¬å†…å®¹ï¼ˆé¢‘é“ï¼Œæ ‡é¢˜ä»¥åŠå†…å®¹åˆå¹¶ï¼‰ oa.spark.sql(&quot;use article&quot;) sentence_df = channel_basic_content.select(&quot;article_id&quot;, &quot;channel_id&quot;, &quot;channel_name&quot;, &quot;title&quot;, &quot;content&quot;, \\ F.concat_ws( &quot;,&quot;, # æŒ‡å®šå¤§å­—ç¬¦ä¸²åˆ†éš”ç¬¦ channel_basic_content.channel_name, channel_basic_content.title, channel_basic_content.content ).alias(&quot;sentence&quot;) # æ–°åˆ— å¤§å­—ç¬¦ä¸² å–å ) del basic_content del channel_basic_content gc.collect() # sentence_df.write.insertInto(&quot;article_data&quot;) # å†™å…¥æå‰åˆ›å»ºå¥½çš„Hiveè¡¨ä¸­ åˆ†è¯ def segmentation(partition): # å°±è¿™ä¸€è¡Œçš„ç¼©è¿›éœ€è¦è°ƒæ•´ä¸‹ import os import re import jieba import jieba.analyse import jieba.posseg as pseg import codecs abspath = &quot;/root/words&quot; # ç»“å·´åŠ è½½ç”¨æˆ·è¯å…¸ userDict_path = os.path.join(abspath, &quot;ITKeywords.txt&quot;) jieba.load_userdict(userDict_path) # åœç”¨è¯æ–‡æœ¬ stopwords_path = os.path.join(abspath, &quot;stopwords.txt&quot;) def get_stopwords_list(): &quot;&quot;&quot;è¿”å›stopwordsåˆ—è¡¨&quot;&quot;&quot; stopwords_list = [i.strip() for i in codecs.open(stopwords_path).readlines()] return stopwords_list # æ‰€æœ‰çš„åœç”¨è¯åˆ—è¡¨ stopwords_list = get_stopwords_list() # åˆ†è¯ def cut_sentence(sentence): &quot;&quot;&quot;å¯¹åˆ‡å‰²ä¹‹åçš„è¯è¯­è¿›è¡Œè¿‡æ»¤ï¼Œå»é™¤åœç”¨è¯ï¼Œä¿ç•™åè¯ï¼Œè‹±æ–‡å’Œè‡ªå®šä¹‰è¯åº“ä¸­çš„è¯ï¼Œé•¿åº¦å¤§äº2çš„è¯&quot;&quot;&quot; # print(sentence,&quot;*&quot;*100) # eg:[pair('ä»Šå¤©', 't'), pair('æœ‰', 'd'), pair('é›¾', 'n'), pair('éœ¾', 'g')] seg_list = pseg.lcut(sentence) seg_list = [i for i in seg_list if i.flag not in stopwords_list] filtered_words_list = [] for seg in seg_list: # print(seg) if len(seg.word) &lt;= 1: continue elif seg.flag == &quot;eng&quot;: if len(seg.word) &lt;= 2: continue else: filtered_words_list.append(seg.word) elif seg.flag.startswith(&quot;n&quot;): filtered_words_list.append(seg.word) elif seg.flag in [&quot;x&quot;, &quot;eng&quot;]: # æ˜¯è‡ªå®šä¸€ä¸ªè¯è¯­æˆ–è€…æ˜¯è‹±æ–‡å•è¯ filtered_words_list.append(seg.word) return filtered_words_list for row in partition: sentence = re.sub(&quot;&lt;.*?&gt;&quot;, &quot;&quot;, row.sentence) # æ›¿æ¢æ‰æ ‡ç­¾æ•°æ® words = cut_sentence(sentence) yield row.article_id, row.channel_id, words è®¡ç®— TF-IDF TF: ktt.spark.sql(&quot;use article&quot;) article_dataframe = ktt.spark.sql(&quot;select * from article_data limit 20&quot;) words_df = article_dataframe.rdd.mapPartitions(segmentation).toDF([&quot;article_id&quot;, &quot;channel_id&quot;, &quot;words&quot;]) from pyspark.ml.feature import CountVectorizer # æ€»è¯æ±‡çš„å¤§å°ï¼Œæ–‡æœ¬ä¸­å¿…é¡»å‡ºç°çš„æ¬¡æ•° cv = CountVectorizer(inputCol=&quot;words&quot;, outputCol=&quot;countFeatures&quot;, vocabSize=200*10000, minDF=1.0) # è®­ç»ƒè¯é¢‘ç»Ÿè®¡æ¨¡å‹ cv_model = cv.fit(words_df) cv_model.write().overwrite().save(&quot;hdfs://hadoop-master:9000/headlines/models/CV.model&quot;) # cv_model.vocabulary æŸ¥çœ‹ç»Ÿè®¡è¯è¡¨ï¼ˆç›¸å½“äºgroupbyç»“æœçš„ key, ä½†ä¸åŒ…æ‹¬valueï¼‰ è®­ç»ƒTF-IDF: # è¯è¯­ä¸è¯é¢‘ç»Ÿè®¡ from pyspark.ml.feature import CountVectorizerModel cv_model = CountVectorizerModel.load(&quot;hdfs://hadoop-master:9000/headlines/models/CV.model&quot;) # å¾—å‡ºè¯é¢‘å‘é‡ç»“æœ cv_result = cv_model.transform(words_df) # è®­ç»ƒIDFæ¨¡å‹ (æŠŠ tfç»“æœä¼ è¿›å»ï¼Œå…¶å®è¯´æ˜¯ IDFæ¨¡å‹ï¼Œè®¡ç®—ç»“æœå¾—å‡ºçš„å°±æ˜¯ TF-IDF) from pyspark.ml.feature import IDF idf = IDF(inputCol=&quot;countFeatures&quot;, outputCol=&quot;idfFeatures&quot;) idfModel = idf.fit(cv_result) idfModel.write().overwrite().save(&quot;hdfs://hadoop-master:9000/headlines/models/IDF.model&quot;) # idfModel.idf.toArray()[:20] æŸ¥çœ‹é€†æ–‡æ¡£é¢‘ç‡çŸ©é˜µ TF-IDFç»“æœæ•°æ®æ ¼å¼ï¼š åˆ—1ï¼Œ åˆ—...ï¼Œ åˆ— TF-IDF (1000,[804,1032],[6.349777077,7.0761797]) ã€‚ã€‚ã€‚ ä½¿ç”¨TF-IDFæ¨¡å‹ï¼Œå–Top-Kä¸ªè¯ï¼š from pyspark.ml.feature import CountVectorizerModel cv_model = CountVectorizerModel.load(&quot;hdfs://hadoop-master:9000/headlines/models/countVectorizerOfArticleWords.model&quot;) from pyspark.ml.feature import IDFModel idf_model = IDFModel.load(&quot;hdfs://hadoop-master:9000/headlines/models/IDFOfArticleWords.model&quot;) cv_result = cv_model.transform(words_df) tfidf_result = idf_model.transform(cv_result) def func(partition): TOPK = 20 for row in partition: # æ‰¾åˆ°ç´¢å¼•ä¸IDFå€¼å¹¶è¿›è¡Œæ’åº _ = list(zip(row.idfFeatures.indices, row.idfFeatures.values)) # [ (indexes,values)ï¼Œ (indexes,values)] _ = sorted(_, key=lambda x: x[1], reverse=True) result = _[:TOPK] for word_index, tfidf in result: yield row.article_id, row.channel_id, int(word_index), round(float(tfidf), 4) # yieldè¿™å¥æ³¨å®šäº†è¿”å›ç»“æœæ ¼å¼ (å¤šå±‚forå¾ªç¯ yieldï¼Œ åŸæœ¬ä¸€è¡Œæ•°æ®æŒ‰æ¯ä¸ªå•è¯çˆ†ç‚¸å±•å¼€) # article_id, channel_id, word_index, tfidf # 1 100 40 15.5 # 1 100 14 10.3 # 1 100 23 13.2 _keywordsByTFIDF = tfidf_result.rdd.mapPartitions(func).toDF([&quot;article_id&quot;, &quot;channel_id&quot;, &quot;index&quot;, &quot;tfidf&quot;]) æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼š æ„æˆ è¯+TFIDFå€¼, è€Œä¸æ˜¯ç´¢å¼•+TFIDF cv_model.vocabulary ç»“æœæ˜¯æ‰€æœ‰å•è¯çš„åˆ—è¡¨ã€‚ ä¸Šé¢çš„ indexå°±æ˜¯å¯¹åº”è¿™ä¸ªåˆ—è¡¨çš„ç´¢å¼• æœ€ç»ˆæ„å»ºä¸€ä¸ªè¯å…¸+ç´¢å¼•è¡¨ï¼š index word .. .. ç„¶åå°† ä¸»è¡¨ï¼ˆæ–‡ç« id,é¢‘é“id,ç´¢å¼•ï¼Œtfidfï¼‰ä¸ è¯å…¸è¡¨ï¼ˆindex+wordï¼‰ åˆå¹¶ å¾—åˆ° ï¼ˆæ–‡ç« id,é¢‘é“id, è¯ï¼Œ tfidfï¼‰ è®¡ç®— TextRank TextRankå’Œæ ¸å¿ƒå°±æ˜¯è®¾å®šä¸€ä¸ªå›ºå®šçª—å£æ¥æ»‘åŠ¨ æŠŠæ¯ä¸ªçª—å£å†…çš„æ¯ä¸ªè¯ï¼Œ è®¾ä¸ºå­—å…¸çš„Key, valueå°±æ˜¯ä»–é™„è¿‘çš„nä¸ªè¯çš„åˆ—è¡¨ ç„¶åæ¯ä¸ªè¯éƒ½è¿™æ ·åšï¼Œ é‡åˆ°ç›¸åŒçš„è¯å°±è¿½åŠ åˆ°å­—å…¸çš„value åˆ—è¡¨ä¸­ # åˆ†è¯ def textrank(partition): import os import jieba import jieba.analyse import jieba.posseg as pseg import codecs abspath = &quot;/root/words&quot; # ç»“å·´åŠ è½½ç”¨æˆ·è¯å…¸ userDict_path = os.path.join(abspath, &quot;ITKeywords.txt&quot;) jieba.load_userdict(userDict_path) # åœç”¨è¯æ–‡æœ¬ stopwords_path = os.path.join(abspath, &quot;stopwords.txt&quot;) def get_stopwords_list(): &quot;&quot;&quot;è¿”å›stopwordsåˆ—è¡¨&quot;&quot;&quot; stopwords_list = [i.strip() for i in codecs.open(stopwords_path).readlines()] return stopwords_list # æ‰€æœ‰çš„åœç”¨è¯åˆ—è¡¨ stopwords_list = get_stopwords_list() class TextRank(jieba.analyse.TextRank): def __init__(self, window=20, word_min_len=2): super(TextRank, self).__init__() self.span = window # çª—å£å¤§å° self.word_min_len = word_min_len # å•è¯çš„æœ€å°é•¿åº¦ # è¦ä¿ç•™çš„è¯æ€§ï¼Œæ ¹æ®jieba github ï¼Œå…·ä½“å‚è§https://github.com/baidu/lac self.pos_filt = frozenset( ('n', 'x', 'eng', 'f', 's', 't', 'nr', 'ns', 'nt', &quot;nw&quot;, &quot;nz&quot;, &quot;PER&quot;, &quot;LOC&quot;, &quot;ORG&quot;)) def pairfilter(self, wp): &quot;&quot;&quot;è¿‡æ»¤æ¡ä»¶ï¼Œè¿”å›Trueæˆ–è€…False&quot;&quot;&quot; if wp.flag == &quot;eng&quot;: if len(wp.word) &lt;= 2: return False if wp.flag in self.pos_filt and len(wp.word.strip()) &gt;= self.word_min_len \\ and wp.word.lower() not in stopwords_list: return True # TextRankè¿‡æ»¤çª—å£å¤§å°ä¸º5ï¼Œå•è¯æœ€å°ä¸º2 textrank_model = TextRank(window=5, word_min_len=2) allowPOS = ('n', &quot;x&quot;, 'eng', 'nr', 'ns', 'nt', &quot;nw&quot;, &quot;nz&quot;, &quot;c&quot;) for row in partition: tags = textrank_model.textrank(row.sentence, topK=20, withWeight=True, allowPOS=allowPOS, withFlag=False) for tag in tags: yield row.article_id, row.channel_id, tag[0], tag[1] # è®¡ç®—textrank textrank_keywords_df = article_dataframe.rdd.mapPartitions(textrank).toDF( [&quot;article_id&quot;, &quot;channel_id&quot;, &quot;keyword&quot;, &quot;textrank&quot;] ) # textrank_keywords_df.write.insertInto(&quot;textrank_keywords_values&quot;) textrankè¿è¡Œç»“æœå¦‚ä¸‹ï¼š hive&gt; select * from textrank_keywords_values limit 20; OK æ–‡ç« ID channel word textrank 98319 17 var 20.6079 98323 17 var 7.4938 98326 17 var 104.9128 ç„¶åå’Œ tfidfä¸€æ · æ ¹æ® textrankå€¼ï¼Œ å–TOP-Kä¸ªè¯ è®¡ç®— ä¸»é¢˜è¯ å’Œ å…³é”®è¯ å…³é”®è¯ï¼šTEXTRANKè®¡ç®—å‡ºçš„ç»“æœTOPKä¸ªè¯ä»¥åŠæƒé‡ ä¸»é¢˜è¯ï¼šTEXTRANKçš„TOPKè¯ ä¸ ITFDFè®¡ç®—çš„TOPKä¸ªè¯çš„äº¤é›† æ ¼å¼å¦‚ä¸‹ï¼š hive&gt; desc article_profile; OK article_id int article_id channel_id int channel_id keywords map keywords topics array topics hive&gt; select * from article_profile limit 1; # è¿™é‡ŒæŠŠç»“æœæŒ‰è¡Œæ’åˆ—å¼€æ–¹ä¾¿è§‚çœ‹ article_id 26 channel_id 17 å…³é”®è¯å­—å…¸ {&quot;ç­–ç•¥&quot;:0.3973770571351729,&quot;jpg&quot;:0.9806348975390871,&quot;ç”¨æˆ·&quot;:1.2794959063944176,&quot;strong&quot;:1.6488457985625076,&quot;æ–‡ä»¶&quot;:0.28144603583387057,&quot;é€»è¾‘&quot;:0.45256526469610714,&quot;å½¢å¼&quot;:0.4123994242601279,&quot;å…¨è‡ª&quot;:0.9594604850547191,&quot;h2&quot;:0.6244481634710125,&quot;ç‰ˆæœ¬&quot;:0.44280276959510817,&quot;Adobe&quot;:0.8553618185108718,&quot;å®‰è£…&quot;:0.8305037437573172,&quot;æ£€æŸ¥æ›´æ–°&quot;:1.8088946300014435,&quot;äº§å“&quot;:0.774842382276899,&quot;ä¸‹è½½é¡µ&quot;:1.4256311032544344,&quot;è¿‡ç¨‹&quot;:0.19827163395829256,&quot;json&quot;:0.6423301791599972,&quot;æ–¹å¼&quot;:0.582762869780791,&quot;é€€å‡ºåº”ç”¨&quot;:1.2338671268242603,&quot;Setup&quot;:1.004399549339134} ä¸»é¢˜è¯åˆ—è¡¨ [&quot;Electron&quot;,&quot;å…¨è‡ªåŠ¨&quot;,&quot;äº§å“&quot;,&quot;ç‰ˆæœ¬å·&quot;,&quot;å®‰è£…åŒ…&quot;,&quot;æ£€æŸ¥æ›´æ–°&quot;,&quot;æ–¹æ¡ˆ&quot;,&quot;ç‰ˆæœ¬&quot;,&quot;é€€å‡ºåº”ç”¨&quot;,&quot;é€»è¾‘&quot;,&quot;å®‰è£…è¿‡ç¨‹&quot;,&quot;æ–¹å¼&quot;,&quot;å®šæ€§&quot;,&quot;æ–°ç‰ˆæœ¬&quot;,&quot;Setup&quot;,&quot;é™é»˜&quot;,&quot;ç”¨æˆ·&quot;] å¢é‡æ›´æ–° ç¦»çº¿æ–‡ç« ç”»åƒ æ›´æ–°æµç¨‹ï¼š 1ã€toutiao æ•°æ®åº“ä¸­ï¼Œnews_article_content ä¸news_article_basicâ€”&gt;æ›´æ–°åˆ°articleæ•°æ®åº“ä¸­article_dataè¡¨ï¼Œæ–¹ä¾¿æ“ä½œ 2. ç¬¬ä¸€æ¬¡ï¼šæ‰€æœ‰æ›´æ–°ï¼Œåé¢å¢é‡æ¯å¤©çš„æ•°æ®æ›´æ–°26æ—¥ï¼š1ï¼š002ï¼š00ï¼Œ2ï¼š003ï¼š00ï¼Œå·¦é—­å³å¼€,ä¸€ä¸ªå°æ—¶æ›´æ–°ä¸€æ¬¡ 3ã€åˆšæ‰æ–°æ›´æ–°çš„æ–‡ç« ï¼Œé€šè¿‡å·²æœ‰çš„idfè®¡ç®—å‡ºtfidfå€¼ä»¥åŠhive çš„textrank_keywords_values 4ã€æ›´æ–°hiveçš„article_profile ç¦»çº¿æ›´æ–°æ–‡ç« ç”»åƒ ä»£ç ç»„è£…ï¼šPycharm æ³¨æ„åœ¨Pycharmä¸­è¿è¡Œè¦è®¾ç½®ç¯å¢ƒï¼š PYTHONUNBUFFERED=1 JAVA_HOME=/root/bigdata/jdk SPARK_HOME=/root/bigdata/spark HADOOP_HOME=/root/bigdata/hadoop PYSPARK_PYTHON=/root/anaconda3/envs/reco_sys/bin/python PYSPARK_DRIVER_PYTHON=/root/anaconda3/envs/reco_sys/bin/python å…·ä½“ä»£ç å¦‚ä¸‹ï¼š import os import sys BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(file))) sys.path.insert(0, os.path.join(BASE_DIR)) from offline import SparkSessionBase from datetime import datetime from datetime import timedelta import pyspark.sql.functions as F import pyspark import gc class UpdateArticle(SparkSessionBase): &quot;&quot;&quot; æ›´æ–°æ–‡ç« ç”»åƒ &quot;&quot;&quot; SPARK_APP_NAME = &quot;updateArticle&quot; ENABLE_HIVE_SUPPORT = True SPARK_EXECUTOR_MEMORY = &quot;7g&quot; def __init__(self): self.spark = self._create_spark_session() self.cv_path = &quot;hdfs://hadoop-master:9000/headlines/models/countVectorizerOfArticleWords.model&quot; self.idf_path = &quot;hdfs://hadoop-master:9000/headlines/models/IDFOfArticleWords.model&quot; def get_cv_model(self): # è¯è¯­ä¸è¯é¢‘ç»Ÿè®¡ from pyspark.ml.feature import CountVectorizerModel cv_model = CountVectorizerModel.load(self.cv_path) return cv_model def get_idf_model(self): from pyspark.ml.feature import IDFModel idf_model = IDFModel.load(self.idf_path) return idf_model @staticmethod def compute_keywords_tfidf_topk(words_df, cv_model, idf_model): &quot;&quot;&quot;ä¿å­˜tfidfå€¼é«˜çš„20ä¸ªå…³é”®è¯ :param spark: :param words_df: :return: &quot;&quot;&quot; cv_result = cv_model.transform(words_df) tfidf_result = idf_model.transform(cv_result) # print(&quot;transform compelete&quot;) # å–TOP-Nçš„TFIDFå€¼é«˜çš„ç»“æœ def func(partition): TOPK = 20 for row in partition: _ = list(zip(row.idfFeatures.indices, row.idfFeatures.values)) _ = sorted(_, key=lambda x: x[1], reverse=True) result = _[:TOPK] # words_index = [int(i[0]) for i in result] # yield row.article_id, row.channel_id, words_index for word_index, tfidf in result: yield row.article_id, row.channel_id, int(word_index), round(float(tfidf), 4) _keywordsByTFIDF = tfidf_result.rdd.mapPartitions(func).toDF([&quot;article_id&quot;, &quot;channel_id&quot;, &quot;index&quot;, &quot;tfidf&quot;]) return _keywordsByTFIDF def merge_article_data(self): &quot;&quot;&quot; åˆå¹¶ä¸šåŠ¡ä¸­å¢é‡æ›´æ–°çš„æ–‡ç« æ•°æ® :return: &quot;&quot;&quot; # è·å–æ–‡ç« ç›¸å…³æ•°æ®, æŒ‡å®šè¿‡å»ä¸€ä¸ªå°æ—¶æ•´ç‚¹åˆ°æ•´ç‚¹çš„æ›´æ–°æ•°æ® # å¦‚ï¼š26æ—¥ï¼š1ï¼š00~2ï¼š00ï¼Œ2ï¼š00~3ï¼š00ï¼Œå·¦é—­å³å¼€ self.spark.sql(&quot;use toutiao&quot;) _yester = datetime.today().replace(minute=0, second=0, microsecond=0) start = datetime.strftime(_yester + timedelta(days=0, hours=-1, minutes=0), &quot;%Y-%m-%d %H:%M:%S&quot;) end = datetime.strftime(_yester, &quot;%Y-%m-%d %H:%M:%S&quot;) # åˆå¹¶åä¿ç•™ï¼šarticle_idã€channel_idã€channel_nameã€titleã€content # +----------+----------+--------------------+--------------------+ # | article_id | channel_id | title | content | # +----------+----------+--------------------+--------------------+ # | 141462 | 3 | test - 20190316 - 115123 | ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œå¿ƒæƒ…å¾ˆç¾ä¸½ï¼ï¼ï¼ | basic_content = self.spark.sql( &quot;select a.article_id, a.channel_id, a.title, b.content from news_article_basic a &quot; &quot;inner join news_article_content b on a.article_id=b.article_id where a.review_time &gt;= '{}' &quot; &quot;and a.review_time &lt; '{}' and a.status = 2&quot;.format(start, end)) # å¢åŠ channelçš„åå­—ï¼Œåé¢ä¼šä½¿ç”¨ basic_content.registerTempTable(&quot;temparticle&quot;) channel_basic_content = self.spark.sql( &quot;select t.*, n.channel_name from temparticle t left join news_channel n on t.channel_id=n.channel_id&quot;) # åˆ©ç”¨concat_wsæ–¹æ³•ï¼Œå°†å¤šåˆ—æ•°æ®åˆå¹¶ä¸ºä¸€ä¸ªé•¿æ–‡æœ¬å†…å®¹ï¼ˆé¢‘é“ï¼Œæ ‡é¢˜ä»¥åŠå†…å®¹åˆå¹¶ï¼‰ self.spark.sql(&quot;use article&quot;) sentence_df = channel_basic_content.select(&quot;article_id&quot;, &quot;channel_id&quot;, &quot;channel_name&quot;, &quot;title&quot;, &quot;content&quot;, \\ F.concat_ws( &quot;,&quot;, channel_basic_content.channel_name, channel_basic_content.title, channel_basic_content.content ).alias(&quot;sentence&quot;) ) del basic_content del channel_basic_content gc.collect() sentence_df.write.insertInto(&quot;article_data&quot;) return sentence_df def generate_article_label(self, sentence_df): &quot;&quot;&quot; ç”Ÿæˆæ–‡ç« æ ‡ç­¾ tfidf, textrank :param sentence_df: å¢é‡çš„æ–‡ç« å†…å®¹ :return: &quot;&quot;&quot; # è¿›è¡Œåˆ†è¯ words_df = sentence_df.rdd.mapPartitions(segmentation).toDF([&quot;article_id&quot;, &quot;channel_id&quot;, &quot;words&quot;]) cv_model = self.get_cv_model() idf_model = self.get_idf_model() # 1ã€ä¿å­˜æ‰€æœ‰çš„è¯çš„idfçš„å€¼ï¼Œåˆ©ç”¨idfä¸­çš„è¯çš„æ ‡ç­¾ç´¢å¼• # å·¥å…·ä¸ä¸šåŠ¡éš”ç¦» _keywordsByTFIDF = UpdateArticle.compute_keywords_tfidf_topk(words_df, cv_model, idf_model) keywordsIndex = self.spark.sql(&quot;select keyword, index idx from idf_keywords_values&quot;) keywordsByTFIDF = _keywordsByTFIDF.join(keywordsIndex, keywordsIndex.idx == _keywordsByTFIDF.index).select( [&quot;article_id&quot;, &quot;channel_id&quot;, &quot;keyword&quot;, &quot;tfidf&quot;]) keywordsByTFIDF.write.insertInto(&quot;tfidf_keywords_values&quot;) del cv_model del idf_model del words_df del _keywordsByTFIDF gc.collect() # è®¡ç®—textrank textrank_keywords_df = sentence_df.rdd.mapPartitions(textrank).toDF( [&quot;article_id&quot;, &quot;channel_id&quot;, &quot;keyword&quot;, &quot;textrank&quot;]) textrank_keywords_df.write.insertInto(&quot;textrank_keywords_values&quot;) return textrank_keywords_df, keywordsIndex def get_article_profile(self, textrank, keywordsIndex): &quot;&quot;&quot; æ–‡ç« ç”»åƒä¸»é¢˜è¯å»ºç«‹ :param idf: æ‰€æœ‰è¯çš„idfå€¼ :param textrank: æ¯ä¸ªæ–‡ç« çš„textrankå€¼ :return: è¿”å›å»ºç«‹å·å¢é‡æ–‡ç« ç”»åƒ &quot;&quot;&quot; keywordsIndex = keywordsIndex.withColumnRenamed(&quot;keyword&quot;, &quot;keyword1&quot;) result = textrank.join(keywordsIndex, textrank.keyword == keywordsIndex.keyword1) # 1ã€å…³é”®è¯ï¼ˆè¯ï¼Œæƒé‡ï¼‰ # è®¡ç®—å…³é”®è¯æƒé‡ _articleKeywordsWeights = result.withColumn(&quot;weights&quot;, result.textrank * result.idf).select( [&quot;article_id&quot;, &quot;channel_id&quot;, &quot;keyword&quot;, &quot;weights&quot;]) # åˆå¹¶å…³é”®è¯æƒé‡åˆ°å­—å…¸ _articleKeywordsWeights.registerTempTable(&quot;temptable&quot;) articleKeywordsWeights = self.spark.sql( &quot;select article_id, min(channel_id) channel_id, collect_list(keyword) keyword_list, collect_list(weights) weights_list from temptable group by article_id&quot;) def _func(row): return row.article_id, row.channel_id, dict(zip(row.keyword_list, row.weights_list)) articleKeywords = articleKeywordsWeights.rdd.map(_func).toDF([&quot;article_id&quot;, &quot;channel_id&quot;, &quot;keywords&quot;]) # 2ã€ä¸»é¢˜è¯ # å°†tfidfå’Œtextrankå…±ç°çš„è¯ä½œä¸ºä¸»é¢˜è¯ topic_sql = &quot;&quot;&quot; select t.article_id article_id2, collect_set(t.keyword) topics from tfidf_keywords_values t inner join textrank_keywords_values r where t.keyword=r.keyword group by article_id2 &quot;&quot;&quot; articleTopics = self.spark.sql(topic_sql) # 3ã€å°†ä¸»é¢˜è¯è¡¨å’Œå…³é”®è¯è¡¨è¿›è¡Œåˆå¹¶ï¼Œæ’å…¥è¡¨ articleProfile = articleKeywords.join(articleTopics, articleKeywords.article_id == articleTopics.article_id2).select( [&quot;article_id&quot;, &quot;channel_id&quot;, &quot;keywords&quot;, &quot;topics&quot;]) articleProfile.write.insertInto(&quot;article_profile&quot;) del keywordsIndex del _articleKeywordsWeights del articleKeywords del articleTopics gc.collect() return articleProfile if __name__ == '__main__': ua = UpdateArticle() sentence_df = ua.merge_article_data() if sentence_df.rdd.collect(): rank, idf = ua.generate_article_label(sentence_df) articleProfile = ua.get_article_profile(rank, idf) ä½¿ç”¨å·¥å…·ï¼šSupervisor+Apscheduler # pip install APScheduler from apscheduler.schedulers.blocking import BlockingScheduler from apscheduler.executors.pool import ProcessPoolExecutor from scheduler.update import update_article_profile # åˆ›å»ºschedulerï¼Œå¤šè¿›ç¨‹æ‰§è¡Œ executors = { 'default': ProcessPoolExecutor(3) } scheduler = BlockingScheduler(executors=executors) # æ·»åŠ å®šæ—¶æ›´æ–°ä»»åŠ¡æ›´æ–°æ–‡ç« ç”»åƒ,æ¯éš”ä¸€å°æ—¶æ›´æ–°ï¼Œ triggerè¿˜æœ‰å…¶ä»–å®šæ—¶æ–¹å¼ scheduler.add_job(update_article_profile, trigger='interval', hours=1) scheduler.start() è‡ªå®šä¹‰Logger: import logging import logging.handlers import os logging_file_dir = '/root/logs/' def create_logger(): # ç¦»çº¿å¤„ç†æ›´æ–°æ‰“å°æ—¥å¿— log_trace = logging.getLogger('offline') trace_file_handler = logging.FileHandler( os.path.join(logging_file_dir, 'offline.log') ) trace_file_handler.setFormatter(logging.Formatter('%(message)s')) log_trace.addHandler(trace_file_handler) log_trace.setLevel(logging.INFO) supervisorç®¡ç†apscheduler: [program:offline] environment=JAVA_HOME=/root/bigdata/jdk,SPARK_HOME=/root/bigdata/spark,HADOOP_HOME=/root/bigdata/hadoop,PYSPARK_PYTHON=/miniconda2/envs/reco_sys/bin/python,PYSPARK_DRIVER_PYTHON=/miniconda2/envs/reco_sys/bin/python command=/miniconda2/envs/reco_sys/bin/python /root/toutiao_project/scheduler/main.py directory=/root/toutiao_project/scheduler user=root autorestart=true redirect_stderr=true stdout_logfile=/root/logs/offlinesuper.log loglevel=info stopsignal=KILL stopasgroup=true killasgroup=true Word2Vecä¸æ–‡ç« ç›¸ä¼¼åº¦ w2v.spark.sql(&quot;use article&quot;) article = w2v.spark.sql(&quot;select * from article_data where channel_id=18 limit 2&quot;) words_df = article.rdd.mapPartitions(segmentation).toDF(['article_id', 'channel_id', 'words']) Spark Word2Vec APIä»‹ç»ï¼š æ¨¡å—ï¼šfrom pyspark.ml.feature import Word2Vec APIï¼šclass pyspark.ml.feature.Word2Vec(vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000) å‚æ•°è¯´æ˜ï¼š vectorSize=100: è¯å‘é‡é•¿åº¦ minCountï¼šè¿‡æ»¤æ¬¡æ•°å°äºé»˜è®¤5æ¬¡çš„è¯ windowSize=5ï¼šè®­ç»ƒæ—¶å€™çš„çª—å£å¤§å° inputCol=Noneï¼šè¾“å…¥åˆ—å outputCol=Noneï¼šè¾“å‡ºåˆ—å Spark Word2Vecè®­ç»ƒä¿å­˜æ¨¡å‹ï¼š new_word2Vec = Word2Vec(vectorSize=100, inputCol=&quot;words&quot;, outputCol=&quot;model&quot;, minCount=3) new_model = new_word2Vec.fit(words_df) new_model.save(&quot;hdfs://hadoop-master:9000/headlines/models/test.word2vec&quot;) ä¸Šä¼ å†å²æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼š hadoop dfs -put ./word2vec_model /headlines/models/ å¢é‡æ›´æ–°-æ–‡ç« å‘é‡è®¡ç®— æœ‰äº†è¯å‘é‡ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°ä¸€ç¯‡æ–‡ç« çš„å‘é‡äº†ï¼Œä¸ºäº†åé¢å¿«é€Ÿä½¿ç”¨æ–‡ç« çš„å‘é‡ï¼Œæˆ‘ä»¬ä¼šå°†æ¯ä¸ªé¢‘é“æ‰€æœ‰çš„æ–‡ç« å‘é‡ä¿å­˜èµ·æ¥ã€‚ ç›®çš„ï¼šä¿å­˜æ‰€æœ‰å†å²è®­ç»ƒçš„æ–‡ç« å‘é‡ æ­¥éª¤ï¼š 1ã€åŠ è½½æŸä¸ªé¢‘é“æ¨¡å‹ï¼Œå¾—åˆ°æ¯ä¸ªè¯çš„å‘é‡ 2ã€è·å–é¢‘é“çš„æ–‡ç« ç”»åƒï¼Œå¾—åˆ°æ–‡ç« ç”»åƒçš„å…³é”®è¯(æ¥ç€ä¹‹å‰å¢é‡æ›´æ–°çš„æ–‡ç« article_profile) 3ã€è®¡ç®—å¾—åˆ°æ–‡ç« æ¯ä¸ªè¯çš„å‘é‡ 4ã€è®¡ç®—å¾—åˆ°æ–‡ç« çš„å¹³å‡è¯å‘é‡å³æ–‡ç« çš„å‘é‡ åŠ è½½æŸä¸ªé¢‘é“æ¨¡å‹ï¼Œå¾—åˆ°æ¯ä¸ªè¯çš„å‘é‡ from pyspark.ml.feature import Word2VecModel channel_id = 18 channel = &quot;python&quot; wv_model = Word2VecModel.load( &quot;hdfs://hadoop-master:9000/headlines/models/word2vec_model/channel_%d_%s.word2vec&quot; % (channel_id, channel)) vectors = wv_model.getVectors() è·å–æ–°å¢çš„æ–‡ç« ç”»åƒï¼Œå¾—åˆ°æ–‡ç« ç”»åƒçš„å…³é”®è¯ï¼š # é€‰å‡ºæ–°å¢çš„æ–‡ç« çš„ç”»åƒåšæµ‹è¯•ï¼Œä¸ŠèŠ‚è®¡ç®—çš„ç”»åƒä¸­æœ‰ä¸åŒé¢‘é“çš„ï¼Œæˆ‘ä»¬é€‰å–Pythoné¢‘é“çš„è¿›è¡Œè®¡ç®—æµ‹è¯• # æ–°å¢çš„æ–‡ç« ç”»åƒè·å–éƒ¨åˆ† profile = w2v.spark.sql(&quot;select * from article_profile where channel_id=18 limit 10&quot;) # profile = articleProfile.filter('channel_id = {}'.format(channel_id)) profile.registerTempTable(&quot;incremental&quot;) articleKeywordsWeights = w2v.spark.sql( &quot;select article_id, channel_id, keyword, weight from incremental LATERAL VIEW explode(keywords) AS keyword, weight&quot;) _article_profile = articleKeywordsWeights.join(vectors, vectors.word==articleKeywordsWeights.keyword, &quot;inner&quot;) è®¡ç®—å¾—åˆ°æ–‡ç« çš„å¹³å‡è¯å‘é‡å³æ–‡ç« çš„å‘é‡ def avg(row): x = 0 for v in row.vectors: x += v # å°†å¹³å‡å‘é‡ä½œä¸ºarticleçš„å‘é‡ return row.article_id, row.channel_id, x / len(row.vectors) articleKeywordVectors.registerTempTable(&quot;tempTable&quot;) articleVector = w2v.spark.sql( &quot;select article_id, min(channel_id) channel_id, collect_set(weightingVector) vectors from tempTable group by article_id&quot;).rdd \\ # åˆ†ç»„ä¹‹åï¼Œ æ±‚mapçš„å¹³å‡ä¹‹å‰ï¼Œ ç»“æœæ˜¯ artile_id, channel_id, vector_list # vector_list æ˜¯äºŒç»´æ•°ç»„ã€‚ .map(avg).toDF([&quot;article_id&quot;, &quot;channel_id&quot;, &quot;articleVector&quot;]) # æ±‚mapçš„å¹³å‡ä¹‹åç»“æœæ˜¯ article_id, channel_id, article_vector # article_vector ä»£è¡¨æ–‡ç« å‘é‡ æ–‡ç« ç›¸ä¼¼åº¦è®¡ç®— å­˜åœ¨çš„é—®é¢˜ï¼šä»¥è¿›è¡ŒæŸé¢‘é“å…¨é‡æ‰€æœ‰çš„ä¸¤ä¸¤ç›¸ä¼¼åº¦è®¡ç®—ã€‚ä½†æ˜¯äº‹å®å½“æ–‡ç« é‡è¾¾åˆ°åƒä¸‡çº§åˆ«æˆ–è€…ä¸Šäº¿çº§åˆ«ï¼Œç‰¹å¾ä¹Ÿä¼šä¸Šäº¿çº§åˆ«ï¼Œè®¡ç®—é‡å°±ä¼šå¾ˆå¤§ã€‚ä»¥ä¸‹æœ‰ä¸¤ç§ç±»å‹è§£å†³æ–¹æ¡ˆï¼š æ¯ä¸ªé¢‘é“çš„æ–‡ç« å…ˆè¿›è¡Œèšç±»ï¼ˆç¼ºç‚¹ï¼Œï¼ˆåˆ†æˆå‡ ä¸ªç°‡ï¼‰ä¹Ÿæ˜¯ä¸ªè¶…å‚æ•°ï¼‰ å±€éƒ¨æ•æ„Ÿå“ˆå¸ŒLSH(Locality Sensitive Hashing) åŸºæœ¬æ€æƒ³1ï¼šLSHç®—æ³•åŸºäºä¸€ä¸ªå‡è®¾ï¼Œå¦‚æœä¸¤ä¸ªæ–‡æœ¬åœ¨åŸæœ‰çš„æ•°æ®ç©ºé—´æ˜¯ç›¸ä¼¼çš„ï¼Œé‚£ä¹ˆåˆ†åˆ«ç»è¿‡å“ˆå¸Œå‡½æ•°è½¬æ¢ä»¥åçš„å®ƒä»¬ä¹Ÿå…·æœ‰å¾ˆé«˜çš„ç›¸ä¼¼åº¦ åŸºæœ¬æ€æƒ³2: ç»å¸¸ä½¿ç”¨çš„å“ˆå¸Œå‡½æ•°ï¼Œå†²çªæ€»æ˜¯éš¾ä»¥é¿å…ã€‚LSHå´ä¾èµ–äºå†²çªï¼Œåœ¨è§£å†³NNS(Nearest neighbor search )æ—¶ï¼Œæˆ‘ä»¬æœŸæœ›ï¼š ç¦»å¾—è¶Šè¿‘çš„å¯¹è±¡ï¼Œå‘ç”Ÿå†²çªçš„æ¦‚ç‡è¶Šé«˜ ç¦»å¾—è¶Šè¿œçš„å¯¹è±¡ï¼Œå‘ç”Ÿå†²çªçš„æ¦‚ç‡è¶Šä½ å±€éƒ¨æ•æ„Ÿå“ˆå¸ŒLSH(Locality Sensitive Hashing) LSHè¿‡ç¨‹ï¼š mini hashing(ç•¥) Random Projectionï¼ˆç‰¹å¾å‹ç¼©ï¼‰ï¼š Random Projectionæ˜¯ä¸€ç§éšæœºç®—æ³•.éšæœºæŠ•å½±çš„ç®—æ³•æœ‰å¾ˆå¤šï¼Œå¦‚PCAã€Gaussian random projection - é«˜æ–¯éšæœºæŠ•å½±ã€‚ éšæœºæ¡¶æŠ•å½±æ˜¯ç”¨äºæ¬§å‡ é‡Œå¾·è·ç¦»çš„ LSH familyã€‚å…¶LSH familyå°†xç‰¹å¾å‘é‡æ˜ å°„åˆ°éšæœºå•ä½çŸ¢é‡vï¼Œå¹¶å°†æ˜ å°„ç»“æœåˆ†ä¸ºå“ˆå¸Œæ¡¶ä¸­ã€‚å“ˆå¸Œè¡¨ä¸­çš„æ¯ä¸ªä½ç½®è¡¨ç¤ºä¸€ä¸ªå“ˆå¸Œæ¡¶ã€‚ ä½¿å¾—ï¼š ç¦»å¾—è¶Šè¿‘çš„å¯¹è±¡ï¼Œå‘ç”Ÿå†²çªçš„æ¦‚ç‡è¶Šé«˜ ç¦»å¾—è¶Šè¿œçš„å¯¹è±¡ï¼Œå‘ç”Ÿå†²çªçš„æ¦‚ç‡è¶Šä½ ä»£ç å®ç°ï¼š è¯»å–æ•°æ®ï¼Œè¿›è¡Œç±»å‹å¤„ç†(æ•°ç»„è½¬æ¢ç±»å‹ä¸ºVector)ï¼š from pyspark.ml.linalg import Vectors # é€‰å–éƒ¨åˆ†æ•°æ®åšæµ‹è¯• article_vector = w2v.spark.sql(&quot;select article_id, articlevector from article_vector where channel_id=18 limit 10&quot;) train = articlevector.select(['article_id', 'articleVector']) def _array_to_vector(row): return row.article_id, Vectors.dense(row.articleVector) train = train.rdd.map(_array_to_vector).toDF(['article_id', 'articleVector']) ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆBRPè¿›è¡ŒFITï¼‰ï¼š å‡½æ•°å‚æ•°è¯´æ˜ï¼š class pyspark.ml.feature.BucketedRandomProjectionLSH(inputCol=None, outputCol=None, seed=None, numHashTables=1, bucketLength=None) inputCol=Noneï¼šè¾“å…¥ç‰¹å¾åˆ— outputCol=Noneï¼šè¾“å‡ºç‰¹å¾åˆ— numHashTables=1ï¼šå“ˆå¸Œè¡¨æ•°é‡ï¼Œå‡ ä¸ªhash functionå¯¹æ•°æ®è¿›è¡Œhashæ“ä½œ bucketLength=Noneï¼šæ¡¶çš„æ•°é‡ï¼Œå€¼è¶Šå¤§ç›¸åŒæ•°æ®è¿›å…¥åˆ°åŒä¸€ä¸ªæ¡¶çš„æ¦‚ç‡è¶Šé«˜ method: # è®¡ç®—df1æ¯ä¸ªæ–‡ç« ç›¸ä¼¼çš„df2æ•°æ®é›†çš„æ•°æ® approxSimilarityJoin(df1, df2, 2.0, distCol='EuclideanDistance') # è½¬ä¸ºå‘é‡ # ä»£ç è°ƒç”¨ï¼š from pyspark.ml.feature import BucketedRandomProjectionLSH brp = BucketedRandomProjectionLSH(inputCol='articleVector', outputCol='hashes', numHashTables=4.0, bucketLength=10.0) model = brp.fit(æ—§æ–‡ç« å‘é‡) è®¡ç®—ç›¸ä¼¼çš„æ–‡ç« ä»¥åŠç›¸ä¼¼åº¦ # è®¡ç®—æ–‡ç« å’Œæ–‡ç« ä¹‹é—´çš„ç›¸ä¼¼åº¦ similar = model.approxSimilarityJoin(æ–°å¢æ–‡ç« å‘é‡, æ–°å¢æ–‡ç« å‘é‡, 2.0, distCol='Similarity') # è¾“å‡ºåˆ—å similar.sort(['EuclideanDistance']).show() è®¡ç®—ç»“æœï¼š datasetA(æ–°å¢), datasetBï¼ˆæ—§çš„ï¼‰, Similarity [2,[æ–‡ç« å‘é‡]] [5,[æ–‡ç« å‘é‡]] 0.0051 [1,[æ–‡ç« å‘é‡]] [3,[æ–‡ç« å‘é‡]] 0.0054 [2,[æ–‡ç« å‘é‡]] [8,[æ–‡ç« å‘é‡]] 0.0053 [1,[æ–‡ç« å‘é‡]] [4,[æ–‡ç« å‘é‡]] 0.0052 [2,[æ–‡ç« å‘é‡]] [7,[æ–‡ç« å‘é‡]] 0.0055 ... æ–‡ç« ç›¸ä¼¼åº¦å­˜å‚¨ HBase å­˜å‚¨ç›®æ ‡ï¼šå­˜å‚¨ æ–‡ç« ï¼Œç›¸ä¼¼æ–‡ç« ï¼Œ ç›¸ä¼¼åº¦ è°ƒç”¨foreachPartitionï¼š foreachPartitionä¸åŒäºmapå’ŒmapPartitionã€‚ æ— è¿”å›ç»“æœï¼Œä¸»è¦ç”¨äºç¦»çº¿åˆ†æä¹‹åçš„æ•°æ®ï¼ˆæ•°æ®åº“å­˜å‚¨ç­‰ï¼‰è½åœ° å¦‚æœæƒ³è¦è¿”å›æ–°çš„ä¸€ä¸ªæ•°æ®DFï¼Œå°±ä½¿ç”¨mapåè€…ã€‚ æˆ‘ä»¬éœ€è¦å»ºç«‹ä¸€ä¸ªHBaseå­˜å‚¨æ–‡ç« ç›¸ä¼¼åº¦çš„è¡¨ï¼š create 'article_similar', 'similar' # å­˜å‚¨æ ¼å¼å¦‚ä¸‹ï¼š è¡¨ row_key column_family value put 'article_similar', '1', 'similar:1', 0.2 put 'article_similar', '1', 'similar:2', 0.34 HBase å¼€å¯å¤±è´¥å¯èƒ½çš„åŸå› çš„ï¼š æ—¶é—´æœªåŒæ­¥çš„è§£å†³åŠæ³•ï¼š ntpdate 0.cn.pool.ntp.org æˆ– ntpdate ntp1.aliyun.com thriftæœåŠ¡æœªå¼€å¯çš„è§£å†³åŠæ³•ï¼š hbase-daemon.sh start thrift happybaseä»£ç å®ç°ï¼š def save_hbase(partition): import happybase pool = happybase.ConnectionPool(size=3, host='hadoop-master') with pool.connection() as conn: # å»ºè®®è¡¨çš„è¿æ¥ table = conn.table('article_similar') for row in partition: if row.datasetA.article_id == row.datasetB.article_id: pass else: table.put(str(row.datasetA.article_id).encode(), {&quot;similar:{}&quot;.format(row.datasetB.article_id).encode(): b'%0.4f' % (row.EuclideanDistance)}) # æ‰‹åŠ¨å…³é—­æ‰€æœ‰çš„è¿æ¥ conn.close() similar.foreachPartition(save_hbase) æ–‡ç« ç›¸ä¼¼åº¦å¢é‡æ›´æ–°ä»£ç æ•´ç† def compute_article_similar(self, articleProfile): &quot;&quot;&quot; è®¡ç®—å¢é‡æ–‡ç« ä¸å†å²æ–‡ç« çš„ç›¸ä¼¼åº¦ word2vec :return: &quot;&quot;&quot; # å¾—åˆ°è¦æ›´æ–°çš„æ–°æ–‡ç« é€šé“ç±»åˆ«(ä¸é‡‡ç”¨) # all_channel = set(articleProfile.rdd.map(lambda x: x.channel_id).collect()) def avg(row): x = 0 for v in row.vectors: x += v # å°†å¹³å‡å‘é‡ä½œä¸ºarticleçš„å‘é‡ return row.article_id, row.channel_id, x / len(row.vectors) for channel_id, channel_name in CHANNEL_INFO.items(): profile = articleProfile.filter('channel_id = {}'.format(channel_id)) wv_model = Word2VecModel.load( &quot;hdfs://hadoop-master:9000/headlines/models/channel_%d_%s.word2vec&quot; % (channel_id, channel_name)) vectors = wv_model.getVectors() # è®¡ç®—å‘é‡ profile.registerTempTable(&quot;incremental&quot;) articleKeywordsWeights = ua.spark.sql( &quot;select article_id, channel_id, keyword, weight from incremental LATERAL VIEW explode(keywords) AS keyword, weight where channel_id=%d&quot; % channel_id) articleKeywordsWeightsAndVectors = articleKeywordsWeights.join(vectors, vectors.word == articleKeywordsWeights.keyword, &quot;inner&quot;) articleKeywordVectors = articleKeywordsWeightsAndVectors.rdd.map( lambda r: (r.article_id, r.channel_id, r.keyword, r.weight * r.vector)).toDF( [&quot;article_id&quot;, &quot;channel_id&quot;, &quot;keyword&quot;, &quot;weightingVector&quot;]) articleKeywordVectors.registerTempTable(&quot;tempTable&quot;) articleVector = self.spark.sql( &quot;select article_id, min(channel_id) channel_id, collect_set(weightingVector) vectors from tempTable group by article_id&quot;).rdd.map( avg).toDF([&quot;article_id&quot;, &quot;channel_id&quot;, &quot;articleVector&quot;]) # å†™å…¥æ•°æ®åº“ def toArray(row): return row.article_id, row.channel_id, [float(i) for i in row.articleVector.toArray()] articleVector = articleVector.rdd.map(toArray).toDF(['article_id', 'channel_id', 'articleVector']) articleVector.write.insertInto(&quot;article_vector&quot;) import gc del wv_model del vectors del articleKeywordsWeights del articleKeywordsWeightsAndVectors del articleKeywordVectors gc.collect() # å¾—åˆ°å†å²æ•°æ®, è½¬æ¢æˆå›ºå®šæ ¼å¼ä½¿ç”¨LSHè¿›è¡Œæ±‚ç›¸ä¼¼ train = self.spark.sql(&quot;select * from article_vector where channel_id=%d&quot; % channel_id) def _array_to_vector(row): return row.article_id, Vectors.dense(row.articleVector) train = train.rdd.map(_array_to_vector).toDF(['article_id', 'articleVector']) test = articleVector.rdd.map(_array_to_vector).toDF(['article_id', 'articleVector']) brp = BucketedRandomProjectionLSH(inputCol='articleVector', outputCol='hashes', seed=12345, bucketLength=1.0) model = brp.fit(train) similar = model.approxSimilarityJoin(test, train, 2.0, distCol='EuclideanDistance') def save_hbase(partition): import happybase for row in partition: pool = happybase.ConnectionPool(size=3, host='hadoop-master') # article_similar article_id similar:article_id sim with pool.connection() as conn: table = connection.table(&quot;article_similar&quot;) for row in partition: if row.datasetA.article_id == row.datasetB.article_id: pass else: table.put(str(row.datasetA.article_id).encode(), {b&quot;similar:%d&quot; % row.datasetB.article_id: b&quot;%0.4f&quot; % row.EuclideanDistance}) conn.close() similar.foreachPartition(save_hbase) æ·»åŠ å‡½æ•°åˆ°ä¸»å‡½æ•°ä¸­æ–‡ä»¶ä¸­ï¼Œä¿®æ”¹updateæ›´æ–°ä»£ç ï¼š ua = UpdateArticle() sentence_df = ua.merge_article_data() if sentence_df.rdd.collect(): rank, idf = ua.generate_article_label(sentence_df) articleProfile = ua.get_article_profile(rank, idf) ua.compute_article_similar(articleProfile) ç”¨æˆ·ç”»åƒæ„å»ºä¸æ›´æ–° ç»„æˆæˆåˆ† ç”¨æˆ·åŸºæœ¬ä¿¡æ¯+ç”¨æˆ·è¡Œä¸º(å†å²+æ–°å¢) ç”¨æˆ·è¡Œä¸ºåŒ…æ‹¬ï¼š hive&gt; select * from user_action limit 1; OK 2019-03-05 10:19:40 0 {&quot;action&quot;:&quot;exposure&quot;,&quot;userId&quot;:&quot;2&quot;,&quot;articleId&quot;:&quot;[16000, 44371, 16421, 16181, 17454]&quot;,&quot;algorithmCombine&quot;:&quot;C2&quot;} 2019-03-05 æˆ‘ä»¬éœ€è¦å¯¹ç”¨æˆ·è¡Œä¸ºï¼ˆå­—å…¸ï¼‰æ•°æ®æ ¼å¼å¹³é“ºå¤„ç† user_id action_time article_id share click collected exposure read_time æ­¥éª¤ï¼š 1ã€åˆ›å»ºHIVEåŸºæœ¬æ•°æ®è¡¨ 2ã€è¯»å–å›ºå®šæ—¶é—´å†…çš„ç”¨æˆ·è¡Œä¸ºæ—¥å¿— 3ã€è¿›è¡Œç”¨æˆ·æ—¥å¿—æ•°æ®å¤„ç† 4ã€å­˜å‚¨åˆ°user_article_basicè¡¨ä¸­ åˆ›å»ºHIVEåŸºæœ¬æ•°æ®è¡¨ create table user_article_basic( user_id BIGINT comment &quot;userID&quot;, action_time STRING comment &quot;user actions time&quot;, article_id BIGINT comment &quot;articleid&quot;, channel_id INT comment &quot;channel_id&quot;, shared BOOLEAN comment &quot;is shared&quot;, clicked BOOLEAN comment &quot;is clicked&quot;, collected BOOLEAN comment &quot;is collected&quot;, exposure BOOLEAN comment &quot;is exposured&quot;, read_time STRING comment &quot;reading time&quot;) COMMENT &quot;user_article_basic&quot; CLUSTERED by (user_id) into 2 buckets STORED as textfile LOCATION '/user/hive/warehouse/profile.db/user_article_basic'; è¯»å–å¢é‡ç”¨æˆ·è¡Œä¸ºæ•°æ®-å›ºå®šæ—¶é—´å†…çš„ç”¨æˆ·è¡Œä¸ºæ—¥å¿— å…³è”å†å²æ—¥æœŸæ–‡ä»¶ # åœ¨è¿›è¡Œæ—¥å¿—ä¿¡æ¯çš„å¤„ç†ä¹‹å‰ï¼Œå…ˆå°†æˆ‘ä»¬ä¹‹å‰å»ºç«‹çš„user_actionè¡¨ä¹‹é—´è¿›è¡Œæ‰€æœ‰æ—¥æœŸå…³è”ï¼Œspark hiveä¸ä¼šè‡ªåŠ¨å…³è” import pandas as pd from datetime import datetime def datelist(beginDate, endDate): date_list=[datetime.strftime(x,'%Y-%m-%d') for x in list(pd.date_range(start=beginDate, end=endDate))] return date_list dl = datelist(&quot;2019-03-05&quot;, time.strftime(&quot;%Y-%m-%d&quot;, time.localtime())) fs = pyhdfs.HdfsClient(hosts='hadoop-master:50070') for d in dl: try: _localions = '/user/hive/warehouse/profile.db/user_action/' + d if fs.exists(_localions): uup.spark.sql(&quot;alter table user_action add partition (dt='%s') location '%s'&quot; % (d, _localions)) except Exception as e: # å·²ç»å…³è”è¿‡çš„å¼‚å¸¸å¿½ç•¥,partitionä¸hdfsæ–‡ä»¶ä¸ç›´æ¥å…³è” pass sqlDF = uup.spark.sql( &quot;select actionTime, readTime, channelId, param.articleId, param.algorithmCombine, param.action, param.userId from user_action where dt={}&quot;.format(time_str) ) åŸå§‹æ•°æ®æ ¼å¼ä¸ç›®æ ‡æ•°æ®æ ¼å¼ åŸå§‹æ•°æ®æ ¼å¼ï¼šï¼ˆè¡Œä¸ºå‚æ•°éƒ½ç®—åœ¨ actionåˆ—å†…ï¼‰ actionTime readTime channelID articleId ç®—æ³•åç§° action userId 123 1 exposure 1 321 1 click 1 ç›®æ ‡æ•°æ®æ ¼å¼ï¼ˆè¡Œä¸ºå‚æ•°1æ‹†4ï¼Œactionåˆ—è¢«çˆ†ç‚¸ä¸º4åˆ—ï¼Œå‡ä¸ºboolç±»å‹ï¼‰ user_id action_time article_id shared clicked collected expore read_time 1 1 false false false true 1 2 false true false true è¿›è¡Œç”¨æˆ·æ—¥å¿—æ•°æ®æ ¼å¼å¤„ç† if sqlDF.collect(): def _compute(row): # è¿›è¡Œåˆ¤æ–­è¡Œä¸ºç±»å‹ _list = [] if row.action == &quot;exposure&quot;: for article_id in eval(row.articleId): _list.append( [row.userId, row.actionTime, article_id, row.channelId, False, False, False, True, row.readTime]) return _list else: class Temp(object): shared = False clicked = False collected = False read_time = &quot;&quot; _tp = Temp() if row.action == &quot;share&quot;: _tp.shared = True elif row.action == &quot;click&quot;: _tp.clicked = True elif row.action == &quot;collect&quot;: _tp.collected = True elif row.action == &quot;read&quot;: _tp.clicked = True else: pass _list.append( [row.userId, row.actionTime, int(row.articleId), row.channelId, _tp.shared, _tp.clicked, _tp.collected, True, row.readTime]) return _list # è¿›è¡Œå¤„ç† # æŸ¥è¯¢å†…å®¹ï¼Œå°†åŸå§‹æ—¥å¿—è¡¨æ•°æ®è¿›è¡Œå¤„ç† _res = sqlDF.rdd.flatMap(_compute) data = _res.toDF([&quot;user_id&quot;, &quot;action_time&quot;,&quot;article_id&quot;, &quot;channel_id&quot;, &quot;shared&quot;, &quot;clicked&quot;, &quot;collected&quot;, &quot;exposure&quot;, &quot;read_time&quot;]) å°†ä¸Šè¿°ç›®æ ‡æ ¼å¼çš„æ•°æ®æŒ‰ç…§ userid å’Œ articleid åˆ†ç»„ å…ˆåˆå¹¶å†å²æ•°æ®ï¼Œå­˜å‚¨åˆ°user-article-basicè¡¨ä¸­ # åˆå¹¶å†å²æ•°æ®ï¼Œæ’å…¥è¡¨ä¸­ old = uup.spark.sql(&quot;select * from user_article_basic&quot;) # ç”±äºåˆå¹¶çš„ç»“æœä¸­ä¸æ˜¯å¯¹äºuser_idå’Œarticle_idå”¯ä¸€çš„ï¼Œä¸€ä¸ªç”¨æˆ·ä¼šå¯¹æ–‡ç« å¤šç§æ“ä½œ new_old = old.unionAll(data) HIVEç›®å‰æ”¯æŒhiveç»ˆç«¯æ“ä½œACIDï¼Œä¸æ”¯æŒpythonçš„pysparkåŸå­æ€§æ“ä½œï¼Œå¹¶ä¸”å¼€å¯é…ç½®ä¸­å¼€å¯åŸå­æ€§ç›¸å…³é…ç½®ä¹Ÿä¸è¡Œã€‚ new_old.registerTempTable(&quot;temptable&quot;) # æŒ‰ç…§ç”¨æˆ·ï¼Œæ–‡ç« åˆ†ç»„å­˜æ”¾è¿›å» uup.spark.sql( &quot;insert overwrite table user_article_basic select user_id, max(action_time) as action_time, &quot; &quot;article_id, max(channel_id) as channel_id, max(shared) as shared, max(clicked) as clicked, &quot; &quot;max(collected) as collected, max(exposure) as exposure, max(read_time) as read_time from temptable &quot; &quot;group by user_id, article_id&quot;) ç”¨æˆ·ç”»åƒæ ‡ç­¾æƒé‡è®¡ç®— å¦‚ä½•å­˜å‚¨ ç”¨æˆ·ç”»åƒï¼Œä½œä¸ºç‰¹å¾æä¾›ç»™ä¸€äº›ç®—æ³•æ’åºï¼Œæ–¹ä¾¿ä¸å¿«é€Ÿè¯»å–ä½¿ç”¨ é€‰æ‹©å­˜å‚¨åœ¨Hbaseå½“ä¸­ã€‚ ç„¶åç”¨ Hive å¤–è¡¨å…³è” hbase å¦‚æœç¦»çº¿åˆ†æä¹Ÿæƒ³è¦ä½¿ç”¨æˆ‘ä»¬å¯ä»¥å»ºç«‹HIVEåˆ°Hbaseçš„å¤–éƒ¨è¡¨ã€‚ HBaseè¡¨è®¾è®¡ table_name column1 column2 column3 create 'user_profile', 'basic','partial','env' row_key column_family value put 'user_profile', 'user:2', 'partial:{channel_id}:{topic}': weights put 'user_profile', 'user:2', 'basic:{info}': value put 'user_profile', 'user:2', 'env:{info}': value Hiveè¡¨è®¾è®¡ create external table user_profile_hbase( user_id STRING comment &quot;userID&quot;, information map&lt;string, DOUBLE&gt; comment &quot;user basic information&quot;, article_partial map&lt;string, DOUBLE&gt; comment &quot;article partial&quot;, env map&lt;string, INT&gt; comment &quot;user env&quot;) COMMENT &quot;user profile table&quot; STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; = &quot;:key,basic:,partial:,env:&quot;) TBLPROPERTIES (&quot;hbase.table.name&quot; = &quot;user_profile&quot;); Spark SQLå…³è”è¡¨è¯»å–é—®é¢˜ åˆ›å»ºå…³è”è¡¨ä¹‹åï¼Œç¦»çº¿è¯»å–è¡¨å†…å®¹éœ€è¦ä¸€äº›ä¾èµ–åŒ…ã€‚è§£å†³åŠæ³•ï¼š æ‹·è´/root/bigdata/hbase/lib/ä¸‹é¢hbase-.jar åˆ° /root/bigdata/spark/jars/ç›®å½•ä¸‹ æ‹·è´/root/bigdata/hive/lib/h.jar åˆ° /root/bigdata/spark/jars/ç›®å½•ä¸‹ ä¸Šè¿°æ“ä½œä¸‰å°è™šæ‹Ÿæœºéƒ½æ‰§è¡Œä¸€éã€‚ ç”¨æˆ·ç”»åƒé¢‘é“å…³é”®è¯è·å–ä¸æƒé‡è®¡ç®— ç›®æ ‡ï¼šè·å–ç”¨æˆ·1~25é¢‘é“(ä¸åŒ…æ‹¬æ¨èé¢‘é“)çš„å…³é”®è¯ï¼Œå¹¶è®¡ç®—æƒé‡ 1ã€è¯»å–user-article-basicè¡¨ï¼Œåˆå¹¶è¡Œä¸ºè¡¨ä¸æ–‡ç« ç”»åƒä¸­çš„ä¸»é¢˜è¯ 2ã€è¿›è¡Œç”¨æˆ·æƒé‡è®¡ç®—å…¬å¼ã€åŒæ—¶è½åœ°å­˜å‚¨ # è·å–åŸºæœ¬ç”¨æˆ·è¡Œä¸ºä¿¡æ¯ï¼Œç„¶åè¿›è¡Œæ–‡ç« ç”»åƒçš„ä¸»é¢˜è¯åˆå¹¶ uup.spark.sql(&quot;use profile&quot;) # å–å‡ºæ—¥å¿—ä¸­çš„channel_id user_article_ = uup.spark.sql(&quot;select * from user_article_basic&quot;).drop('channel_id') uup.spark.sql('use article') article_label = uup.spark.sql(&quot;select article_id, channel_id, topics from article_profile&quot;) # åˆå¹¶ä½¿ç”¨æ–‡ç« ä¸­æ­£ç¡®çš„channel_id click_article_res = user_article_.join(article_label, how='left', on=['article_id']) å°†å…³é”®è¯å­—æ®µçš„åˆ—è¡¨çˆ†ç‚¸ import pyspark.sql.functions as F click_article_res = click_article_res.withColumn('topic', F.explode('topics')).drop('topics') çˆ†ç‚¸åæ ¼å¼å¦‚ä¸‹ï¼š user_id article_id topic ... 1 1 python 1 1 golang 1 1 linux ... ... ... ç”¨æˆ·ç”»åƒä¹‹æ ‡ç­¾æƒé‡ç®—æ³• ç”¨æˆ·æ ‡ç­¾æƒé‡ =( è¡Œä¸ºç±»å‹æƒé‡ä¹‹å’Œ) Ã— æ—¶é—´è¡°å‡ è¡Œä¸ºç±»å‹æƒé‡ çš„ åˆ†å€¼ çš„ç¡®å®šéœ€è¦æ•´ä½“åå•† è¡Œä¸º åˆ†å€¼ é˜…è¯»æ—¶é—´&lt;1000ms 1 é˜…è¯»æ—¶é—´&gt;=1000ms 2 æ”¶è— 2 åˆ†äº« 3 ç‚¹å‡» 5 æ—¶é—´è¡°å‡: 1/(log(t)+1) ,tä¸ºæ—¶é—´å‘ç”Ÿæ—¶é—´è·ç¦»å½“å‰æ—¶é—´çš„å¤§å°ã€‚ # è®¡ç®—æ¯ä¸ªç”¨æˆ·å¯¹æ¯ç¯‡æ–‡ç« çš„æ ‡ç­¾çš„æƒé‡ def compute_weights(rowpartition): &quot;&quot;&quot;å¤„ç†æ¯ä¸ªç”¨æˆ·å¯¹æ–‡ç« çš„ç‚¹å‡»æ•°æ® &quot;&quot;&quot; weightsOfaction = { &quot;read_min&quot;: 1, &quot;read_middle&quot;: 2, &quot;collect&quot;: 2, &quot;share&quot;: 3, &quot;click&quot;: 5 } import happybase from datetime import datetime import numpy as np # ç”¨äºè¯»å–hbaseç¼“å­˜ç»“æœé…ç½® pool = happybase.ConnectionPool(size=10, host='192.168.19.137', port=9090) # è¯»å–æ–‡ç« çš„æ ‡ç­¾æ•°æ® # è®¡ç®—æƒé‡å€¼ # æ—¶é—´é—´éš” for row in rowpartition: t = datetime.now() - datetime.strptime(row.action_time, '%Y-%m-%d %H:%M:%S') # æ—¶é—´è¡°å‡ç³»æ•° time_exp = 1 / (np.log(t.days + 1) + 1) if row.read_time == '': r_t = 0 else: r_t = int(row.read_time) # æµè§ˆæ—¶é—´åˆ†æ•° is_read = weightsOfaction['read_middle'] if r_t &gt; 1000 else weightsOfaction['read_min'] # æ¯ä¸ªè¯çš„æƒé‡åˆ†æ•° weigths = time_exp * ( row.shared * weightsOfaction['share'] + row.collected * weightsOfaction['collect'] + row. clicked * weightsOfaction['click'] + is_read) # with pool.connection() as conn: # table = conn.table('user_profile') # table.put('user:{}'.format(row.user_id).encode(), # {'partial:{}:{}'.format(row.channel_id, row.topic).encode(): json.dumps( # weigths).encode()}) # conn.close() click_article_res.foreachPartition(compute_weights) è½åœ°Hbaseä¸­ä¹‹åï¼Œåœ¨HBASEä¸­æŸ¥è¯¢ï¼Œhappybaseæˆ–è€…hbaseç»ˆç«¯ import happybase # ç”¨äºè¯»å–hbaseç¼“å­˜ç»“æœé…ç½® pool = happybase.ConnectionPool(size=10, host='192.168.19.137', port=9090) with pool.connection() as conn: table = conn.table('user_profile') # è·å–æ¯ä¸ªé”® å¯¹åº”çš„æ‰€æœ‰åˆ—çš„ç»“æœ data = table.row(b'user:2', columns=[b'partial']) conn.close() # ç­‰ä»·äº hbase(main):015:0&gt; get 'user_profile', 'user:2' åŸºç¡€ä¿¡æ¯ç”»åƒæ›´æ–° def update_user_info(self): &quot;&quot;&quot; æ›´æ–°ç”¨æˆ·çš„åŸºç¡€ä¿¡æ¯ç”»åƒ :return: &quot;&quot;&quot; self.spark.sql(&quot;use toutiao&quot;) user_basic = self.spark.sql(&quot;select user_id, gender, birthday from user_profile&quot;) # æ›´æ–°ç”¨æˆ·åŸºç¡€ä¿¡æ¯ def _udapte_user_basic(partition): &quot;&quot;&quot;æ›´æ–°ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ &quot;&quot;&quot; import happybase # ç”¨äºè¯»å–hbaseç¼“å­˜ç»“æœé…ç½® pool = happybase.ConnectionPool(size=10, host='172.17.0.134', port=9090) for row in partition: from datetime import date age = 0 if row.birthday != 'null': born = datetime.strptime(row.birthday, '%Y-%m-%d') today = date.today() age = today.year - born.year - ((today.month, today.day) &lt; (born.month, born.day)) with pool.connection() as conn: table = conn.table('user_profile') table.put('user:{}'.format(row.user_id).encode(), {'basic:gender'.encode(): json.dumps(row.gender).encode()}) table.put('user:{}'.format(row.user_id).encode(), {'basic:birthday'.encode(): json.dumps(age).encode()}) conn.close() user_basic.foreachPartition(_udapte_user_basic) logger.info( &quot;{} INFO completely update infomation of basic&quot;.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))) # hbase(main):016:0&gt; get 'user_profile', 'user:2' ç”¨æˆ·ç”»åƒå¢é‡æ›´æ–°å®šæ—¶å¼€å¯: ç”¨æˆ·ç”»åƒå¢é‡æ›´æ–°ä»£ç æ•´ç† æ·»åŠ å®šæ—¶ä»»åŠ¡ä»¥åŠè¿›ç¨‹ç®¡ç† from offline.update_user import UpdateUserProfile def update_user_profile(): &quot;&quot;&quot; æ›´æ–°ç”¨æˆ·ç”»åƒ &quot;&quot;&quot; uup = UpdateUserProfile() if uup.update_user_action_basic(): uup.update_user_label() uup.update_user_info() scheduler.add_job(update_user_profile, trigger='interval', hours=2) ","link":"https://cythonlin.github.io/post/rs-greater-tui-jian-xi-tong-er-chi-xian-hua-xiang-gou-jian/"},{"title":"PY => Spark mapPartition","content":"æ­£è§£ map()ï¼šæ¯æ¬¡å¤„ç†ä¸€æ¡æ•°æ® mapPartition()ï¼šæ¯æ¬¡å¤„ç†ä¸€ä¸ªåˆ†åŒºçš„æ•°æ®ï¼Œè¿™ä¸ªåˆ†åŒºçš„æ•°æ®å¤„ç†å®Œåï¼ŒåŸRDDä¸­åˆ†åŒºçš„æ•°æ®æ‰èƒ½é‡Šæ”¾ï¼Œå¯èƒ½å¯¼è‡´OOM å½“å†…å­˜ç©ºé—´è¾ƒå¤§çš„æ—¶å€™å»ºè®®ä½¿ç”¨mapPartition()ï¼Œä»¥æé«˜å¤„ç†æ•ˆç‡ åˆ†éš” ä¸‹é¢æ‰€æœ‰æ˜¯è‡ªå·±çš„æ€è·¯ï¼Œæ¨åˆ°æœ€åç»™è‡ªå·±æ¨è’™äº†ï¼Œå¯ä»¥æ è¿‡ æ­£æ–‡å®éªŒï¼ˆå¯å¿½ç•¥ï¼Œç›´å¥”ç»“æœï¼‰ ä¸ºäº†æ–¹ä¾¿ï¼Œç”¨æŠŠç»„è£…çš„æ•°æ®ç±»å‹çŒå…¥ map æ¥æ¨¡æ‹Ÿ mapPartitions åŠŸèƒ½æ˜¯æ¨¡æ‹Ÿè®¡ç®— tf-idf class Article: '''æ–‡ç« ç±»''' def __init__(self,id, indexex, tfidfs): self.id = id self.indexex = indexex # æ–‡ç« åˆ†è¯åçš„æ‰€æœ‰è¯ç´¢å¼•åˆ—è¡¨ self.tfidfs = tfidfs # æ¯ä¸ªè¯å¯¹åº”çš„TF-IDFå€¼ åˆ—è¡¨ def f(partition): for row in partition: # row ä»£è¡¨æ¯ä¸ªæ–‡ç«  # row.indexex ä»£è¡¨ æ–‡ç« åˆ†è¯åçš„æ‰€æœ‰è¯ç´¢å¼•åˆ—è¡¨ # row.tfidfs ä»£è¡¨ æ¯ä¸ªè¯å¯¹åº”çš„TF-IDFå€¼ åˆ—è¡¨ word_list = list(zip(row.indexex, row.tfidfs)) for index, tfidf in word_list: # éå† &quot;æ¯ä¸ª&quot;è¯è¯­ çš„ indexä¸tfidf ########### è¿™é‡Œ yield æ˜¯é‡ç‚¹ ########### yield f'æ–‡ç« {row.id}', index, tfidf c = map(f, [ # &lt;-ä¸ºäº†æ¨¡æ‹Ÿåˆ†åŒºï¼Œè¿™ä¸€å±‚çš„åˆ—è¡¨ä»£è¡¨partition [ # &lt;- è¿™ä¸€å±‚æ¨¡æ‹Ÿçš„æ˜¯æ¯ä¸ªåˆ†åŒºé‡Œé¢çš„æ–‡ç« åˆ—è¡¨ Article(0, [1,2],[0.1,0.4] ), # &lt;-æ–‡ç« 0 Article(1, [3,4],[3.4,3.7] ) # &lt;-æ–‡ç« 1 ] ] ) ######################## æ‰§è¡Œ ######################## for x in c: # è§£zip print(list(x)) # è§£yield ç»“æœï¼š å¦‚æœä½¿ç”¨ return å…³é”®è¯ï¼Œå¾—å‡ºçš„æœ€ç»ˆæ‰“å°ç»“æœ: ï¼ˆä¸æ»¡è¶³ï¼‰ ['æ–‡ç« 0', 1, 0.1] å¦‚æœä½¿ç”¨ yield å…³é”®è¯ï¼Œå¾—å‡ºçš„æœ€ç»ˆæ‰“å°ç»“æœ: ï¼ˆæ»¡è¶³ï¼‰ [('æ–‡ç« 0', 1, 0.1), ('æ–‡ç« 0', 2, 0.4), ('æ–‡ç« 1', 3, 3.4), ('æ–‡ç« 1', 4, 3.7)] è¿™é‡Œå°±å‡ºç°äº†ä¸€ä¸ªé—®é¢˜ï¼š æ­£å¸¸ç”¨æ³•éƒ½æ˜¯ç”¨ returnï¼Œæ—¶å¸¸ç”¨ lambdaï¼ˆlambdaé»˜è®¤ä¹Ÿæ˜¯éšå¼ returnã€‚ï¼‰ æ˜¯ä½•åŸå› è®©æˆ‘ä»¬ä¸å¾—ä¸ç”¨ yield? ä¸€ç‚¹ä¸€ç‚¹å¾€ä¸‹æ¨ï¼š map: æ ¸å¿ƒæ˜¯ &quot;æŒ‰å•ä¸ªæ•°æ®æ˜ å°„&quot; mapPartitionï¼š æ ¸å¿ƒæ˜¯&quot;æŠŠæ•°æ®åˆ†ç»„ï¼ŒæŒ‰ç»„æ˜ å°„&quot; æŒ‰ç»„æ˜ å°„æ˜¯æ²¡é”™ï¼Œä½†æˆ‘ä»¬çš„ç›®çš„æ˜¯æƒ³æ“ä½œç»„å†…çš„æ¯æ¡æ•°æ®ã€‚ æ‰€ä»¥æˆ‘ä»¬å¿…é¡»éœ€è¦æ¯æ¬¡å¯¹ç»„å†…æ•°æ® forå¾ªç¯éå†å‡ºæ¥å•ç‹¬å¤„ç†ã€‚ ç„¶å è¿”å›å›å»ã€‚ é‚£æˆ‘ä»¬å…ˆç”¨æ­£å¸¸çš„ return è¿”å›è¯•è¯•ï¼š def(partation): for x in partition: return x.name, x.age ä¹Ÿè®¸çœ‹åˆ°è¿™é‡Œä½ è§‰å¾—æ²¡ä»€ä¹ˆé—®é¢˜ã€‚ã€‚ã€‚ ä½†æ˜¯ä¸è¦å¿˜äº†æœ€åŸºç¡€çš„å†…å®¹ï¼Œ return æ˜¯ç›´æ¥è·³å‡º for å¾ªç¯å’Œå‡½æ•°çš„ã€‚ å†æ¬¡å¼ºè°ƒï¼ŒmapPartitionæ˜¯æŒ‰ç»„æ˜ å°„ï¼Œæ‰€ä»¥ä»”ç»†çœ‹ä¸Šé¢ä»£ç : æœ€ç»ˆçš„mapPartitionæ˜¯æŒ‰ç»„æ˜ å°„ç»“æœå°±æ˜¯ï¼š æ¯ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ çš„é›†åˆ ï¼ˆå› ä¸ºforè¢«returnäº†ï¼Œæ¯ç»„çš„å‡½æ•°ä¹Ÿè¢«returnäº†ï¼‰ è§£å†³è¿™ç§é—®é¢˜ï¼Œæœ‰ä¸¤ç§æ–¹å¼ï¼š æœ€ç®€å•å°†æºä»£ç forå¾ªç¯å†…éƒ¨çš„ return æ”¹ä¸º yield æ–°å»ºä¸´æ—¶åˆ—è¡¨è¿‡æ¸¡ï¼Œreturnæ”¾åœ¨forå¤–é¢ï¼Œå¦‚ä¸‹æ¡ˆä¾‹ï¼š def f(partition): _ = [] for x in partition: _.append(x) return _ b = [[1,2,3], [4,5,6]] c = map(f,b) print(list(c)) ","link":"https://cythonlin.github.io/post/py-greater-spark-mappartition/"},{"title":"RS => æ¨èç³»ç»Ÿï¼ˆä¸€ï¼‰ç¯å¢ƒé…ç½®+æ•°æ®æ”¶é›†","content":"Pythonç¯å¢ƒ minicondaåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š conda create -n reco_sys python=3.6.7 æ¿€æ´»/é€€å‡º è™šæ‹Ÿç¯å¢ƒï¼š conda activate spider-venv conda deactivate 2ä¸ªslaveéœ€è¦å®‰è£…ä¾èµ–ï¼š yum -y install gcc å®‰è£…æ¨¡å—ï¼š pip install redis supervisor apscheduler chardet jieba jupyter numpy pandas scipy scikit-learn pyspark findspark happybase pyhdfs -i https://pypi.douban.com/simple å¤§æ•°æ®ç¯å¢ƒ Lambdaç¯å¢ƒå¯åŠ¨è„šæœ¬é…ç½® ç¦ç”¨+å…³é—­é˜²ç«å¢™ï¼š systemctl disable firewalld.service systemctl stop firewalld.service åŒæ­¥ç³»ç»Ÿæ—¶é—´ï¼ˆä¸è¿™æ ·åš hbaseå¯èƒ½å¯åŠ¨å¤±è´¥ï¼‰ï¼ˆ3å°éƒ½è¿è¡Œå‘½ä»¤ï¼‰ï¼š yum install ntpdate -y ntpdate 0.cn.pool.ntp.org åˆ›å»ºç»¼åˆå¯åŠ¨è„šæœ¬ vi start.sh /root/bigdata/hadoop/sbin/start-all.sh start-hbase.sh /root/bigdata/spark/sbin/start-all.sh vi stop.sh /root/bigdata/spark/sbin/stop-all.sh stop-hbase.sh /root/bigdata/hadoop/sbin/stop-all.sh å¼€å¯ /root/scripts/start.sh åœæ­¢ /root/scripts/stop.sh UIåœ°å€ï¼ˆæŸ¥logä¹Ÿå¯ï¼‰ï¼š Hadoop UI: http://192.168.19.137:8088 YARN UIï¼š http://192.168.19.137:50070 Hbase UI: http://192.168.19.137:16010 Spark UIï¼š http://192.168.19.137:8080/ æ•°æ®åº“è¿è¡Œï¼š MySQLå¯åŠ¨ï¼š systemctl start docker docker start mysql Hiveå…ƒæ•°æ®æœåŠ¡å¼€å¯: nohup hive --service metastore &amp; sparkç›¸å…³é—®é¢˜ spark on yarn å¯åŠ¨å·¨æ…¢ï¼Œè§£å†³åŠæ³•ï¼š hadoop fs -mkdir -p /system/spark-lib hadoop fs -put /root/bigdata/spark-2.2.2-bin-hadoop2.7/jars/* /system/spark-lib hadoop fs -chmod -R 755 /system/spark-lib cd $SPARK_HOME/conf cp spark-defaults.conf.template spark-defaults.conf vi spark-defaults.conf spark.yarn.jars hdfs://192.168.19.137:9000//system/spark-lib/* å¦‚æœç”¨çš„æ˜¯ jupyter, è®°å¾—é‡å¯ jupyteræœåŠ¡ jupyter notebook --allow-root --ip 0.0.0.0 HDFS-Hiveç›¸å…³é—®é¢˜ å†…éƒ¨è¡¨ä¿®æ”¹ä¸ºå¤–éƒ¨è¡¨ï¼š alter table user_profile SET TBLPROPERTIES('EXTERNAL'='TRUE'); æ•°æ®æ„æˆ æ•°æ®åº“1ï¼š toutiao news_article_basic # æ–‡ç« æ ‡é¢˜ news_article_content # æ–‡ç« å†…å®¹ news_channel # æ–‡ç« é¢‘é“ï¼ˆç±»åˆ«ï¼‰ user_basic # ç”¨æˆ·ä¸šåŠ¡æ•°æ® user_profile # ç”¨æˆ·ç§äººä¿¡æ¯ æ•°æ®åº“2ï¼š profile user_action # ç”¨æˆ·è¡Œä¸ºæ—¥å¿— æ•°æ®åº“2ï¼š article article_data # åˆå¹¶æ–‡ç« æ ‡é¢˜+å†…å®¹+é¢‘é“åçš„å­˜å‚¨ç»“æœ ... æ•°æ®è¿ç§»ï¼ˆSqoopï¼‰ è€—æ—¶ 4000w (10+g): 30+ min æ£€æµ‹Sqoopæ˜¯å¦èƒ½è¿é€šMySQL, å¹¶åˆ—å‡ºMySQLæ‰€æœ‰æ•°æ®åº“: sqoop list-databases --connect jdbc:mysql://192.168.19.137:3306/ --username root -P å…¨é‡å¯¼å…¥æ–¹å¼ï¼ˆä¸æ¨èï¼‰ï¼š #!/bin/bash array=(user_profile user_basic news_user_channel news_channel user_follow user_blacklist user_search news_collection news_article_basic news_article_content news_read news_article_statistic user_material) for table_name in ${array[@]}; do sqoop import \\ --connect jdbc:mysql://192.168.19.137/toutiao \\ --username root \\ --password password \\ --table $table_name \\ --m 5 \\ --hive-home /root/bigdata/hive \\ --hive-import \\ --create-hive-table \\ --hive-drop-import-delims \\ --warehouse-dir /user/hive/warehouse/toutiao.db \\ --hive-table toutiao.$table_name done å¢é‡å¯¼å…¥æ–¹å¼ æ–¹å¼1ï¼š é€šè¿‡æŒ‡å®šé€’å¢çš„å­—æ®µæ¥å¯¼å…¥ï¼ˆä¸æ¨èï¼Œå› ä¸ºæŸäº›å­—æ®µçš„å€¼ä¸æ˜¯é€’å¢çš„ï¼‰ appendï¼šå³é€šè¿‡æŒ‡å®šä¸€ä¸ªé€’å¢çš„åˆ—ï¼Œå¦‚ï¼š--incremental append --check-column num_iid --last-value 0 æ–¹å¼2ï¼šincrementalï¼š æ—¶é—´æˆ³ --incremental lastmodified --check-column column --merge-key key --last-value '2012-02-01 11:0:00' å°±æ˜¯åªå¯¼å…¥check-columnçš„åˆ—æ¯”'2012-02-01 11:0:00'æ›´å¤§ï¼ˆæ–°ï¼‰çš„æ•°æ®,æŒ‰ç…§keyåˆå¹¶ å¢é‡å¯¼å…¥ä½ç½® ç›´æ¥sqoopå¯¼å…¥åˆ°hive(â€“incremental lastmodified æ¨¡å¼ä¸æ”¯æŒå¯¼å…¥ Hive ) sqoopå¯¼å…¥åˆ°hdfsï¼Œç„¶åå»ºç«‹hiveè¡¨å…³è” --target-dir /user/hive/warehouse/toutiao.db/ sqoopå¯¼å…¥åˆ°hdfsï¼Œhiveè¡¨å…³è”åˆ°hdfså¡«å‘ ç°è±¡ï¼š æŸ¥å‡ºä¸€å † null åŸå› ï¼š sqoop å¯¼å‡ºçš„ hdfs åˆ†ç‰‡æ•°æ®ï¼Œéƒ½æ˜¯ä½¿ç”¨é€—å· , åˆ†å‰²çš„ã€‚ ç”±äº hive é»˜è®¤çš„åˆ†éš”ç¬¦æ˜¯ /u0001ï¼ˆCtrl+Aï¼‰,ä¸ºäº†å¹³æ»‘è¿ç§»ï¼Œéœ€è¦åœ¨åˆ›å»ºè¡¨æ ¼æ—¶æŒ‡å®šæ•°æ®çš„åˆ†å‰²ç¬¦å·ã€‚ è§£å†³æ–¹å¼ï¼š å¯¼å…¥æ•°æ®åˆ°hiveä¸­ï¼Œéœ€è¦åœ¨åˆ›å»ºHIVEè¡¨åŠ å…¥ row format delimited fields terminated by ',' sqoopè¿ç§»åˆ°hdfsåï¼ŒHiveåˆ›å»ºè¡¨å¹¶æŒ‡å®šå…³è”ä½ç½®å®ä¾‹ create table user_profile( user_id BIGINT comment &quot;userID&quot;, gender BOOLEAN comment &quot;gender&quot;) COMMENT &quot;toutiao user profile&quot; row format delimited fields terminated by ',' LOCATION '/user/hive/warehouse/toutiao.db/user_profile'; æ³¨ï¼š 5ä¸ªè¡¨ä¸­ï¼Œåªæœ‰ news_article_content ï¼ˆå› ä¸ºè¿™ä¸ªè¡¨å¥‡æ€ªå­—ç¬¦å¤ªå¤šï¼Œæ˜¯å…¨é‡å¯¼å…¥çš„ï¼Œhiveä¸éœ€è¦æ‰‹åŠ¨åˆ›å»ºè¡¨ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºçš„ï¼‰ è€Œè¿™ä¸ªè¡¨ä» hdfs æ‹¿åˆ°çš„æ•°æ®æ˜¯å·²ç»åšè¿‡è¿‡æ»¤çš„ï¼Œæ‰€ä»¥ä¸éœ€è¦ åŠ åˆ†éš”ç¬¦äº†ï¼Œä¹Ÿå°±æ˜¯ä¸éœ€è¦ä¸‹é¢è¿™è¡Œä»£ç ï¼š row format delimited fields terminated by ',' Flumeæ—¥å¿—æ”¶é›†åˆ°Hiveä¸­ æ–°å»ºæ•°æ®åº“ create database if not exists profile comment &quot;use action&quot; location '/user/hive/warehouse/profile.db/'; åˆ›å»ºè¡¨çš„æ ¼å¼è¯­æ³•å®ä¾‹å¦‚ä¸‹ï¼š create table user_action( actionTime STRING comment &quot;user actions time&quot;, readTime STRING comment &quot;user reading time&quot;, channelId INT comment &quot;article channel id&quot;, param map&lt;string, string&gt; comment &quot;action parameter&quot;) COMMENT &quot;user primitive action&quot; PARTITIONED BY(dt STRING) ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe' LOCATION '/user/hive/warehouse/profile.db/user_action'; æ–‡æ¡£ä¸­ï¼šHiveå»ºè¡¨ï¼Œæœ‰ä¸ªé—®é¢˜ map éœ€è¦æŒ‡å®šæ•°æ®ç±»å‹: param map&lt;string, string&gt; comment &quot;action parameter&quot;) map è¦å‘ä¸Šé¢ä¸€æ ·æŒ‡å®š &lt;string, string&gt; æ‰å¯ä»¥ï¼Œ ä¸ç„¶ä¼šæŠ¥å¦‚ä¸‹é”™è¯¯ï¼š '''mismatched input 'comment' expecting &lt; near 'map' in map type''' ç–‘éš¾å‚æ•°è§£è¯»ï¼š PARTITIONED BY(dt STRING)ï¼š hiveæŒ‰ç…§ dt å­—æ®µåˆ†åŒº ä¸ºä»€ä¹ˆè¦åˆ†åŒºï¼š Hiveé€‚åˆå¤„ç†å¤§çš„æ–‡ä»¶å†…å®¹é‡ï¼Œå°‘çš„æ–‡ä»¶æ•°é‡ã€‚ Flumeæ”¶é›†æ—¥å¿—å¯èƒ½æ¥ä¸€ç‚¹æ—¥å¿—å°±åŠ åˆ°ä¸€ä¸ªæ–°æ–‡ä»¶ä¸­ã€‚ å¦‚æ­¤ä¸€æ¥ï¼Œæ–‡ä»¶é›¶æ•£çš„ç‰¹åˆ«å¤šã€‚ Hiveå¤„ç†çš„ä¼šå¾ˆæ…¢ã€‚ æ‰€ä»¥ï¼ŒHiveæŒ‡å®šä¸ªåˆ†åŒºï¼Œæ¥æŠŠå°æ–‡ä»¶ä»¬åˆ†æˆå‡ å¤§å—ï¼ˆå°±æ˜¯å‡ ä¸ªåˆ†åŒºï¼‰ï¼Œè¿™æ ·å¤„ç†ä¼šæ›´å¿« ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'ï¼š å¤„ç†Jsonæ ¼å¼æ•°æ® æ•°æ®å¯¼å…¥æ­¥éª¤å¦‚ä¸‹ï¼ˆè™šä»£æ›¿Flumeï¼‰ï¼ˆæ“ä½œå®Œæˆåæ˜¯æŸ¥ä¸åˆ°æ•°æ®çš„ï¼Œéœ€è¦å…³è”ï¼Œä¸‹é¢ä¼šè§£é‡Šï¼‰ï¼š hadoop fs -put /root/data/backup/profile.db/user_action/* /user/hive/warehouse/profile.db/user_action/ # åˆ é™¤: hadoop fs -rmr /user/hive/warehouse/profile.db/* Flume æ”¶é›†é…ç½® è¿›å…¥flume/confç›®å½• åˆ›å»ºä¸€ä¸ªcollect _ click.confçš„æ–‡ä»¶ï¼Œå†™å…¥flumeçš„é…ç½®ï¼š a1.sources = s1 a1.sinks = k1 a1.channels = c1 a1.sources.s1.channels= c1 a1.sources.s1.type = exec a1.sources.s1.command = tail -F /root/logs/userClick.log a1.sources.s1.interceptors=i1 i2 a1.sources.s1.interceptors.i1.type=regex_filter a1.sources.s1.interceptors.i1.regex=\\\\{.*\\\\} a1.sources.s1.interceptors.i2.type=timestamp # channel1 a1.channels.c1.type=memory a1.channels.c1.capacity=30000 a1.channels.c1.transactionCapacity=1000 # k1 a1.sinks.k1.type=hdfs a1.sinks.k1.channel=c1 a1.sinks.k1.hdfs.path=hdfs://192.168.19.137:9000/user/hive/warehouse/profile.db/user_action/%Y-%m-%d a1.sinks.k1.hdfs.useLocalTimeStamp = true a1.sinks.k1.hdfs.fileType=DataStream a1.sinks.k1.hdfs.writeFormat=Text a1.sinks.k1.hdfs.rollInterval=0 a1.sinks.k1.hdfs.rollSize=10240 a1.sinks.k1.hdfs.rollCount=0 a1.sinks.k1.hdfs.idleTimeout=60 å‚æ•°è¯´æ˜ï¼š sourcesï¼šä¸ºå®æ—¶æŸ¥çœ‹æ–‡ä»¶æœ«å°¾ï¼Œinterceptorsè§£æjsonæ–‡ä»¶ channelsï¼šæŒ‡å®šå†…å­˜å­˜å‚¨ï¼Œå¹¶ä¸”åˆ¶å®šbatchDataçš„å¤§å°ï¼ŒPutListå’ŒTakeListçš„å¤§å°è§å‚æ•°ï¼ŒChannelæ€»å®¹é‡å¤§å°è§å‚æ•° æŒ‡å®šsinkï¼šå½¢å¼ç›´æ¥åˆ°hdfsï¼Œä»¥åŠè·¯å¾„ï¼Œæ–‡ä»¶å¤§å°ç­–ç•¥é»˜è®¤1024ã€eventæ•°é‡ç­–ç•¥ã€æ–‡ä»¶é—²ç½®æ—¶é—´ å¼€å§‹æ”¶é›†ï¼š /root/bigdata/flume/bin/flume-ng agent -c /root/bigdata/flume/conf -f /root/bigdata/flume/conf/collect_click.conf -Dflume.root.logger=INFO,console -name a1 Hive å…³è”åˆ†åŒºï¼š å¦‚æœä¸å…³è”åˆ†åŒºï¼Œæ— è®ºæ˜¯ Flumeæ”¶é›†åˆ°HDFSçš„åˆ†åŒºæ•°æ®ï¼Œè¿˜æ˜¯æˆ‘ä»¬ä¼ è¿›å»HDFSæ¨¡æ‹Ÿçš„åˆ†åŒºæ•°æ® é€šè¿‡Hiveæ˜¯æŸ¥ä¸åˆ°çš„ å…³è”åˆ†åŒºå¦‚ä¸‹æ“ä½œï¼š alter table user_action add partition (dt='2018-12-11') location &quot;/user/hive/warehouse/profile.db/user_action/2018-12-11/&quot; è¿›ç¨‹ç®¡ç† Supervisor æ­£å¸¸é…ç½®æµç¨‹ å®‰è£…: pip install supervisor åˆ›å»ºé…ç½®æ–‡ä»¶ï¼ˆå½“å‰ç›®å½•æ‰§è¡Œï¼Œæˆ–è€…ä¸»ç›®å½•æ‰§è¡Œéƒ½å¯ï¼Œæ€»é…ç½®æ–‡ä»¶å°±ä¼šç”Ÿæˆåˆ°å½“å‰ç›®å½•ä¸‹ï¼‰ï¼š echo_supervisord_conf &gt; supervisord.conf åˆ›å»ºè‡ªå®šä¹‰é…ç½®æ–‡ä»¶ç›®å½•ï¼š mkdir /etc/supervisor vim æ‰“å¼€ç¼–è¾‘supervisord.confæ–‡ä»¶ï¼Œä¿®æ”¹æœ€å1è¡Œï¼š [include] files = relative/directory/.ini ä¸º [include] files = /etc/supervisor/.conf å°†æœ€å¼€å§‹ç”Ÿæˆçš„ supervisord.conf å¤åˆ¶åˆ° /etc/ ä¸‹ï¼Œ ç„¶åä¸»æ–‡ä»¶å°±ä¸ç”¨åŠ¨äº†ï¼š cp supervisord.conf /etc/ æœ€ååœ¨ /etc/supervisor è¿™ä¸ªç›®å½•ä¸­ï¼Œè‡ªå®šä¹‰æˆ‘ä»¬è‡ªå·±éœ€è¦çš„ å¯åŠ¨ç¨‹åºçš„é…ç½®æ–‡ä»¶æ¨¡æ¿ï¼Œè¿™é‡Œä¸º vi reco.confï¼š è§ä¸‹é¢Flumeæ¡ˆä¾‹ Flume+Supervisor é…ç½®æ¡ˆä¾‹ flumeå¯åŠ¨éœ€è¦ç›¸å…³hadoop,javaç¯å¢ƒï¼Œå¯ä»¥åœ¨shellè„šæœ¬æ±‡æ€»æ·»åŠ : å…ˆåˆ›å»ºä¸€ä¸ªå­˜æ”¾æ­¤shellè„šæœ¬çš„ç›®å½•ï¼š mkdir /root/toutiao_project/scripts æ‰“å¼€æ–‡ä»¶: vi /root/toutiao_project/scripts/collect_click.sh å¹¶å†™å…¥: #!/usr/bin/env bash export JAVA_HOME=/root/bigdata/jdk export HADOOP_HOME=/root/bigdata/hadoop export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin /root/bigdata/flume/bin/flume-ng agent -c /root/bigdata/flume/conf -f /root/bigdata/flume/conf/collect_click.conf -Dflume.root.logger=INFO,console -name a1 å¹¶åœ¨ /etc/supervisor çš„reco.confæ·»åŠ : [program:flume] command=/bin/bash /root/toutiao_project/scripts/collect_click.sh user=root autorestart=true redirect_stderr=true stdout_logfile=/root/logs/collect.log loglevel=info stopsignal=KILL stopasgroup=true killasgroup=true å¯åŠ¨ supervisoræœåŠ¡: supervisord -c /etc/supervisord.conf æŸ¥çœ‹ supervisoræ˜¯å¦è¿è¡Œï¼š ps aux | grep supervisord ç®¡ç† supervisorè¿›ç¨‹ç®¡ç†ç•Œé¢ï¼Œè¾“å…¥å‘½ä»¤ï¼š supervisorctl ç®¡ç†ç•Œé¢å¯é€šè¿‡å¦‚ä¸‹ å‘½ä»¤+è¿›ç¨‹å æ¥ç®¡ç†è¿›ç¨‹ï¼š start flume stop flume restart flume status # æŸ¥çœ‹æ‰€æœ‰è¿›ç¨‹çŠ¶æ€ update # é‡å¯é…ç½®æ–‡ä»¶ä¿®æ”¹è¿‡çš„ç¨‹åº ","link":"https://cythonlin.github.io/post/rs-greater-tui-jian-xi-tong-yi-huan-jing-pei-zhi-shu-ju-shou-ji/"},{"title":"PY => PySpark-Spark SQL","content":"Spark SQL Spark SQL åˆ†ä¸ºä¸‰ç±»ï¼š SQL DataFrame (å‚è€ƒpandasï¼Œä½†ç•¥æœ‰ä¸åŒ) Datasets (ç”±äºpythonæ˜¯åŠ¨æ€çš„ï¼Œæ‰€ä»¥ä¸æ”¯æŒpython) åˆå§‹ç¯å¢ƒï¼š import findspark findspark.init() from pyspark.sql import SparkSession spark = SparkSession.builder.appName('myspark').getOrCreate() # åˆå§‹åŒ–session # spark.sparkContext.parallelize([1,2,3,4]).collect() # é‡Œé¢åŒ…å«ä¹‹å‰è¯´è¿‡çš„sparkContext ... ä¸­é—´è¿™éƒ¨åˆ†ç•™ç»™ä¸‹é¢å†™ ... spark.stop() # å…³é—­ session ä»jsonå¯¼å…¥ä¸ºdf: df = spark.read.json(&quot;file:///home/lin/data/user.json&quot;,multiLine=True) æ‰“å°DFå­—æ®µä¿¡æ¯ï¼š df.printSchema() root |-- age: long (nullable = true) |-- gender: string (nullable = true) |-- name: string (nullable = true) CRUD å¢ from pyspark.sql import functions as f # schemaå°±ç›¸å½“äº pandas æŒ‡å®šçš„ columns, åŒå±‚åºåˆ—ï¼Œ [2x4] çš„æ ·æœ¬ df1 = spark.createDataFrame([[1,2,3,4],[5,6,7,8]],schema=['1_c','2_c', '3_c', '4_c']) +-----+-----+-----+-----+ |1\\_col|2\\_col|3\\_col|4\\_col| +-----+-----+-----+-----+ | 1| 2| 3| 4| | 5| 6| 7| 8| +-----+-----+-----+-----+ # litå¯ä»¥åœ¨æŒ‡å®šç©ºåˆ—çš„æ—¶å€™ï¼ŒæŒ‡å®š nullå€¼ï¼Œ æˆ–è€… intå‹ï¼ˆé‡Œé¢æœ‰å¾ˆå¤šç±»å‹ï¼Œå¯ä»¥å‘ç°ï¼‰ # df2 = df1.withColumn('null_col', f.lit(None)).withColumn('digit_col', f.lit(2)) df2 = df1.withColumn('5_col', df1['4_col']+1) # åœ¨åŸæ¥åˆ—å­—æ®µåŸºç¡€ä¸Šã€‚ df2.show() åˆ  df2 = df1.drop('age') # åˆ é™¤ ageåˆ— df2 = df1.dropna() # åˆ é™¤ç©ºè¡Œ df2 = df1.drop_duplicates() # åˆ é™¤é‡å¤-è¡Œ æ”¹ å’Œ&quot;å¢&quot;ï¼Œå·®ä¸å¤šï¼Œåªä¸è¿‡å­—æ®µï¼ŒæŒ‡å®šä¸ºåŸæœ‰å­—æ®µå­—ç¬¦ä¸²å³å¯ã€‚ æŸ¥ ä¸‹é¢çš„è®²çš„ï¼ˆæŠ•å½±ã€è¿‡æ»¤ã€æ’åºã€åˆ†ç»„ï¼‰ï¼Œå‡ ä¹éƒ½æ˜¯æŸ¥ã€‚ æŠ•å½± æŠ•å½±æ‰€æœ‰ï¼š df.show(n=20) # é»˜è®¤å°±æ˜¯ n=20 åªè¿”å› å‰20æ¡è®°å½• +---+------+--------+ |age|gender| name| +---+------+--------+ | 18| man|zhangsan| +---+------+--------+ é€‰ä¸­æŸåˆ—æŠ•å½±ï¼š df.select('name','age').show() # è‹¥ç›´æ¥å†™ '*', å’Œç›´æ¥ df.show()æ˜¯ä¸€ä¸ªæ•ˆæœ +--------+---+ | name|age| +--------+---+ |zhangsan| 18| +--------+---+ æˆ–è€…ç”¨å¦ä¸¤ç§æ–¹å¼æŠ•å½±ï¼ˆæŠ•å½±è¿‡ç¨‹å¯è®¡ç®—ï¼‰ï¼š df.select(df['name'],df['age']+20).show() # åŒä¸Šï¼Œè¿™æ˜¯å¦ä¸€ç§å†™æ³•ï¼Œæ³¨æ„ä¸€ä¸‹åˆ—å df.select(df.name, df.age+20).show() # åŒä¸Šï¼Œè¿™æ˜¯å¦äºŒç§å†™æ³•ï¼Œæ³¨æ„ä¸€ä¸‹åˆ—å +--------+----------+ | name|(age + 20)| +--------+----------+ |zhangsan| 38| +--------+----------+ å–å‡ºå‰Næ¡DFï¼Œå¹¶è½¬åŒ–ä¸º [ {} , {} ] æ ¼å¼ df_user.take(1) # [Row(age=18, name='å¼ ä¸‰')] df_user.head(1) # [Row(age=18, name='å¼ ä¸‰')] df_user.first() # Row(age=18, name='å¼ ä¸‰') # æ³¨æ„,æ— åˆ—è¡¨ æ’åº df_user.head(1) df_user.sort(df_user.name.desc()).show() # å¦å¤–è¯´æ˜ä¸€ç‚¹, dfçš„æ¯ä¸ªç†Ÿæ‚‰éƒ½æœ‰,ä¸€äº›æ“ä½œç¬¦å‡½æ•°, desc()å°±æ˜¯ä¸€ç§æ“ä½œç¬¦å‡½æ•° è¿‡æ»¤ï¼š df.filter( df['age'] &gt; 15).show() +---+------+----+ |age|gender|name| +---+------+----+ +---+------+----+ åˆ†ç»„ï¼š df.groupBy('name').count().show() +--------+-----+ | name|count| +--------+-----+ |zhangsan| 1| +--------+-----+ Join df_user.join(df_user, on=df_user.name==df_user.name, how='inner').show() +----+---+----+---+ |name|age|name|age| +----+---+----+---+ |æå››| 20|æå››| 20 | |å¼ ä¸‰| 18|å¼ ä¸‰| 18 | +----+---+----+---+ # ç‰¹åˆ«æé†’ï¼Œ æ­¤ Joinï¼Œ åªè¦éƒ½è¿›æ¥æ˜¯ DFæ ¼å¼çš„ä»»ä½•æ•°æ®åº“ï¼Œéƒ½å¯ Join # æ¯”å¦‚ï¼š MySQL å’Œ Hive , Json ä¹Ÿå¯ã€‚ å‚¨å­˜ä¸ºä¸´æ—¶è§†å›¾ï¼ˆè¡¨), å¹¶è°ƒç”¨sqlè¯­å¥ï¼š df.createOrReplaceTempView('user') # åˆ›å»ºä¸º userä¸´æ—¶è§†å›¾ df_sql = spark.sql('select * from user').show() # spark.sqlè¿”å›çš„è¿˜æ˜¯df, æ‰€ä»¥è¦show() +---+------+--------+ |age|gender| name| +---+------+--------+ | 18| man|zhangsan| +---+------+--------+ RDD ä¸ DFäº’è½¬ RDD -&gt; DF ### RDD -&gt; DF éœ€è¦æŠŠRDDåšæˆä¸¤ç§æ ¼å¼(ä»»é€‰å…¶ä¸€) ### ç¬¬ä¸€ç§ Row æ ¼å¼ from pyspark import Row rdd_user = spark.sparkContext.parallelize( [('å¼ ä¸‰',18), ('æå››',20)] ) rdd_user_row = rdd_user.map(lambda x:Row(name=x[0], age=x[1])) print(rdd_user_row.collect()) # [Row(age=18, name='å¼ ä¸‰'), Row(age=20, name='æå››')] df_user = spark.createDataFrame(rdd_user_row) ### ç¬¬äºŒç§ [('å¼ ä¸‰', 18),('æå››', 20)] rdd_user = spark.sparkContext.parallelize( [('å¼ ä¸‰',18), ('æå››',20)] ) df_user = rdd_user.toDF(['name', 'age']) # ç»™å®šåˆ—å df_user.show() DF -&gt; RDD rdd_row = df_user.rdd.map(lambda x: x.asDict()) # æˆ–è€… x.name, x.ageå–å€¼ rdd_row.collect() # [{'age': 18, 'name': 'å¼ ä¸‰'}, {'age': 20, 'name': 'æå››'}] CSVè¯»å†™ ä»HDFSä¸­è¯»å–(æˆ‘ä»¬å…ˆæ–°å»ºä¸€ä¸ªCSVå¹¶æ‰”åˆ°HDFSä¸­), vi mydata.csv: name,age zhangsan,18 lisi, 20 hadoop fs -mkdir /data # åœ¨HDFSä¸­æ–°å»ºä¸€ä¸ªç›®å½• /data hadoop fs -put mydata.csv /data # å¹¶æŠŠæœ¬åœ° mydata.csvæ‰”è¿›å» (-getå¯æ‹¿å‡ºæ¥) åœ¨ä»£ç ä¸­è¯»å– HDFSæ•°æ®: df = spark.read.csv(&quot;hdfs:///data/mydata.csv&quot;, header=True) df.show() # header=True ä»£è¡¨, csvæ–‡ä»¶çš„ç¬¬ä¸€è¡Œä½œä¸ºcsvçš„æŠ¬å¤´(åˆ—å) # df.write.csv(&quot;hdfs:///data/mydata.csv&quot;, header=True) # readæ”¹ä¸ºwriteå°±å˜æˆäº†å†™ Hiveè¯»å†™ Hiveçš„é…ç½®ä¸ä¾èµ–ä¹‹å‰è®²è¿‡äº†ï¼ˆæœ€å€¼å¾—æ³¨æ„çš„æ˜¯éœ€è¦å…ˆå¯åŠ¨ä¸€ä¸ª metadataçš„æœåŠ¡ï¼‰ å…ˆéªŒä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020841646 import findspark findspark.init() from pyspark.sql import SparkSession spark = SparkSession.builder\\ .appName(&quot;Spark Hive Example&quot;)\\ .master(&quot;local[*]&quot;)\\ .config(&quot;hive.metastore.uris&quot;, &quot;thrift://localhost:9083&quot;)\\ .enableHiveSupport()\\ .getOrCreate() spark.sql(&quot;use mydatabase&quot;) # æ‰§è¡ŒHive çš„ SQL, åˆ‡æ¢æ•°æ®åº“ï¼ˆå‰æä½ å¾—æœ‰ï¼‰ è¯»ï¼š df = spark.table('person').show() # ç›´æ¥å¯¹è¡¨æ“ä½œ (æ³¨æ„ï¼Œsqlè¯­å¥ä¹Ÿå¯) å†™ï¼š df = spark.table('person') df2 = df.withColumn('nickname', df.name) # ç¨å¾®å˜åŠ¨ä¸€ä¸‹ï¼Œæ·»ä¸€ä¸ªå­—æ®µ df2.write.saveAsTable(&quot;new_person&quot;) # å†™å…¥æ–°è¡¨ MySQLè¯»å†™ è¯»ï¼š # æ³¨æ„0ï¼šæœ‰å¥½å‡ ç§æ–¹å¼ï¼Œæˆ‘åªåˆ—ä¸¾ä¸€ä¸ª æˆå¯¹çš„è¯»å†™é…ç½®ã€‚ # æ³¨æ„1: urlä¸­ &quot;hive&quot;æ˜¯æ•°æ®åº“å. ä½ ä¹Ÿå¯ä»¥èµ·ä¸ºåˆ«çš„å # æ³¨æ„2ï¼štableçš„å€¼--&quot;TBLS&quot;, å®ƒæ˜¯ MySQLä¸­&quot;hiveåº“&quot;ä¸­çš„ä¸€ä¸ªè¡¨ã€‚ # æ³¨æ„3ï¼šç‰¹åˆ«æ³¨æ„ï¼ TBLSä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„è¡¨ã€‚ä»–åªæ˜¯ä¸€ä¸ªå¤§è¡¨ï¼Œç®¡ç†äº†æˆ‘ä»¬hiveçš„ä¿¡æ¯ # TBLSä¸­çš„ ä¸€ä¸ªåˆ—å±æ€§ &quot;TBL_NAME&quot; æ‰æ˜¯çœŸæ­£æˆ‘ä»¬éœ€è¦çš„è¡¨ï¼ï¼ df = spark.read.jdbc( url='jdbc:mysql://localhost:3306/hive?user=root&amp;password=123', table=&quot;TBLS&quot;, properties={&quot;driver&quot;:&quot;com.mysql.jdbc.Driver&quot;}, ) df.show() df.select(&quot;TBL_NAME&quot;).show() å†™ï¼š df.write.jdbc( url='jdbc:mysql://localhost:3306/hive?user=root&amp;password=123', table=&quot;new_table&quot;, mode='append', properties={&quot;driver&quot;: &quot;com.mysql.jdbc.Driver&quot;} ) # åŒæ˜¯ç‰¹åˆ«æ³¨æ„ï¼š å’Œè¯»ä¸€æ ·ï¼Œ å®ƒå†™å…¥çš„æ–°è¡¨ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªæ•´ä½“çš„è¡¨ç»“æ„ã€‚ # æ­¤è¡¨çš„ä¸€ä¸ªåˆ—&quot;TBL_NAME&quot;ï¼Œå®ƒæ‰å¯¹åº”äº†æˆ‘ä»¬çœŸæ­£è¦æ“ä½œçš„è¡¨ ","link":"https://cythonlin.github.io/post/py-greater-pyspark-spark-sql/"},{"title":"PY => PySpark-Spark Coreï¼ˆRDDï¼‰","content":"å‰è¨€ ç¬¬ä¸€ç¯‡ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020841646 RDDè®¤çŸ¥ RDDæ˜¯ä»€ä¹ˆï¼Ÿ RDD: å¼¹æ€§åˆ†å¸ƒå¼æ•°æ®é›†ï¼ˆResiliennt Distributed Datasetsï¼‰ è½¬ä¸ºæ ¼å¼RDDçš„å‡ ç§æ–¹å¼ï¼š 1. parallelize: rdd = sc.parallelize([1,2,3,4,5]) # é‡Œé¢ä¼ çš„å°±æ˜¯æ™®é€špythonç±»å‹ 2. è¯»æ–‡ä»¶/è¯»æ•°æ®åº“/è¯»ESç­‰å„ç§æ–¹å¼ï¼Œæ­¤å¤„ä»¥è¯»æ–‡ä»¶ä¸ºä¾‹ï¼š rdd = sc.textFile('file:///home/lin/data/hello.txt') RDDæ ¸å¿ƒæ¦‚å¿µ Application: application: ä¸€ä¸ªapp å°±æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰çš„ pyè„šæœ¬ï¼ˆè¢« spark-submitæäº¤çš„ï¼‰æˆ–ä¸€ä¸ªspark-shell app = 1ä¸ª driver + å¤šä¸ªexecutors(ç›¸å½“äºå¤šä¸ªè¿›ç¨‹) æ³¨æ„ï¼šæ•°æ®åœ¨ä¸åŒçš„ appä¹‹é—´ ä¸èƒ½è¢«å…±äº«ï¼Œ è‹¥æƒ³è¦å…±äº«ï¼ˆéœ€è¦è€ƒè™‘å¤–éƒ¨å­˜å‚¨ï¼‰ Driver: æ¯ä¸€ä¸ª.pyè„šæœ¬ä¸­éƒ½æœ‰ä¸€ä¸ª sparkcontextï¼Œå®ƒå°±æ˜¯driver Worker Node: ç›¸å½“äºstandalone çš„ slaveèŠ‚ç‚¹ Executor: Executor(è¿›ç¨‹)ï¼šæ¯ä¸ªDriverä¸­éƒ½æœ‰å¤šä¸ª Executors å¹¶ä¸”å¯ä»¥è¿è¡Œå¤šä¸ª Tasks Job: job: å¯¹åº”ä¸‹é¢å³å°†è¦è¯´çš„ action : collect() ç­‰ ä¸€ä¸ª task å¯¹åº” ä¸€ä¸ª job (ä¸€ä¸ª transformation å¯¹åº” ä¸€ä¸ª action) ä¸€ä¸ª job å¯¹åº” å¤šä¸ª task (å¤šä¸ª transformationsé“¾å¼è°ƒç”¨ä¹‹åï¼Œå†è°ƒç”¨ä¸€ä¸ªaction) Task: task: å¯¹åº”ä¸‹é¢å³å°†è¦è¯´çš„ transformation :map() ç­‰ æ¯ä¸ªtaskå¯ç”¨ä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œã€‚å¤šä¸ªtaskå¯å¹¶è¡Œ Stage: ä¸€ä¸ªjobè¢«åˆ‡åˆ†ä¸ºå¤šä»½ Cluster Manager: ç®¡ç† ä» Standalone, YARN, Mesos ä¸­è·å–çš„èµ„æº å°±æ˜¯ --master æŒ‡å®šçš„å‚æ•° å…¶ä¸­ è¿˜åŒ…æ‹¬ ç©ºé—´ å†…å­˜ç­‰å‚æ•°é…ç½® Cache: ç¼“å­˜ï¼š ### persist &amp; cache &amp; unpersist ä¸‰ç§APIå¯ä¾›é€‰æ‹© Lineage(ä¾èµ–,è¡€ç¼˜å…³ç³»)ï¼š ä¾èµ–ï¼š çˆ¶ å­ å­™ RDD1 -&gt; map-&gt; RDD2 -&gt; filter-&gt; RDD3 æœåŠ¡å™¨1ï¼š part1 -&gt; part1-&gt; part1 æœåŠ¡å™¨2ï¼š part2 -&gt; part2-&gt; part2 æœåŠ¡å™¨3ï¼š part3 -&gt; part3-&gt; part3 å¦‚ä¸Šå›¾: å‡å¦‚ RDD3 çš„ part2 æŒ‚äº†ï¼Œ é‚£ä¹ˆå°±ä¼šé€€å›åˆ° RDD2çš„part2å†è®¡ç®—ä¸€éã€‚ è€Œä¸æ˜¯å›åˆ°&quot;æœ€åˆ&quot;çš„èµ·ç‚¹ã€‚ çª„ä¾èµ–ï¼ˆNarrow, ä¾èµ–çš„å¾ˆå°‘ï¼Œå¾ˆçª„ï¼‰ï¼š é‡ç‚¹: 'å­part' åªä¾èµ–ä¸€ä¸ª 'çˆ¶part'ã€‚ map, filter ç­‰: å…ƒç´ è¢«æ‘Šåˆ†åœ¨æ¯ä¸€ä¸ªpartä¸­ï¼Œ å­partå‡ºé”™å°±æ‰¾&quot;å¯¹åº”&quot;ï¼ˆä¸€ä¸ªï¼‰ çˆ¶partå³å¯ã€‚ å®½ä¾èµ–ï¼ˆWide, ä¾èµ–çš„å¾ˆå¤šï¼Œå¾ˆå®½ï¼‰ï¼š é‡ç‚¹: 'å­part' ä¾èµ–å¤šä¸ª 'çˆ¶part' åŒæ—¶è®¡ç®—å¾—åˆ°ã€‚ shuffleæ“ä½œ: xxBy, joinç­‰ï¼š å­partå‡ºé”™ æ‰¾&quot;å¯¹åº”&quot;ï¼ˆå¤šä¸ªï¼‰ çˆ¶part é‡æ–°å…±åŒè®¡ç®—ã€‚ stage: é‡åˆ° 1ä¸ªå®½ä¾èµ–ï¼Œ å°±ä¼šåš shuffleæ“ä½œã€‚ ç„¶åå°±ä¼šæŠŠ&quot;ä¹‹å‰&quot;çš„ â€œæ‰€æœ‰çª„ä¾èµ–â€åˆ’åˆ†ä¸º &quot;1ä¸ªstage&quot;ã€‚ æœ€åï¼Œæ•´ä½“å…¨éƒ¨ï¼Œä¹Ÿå½“ä½œ &quot;1ä¸ªstage&quot;ã€‚ å®˜æ¡£å›¾ ä¼ é€é—¨ï¼šhttp://spark.apache.org/docs/latest/cluster-overview.html RDDä¸¤å¤§ç®—å­ Transformation ï¼ˆLazyï¼‰ ä¸»è¦æœºåˆ¶ï¼šå„ç§æ“ä½œä¸ä¼šè¢«ç«‹åˆ»æ‰§è¡Œï¼Œä½†è¿™äº›æ“ä½œä¹‹é—´çš„å…³ç³»ä¼šè¢«è®°å½•ä¸‹æ¥ï¼Œç­‰å¾…ä¸‹é¢actionè°ƒç”¨ã€‚ ç›´è§‚ç†è§£ä¸¾ä¾‹ï¼š 1. åƒ sqlalchemy ä¸­çš„ filter(), groupby(), page()ç­‰æ“ä½œ 2. åƒ tensorflow1.x ä¸­çš„ sess.run() ä¹‹å‰çš„å„ç§æ“ä½œ 3. åƒ æ•°æ®åº“çš„äº‹åŠ¡ï¼Œåœ¨æäº¤ä¹‹å‰çš„å„ç§æ“ä½œ æ¥ä¸‹æ¥ä»‹ç»ï¼ŒTransformation çš„å„ç§æ“ä½œã€‚ map åŒ python çš„ mapã€‚ ä½ åªéœ€è®°ä½RDDç±»å‹é‡Œé¢åŒ…è£¹çš„å°±æ˜¯æˆ‘ä»¬ç†Ÿæ‚‰çš„pythonç±»å‹ æ‰€ä»¥ï¼š python çš„ map æ€ä¹ˆç”¨ï¼Œ RDDå¯¹è±¡çš„ map å°±æ€ä¹ˆç”¨ï¼Œ ä¸‹é¢filteråŒç† åªä¸¾ä¸€ä¸ªè¯­æ³•æ ¼å¼ä¾‹å­ï¼šï¼ˆä¸‹é¢åŒç†ï¼‰ rdd.map(lambda x:x+1) filter åŒä¸Šï¼ŒåŒpython flatMap å’Œ map å‡ ä¹å·®ä¸å¤šã€‚ å”¯ä¸€æœ‰ä¸€ç‚¹åŒºåˆ«ï¼š map æ¯æ¬¡åŸºäºå•ä¸ªå…ƒç´ ï¼Œè¿”å›ä»€ä¹ˆï¼Œé‚£æœ€ç»ˆç»“æœå°±æ˜¯ä»€ä¹ˆï¼ˆæœ€åæ‹¼æˆåºåˆ—ï¼‰ã€‚ flatMap æ¯æ¬¡åŸºäºå•ä¸ªå…ƒç´ ï¼Œè‹¥è¿”å›çš„æ˜¯åºåˆ—ï¼ˆåˆ—è¡¨ç­‰ï¼‰ï¼Œé‚£ä¹ˆä¼šè‡ªåŠ¨è¢«è§£åŒ…ï¼Œå¹¶ä¸€å­—æ’å¼€è¿”å›ã€‚ groupBy å’Œ groupByKey è¯´ä¸€ä¸‹ æ²¡æœ‰key, å’Œ å¸¦æœ‰keyçš„åŒºåˆ«ï¼ˆåé¢åŒç†ï¼Œå°±ä¸å•°å—¦äº†ï¼‰ï¼š æ²¡æœ‰key: 1. ä¸€èˆ¬å¿…é¡»éœ€è¦ä¸€ä¸ª å‡½æ•°å¥æŸ„ (lambda), è€Œè¿™ä¸ªå¥æŸ„æ˜¯é’ˆå¯¹ï¼ˆæ“ä½œåæ–°å½¢æˆçš„keyï¼‰ä½¿ç”¨çš„ 2. é’ˆå¯¹ä¸€å±‚åºåˆ— [, , ...] å¸¦æœ‰key 1. ä¸€èˆ¬æ— å‚ 2. é’ˆå¯¹åŒå±‚åºåˆ— [(),(),...] ç›´æ¥ä¸Šä¾‹å­äº†ï¼ˆå¯¹æ¯”ç€çœ‹ï¼‰ï¼š rdd1 = sc.parallelize(['a','b','c','a']) # ä¸€å±‚åºåˆ— rdd2 = sc.parallelize( [('a',1),('b',2), ('c',3), ('a',4)] ) # åŒå±‚åºåˆ— group1 = rdd1.groupBy(lambda x:x) # é’ˆå¯¹ ä¸€å±‚åºåˆ—ï¼Œ æ³¨æ„è¿™é‡Œï¼Œå¿…é¡»å†™ å‡½æ•°å¥æŸ„ group2 = rdd2.groupByKey() # é’ˆå¯¹ åŒå±‚åºåˆ— print( group1.collect() ) print( group2.collect() ) # å¯ä»¥è¿™æ ·å‘Šè¯‰ä½ ï¼Œ ä»–ä»¬ä¿©çš„æœ€å¤–å±‚ç»“æœæ˜¯ä¸€æ ·çš„: [{key:value}, ...], ç»“æœå¦‚ä¸‹ ~~~~ [ ('a', &lt;pyspark.resultiterable.ResultIterable object at 0x7fb7e4384c88&gt;), ('b', &lt;pyspark.resultiterable.ResultIterable object at 0x7fb7e43848d0&gt;), ('c', &lt;pyspark.resultiterable.ResultIterable object at 0x7fb7e4384940&gt;) ] # å¦‚æœåŠ äº†count(), é‚£ä¹ˆå®ƒä»¬çš„ç»“æœå°±æ˜¯ä¸€æ ·çš„äº†ï¼Œè¿”å›ç»Ÿè®¡çš„ä¸ªæ•°ï¼Œ ç­‰åˆ° actionå†è¯´ã€‚ reduceByKey ç…§åº”åŒå±‚æˆ–å¤šå±‚åºåˆ—ï¼Œæˆ–è€… æ‰¿æ¥ groupByKey() rdd = sc.parallelize(['Tom', 'Jerry', 'Tom', 'Putch']) rdd.map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).collect() # ç»“æœï¼ˆå¯ä»¥å¿½ç•¥ä¸Šé¢çš„ collect(), å®ƒå±äºactionï¼Œæ”¾åœ¨è¿™é‡Œæ–¹ä¾¿è´´ä¸ªç»“æœï¼‰ &gt;&gt; [('Tom', 2), ('Jerry', 1), ('Putch', 1)] sortBy å’Œ sortByKey sortByï¼šæ ¹æ®å…ƒç´ æ’åºï¼ˆè¿™é‡Œçš„ä¾‹å­æ˜¯æ ¹æ®keyæ’åºï¼Œ a[1]ä»£è¡¨æ ¹æ®valueæ’åºï¼‰ &gt;&gt;&gt; a = sc.parallelize([['z',1], ['b',4],['h',3]]) &gt;&gt;&gt; a.sortBy(lambda a:a[0]).collect() [['b', 4], ['h', 3], ['z', 1]] &gt;&gt;&gt; a.sortBy(lambda a:a[1]).collect() [['z', 1], ['h', 3], ['b', 4]] sortByKeyï¼šæ ¹æ®keyæ’åº &gt;&gt;&gt; a.sortByKey().collect() [('b', 4), ('h', 3), ('z', 1)] å¯é€‰å‚æ•°ï¼š ascending=False (é»˜è®¤ä¸ºTrueå‡åº) union rdd1.union(rdd2) # ç›¸å½“äº pythonçš„ &quot;åˆ—è¡¨åŠ æ³•&quot; æˆ–è€… pythonçš„ &quot;extend&quot; distinct rdd.distinct() # å»é‡ join å‰æï¼š ï¼ˆæˆ‘çš„ç†è§£å°±æ˜¯ï¼Œèƒ½è½¬åŒ–æˆ python å­—å…¸çš„åˆ—è¡¨æ ¼å¼å³å¯ï¼‰ eg: [ [1,2], [3,4], [5,6] ] ä¸¤å±‚åˆ—è¡¨ æ¯å±‚åˆ—è¡¨çš„æ¯ä¸ªå…ƒç´ ä¸­ï¼Œ åªæœ‰2ä¸ªå…ƒç´  é”™è¯¯æ ¼å¼ç¤ºä¾‹ï¼š [['a','b','c'], ['d','e','f']] ä¹Ÿä¸èƒ½è¯´é”™è¯¯å§ï¼Œä¸è¿‡è‹¥æ˜¯è¿™ç§3ä¸ª-å¤šä¸ªå­å…ƒç´ çš„æ ¼å¼ï¼Œ joinæ—¶é»˜è®¤ä¼šå–å‰2ä¸ªå…ƒç´ ã€‚å…¶ä½™ä¸¢å¼ƒã€‚ å†…è¿æ¥ï¼ˆinnerJoinï¼‰ï¼š å·¦å¤–è¿æ¥ï¼ˆleftOuterJoinï¼‰ï¼š å³å¤–è¿æ¥ï¼ˆrightOuterJoinï¼‰ï¼š å…¨å¤–è¿æ¥ï¼ˆfullOuterJoinï¼‰ï¼š å®Œæ•´ç¤ºä¾‹ï¼š rdd1 = sc.parallelize( [['a','b'], ['d','e']] ) # å·¦ rdd2 = sc.parallelize( [['a','c'], ['e','f']] ) # å³ # å¼€å¤´è¯´è¿‡:èƒ½è½¬åŒ–æˆå­—å…¸çš„åˆ—è¡¨æ ¼å¼å³å¯ï¼Œæˆ–è€…ä½ å¯ä»¥å†™æˆè¿™æ ·ï¼ˆä½†æ˜¯ä¸èƒ½ä¼ åŸç”Ÿå­—å…¸è¿›å»ï¼‰ï¼š rdd1 = sc.parallelize( list({'a': 'b', 'd': 'e'}.items()) ) rdd2 = sc.parallelize( list({'a': 'c', 'e': 'f'}.items()) ) # å†…è¿æ¥ï¼ˆäº¤é›†ï¼‰ print( rdd1.join(rdd2).collect() ) # [('a', ('b', 'c'))] # å·¦è¿æ¥ï¼ˆå·¦å¹¶é›†ï¼‰ print( rdd1.leftOuterJoin(rdd2).collect() ) # [('d', ('e', None)), ('a', ('b', 'c'))] # å³è¿æ¥ï¼ˆå³å¹¶é›†ï¼‰ print( rdd1.rightOuterJoin(rdd2).collect() ) # [('a', ('b', 'c')), ('e', (None, 'f'))] # å…¨è¿æ¥ï¼ˆå¹¶é›†ï¼‰ print( rdd1.fullOuterJoin(rdd2).collect() ) # [('d', ('e', None)), ('a', ('b', 'c')), ('e', (None, 'f'))] persist &amp; cache &amp; unpersist cache(): ç¼“å­˜ persist(): æŒä¹…åŒ– unpersist(): æ¸…ç©ºç¼“å­˜ ï¼ˆä»–å±äº action-ç«‹å³è§¦å‘ï¼Œ ä¸ºäº†æ–¹ä¾¿å¯¹æ¯”ï¼Œæˆ‘å°±ä¸€èµ·æ”¾åˆ°äº†è¿™é‡Œï¼‰ å®˜æ¡£ï¼šhttp://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence Action (Commit) ä¸»è¦æœºåˆ¶ï¼šæ‹¿åˆ° transformation è®°å½•çš„å…³ç³»ï¼Œ ç”¨ actionçš„å„ç§æ“ä½œæ¥çœŸæ­£è§¦å‘ã€æ‰§è¡Œã€è¿”å›ç»“æœã€‚ å¯¹åº”ä¸Šé¢ï¼Œç»§ç»­ç›´è§‚ä¸¾ä¾‹ï¼š 1. åƒ sqlalchemy ä¸­çš„ commit() 2. åƒ tensorflow1.x ä¸­çš„ sess.run() 3. åƒ æ•°æ®åº“çš„äº‹åŠ¡çš„ &quot;æäº¤&quot; æ¥ä¸‹æ¥ä»‹ç»ï¼ŒAction çš„å„ç§æ“ä½œã€‚ collect æ‰§è¡Œtransformationè®°å½•çš„å…³ç³» å¹¶ è¿”å›ç»“æœï¼Œ åœ¨Pysparkä¸­å°±æ˜¯RDDç±»å‹ è½¬ Pythonæ•°æ®ç±»å‹ã€‚ (ä¸­é—´ä½ å¯ä»¥é“¾å¼è°ƒç”¨å„ç§ transformationæ–¹æ³•ï¼Œç»“å°¾è°ƒç”¨ä¸€ä¸ª collect(), å°±å¯ä»¥å‡ºç»“æœäº†) rdd1.xx().xx().collect() count ç»Ÿè®¡å…ƒç´ é¡¹çš„ä¸ªæ•°ï¼ŒåŒä¸Šè¯­æ³•, åŒä¸Šç†å¿µï¼Œè§¦å‘è¿”å›ç»“æœ rdd2 = sc.parallelize( [['a','c','d'], ['e','f','g']] ) rdd2.count() # æ— å‚ &gt;&gt; 2 reduce rdd2 = sc.parallelize( [['a','c','d'], ['e','f','g']] ) rdd2.reduce(lambda x,y:x+y) # å‚æ•°ä¸º2ä¸ªå‚æ•°çš„å‡½æ•°å¥æŸ„ï¼Œåš&quot;ç´¯&quot;çš„æ“ä½œï¼Œï¼ˆç´¯åŠ ï¼Œç´¯ä¹˜ï¼‰ç­‰ &gt;&gt; ['a', 'c', 'd', 'e', 'f', 'g'] take ç›¸å½“äºmysqlçš„limitæ“ä½œï¼Œå–å‰nä¸ª rdd2 = sc.parallelize( [['a','c','d'], ['e','f','g']] ) rdd2.take(0) # [] rdd2.take(1) # [['a', 'c', 'd']] rdd2.take(2) # [['a', 'c', 'd'], ['e', 'f', 'g']] å†æ¬¡å¼ºè°ƒï¼š takeçš„å‚æ•°æ˜¯ï¼Œä¸ªæ•°çš„æ„æ€ï¼Œè€Œä¸æ˜¯ç´¢å¼•ï¼Œä¸è¦æ··æ·†é¢ top è¿”å›æœ€å¤§çš„nä¸ªå…ƒç´ ï¼ˆä¼šè‡ªåŠ¨ç»™ä½ æ’åºçš„ï¼‰ rdd2 = sc.parallelize( [1,2,3,8,5,3,6,8]) rdd2.top(3) &gt;&gt; [8, 8, 6] foreach éå†æ¯ä¸ªå…ƒç´ ï¼Œå¯¹å­å…ƒç´ åš-å¯¹åº”å‡½æ•°å¥æŸ„çš„æ“ä½œï¼Œä¸‹é¢è¯´è¿™ä¸ªactionçš„ä¸¤ç‚¹æ³¨æ„äº‹é¡¹ï¼š æ³¨æ„1ï¼š æ— è¿”å›å€¼ï¼ˆè¿”å›Noneï¼‰ æ³¨æ„2ï¼š é€šå¸¸ç”¨ä½œ print(), ä½†æ˜¯å®ƒä¸ä¼šåœ¨notebookä¸­æ‰“å°ï¼Œ è€Œæ˜¯åœ¨ä½ åå°å¼€å¯çš„sparkä¸­æ‰“å°ã€‚ rdd2 = sc.parallelize( [['a','c','d'], ['e','f','g']] ) rdd2.foreach(lambda x:print(x)) &gt;&gt; ['a', 'c', 'd'] ['e', 'f', 'g'] saveAsTextFile rdd = sc.textFile('file:///home/lin/data') rdd.saveAsTextFile('file:///home/lin/mydata') # è¿™é‡Œæœ‰ä¸ªæ³¨æ„äº‹é¡¹ï¼š saveAsTextFileçš„å‚æ•°è·¯å¾„ä¸èƒ½åœ¨éƒ½è¿›æ¥çš„è·¯å¾„èŒƒå›´å†…ã€‚ # æˆ–è€…è¯´ï¼Œè¯»æ˜¯ä»è¿™ä¸ªæ–‡ä»¶å¤¹Aï¼ˆè¿™æ˜¯æœ€åä¸€çº§çš„ç›®å½•ï¼‰è¯»è¿›æ¥çš„ï¼Œ å†™å°±ä¸èƒ½å†™å…¥æ–‡ä»¶å¤¹Aäº† # å¦å¤–ï¼Œ mydataæ˜¯ç›®å½•åï¼Œ è¿›å»ä½ ä¼šçœ‹è§ part-00000 è¿™æ ·çš„æ–‡ä»¶åï¼Œè¿™æ‰æ˜¯çœŸæ•°æ®æ–‡ä»¶ã€‚ Sparkä¼˜åŒ–ç›¸å…³ åºåˆ—åŒ–ï¼š å¥½å¤„1ï¼šç½‘ç»œä¼ è¾“å¿…å¤‡ å¥½å¤„2ï¼šèŠ‚çœå†…å­˜ ä¸¤ç§æ–¹å¼åºåˆ—åŒ–æ–¹å¼ï¼š 1. Javaå†…éƒ¨åºåˆ—åŒ–ï¼ˆé»˜è®¤ï¼Œè¾ƒæ…¢ï¼Œä½†å…¼å®¹æ€§å¥½ï¼‰ 2. Kryo ï¼ˆè¾ƒå¿«ï¼Œä½†å…¼å®¹æ€§ä¸å¤ªå¥½ï¼‰ å†…å­˜ç®¡ç†ï¼š å¯åˆ†ä¸º executionï¼ˆè¿›ç¨‹æ‰§è¡Œï¼‰ å’Œ storageï¼ˆå­˜å‚¨ï¼‰ executionç›¸å…³æ“ä½œ: shuffle, join, sort, aggregation storageç›¸å…³æ“ä½œ : cacheï¼Œ ç‰¹ç‚¹ï¼š execution å’Œ storage å…±äº«æ•´ä½“å†…å­˜ï¼š executionèµ·åˆ° &quot;å­˜éœ¸&quot; çš„è§’è‰²: 1. è‹¥ executionåŒºåŸŸå†…å­˜ ä¸å¤Ÿç”¨äº†ï¼Œ å®ƒä¼šå»æŠ¢å¤º storage åŒºåŸŸçš„å†…å­˜ï¼ˆä¸å½’è¿˜ï¼‰ 2. å½“ç„¶ï¼Œå¯ä»¥ä¸º storage è®¾ç½®é˜ˆå€¼ ï¼ˆå¿…é¡»ç»™ storageç•™ä¸‹å¤šå°‘ï¼‰ å…·ä½“åˆ†é…å¤šå°‘ï¼š æ€»å†…å­˜ = n executionå†…å­˜ = (æ€»å†…å­˜ - 300M) * 50% storageå†…å­˜ = (æ€»å†…å­˜ - 300M) * 50% è¯´ç™½äº†ï¼Œå°±æ˜¯ç•™ç»™JVM 300Mï¼Œ ç„¶å execution å’Œ storage å„åˆ†ä¸€åŠã€‚ æŸ¥çœ‹å†…å­˜å ç”¨æƒ…å†µ å¯é€šè¿‡WebUIæŸ¥çœ‹ ï¼ˆåºåˆ—åŒ–åå­˜å‚¨ï¼Œé€šå¸¸ä¼šèŠ‚çœå†…å­˜ï¼‰ Broadcasting Variable æƒ…æ™¯ï¼šæ­£å¸¸æ¥è¯´ï¼Œæ¯ä¸ª taskï¼ˆmap, filterç­‰ï¼‰ éƒ½ä¼šå ç”¨1ä»½æ•°æ®ï¼Œ100ä¸ªtaskå°±ä¼šæ‹¿100ä»½æ•°æ®ã€‚ è¿™ç§æƒ…å†µé€ æˆäº†æ•°æ®çš„å†—ä½™ï¼Œ BroadCasting Variableï¼ˆå¹¿æ’­å˜é‡ï¼‰å°±æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„ã€‚ ","link":"https://cythonlin.github.io/post/py-greater-pyspark-spark-corerdd/"},{"title":"PY => Ubuntu-Hadoop-YARN-HDFS-Hive-Sparkå®‰è£…é…ç½®","content":"ç¯å¢ƒæ¡ä»¶ Java 8 Python 3.7 Scala 2.12.10 Spark 2.4.4 hadoop 2.7.7 hive 2.3.6 mysql 5.7 mysql-connector-java-5.1.48.jar R 3.1+ï¼ˆå¯ä»¥ä¸å®‰è£…ï¼‰ å®‰è£…Java å…ˆéªŒä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020746647#articleHeader0 å®‰è£…Python ç”¨Ubuntuè‡ªå¸¦Python3.7 å®‰è£…Scala ä¸‹è½½ï¼šhttps://downloads.lightbend.com/scala/2.12.10/scala-2.12.10.tgz è§£å‹ï¼š tar -zxvf ä¸‹è½½å¥½çš„Scala é…ç½®ï¼š vi ~/.bashrc export SCALA_HOME=/home/lin/spark/scala-2.12.10 export PATH=SCALAHOME/bin:{SCALA_HOME}/bin:SCALAHâ€‹OME/bin:PATH ä¿å­˜é€€å‡º æ¿€æ´»é…ç½®ï¼š source ~/.bashrc å®‰è£…Hadoop æå‰è¯´æ˜ï¼š è‹¥ä¸ä½¿ç”¨HDFS å’Œ YARNï¼Œæ•´ä¸ª Hadoopå®‰è£…å¯å¿½ç•¥ï¼Œå¯ä»¥ç›´æ¥å®‰è£…sparkã€‚ ä¸‹è½½ï¼šhttps://archive.apache.org/dist/hadoop/common/ è¯¦ç»†åœ°å€: https://archive.apache.org/dist/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz è§£å‹ï¼š tar -zxvf ä¸‹è½½å¥½çš„ hadoop é…ç½®hadoop: vi ~/.bashrc export HADOOP_HOME=/home/lin/hadoop/hadoop-2.7.7 export PATH=HADOOPHOME/bin:{HADOOP_HOME}/bin:HADOOPHâ€‹OME/bin:PATH æ¿€æ´»é…ç½®ï¼š source ~/.bashrc HDFSé…ç½®ï¼š è¿›å…¥è§£å‹åçš„ etc/hadoop (æ³¨æ„è¿™ä¸æ˜¯æ ¹ç›®å½•çš„etcï¼Œ è€Œæ˜¯è§£å‹åçš„hadoopç›®å½•ä¸‹çš„etc) echo $JAVA_HOME # å¤åˆ¶æ‰“å°å‡ºçš„è·¯å¾„ vi hadoop-env.sh: ï¼ˆæ‰¾åˆ° export JAVA_HOME è¿™è¡Œï¼Œå¹¶æ›¿æ¢ä¸ºå¦‚ä¸‹ï¼‰ export JAVA_HOME=/home/lin/spark/jdk1.8.0_181 vi core-site.xml: ï¼ˆhdfsåé¢ä¸º ä¸»æœºå:ç«¯å£å·ï¼‰ ï¼ˆä¸»æœºåå°±æ˜¯ç»ˆç«¯æ˜¾ç¤ºçš„ @åé¢çš„~~~ï¼‰ &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://lin:8020&lt;/value&gt; &lt;/property&gt; vi hdfs-site.xmlï¼š (åŒæ ·åœ¨ &lt;configuration&gt; ä¹‹é—´åŠ å…¥) (/home/lin/hdfsæ˜¯æˆ‘å·²ç»æœ‰çš„ç›®å½•) &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/home/lin/hdfs/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/home/lin/hdfs/dfs/data&lt;/value&gt; &lt;/property&gt; æ ¼å¼åŒ–HDFSï¼š hadoop namenode -format # ç„¶åå»åˆšæ‰ä¸Šé¢é…ç½®çš„è¿™ä¸ªè·¯å¾„é‡Œé¢æ˜¯å¦æœ‰æ–°ä¸œè¥¿å‡ºç°ï¼š /home/lin/hdfs å¼€å¯HDFS (å…ˆè¿›å…¥ sbinç›®å½•ä¸‹ï¼Œ sbin å’Œ etc binæ˜¯åŒçº§çš„ï¼Œ è¿™é‡Œè¯´çš„éƒ½æ˜¯hadoopé‡Œçš„ç›®å½•): ./start-dfs.sh # ä¸€è·¯yes, è‹¥è®©ä½ è¾“å…¥å¯†ç ï¼Œ åˆ™è¾“å…¥å¯¹åº”æœåŠ¡å™¨çš„å¯†ç ã€‚ï¼ˆæˆ‘è¿™é‡Œéƒ½æ˜¯æœ¬æœºï¼‰ # è‹¥æç¤ºæƒé™é”™è¯¯ï¼Œç»§ç»­å¾€ä¸‹çœ‹ï¼ˆæ”¯çº¿ï¼‰ sudo passwd root # æ¿€æ´»ubuntuçš„rootç”¨æˆ·ï¼Œå¹¶è®¾ç½®å¯†ç  vi /etc/ssh/sshd_configï¼š PermitRootLogin yes # ä»»æ„ä½ç½®æ·»åŠ è¿™ä¸ªï¼ˆæ­¤é€‰é¡¹ä¹‹å‰å¯èƒ½æ˜¯å­˜åœ¨çš„æ³¨é‡Šåå†æ·»åŠ ï¼‰ service ssh restart æŸ¥çœ‹HDFSé‡Œé¢æ ¹ç›®å½• / çš„å†…å®¹ï¼š hadoop fs -ls / å‘HDFSé‡Œé¢æ ¹ç›®å½• / ä¸­ ä¼ å…¥æ–‡ä»¶ï¼š echo test &gt; test.txt # é¦–å…ˆï¼Œéšä¾¿å»ºç«‹ä¸€ä¸ªæ–‡ä»¶ hadoop fs -put test.txt / # å‘HDFSé‡Œé¢æ ¹ç›®å½• / ä¸­ ä¼ å…¥æ–‡ä»¶ hadoop fs -ls / # å†æ¬¡æŸ¥çœ‹ï¼Œå°±å‘ç°æœ‰ test.txt æ–‡ä»¶äº†ã€‚ ä»HDFSé‡Œé¢æ ¹ç›®å½• / ä¸­ è¯»å–æ–‡ä»¶test.txtï¼š hadoop fs -text /test.txt ä»Hadoop WebUI ä¸­æŸ¥çœ‹åˆšæ‰çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼š http://192.168.0.108:50070/ # 50070æ˜¯é»˜è®¤ç«¯å£ ç‚¹å‡»å³ä¾§ä¸‹æ‹‰æ¡† &quot;Utilities&quot; -&gt; &quot;Browser the file system &quot; æ¸…æ™°å¯è§ï¼Œ æˆ‘ä»¬çš„test.txt èººåœ¨é‚£é‡Œ~ YARNé…ç½® è¿˜æ˜¯etc/hadoopè¿™ä¸ªç›®å½•: cp mapred-site.xml.template mapred-site.xml vi mapred-site.xmlï¼š &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; vi yarn-site.xml: &lt;property&gt; &lt;name&gt;yarn.nodemanager.services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; å¯åŠ¨ YARN: ï¼ˆè¿˜æ˜¯ sbinç›®å½•ä¸‹ï¼‰ ./start-yarn.sh # åŒæ ·ï¼Œè‹¥æœ‰å¯†ç ï¼Œè¾“å…¥æœºå™¨çš„å¯†ç å³å¯ ä»Hadoop WebUI ä¸­æŸ¥çœ‹YARNï¼š http://192.168.0.108:8088/ å®‰è£…MySQL ä¸‹é¢è¦ç”¨MySQL, æ‰€ä»¥å•ç‹¬æä¸€ä¸‹MySQL çš„ å®‰è£…ä¸é…ç½®: å…¶å®MySQLæ˜¯ä¸éœ€è¦å•ç‹¬è¯´çš„, (ä½†æˆ‘è£…çš„æ—¶å€™å‡ºç°äº†å’Œä»¥å¾€çš„ä¸åŒç»å†), æ‰€ä»¥è¿˜æ˜¯è¯´ä¸€ä¸‹å§: apt-get install mysql-server-5.7 å®‰è£…å®¹æ˜“, ä¸åŒç‰ˆæœ¬çš„MySQLé…ç½®æœ‰äº›é¸¡è‚‹ (æˆ‘ç”¨çš„æ˜¯ Ubuntu19): vi /etc/mysql/mysql.conf.d/mysqld.cnf: bind-address 0.0.0.0 # æ‰¾åˆ°ä¿®æ”¹ä¸€ä¸‹å³å¯ ä¿®æ”¹å¯†ç +è¿œç¨‹è¿æ¥æƒé™ (é»˜è®¤æ— å¯†ç ): mysql # å•¥å‚æ•°ä¹Ÿä¸ç”¨åŠ , ç›´æ¥å°±èƒ½è¿›å» use mysql update mysql.user set authentication_string=password(&quot;123&quot;) where user=&quot;root&quot;; update user set plugin=&quot;mysql_native_password&quot;; flush privileges; select host from user; update user set host ='%' where user ='root'; flush privileges; é‡å¯æœåŠ¡: systemctl restart mysql æœåŠ¡ç«¯è¿æ¥æµ‹è¯•: mysql -uroot -p # å¯†ç  123 è¿œç¨‹è¿æ¥æµ‹è¯• (Navicat): æˆåŠŸ å®‰è£…Hive ä¸‹è½½: https://archive.apache.org/dist/hive/hive-2.3.6/apache-hive-2.3.6-bin.tar.gz è§£å‹ï¼š tar -zxvf apache-hive-2.3.6-bin.tar.gz é…ç½®Hiveï¼š vi ~/.bashrc export HIVE_HOME=/home/lin/hive/apache-hive-2.3.6-bin export PATH=HIVEHOME/bin:{HIVE_HOME}/bin:HIVEHâ€‹OME/bin:PATH æ¿€æ´»é…ç½®ï¼š source ~/.bashrc Hiveå…¶ä»–ç›¸å…³é…ç½®(åŒç†è¿›å…¥hiveè§£å‹ç›®å½•çš„ confç›®å½•ä¸­): cp hive-env.sh.template hive-env.sh vi hive-env.sh: HADOOP_HOME=/home/lin/hadoop/hadoop-2.7.7 Hive-MySQLç›¸å…³é…ç½®(åŒæ˜¯åœ¨ confç›®å½•ä¸‹): vi hive-site.xml: (ç‰¹åˆ«æ³¨æ„åä¸¤ä¸ª é‡Œé¢çš„å†…å®¹, è‡ªå·±ä¿®æ”¹ä¸€ä¸‹ç”¨æˆ·åå’Œå¯†ç ) javax.jdo.option.ConnectionURL jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false javax.jdo.option.ConnectionDriverName com.mysql.jdbc.Driver javax.jdo.option.ConnectionUserName root javax.jdo.option.ConnectionPassword 123 ä¸‹è½½ jdbc-mysqlé©±åŠ¨,å¹¶æ”¾å…¥Hiveä¸­,æ“ä½œå¦‚ä¸‹ (å› ä¸ºæˆ‘ä»¬ä¸Šé¢hive-site.xml ç”¨çš„æ˜¯mysql): é¦–å…ˆä¸‹è½½: http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.48/mysql-connector-java-5.1.48.jar å°†æ­¤jaræ–‡ä»¶æ”¾å…¥ hiveçš„libç›®å½•ä¸­(å’Œ confåŒçº§): å°†æ­¤jaræ–‡ä»¶å†copyä¸€ä»½æ”¾å…¥ sparkçš„ jarç›®å½•ä¸‹ï¼ˆä¸ºäº†åç»­jupyterç›´è¿MySQL(ä¸é€šè¿‡Hive)ä½¿ç”¨ï¼‰ åˆå§‹åŒ–(å…ˆç¡®ä¿ä¹‹å‰çš„HDFSå’ŒMySQLå·²ç»å¯åŠ¨): schematool -dbType mysql -initSchema æ³¨æ„äº‹é¡¹1: è¿™ä¸ªç”¨å‘½ä»¤åˆå§‹åŒ–çš„ æ­¥éª¤æ˜¯ Hive 2.+ æ‰éœ€è¦åšçš„ æ³¨æ„äº‹é¡¹2: åˆå§‹åŒ–ä¸€æ¬¡å³å¯, å¤šæ¬¡åˆå§‹åŒ–,ä¼šä½¿å¾—MySQLæœ‰é‡å¤çš„é”®. æŠ¥é”™. å¼€å¯ metastore æœåŠ¡ï¼š nohup hive --service metastore &amp; æ£€æµ‹æ˜¯å¦åˆå§‹åŒ–(å»MySQLè¡¨ä¸­æŸ¥çœ‹): use hive show tables; # è‹¥æœ‰æ•°æ®,åˆ™è¯´æ˜åˆå§‹åŒ–æˆåŠŸ å¯åŠ¨hive: hive å»ºåº“, å»ºè¡¨æµ‹è¯• (æ³¨æ„,åƒä¸‡ä¸è¦ç”¨ userè¿™ç§å…³é”®å­—å½“ä½œè¡¨åç­‰): HIVEä¸­è¾“å…¥: create database mydatabase; use mydatabase; create table person (name string); MySQLä¸­æŸ¥çœ‹Hiveè¡¨çš„ç›¸å…³ä¿¡æ¯: select * from TBLS; # æŸ¥çœ‹æ‰€æœ‰è¡¨ç»“æ„ä¿¡æ¯ select * from COLUMNS_V2; # æŸ¥çœ‹æ‰€æœ‰åˆ—çš„ä¿¡æ¯ å‘Hiveå¯¼å…¥æ–‡ä»¶: vi hive_data.txt: (å†™å…¥å¦‚ä¸‹ä¸¤è¡Œ) tom catch jerry every one can learn AI load data local inpath '/home/lin/data/hive_data.txt' into table person; æŸ¥è¯¢: select * from person; PySparkå®¢æˆ·ç«¯é…ç½®è¿æ¥ä»£ç : import findspark findspark.init() from pyspark.sql import SparkSession spark = SparkSession.builder\\ .appName(&quot;Spark Hive Example&quot;)\\ .master(&quot;local[*]&quot;)\\ .config(&quot;hive.metastore.uris&quot;, &quot;thrift://localhost:9083&quot;)\\ .enableHiveSupport()\\ .getOrCreate() spark.sql(&quot;use mydatabase&quot;).show() spark.sql('show tables').show() å®‰è£…Spark ä¸‹è½½ï¼šspark-2.4.4-bin-hadoop2.7.tgzï¼š ç²—ç³™ä¼ é€é—¨ï¼šhttps://spark.apache.org/downloads.html è¯¦ç»†ä¼ é€é—¨ï¼šhttp://ftp.riken.jp/net/apache/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz è§£å‹ï¼š tar -zxvf ä¸‹è½½å¥½çš„spark-bin-hadoop é…ç½®sparkï¼š vi ~/.bashrc export SPARK_HOME=home/lin/spark/spark-2.4.4-bin-hadoop2.7 export PATH=SPARKHOME/bin:{SPARK_HOME}/bin:SPARKHâ€‹OME/bin:PATH æ¿€æ´»é…ç½®ï¼š source ~/.bashrc æœ€åä¸€æ­¥ï¼ˆPythonç¯å¢ƒå¯èƒ½å‡ºé”™ï¼‰ pysparkè„šæœ¬é»˜è®¤è°ƒç”¨çš„æ˜¯ &quot;python&quot; è¿™ä¸ªåï¼Œ è€Œubuntué»˜è®¤åªæœ‰&quot;python&quot; å’Œ &quot;python3&quot;ã€‚ æ‰€ä»¥æˆ‘ä»¬éœ€è¦åšå¦‚ä¸‹è½¯è¿æ¥ï¼Œæ¥ä½¿å¾—å¯ä»¥è¾“å…¥pythonï¼Œ ç›´æ¥å¯»æ‰¾python3.7å‘½ä»¤ï¼ˆä¸è¦ç”¨aliasï¼‰ ln -s /usr/bin/python3.7 /usr/bin/python æµ‹è¯• æœåŠ¡ç«¯ç›´æ¥è¾“å…¥å‘½ä»¤ï¼š pyspark æˆ–è¿œç¨‹æµè§ˆå™¨è¾“å…¥: http://192.xx.xx.xx:4040/jobs è¿œç¨‹ä½¿ç”¨Jupyterè¿æ¥ å®‰è£… Jupyter Notebook: pip3 install jupyter # è‹¥æ–°ç¯å¢ƒï¼Œéœ€è¦å®‰pip: apt-get install python3-pip pip å®‰è£… findspark å’Œ pyspark pip install pyspark pip install findspark ï¼ˆLinuxæœåŠ¡ç«¯ï¼‰ å¯åŠ¨ Jupyter Notebook æœåŠ¡ï¼ˆ--ipæŒ‡å®š 0.0.0.0ï¼‰ï¼Œ(--allow-rootè‹¥ä¸åŠ ä¸Šå¯èƒ½ä¼šæŠ¥é”™) jupyter notebook --allow-root --ip 0.0.0.0 ï¼ˆLinuxæœåŠ¡ç«¯ï¼‰ ä¸‹é¢è¯´çš„æ˜¯Jupyter Notebook å®¢æˆ·ç«¯ï¼ˆWindows10ï¼‰ ä¸‹é¢ä¸¤è¡Œfindsparkä»£ç å¿…é¡»æ”¾åœ¨æ¯ä¸ªpyè„šæœ¬çš„ç¬¬ä¸€è¡Œ import findspark findspark.init() PYSPARK_PYTHON = &quot;/usr/bin/python&quot; os.environ[&quot;PYSPARK_PYTHON&quot;] = PYSPARK_PYTHON os.environ[&quot;PYSPARK_DRIVER_PYTHON&quot;] = PYSPARK_PYTHON ç„¶åæ‰å¯æ­£å¸¸å†™å…¶ä»–ä»£ç  from pyspark import SparkConf, SparkContext sc = SparkContext( master='local[*]', # ä¸‹é¢ä¼šè®²è¿™ä¸ªå‚æ•° appName='myPyspark', # éšä¾¿èµ·å ) # è¿™å¥è¯ï¼Œå°±æŠŠ sparkå¯åŠ¨èµ·æ¥äº†ï¼Œç„¶åæ‰å¯ä»¥é€šè¿‡æµè§ˆå™¨è®¿é—®äº†ã€‚ 4040 # å¦‚æœä½  pythoné­”æ³•ç©çš„6ï¼Œé‚£ä¹ˆæåˆ°ä¸Šä¸‹æ–‡ï¼Œä½ åº”è¯¥ä¼šè‡ªåŠ¨æƒ³åˆ° withè¯­å¥ ï¼ˆ__enter__,__exit__ï¼‰ # ä¸å†™å‚æ•°ï¼Œæœ¬åœ°è¿è¡Œï¼Œè¿™æ ·ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œ sc = SparkContext() raw_data = [1,2,3] rdd_data = sc.parallelize(raw_data) # pythonåˆ—è¡¨ç±»å‹ è½¬ sparkçš„RDD print(rdd_data) raw_data = rdd_data.collect() # sparkçš„RDD è½¬å›åˆ° pythonåˆ—è¡¨ç±»å‹ print(raw_data) sc.stop() # å…³é—­spark, åŒç†ï¼Œæµè§ˆå™¨ä¹Ÿå°±è®¿é—®ä¸åˆ°äº†ã€‚ è§£é‡Š SparkContext çš„ masterå‚æ•°ï¼š &quot;local&quot; : è¡¨ç¤ºåªç”¨ä¸€ä¸ªçº¿ç¨‹ï¼Œæœ¬åœ°è¿è¡Œã€‚ &quot;local[*]&quot; : è¡¨ç¤ºç”¨(cpuçš„ä¸ªæ•°)ä¸ªçº¿ç¨‹ï¼Œæœ¬åœ°è¿è¡Œã€‚ &quot;local[n]&quot; : è¡¨ç¤ºç”¨nä¸ªçº¿ç¨‹ï¼Œæœ¬åœ°è¿è¡Œã€‚ &quot;spark://ip:host&quot; : è¿å…¶ä»–é›†ç¾¤ å›é¡¾ç¯å¢ƒé—®é¢˜ å¹¶ è§£é‡Š &quot;æœ¬åœ°&quot; çš„æ¦‚å¿µï¼š åœ¨ Linux ä¸­ å®‰è£…äº† Sparkå…¨å¥—ç¯å¢ƒã€‚ åœ¨ Linux ä¸­ å®‰è£…äº† Jupyterï¼Œ å¹¶å¯åŠ¨äº† Jupyter Notebook æœåŠ¡ã€‚ åœ¨ Win10 ä¸­ è¿œç¨‹è¿æ¥ Linuxä¸­çš„ &quot;Jupyter Notebook&quot;æœåŠ¡ å†™ä¸šåŠ¡ä»£ç ï¼ˆç›¸å½“äºå®¢æˆ·ç«¯è¿æ¥ï¼‰ æ‰€ä»¥ï¼Œ ä¹‹å‰æ‰€è¯´çš„ &quot;æœ¬åœ°&quot;, è¿™ä¸ªè¯å½’æ ¹ç»“åº•æ˜¯ç›¸å¯¹äº Linuxæ¥è¯´çš„ï¼Œæˆ‘ä»¬å†™ä»£ç ä¸€ç›´æ“ä½œçš„æ˜¯Linuxã€‚ é€šå¸¸ä½¿ç”¨spark-submit é¦–å…ˆï¼šæˆ‘ä»¬è‡ªå·±ç¼–å†™ä¸€ä¸ªåŒ…å«å„ç§ pyspark-API çš„ xx.py è„šæœ¬ å¦‚æœï¼šä½ ç”¨äº†æˆ‘ä¸Šé¢æ¨èçš„ Jupyter Notebookï¼Œä½ ä¼šå‘ç°æ–‡ä»¶æ˜¯.ipynbæ ¼å¼ï¼Œå¯ä»¥è½»æ¾è½¬.py æœ€åæäº¤pyè„šæœ¬ï¼š spark-submit --master local[*] --name myspark /xx/xx/myspark.py # ä½ ä¼šå‘ç° --master å’Œ --name å°±æ˜¯ä¸Šé¢æˆ‘ä»¬ä»£ç ä¸­é…ç½®çš„é€‰é¡¹ï¼Œå¯¹å·å…¥åº§å†™å…¥å³å¯ã€‚ # /xx/xx/myspark.py å°±æ˜¯ pyè„šæœ¬çš„ç»å¯¹è·¯å¾„ã€‚ å–‚ç»™sparkï¼Œè®©ä»–å»æ‰§è¡Œã€‚å³å¯ã€‚ Standaloneéƒ¨ç½²Spark ä»‹ç»ï¼š Standaloneéƒ¨ç½²éœ€è¦åŒæ—¶å¯åŠ¨ï¼š masterç«¯ slave ç«¯ æŒ‰ç€ä¸‹é¢é…ç½®ï¼Œæœ€åä¸€æ¡ ./start-all.sh å³å¯åŒæ—¶å¯åŠ¨ã€‚ æŸ¥çœ‹ JAVA_HOMEç¯å¢ƒå˜é‡ã€‚ echo $JAVA_HOME # è®°ä½ç»“æœï¼Œå¤åˆ¶å‡ºæ¥ è¿›å…¥confç›®å½•ï¼Œåšä¸€äº›é…ç½®ï¼ˆconfå’Œsparkä¸­çš„binç›®å½•åŒçº§ï¼‰ï¼š cp spark-env.sh.template spark-env.sh vi spark-env.shï¼šï¼ˆé‡Œé¢å†™ï¼‰ JAVA_HOME=ä¸Šé¢çš„ç»“æœ cp slaves.template slaves vi slaves: ï¼ˆlocalhostæ”¹æˆæœ¬æœºæœºå™¨åï¼‰ lin ä¸Šé¢é…ç½®å®Œæ¯•åï¼Œè¿›å…¥sbinç›®å½•ï¼ˆå’Œä¸Šé¢çš„confåœ¨ä¸€ä¸ªç›®å½•ä¸­ï¼‰ ./start-all.sh # å¯åŠ¨ # è‹¥æç¤ºæƒé™é”™è¯¯ï¼Œç»§ç»­å¾€ä¸‹çœ‹ï¼ˆæ”¯çº¿ï¼‰ sudo passwd root # æ¿€æ´»ubuntuçš„rootç”¨æˆ·ï¼Œå¹¶è®¾ç½®å¯†ç  vi /etc/ssh/sshd_configï¼š PermitRootLogin yes # ä»»æ„ä½ç½®æ·»åŠ è¿™ä¸ªï¼ˆæ­¤é€‰é¡¹ä¹‹å‰å¯èƒ½æ˜¯å­˜åœ¨çš„æ³¨é‡Šåå†æ·»åŠ ï¼‰ service ssh restart å¯åŠ¨æ²¡æŠ¥é”™ï¼Œä¼šç»™ä½ å¼¹å‡ºä¸€æ¡ç»å¯¹è·¯å¾„çš„æ—¥å¿—æ–‡ä»¶ xxx cat xxx # å³å¯çœ‹è§å¯åŠ¨çŠ¶æ€ ï¼Œå„ç§æ—¥å¿—ä¿¡æ¯ å…¶ä¸­æœ‰å‡ æ¡ä¿¡æ¯: Successfully started service 'WorkerUI' on port 8082 ï¼ˆæµè§ˆå™¨è®¿é—® 8082ç«¯å£ï¼‰ Successfully registered with master spark://lin:7077 ï¼ˆä»£ç ä¸Šä¸‹æ–‡è®¿é—®ï¼‰ å…¶ä¸­ï¼Œæœ‰äº›ä¿¡æ¯å¯èƒ½æœªæ‰“å°å‡ºæ¥ï¼š å»ºè®®æµè§ˆå™¨ä¸­ï¼š( 8080-8082 )ç«¯å£éƒ½å¯ä»¥å°è¯•ä¸€ä¸‹ã€‚ è¾“å…¥å‘½ä»¤ï¼ŒæŸ¥çœ‹å¯åŠ¨çŠ¶æ€ï¼š jps # è‹¥åŒæ—¶æœ‰ worker å’Œ master è¯´æ˜å¯åŠ¨æˆåŠŸ æµ‹è¯•ï¼š pyspark --master spark://lin:7077 # WebUI çš„ Workerç«¯ï¼Œå°±å¯çœ‹è§æœ‰ ä¸€ä¸ªJobè¢«æ·»åŠ äº†è¿›æ¥ YARNéƒ¨ç½²Spark é…ç½®ï¼š echo $HADOOP_HOME # æˆ‘çš„æ˜¯ /home/lin/hadoop/hadoop-2.7.7 è¿›å…¥sparkè§£å‹åŒ…çš„è·¯å¾„çš„ conf ç›®å½•ä¸­: vi spark-env.sh: ( etc/hadoopå‰é¢å°±æ˜¯åˆšæ‰ echoå‡ºæ¥çš„ï¼Œ etc/hadoopå¤§å®¶éƒ½æ˜¯ä¸€æ ·çš„) HADOOP_CONF_DIR=/home/lin/hadoop/hadoop-2.7.7/etc/hadoop å¯åŠ¨sparkï¼š spark-submit --master yarn --name myspark script/myspark.py # æ³¨æ„ --master çš„å€¼æ”¹æˆäº† yarn ï¼Œ å…¶ä»–ä¸å˜ã€‚ æˆ–è€…ä½ å¯ä»¥ï¼š pyspark --master yarn çœ‹åˆ°å¯åŠ¨æˆåŠŸï¼Œè¯´æ˜é…ç½®æˆåŠŸ Sparkå†å²æœåŠ¡é…ç½® ç—›ç‚¹ï¼šæœ‰æ—¶æˆ‘ä»¬çš„sparkä¸Šä¸‹æ–‡ stopåï¼ŒWebUIå°±ä¸å¯è®¿é—®äº†ã€‚ è‹¥æœ‰æœªå®Œæˆï¼Œæˆ–è€…å†å²ä¿¡æ¯, ä¹Ÿå°±çœ‹ä¸åˆ°äº†ã€‚ è¿™æ—¶æˆ‘ä»¬é…ç½® history æœåŠ¡å°±å¯åœ¨ context stopåï¼Œä»å¯æŸ¥çœ‹ æœªå®Œæˆjobã€‚ é¢„æ–°å»ºä¸€ä¸ªHDFSç›®å½•myhistory (æ ¹è·¯å¾„ä¸‹),ä¸‹é¢ç”¨å¾—åˆ°ï¼š hadoop fs -mkdir /myhistory é¦–å…ˆï¼Œè¿›å…¥ sparkè§£å‹åŒ…çš„ confç›®å½•ä¸‹ï¼š cp spark-defaults.conf.template spark-defaults.conf vi spark-defaults.conf: (è§£å¼€å¦‚ä¸‹æ³¨é‡Š, linæœ¬æœºåç§°, æ”¾åœ¨HDFSçš„æ ¹è·¯å¾„ä¸‹çš„myhistory) spark.eventLog.enabled true spark.eventLog.dir hdfs://lin:8020/myhistory vi spark-env.sh: (æˆ‘ä»¬ä¹‹å‰ æŠŠtemplate å¤åˆ¶è¿‡ä¸€æ¬¡ï¼Œæ‰€ä»¥è¿™æ¬¡ç›´æ¥ç¼–è¾‘å³å¯) SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://lin:8020/myhistory&quot; å¯åŠ¨ï¼ˆè¿›å…¥ sparkè§£å‹åŒ…çš„ sbinç›®å½•ä¸‹ï¼‰ï¼š ./start-history-server.sh # cat è¾“å…¥çš„ä¿¡æ¯ï¼ˆæ—¥å¿—æ–‡ä»¶ï¼‰ã€‚ å³å¯æŸ¥çœ‹æ˜¯å¦å¯åŠ¨æˆåŠŸ # WebUIé»˜è®¤æ˜¯ ï¼šhttp://192.168.0.108:18080/ æµ‹è¯•ï¼š æµè§ˆå™¨ä¸­è®¿é—®History WebUIï¼š http://192.168.0.108:18080/ å‘ç°å•¥ä¹Ÿæ²¡æœ‰ï¼š è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬è¿˜æ²¡è¿è¡Œ spark contextä¸»ç¨‹åºè„šæœ¬ã€‚ --------------------------------------------------------------------- è¿è¡Œspark-contextä¸»ç¨‹åºè„šæœ¬ï¼š spark-submit script/myspark.py # è¿™ä¸ªè„šæœ¬æ˜¯éšä¾¿å†™çš„ï¼Œæ²¡ä»€ä¹ˆæ„ä¹‰ã€‚ ä¸è¿‡é‡Œé¢æœ‰ä¸ªæˆ‘ä»¬å¸¸ç”¨çš„ä¸€ä¸ªæ³¨æ„äº‹é¡¹ï¼ï¼ï¼ # æˆ‘çš„è¿™ä¸ªè„šæœ¬çš„ context ç”¨å®Œï¼Œè¢«æˆ‘ stopäº† # æ‰€ä»¥æˆ‘ä»¬è®¿é—®ä¸åˆ°å®ƒçš„è¿è¡ŒçŠ¶æ€çš„ Spark Context çš„ WebUI # ä½†æ˜¯æˆ‘ä»¬åˆšæ‰è¾›è¾›è‹¦è‹¦é…ç½®Spark history æœåŠ¡ï¼Œå¹¶å¯åŠ¨äº†å®ƒã€‚ # æ‰€ä»¥ contextçš„ä¿¡æ¯ï¼Œè¢«å†™å…¥äº†æˆ‘ä»¬åˆšæ‰é…ç½®çš„ Spark history ä¸­ # æ‰€ä»¥ æˆ‘ä»¬å†æ¬¡è®¿é—® Spark history WebUI å³å¯çœ‹åˆ°æœ‰å†…å®¹è¢«å†™å…¥è¿›æ¥ã€‚ --------------------------------------------------------------------- å†æ¬¡è®¿é—®History WebUIï¼š http://192.168.0.108:18080/ ä½ å°±ä¼šå‘ç°ï¼Œé‡Œé¢æœ‰å†…å®¹äº†(spark historyæœåŠ¡å·²ç»ä¸ºæˆ‘ä»¬å¹²æ´»äº†)~~~~ å…å¯†ç ç™»å½• ç¯å¢ƒUbuntu(CentOSåº”è¯¥ä¹Ÿå¯ï¼Œå¾ˆå°‘ç”¨) å…å¯†ç ç™»å½•è®¾ç½®ï¼š cd ~ ssh-keygen -t rsa -P &quot;&quot; cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys chmod 600 .ssh/authorized_keys æ³¨æ„å‡ ç§æƒ…å†µï¼š ä½ å¦‚æœæ˜¯rootç”¨æˆ·ï¼Œé‚£ä¹ˆä½ éœ€è¦åˆ‡æ¢åˆ° /root/ æ‰§è¡Œä¸Šé¢çš„å‘½ä»¤ å¦‚æœæ˜¯æ™®é€šç”¨æˆ·ï¼Œ é‚£ä¹ˆä½ éœ€è¦åˆ‡æ¢åˆ° /home/xxx/ æ‰§è¡Œä¸Šé¢çš„å‘½ä»¤ è¿™ä¸ªè¦ç‰¹åˆ«æ³¨æ„ä¸€ä¸‹ï¼Œæœ‰æ—¶å€™ç”¨ sudo -s ,è·¯å¾„æ˜¯æ²¡æœ‰è‡ªåŠ¨åˆ‡æ¢çš„ã€‚ éœ€è¦æˆ‘ä»¬è‡ªå·±æ‰‹åŠ¨åˆ‡æ¢ä¸€ä¸‹ &quot;å®¶&quot; è·¯å¾„ è‡ªå®šä¹‰è„šæœ¬å¯åŠ¨æœåŠ¡ ä¸‹é¢å†…å®¹ä»…ä¾›ä¸ªäººæ–¹ä¾¿ï¼Œ shellä¸ç†Ÿï¼Œç”¨pyè„šæœ¬äº†, ä½ éšæ„ã€‚ vi start.py: (æ­¤è„šæœ¬ç”¨äºå¯åŠ¨ä¸Šé¢é…ç½®çš„ HDFS,YARN,SparkHistory å’Œ Jupyter Notebook) import os import subprocess as sub ###### å¯åŠ¨ HDFS + YARN ############### hadoop_path = os.environ['HADOOP_HOME'] hadoop_sbin = os.path.join(hadoop_path, 'sbin') os.chdir(hadoop_sbin) sub.run('./start-dfs.sh') sub.run('./start-yarn.sh') ###### å¯åŠ¨ SparkHistory ############## spark_path = os.environ['SPARK_HOME'] spark_sbin = os.path.join(spark_path, 'sbin') os.chdir(spark_sbin) sub.run('./start-history-server.sh') ###### å¯åŠ¨ Jupyter Notebook ############### # home_path = os.environ['HOME'] home_path = '/home/lin' os.chdir(home_path) sub.run('jupyter notebook --allow-root --ip 0.0.0.0'.split()) ä¹‹åæ¯æ¬¡é‡å¯ï¼Œå°±ä¸ç”¨è¿›å…¥æ¯ä¸ªç›®å½•å»å¯åŠ¨äº†ã€‚ç›´æ¥ä¸€æ¡å‘½ä»¤ï¼š sudo python start.py nohup hive --service metastore &amp; æŸ¥çœ‹æœ¬è„šæœ¬å¯åŠ¨ç›¸å…³çš„WebUIï¼š HDFS: http://192.168.0.108:50070/ YARN: http://192.168.0.108:8088/ SparkHistory: http://192.168.0.108:18080/ å¦é™„å…¶ä»– WebUIï¼š spark: http://192.168.0.108:4040/ standaloneå¯åŠ¨æŒ‡å®šçš„ç«¯å£(å¦‚æœä½ ä½¿ç”¨çš„ standaloneæ–¹å¼ï¼Œè€Œä¸æ˜¯local,å¯èƒ½ç”¨åˆ°å¦‚ä¸‹ç«¯å£): pyspark --master spark://lin:7077 ","link":"https://cythonlin.github.io/post/py-greater-ubuntu-hadoop-yarn-hdfs-hive-spark-an-zhuang-pei-zhi/"},{"title":"AI => Seq2Seq+Attention+Transformer(ç®€)","content":"æ•°æ®é¢„å¤„ç†ï¼ˆTF20-Keras-Preprocessingï¼‰ æˆ‘ä»¬è‡ªå·±çš„æ™®é€šæ•°æ®é›†ï¼ˆå¸¸ç”¨ï¼‰ ä¸»è¦ä½¿ç”¨tensorflow.keras.preprocessingè¿™ä¸ªåº“ä¸­çš„ï¼ˆimage, textï¼Œsequenceï¼‰è¿™ä¸‰ä¸ªæ¨¡å—ã€‚ textï¼š å¯ä»¥ç”¨æ¥ ï¼ˆç»Ÿè®¡è¯é¢‘ï¼Œåˆ†å­—ï¼Œword_2_id, id_2_wordç­‰æ“ä½œã€‚ï¼‰ sequence å¯ä»¥ï¼ˆç»™å¥å­åšç»“æ„åŒ–æ“ä½œï¼ˆå¡«å……0ï¼Œè£å‰ªé•¿åº¦ï¼‰ï¼‰ from tensorflow.keras.preprocessing.text import Tokenizer # ä¸»å¹²ï¼Œå¥å­ç¼–ç  from tensorflow.keras.preprocessing.sequence import pad_sequences # è¾…åŠ©ï¼Œå¡«å……ï¼Œå‰ªæ q1 = 'æ¬¢ è¿ ä½  ä½  ä½ ' q2 = 'æˆ‘ å¾ˆ å¥½' q_list = [q1,q2] # éœ€è¦ç‰¹åˆ«æ³¨æ„ï¼Œå› ä¸ºæ­¤APIå¯¹è‹±æ–‡å‹å¥½ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬å¿…é¡»æŠŠå¥å­ç”¨ ç©ºæ ¼ éš”å¼€è¾“å…¥ token = Tokenizer( num_words=2, # num_wordsä»£è¡¨è®¾ç½®è¿‡æ»¤num_words-1ä¸ªè¯é¢‘ï¼Œ ä¾‹å¦‚num_words=2ï¼Œ # é‚£ä¹ˆè¿‡æ»¤æ‰2-1=1ä¸ªè¯é¢‘ï¼Œ æ‰€ä»¥ä¸€ä¼šä½ ä¼šçœ‹åˆ°ä¸‹é¢è¯é¢‘ä¸º1çš„éƒ½è¢«è¿‡æ»¤æ‰äº† ) # è¿™é‡Œé¢å‚æ•°å¾ˆå¤šï¼Œè¿˜æœ‰æ ‡ç‚¹ç¬¦å·è¿‡æ»¤å™¨ç­‰ token.fit_on_texts(q_list) # æŠŠåŸå§‹å¥å­é›†åˆï¼Œæ”¾è¿›å»æ‹Ÿåˆä¸€ä¸‹ï¼ˆå°è£…æˆä¸€ä¸ªç±»ï¼‰ print(token.document_count) # 2 # å¥å­ä¸ªæ•° print(token.word_index) # {'ä½ ': 1, 'æ¬¢': 2, 'è¿': 3, 'æˆ‘': 4, 'å¾ˆ': 5, 'å¥½': 6} # word_2_id print(token.index_word) # {1: 'ä½ ', 2: 'æ¬¢', 3: 'è¿', 4: 'æˆ‘', 5: 'å¾ˆ', 6: 'å¥½'} # id_2_word print(token.word_counts) # OrderedDict([('æ¬¢', 1), ('è¿', 1), ('ä½ ', 3), ('æˆ‘', 1), ('å¾ˆ', 1), ('å¥½', 1)]) # ç»Ÿè®¡è¯é¢‘ seq = token.texts_to_sequences(q_list) # å…ˆæŠŠæ‰€æœ‰çš„è¾“å…¥ï¼Œå˜æˆä¸€ä¸€å˜æˆç¼–ç åŒ– print(seq) # [[1, 1, 1], []] # ä¼šä¸ä¼šå¥½å¥‡ï¼Ÿæ•°æ®æ€ä¹ˆæ²¡äº†ï¼Ÿå› ä¸ºæˆ‘ä»¬ä¸Šé¢è®¾ç½®äº†è¿‡æ»¤è¯é¢‘ä¸º1çš„éƒ½è¿‡æ»¤äº† pad_seq = pad_sequences( seq, # è¾“å…¥ç¼–ç åŒ–åçš„ å¥å­ maxlen=2, # ç»Ÿä¸€å¥å­æœ€å¤§é•¿åº¦ padding='pre', # ä¸è¶³çš„è¡¥0ï¼Œ ä»å‰é¢è¡¥0ï¼Œ ï¼ˆä¹Ÿå¯ä»¥ç”¨ postï¼Œä»£è¡¨åé¢ï¼‰ truncating='pre' # å¤šä½™çš„é•¿åº¦è£å‰ªï¼Œä»å‰é¢è£å‰ª ) print(pad_seq) # æ‰“å°ä¸€ä¸‹æˆ‘ä»¬å¡«å……åçš„å¥å­å½¢çŠ¶ã€‚ # [ # [1 1], # å¦‚ä½ æ‰€æ„¿,æœ€å¤§é•¿åº¦ä¸º2ï¼Œ[1,1,1] å·²ç»è£å‰ªæˆäº† [1,1] # [0 0], # å¦‚ä½ æ‰€æ„¿ï¼Œä¹‹å‰[] ï¼Œå·²ç»éƒ½å¡«æ»¡äº†0 # ] è™½ç„¶æˆ‘ä»¬ç”¨ä¸åˆ° imageè¿™ä¸ªæ¨¡å—æ•°æ®å¢å¼ºæ¨¡å—ï¼Œä½†æ˜¯æˆ‘æŠŠäº†è§£çš„APIä¹Ÿå†™å‡ºæ¥ã€‚ train_datagen = keras.preprocessing.image.ImageDataGenerator( # æ•°æ®å¢å¼ºç”Ÿæˆå™¨ï¼ˆå®šä¹‰ï¼‰ rescale=1. / 255, # æ•°æ®å½’ä¸€åŒ– rotation_range = 40, # -40-40 éšæœºè§’åº¦ ï¼ˆæ•°æ®å¢å¼ºï¼‰ width_shift_range = 0.2, # å®½åº¦ä½ç§»ï¼ˆ0-20%éšæœºé€‰ä¸ªæ¯”ä¾‹å»å¹³ç§»ï¼‰ ï¼ˆæ•°æ®å¢å¼ºï¼‰ height_shift_range = 0.2, # é«˜åº¦ä½ç§»ï¼ˆåŒä¸Šï¼‰ ï¼ˆæ•°æ®å¢å¼ºï¼‰ shear_range=0.2, # å›¾ç‰‡å‰ªåˆ‡ï¼ˆ0.2ï¼‰ ï¼ˆæ•°æ®å¢å¼ºï¼‰ zoom_range=0.2, # å›¾ç‰‡ç¼©æ”¾ï¼ˆ0.2ï¼‰ ï¼ˆæ•°æ®å¢å¼ºï¼‰ horizontal_flip=True, # å›¾ç‰‡éšæœºæ°´å¹³åè½¬ ï¼ˆæ•°æ®å¢å¼ºï¼‰ fill_mode='nearest', # å›¾ç‰‡å¡«å……åƒç´ ï¼ˆæ”¾å¤§åå¤±å¸§ï¼‰ç”¨é™„è¿‘åƒç´ å€¼æ¥å¡«å…… ï¼ˆæ•°æ®å¢å¼ºï¼‰ ) # train_generator = train_datagen.flow_from_dataframe() # å¦‚æœä½ ç”¨Pandasï¼Œä½ å¯ä»¥é€‰è¿™ä¸ª train_generator = train_datagen.flow_from_directory( # ä»æ–‡ä»¶ä¸­è¯»å–ï¼ˆKaggleï¼‰ train_dir, # å›¾ç‰‡ç›®å½• target_size = (height, width), # å›¾ç‰‡è¯»å–è¿›æ¥åç¼©æ”¾å¤§å° batch_size = batch_size, # å°±æ˜¯æ‰¹æ¬¡ seed=6, # éšæœºåŒ–ç§å­ shuffle=True, # æ ·æœ¬éšæœºæ‰“æ•£è®­ç»ƒï¼Œå¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ› class_mode='categorical', # labelæ ¼å¼ï¼Œæ˜¯å¦éœ€è¦one_hotï¼Œ æ˜¯ ) ... ... train_num = train_generator.samples # æ‰“å°æ ·æœ¬å½¢çŠ¶ history = model.fit_generator( # æ³¨æ„æˆ‘ä»¬ä¸Šé¢æ˜¯ç”¨çš„æ•°æ®ç”Ÿæˆå™¨ï¼Œæ‰€ä»¥è¿™è¦ç”¨ fit_generator train_generator, steps_per_epoch=train_num//batch_size, # æ¯ä¸ªepochå¤šå°‘ step(å› ä¸ºæ•°æ®å¢å¼ºAPIæ˜¯ç”Ÿæˆå™¨æ–¹å¼ï¼Œæ‰€ä»¥éœ€è¦è‡ªå·±æ‰‹åŠ¨è®¡ç®—ä¸€ä¸‹) epochs=epochs, validation_data=valid_generator, # å¦‚æœä½ æœ‰éªŒè¯é›†ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨è¿™ä¸ªã€‚å¦åˆ™å¯ä»¥ä¸ç”¨ validation_steps=valid_num//batch_size # åŒä¸Š ) Seq2Seq æ€æƒ³ è¯­è¨€ä¸åŒï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æ­å»ºæ¡¥æ¢ã€‚ å³ä½¿æˆ‘ä»¬è¡¨é¢ä¸Šä¸ç›¸åŒã€‚ ä½†æ˜¯æˆ‘ä»¬æ˜ å°„åˆ°è¿™ä¸ªæ¡¥æ¢ä¸Šçš„ç»“æœæ˜¯å‡ ä¹ç±»ä¼¼çš„ã€‚ æ ·æœ¬å¥å­é•¿åº¦ç»Ÿä¸€ ä¸ºä»€ä¹ˆæ¯ä¸ªå¥å­çš„é•¿åº¦éœ€è¦ç»Ÿä¸€ï¼Ÿ å› ä¸ºï¼Œæ¯ä¸ªå¥å­forå¾ªç¯æ“ä½œä¼šå¾ˆè€—ç®—åŠ›ï¼Œ è€Œè½¬åŒ–ä¸ºçŸ©é˜µ/å‘é‡åŒ–æ“ä½œï¼Œä¼šèŠ‚çº¦å¤ªå¤šç®—åŠ›ã€‚ å› ä¸ºçŸ©é˜µè¿ç®—ä¸¥æ ¼è¦æ±‚æ ·æœ¬çš„å½¢çŠ¶ï¼Œæ‰€ä»¥æ¯ä¸ªå¥å­çš„é•¿åº¦éœ€è¦ä¸€è‡´ å¦‚ä½•åšåˆ°å¥å­é•¿åº¦ç»Ÿä¸€ï¼Ÿ å¡«0ï¼Œ å¯¹åº”TFæ“ä½œå°±æ˜¯paddingï¼Œ ä¸è¿‡TF20 çš„kerasé¢„å¤„ç†åŒ…ä¸­å·²ç»æœ‰ æˆå“çš„æ•°æ®ç»Ÿä¸€åŒ–æ“ä½œã€‚ å¹¶ä¸”è¿˜å…·æœ‰ word_2_idï¼Œè¯å‘é‡ç¼–ç æ“ä½œã€‚ ç»„æˆ ç¼–ç å™¨ ï¼ˆè¾“å…¥æ¯æ¡æ ·æœ¬å¥å­çš„æ¯ä¸ªå•è¯ï¼Œ ç¼–ç å™¨çš„æœ€åä¸€ä¸ªRNNå•å…ƒï¼Œæµ“ç¼©äº†æ•´ä¸ªå¥å­çš„ä¿¡æ¯ï¼‰ ä¸­é—´å‘é‡ ï¼ˆä½œä¸ºä¸­é—´ç‰¹å¾æ¡¥æ¢ï¼Œ ç”¨æ¥ä¿å­˜ï¼Œè¾“å…¥è¿›æ¥çš„æ•´ä¸ªå¥å­ï¼‰ è§£ç å™¨ ï¼ˆä¸­é—´å‘é‡ä½œä¸ºè§£ç å™¨ç¬¬ä¸€ä¸ªRNNå•å…ƒçš„è¾“å…¥ï¼Œè€Œæ¯ä¸ªå•å…ƒçš„è¾“å‡ºy,ä½œä¸ºä¸‹ä¸€ä¸ªå•å…ƒçš„è¾“å…¥ï¼‰ å…¶ä¸­è§£ç å™¨éƒ¨åˆ†çš„è¾“å‡ºyä¼šç”¨ softmax å¯¹ è¯åº“ï¼ˆè¯å…¸ï¼‰æ±‚å¤šåˆ†ç±»æ¦‚ç‡ã€‚ ç„¶åæ±‚æŸå¤±ï¼ˆMSEæˆ–è€…CrossEntropyï¼‰ æ³¨æ„äº†ï¼š softmaxæ±‚å‡ºçš„æ¦‚ç‡è¯¥å¦‚ä½•é€‰æ‹©ï¼Œè¿™æ˜¯ä¸ªé—®é¢˜: å‡å¦‚: æ¯ä¸ªå•å…ƒçš„è¾“å‡ºyçš„æ¦‚ç‡éƒ½å–æœ€å¤§å€¼, é‚£ä¹ˆå¯èƒ½ä¸€æ­¥é”™ï¼Œæ­¥æ­¥é”™ã€‚ å¤ªæç«¯äº†ï¼ˆè´ªå¿ƒæœç´¢ï¼‰ æ¥ä¸‹æ¥ï¼ŒèŠä¸€èŠä¸€å‘¨ é›†æŸæœç´¢çš„ç®—æ³• BeamSearch BeamSearch ç”±äºè´ªå¿ƒæœç´¢ï¼ˆåªå–æ¦‚ç‡çš„ä¸€ä¸ªæœ€å¤§å€¼ï¼Œçš„ç»“æœä¸å°½äººæ„ã€‚æ‰€ä»¥ BeamSearchæ¥å•¦ï¼‰ BeamSearchçš„ä¸»è¦æ€æƒ³: åªå–ä¸€ä¸ªå¤ªå†’é™©äº†ï¼Œæ‰€ä»¥: BeamSearch å–æ¯ä¸ªç»è¿‡softmaxè¾“å‡ºæ¦‚ç‡é›†åˆçš„ Top-Nä¸ª Top-N: çš„ N ä»£è¡¨ä½ ä¿ç•™å‡ ä¸ªæ¦‚ç‡ ï¼ˆä¸¾ä¸€åä¸‰ç†è§£: è´ªå¿ƒç®—æ³•å°±æ˜¯ Top-1ï¼‰ å‡å¦‚æˆ‘ä»¬å–Top-3ä¸ª é‚£ä¹ˆä½ ä¸€ä¸ªRNNèŠ‚ç‚¹çš„é¢„æµ‹yå°†ä¼šä¿ç•™3ä¸ªæ¦‚ç‡å€¼ï¼Œ å¹¶å°†è¿™3ä¸ªæ¦‚ç‡å€¼ä½œä¸º ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„è¾“å…¥ã€‚ å…·ä½“æµç¨‹çœ‹:ä¸‹å›¾ (å¯èƒ½æœ‰ç‚¹ä¸‘) ç„¶åï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©å‡º: 3 ä¸ª &quot;çº¢çº¿&quot; æœ€ä¼˜è·¯å¾„ã€‚ æœ€ç»ˆ: æˆ‘ä»¬é€šè¿‡å•ç‹¬çš„è¯­è¨€æ¨¡å‹ï¼Œæ¥ä»è¿™ 3 ä¸ª &quot;çº¢çº¿&quot; è¾ƒä¼˜è·¯å¾„ä¸­ï¼Œé€‰å‡ºä¸€ä¸ª æœ€ä¼˜è·¯å¾„ã€‚ Attention(æ³¨æ„åŠ›æœºåˆ¶) å‰æƒ…å›é¡¾ Seq2Seq çš„ Encoderéƒ¨åˆ†è™½ç„¶ç”¨çš„æ˜¯ é«˜æ•ˆçš„ LSTMï¼Œå¹¶ä¸”ä¹Ÿå¾ˆå¥½çš„è§£å†³äº†ï¼Œè®°å¿†çš„é—®é¢˜ã€‚ ä½†æ˜¯ä»–ä¸èƒ½å¾ˆå¥½çš„è§£å†³æ¯ä¸ªå•è¯çš„æƒé‡åˆ†é…é—®é¢˜ã€‚ è™½ç„¶: Encoderçš„æ‰€æœ‰å•å…ƒéƒ½ä¼šé€šè¿‡LSTMçš„è®°å¿†ä¼ é€’ï¼Œ è¾“å…¥è¿›â€œä¸­é—´æ¡¥æ¢å‘é‡â€ã€‚ ä½†æ˜¯: è¿˜æ˜¯æœ‰&quot;åå¿ƒ&quot;æˆåˆ†, æœ€åä¸€ä¸ªLSTMå•å…ƒä¿¡æ¯ä¸€å®šæ˜¯æœ€æµ“çš„ã€‚ ï¼ˆæ–°é²œçš„ï¼Œçƒ­ä¹çš„ï¼‰ æ‰€ä»¥: ä½ ç¬¬1ä¸ªLSTMå•å…ƒçš„ä¿¡æ¯ï¼Œæˆ–è€…è¯´å‰é¢çš„LSTMå•å…ƒçš„ä¿¡æ¯ï¼Œè¿™äº›è®°å¿†åˆ°æœ€åå¯èƒ½ä¼šè¢«ç¨€é‡Šã€‚ ä¸ºäº†è§£å†³ä¸Šé¢çš„é—®é¢˜, Attentionå°±å‡ºæ¥å¸®å¿™äº†~~~ AttentioinåŸç† æˆ‘è§‰å¾—å¢¨è¿¹åŠå¤©ä¸å¦‚è‡ªå·±ç”»ä¸€å¼ å›¾~~~ ï¼ˆåªä¼šmspaintç”»å›¾ï¼‰ ä¸Šå›¾ä¸­è®¡ç®—æƒé‡é‚£é‡Œ&quot;é€šè¿‡ä¸€ä¸ªå‡½æ•°ï¼Œå¯ä»¥æ˜¯æ±‚ç›¸ä¼¼åº¦&quot;ï¼Œ æˆ‘ç®€å†™äº†ã€‚ å…¶å®æœ‰ä¸¤ç§å¸¸ç”¨çš„æ–¹å¼ï¼š Bahdanauæ³¨æ„åŠ›: weight = FCå±‚( tanh ( FCå±‚(Encoderçš„æ¯ä¸ªè¾“å‡ºy) + FCå±‚(Decoderçš„ä¸€ä¸ªH) ) ) luongæ³¨æ„åŠ›: weight = Encoderçš„æ¯ä¸ªè¾“å‡ºy @ Wéšæœºæƒé‡çŸ©é˜µ @ Decoderçš„ä¸€ä¸ªH # @æ˜¯TF20çš„çŸ©é˜µä¹˜æ³•æ“ä½œç¬¦ æ— è®ºä½¿ç”¨ä¸Šé¢å“ªç§: éƒ½è¦å¥—ä¸€å±‚ Softmax weight = softmax(weight, axis=1) æ³¨æ„åŠ›å‘é‡C = sum( weight * Encoderçš„æ¯ä¸ªè¾“å‡ºy , axis=1) # åŠ æƒæ±‚å’Œï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªå‘é‡ Decoderçš„ä¸‹ä¸€ä¸ªè¾“å…¥ = concat( æ³¨æ„åŠ›å‘é‡C, ä¸Šä¸€ä¸ªé¢„æµ‹y4 ) Transformer ç¬¬ä¸€å°è±¡æŒ‘æ˜ï¼š ä»–æ˜¯ä¸€ç§æ— RNNçš„ä¸€ç§ç‰¹æ®Šçš„ Seq2Seq æ¨¡å‹ã€‚ RNN-LSTM-GRUè™½ç„¶è¿™äº›NNçš„ä¸»è¦ç‰¹è‰²å°±æ˜¯&quot;æ—¶é—´åºåˆ—&quot;ã€‚ï¼ˆç¼ºç‚¹ï¼šæ…¢ï¼Œè®°å¿†å¼¥æ•£ï¼‰ ä½†æ˜¯æˆ‘ä»¬ä¸Šé¢è¯´äº†ï¼Œè¦æƒ³å–å¾—å¥½çš„æ•ˆæœã€‚é‚£ä¹ˆéœ€è¦åŠ Attentionã€‚ äºæ˜¯æœ‰äººæƒ³åˆ°äº†ï¼Œæ—¢ç„¶Attentionæ•ˆæœè¿™ä¹ˆå¥½ï¼Œä¸ºä»€ä¹ˆä¸ç›´æ¥ç”¨Attentionå‘¢ï¼Ÿ Attentionæ•ˆæœè™½å¥½ï¼Œå…³è”æ€§å¼ºï¼Œä½†æ˜¯å®ƒä¸èƒ½ä¿è¯æ—¶é—´åºåˆ—æ¨¡å¼ã€‚ äºæ˜¯åæ¥å‡ºç°äº† Transformerã€‚ï¼ˆæ—¢èƒ½ä¿è¯è®°å¿†æ³¨æ„åŠ›ï¼Œåˆèƒ½ä¿è¯æ—¶é—´åºåˆ—ï¼‰ã€‚å…·ä½“å¦‚ä¸‹ï¼ Transformeræ•´ä½“ç»“æ„ç»„æˆ Self-Attention self-attentionåŸç†å°±æ˜¯å„ç§é“¾å¼çŸ©é˜µä¹˜æ³•ï¼ˆå¹¶è¡Œè®¡ç®—ï¼Œå¯ç”¨GPUåŠ é€Ÿï¼‰ self-attentionè®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼šï¼ˆå‡è®¾è¾“å…¥å¥å­åˆ‡åˆ†å•è¯ä¸ºï¼šçŸ©é˜µX = [&quot;æ—©&quot;,&quot;ä¸Š&quot;,&quot;å¥½&quot;]ï¼‰ çŸ©é˜µX @ æƒé‡çŸ©é˜µQï¼ˆQ1ï¼ŒQ2ï¼ŒQ3ï¼‰=&gt; QçŸ©é˜µï¼ˆQ1ï¼ŒQ2ï¼ŒQ3ï¼‰ çŸ©é˜µX @ æƒé‡çŸ©é˜µKï¼ˆQ1ï¼ŒQ2ï¼ŒQ3ï¼‰=&gt; KçŸ©é˜µï¼ˆQ1ï¼ŒQ2ï¼ŒQ3ï¼‰ çŸ©é˜µX @ æƒé‡çŸ©é˜µVï¼ˆQ1ï¼ŒQ2ï¼ŒQ3ï¼‰=&gt; VçŸ©é˜µï¼ˆQ1ï¼ŒQ2ï¼ŒQ3ï¼‰ Î± = softmax( (QçŸ©é˜µ @ KçŸ©é˜µ) / q^0.5 ) self_attention = Î± @ VçŸ©é˜µ # å•è¯1 = Q1*K1*V1 + Q1*K2*V2 + Q1*k3*V3 # ç”¨è‡ªå·±çš„Qï¼ŒæŸ¥åˆ«äººçš„KVï¼ŒåŠ æƒæ±‚å’Œï¼Œæœ€ç»ˆå¾—å‡ºçš„å°±æ˜¯è‡ªå·±ï¼ˆè‡ªèº«å•è¯çš„æ³¨æ„åŠ›ï¼‰ Multi-Head Self-Attention Multi-Head Attention å¯¹ Self-Attention å¯¹äº†å¦‚ä¸‹æ‰©å±•ï¼š self-attention: ä¸€ç»„ QçŸ©é˜µï¼ŒKçŸ©é˜µï¼ŒVçŸ©é˜µ Multi-Head Self-Attention: å¤šç»„ QçŸ©é˜µï¼ŒKçŸ©é˜µï¼ŒVçŸ©é˜µ æ‰©å¼ ä¸ºå¤šå¤´æ³¨æ„åŠ›çš„è¿‡ç¨‹ï¼š Q @ W ====&gt; [Q1, Q2, Q3] K @ W ====&gt; [K1, K2, K3] V @ W ====&gt; [V1, V2, V3] å¯ç†è§£ä¸ºï¼Œå¤šä¸ªå·ç§¯æ ¸çš„æ„æ€èƒ½æå–ä¸åŒç‰¹å¾çš„æ„æ€ã€‚ Position Encoder ä¸Šè¿°çš„self-attentionæœ‰ä¸ªé—®é¢˜ï¼Œ æˆ‘ä»¬æ²¡æœ‰ç”¨åˆ°RNNç­‰åºåˆ—NNï¼Œé‚£ä¹ˆçŸ©é˜µç›¸ä¹˜çš„è¿‡ç¨‹ä¸­ã€‚ å•è¯çš„è®¡ç®—é¡ºåºå¯èƒ½æ˜¯ä¸åŒçš„ã€‚ é‚£ä¹ˆå¦‚ä½•ä¿è¯è®©ä»–ä»¬ä½ç½®æœ‰æ¡ä¸ç´Šï¼Ÿ å¯ä»¥ä½¿ç”¨ä½ç½®ç¼–ç ï¼Œèå…¥åˆ°Embeddingï¼Œå½¢æˆå¸¦æœ‰æ—¶é—´åºåˆ—æ€§è´¨çš„æ¨¡å‹ã€‚ å¯è‡ªè¡ŒæŸ¥æ‰¾è®¡ç®—ä½ç½®ç¼–ç çš„åšæ–‡ã€‚ ä¼ é€é—¨ è‡³äºTransformerï¼Œç°åœ¨å®˜æ–¹å·²ç»æœ‰TF20å’ŒPytorchçš„åº“äº†ã€‚ ä¼ é€é—¨å¦‚ä¸‹ã€‚ https://github.com/huggingface/transformers Transformerå»¶ç”³çš„å„ç§æ¨¡å‹ï¼ŒåƒBertç­‰ä¹Ÿæœ‰å¯è°ƒç”¨çš„API https://huggingface.co/transformers/ ","link":"https://cythonlin.github.io/post/ai-greater-seq2seqattentiontransformerjian/"},{"title":"AI => Pytorchä¸Tersorflow2.0ç®€å•å¯¹æ¯”","content":"å‰è¨€ ç›®å‰ä¸€äº›æ¨¡å‹APIå°šæœªè¿ç§»åˆ°TF20ä¸­ã€‚ eg: CRFï¼ŒSeq2Seqç­‰ å¦‚æœé€€å›TF10ï¼Œæœ‰äº›ä¼¤ã€‚ å€’ä¸å¦‚è½¬è‡³Torchã€‚ Pytorchçš„å¤§éƒ¨åˆ†æ€æƒ³å’ŒTF20å¤§è‡´ç›¸ä¼¼ã€‚ è‡³äºå®‰è£…ï¼ŒGPUæˆ‘å‰é¢è¯´è¿‡TF20ã€‚è¿™é‡Œä¸èµ˜è¿°ã€‚ å®˜æ¡£å®‰è£…ï¼šhttps://pytorch.org/get-started/locally/#start-locally æ³¨æ„ æœ¬æ–‡å‡ ä¹é€šç¯‡ä»¥ä»£ç æ¡ˆä¾‹ å’Œ æ³¨é‡Šæ ‡æ³¨ çš„æ–¹å¼è§£é‡ŠAPIã€‚(æ¨¡å‹çš„è®­ç»ƒæ•ˆæœä¸åšè€ƒè™‘ã€‚åªçœ‹è¯­æ³•) ä½ å¦‚æœæ‡‚Tensorflow2.0ï¼ˆStableï¼‰ï¼Œé‚£ä¹ˆä½ çœ‹æœ¬æ–‡ä¸€å®šä¸è´¹åŠ²ã€‚ Torchå’ŒTF20 å¾ˆåƒï¼ï¼ï¼ å› æ­¤ä¸€äº›åœ°æ–¹ï¼Œæˆ‘ä¼šåˆ—å‡º TF20 ä¸ Torchçš„ç»†èŠ‚å¯¹æ¯”ã€‚ å¼€é—¨æ¡ˆä¾‹1-MNIST æ¨¡å—å¯¼å…¥ import torch from torch import nn, optim from torchvision import datasets, transforms from torch.utils.data import DataLoader æ•°æ®é¢„å¤„ç† data_preprocess = transforms.Compose([ # é¡¶é¢„å®šæ•°æ®å¤„ç†å‡½æ•°ï¼Œç±»ä¼¼map()é‡Œçš„å‡½æ•°å¥æŸ„ transforms.Resize(28,28), # å˜å½¢ transforms.ToTensor(), # numpy è½¬ Tensor ]) trian_dataset = datasets.MNIST( # TF20åœ¨keras.datasetsä¸­,æœªå½’ä¸€åŒ–ï¼ˆ0-255ï¼‰ '.', # ä¸‹è½½è‡³å½“å‰ç›®å½•ï¼Œ ï¼ˆå›¾ç‰‡0-1ï¼Œå·²ç»è¢«å½’ä¸€åŒ–äº†ï¼‰ train=True, # train=Trueï¼Œ ä»£è¡¨ç›´æ¥ç»™ä½ åˆ‡å‡º è®­ç»ƒé›† download=True, # Trueï¼Œè‹¥æœªä¸‹è½½ï¼Œåˆ™å…ˆä¸‹è½½ transform=data_preprocess, # æŒ‡å®šæ•°æ®é¢„å¤„ç†å‡½æ•°ã€‚ç¬¬ä¸€è¡Œæˆ‘ä»¬æŒ‡å®šçš„ ) test_dataset = datasets.MNIST( '.', train=False, # Falseä»£è¡¨æµ‹è¯•é›† # å°±è¯´ä¸‹è¿™é‡Œï¼Œ Falseä»£è¡¨ ç»™ä½ åˆ‡å‡ºæµ‹è¯•é›† download=True, transform=data_preprocess, ) train = DataLoader( # å¯¹åº”TF20ä¸­çš„ tf.data.Datasetå¯¹æ•°æ®äºŒæ¬¡é¢„å¤„ç†ï¼ˆåˆ†æ‰¹ï¼Œä¹±åºï¼‰ trian_dataset, # æŠŠä¸Šé¢ç¬¬ä¸€æ¬¡é¢„å¤„ç†çš„æ•°æ®é›† åŠ è½½è¿›æ¥ batch_size=16, # mini-batch shuffle=True, # ä¹±åºï¼Œå¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ› ) test = DataLoader( test_dataset, batch_size=16, shuffle=True, ) MNISTæ¨¡å‹ï¼ˆå®šä¹‰-è®­ç»ƒä»£ç ï¼‰ # æ¨¡å‹å®šä¹‰éƒ¨åˆ† class MyModel(nn.Module): # TF20æ˜¯ tk.models.Model def __init__(self): # TF20 ä¹Ÿæ˜¯ __init__() super().__init__() self.model = nn.Sequential( # tk.models.Sequential , å¹¶ä¸” TFé‡Œé¢ éœ€è¦åŠ ä¸€ä¸ª [] nn.Linear(28*28, 256), # tk.layers.Dense(256) nn.ReLU(), # tk.layers.Relu() nn.Linear(256, 128), # tk.layers.Dense(128) nn.ReLU(), nn.Linear(128, 10), # tk.layers.Dense(10) ) def forward(self, x): # TF20æ˜¯ __call__() x = x.view( x.size(0), 28*28 ) # x.view ==&gt; tf.reshape x.size ==&gt; x.shape[0] y_predict = self.model(x) return y_predict # -------------------------------åä¸½åˆ†å‰²çº¿--------------------------------- # æ¨¡å‹è®­ç»ƒéƒ¨åˆ† def main(): vis = visdom.Visdom() model = MyModel() loss_ = nn.CrossEntropyLoss() # ä¼šå°† y_predictè‡ªåŠ¨åŠ ä¸€å±‚ softmax optimizer = optim.Adam(model.parameters()) # TF20: model.trainable_variables # visdomå¯è§†åŒ– # è¿™æ­¥æ˜¯åˆå§‹åŒ–åæ ‡ç‚¹ï¼Œä¸‹é¢lossä¼šç”¨è¿™ä¸ªç›´æ¥æ›´æ–° vis.line( [0], # xåæ ‡ [0], # yåæ ‡ win='loss', # çª—å£åç§° opts={'title': 'loss'}, # çª—å£æ ‡é¢˜ ) for epoch in range(10): # epochs for step, (x, y_true) in enumerate(train): y_predict = model(x) loss = loss_(y_predict, y_true) optimizer.zero_grad() # ä¼˜åŒ–å™¨æ¸…é›¶ loss.backward() # æ¢¯åº¦è®¡ç®— optimizer.step() # æ¢¯åº¦ä¸‹é™æ›´æ–° tp.gradient(loss, variables)ã€‚ # åœ¨ä¸Šé¢çš„å®šä¹‰çš„åŸºç¡€ä¸Šæ›´æ–°è¿½åŠ ç”»ç‚¹-è¿æˆçº¿ vis.line( [loss.item()], [step], win='loss', update='append', # è¿½åŠ ç”»ç‚¹ï¼Œè€Œä¸æ˜¯æ›´æ–°è¦†ç›– ) print(loss.item()) # .item() =&gt; ç›¸å½“äº tensorflow çš„ numpy() if epoch % 2 == 0: total_correct_samples = 0 # ç”¨äºè®°å½•ï¼ˆé¢„æµ‹æ­£ç¡®çš„æ ·æœ¬çš„ æ€»æ•°é‡ï¼‰ total_samples = 0 # ç”¨äºè®°å½•ï¼ˆæ ·æœ¬çš„ æ€»æ•°é‡ï¼‰ for x_test, y_test in test: y_pred = model(x_test) y_final_pred = y_pred.argmax(dim=1) # TF20çš„åæ ‡è½´å‚æ•°æ˜¯ axis # æ¯ä¸€æ‰¹æ˜¯ batch_size=16ï¼Œæˆ‘ä»¬è¦æŠŠå®ƒä»¬éƒ½åŠ åœ¨ä¸€èµ· total_correct_samples += torch.eq(y_final_pred, y_test).float().sum().item() # è¿™é‡Œæä¸€ä¸‹ eq() å’Œ equal() çš„è¿”å›å€¼çš„åŒºåˆ«ï¼Œ è‡ªå·±çœ‹ï¼Œæˆ‘ä»¬é€šå¸¸ç”¨ eq # print( torch.equal( torch.Tensor([[1,2,3]]), torch.Tensor([[4,5,6]] ) ) ) #ç»“æœ: False # print( torch.eq( torch.Tensor([[1,2,3]]), torch.Tensor([[4,5,6]] ) ) ) #ç»“æœ: tensor([[0, 0, 0]], dtype=torch.uint8) per_sample = x_test.size(0) # å†è¯´ä¸€æ¬¡ï¼Œ size(0) ç›¸å½“äºTF xx.shape[0] # è·å–æ¯æ‰¹æ¬¡æ ·æœ¬æ•°é‡, è™½ç„¶æˆ‘ä»¬çŸ¥é“æ˜¯ 16 # ä½†æ˜¯æœ€åä¸€ä¸ªbatch_size å¯èƒ½ä¸æ˜¯16ï¼Œæ‰€ä»¥è¦å‡†ç¡®è·å–ã€‚ total_samples += per_sample acc = total_correct_samples / total_samples print(f'epoch: {epoch}, loss: {loss}, acc: {acc}') # æµ‹è¯•éƒ¨åˆ† vis.line( [acc], [step], win='acc', update='append', # è¿½åŠ ç”»ç‚¹ï¼Œè€Œä¸æ˜¯æ›´æ–°è¦†ç›– ) x, label = iter(test).next() target_predict = model(x).argmax(dim=1) # ç”»å‡ºæµ‹è¯•é›†å›¾ç‰‡ viz.images(x, nrow=16, win=&quot;test_x&quot;, opts={'title': &quot;test_x&quot;}) vis.text( # æ˜¾ç¤ºé¢„æµ‹æ ‡ç­¾æ–‡æœ¬ str(target_predict.detach().numpy() ), win = 'target_predict', opts = {&quot;title&quot;: target_predict} ) vis.text( # æ˜¾ç¤ºçœŸå€¼æ–‡æœ¬ str(label.detach().numpy() ), win = 'target_true', opts = {&quot;target_true&quot;: target_predict} ) main() æ¨¡å‹å¯è§†åŒ–ï¼ˆvisdom) å®‰è£… å’Œ è¿è¡Œ å’Œ ä½¿ç”¨ å®‰è£… pip install visdom è¿è¡Œ python -m visdom.server ï¼ˆç¬¬ä¸€æ¬¡å¯èƒ½ä¼šæœ‰ç‚¹æ…¢ï¼‰ # è¯­æ³•å’ŒTensorboardå¾ˆåƒ ä½¿ç”¨ import visdom è§ä¸Šä»£ç  vis.xxxxx æ¡ˆä¾‹2-CIFAR10+CNN è¯´æ˜ æ¨¡å—å¯¼å…¥å’Œæ•°æ®é¢„å¤„ç†éƒ¨åˆ†å’Œæ¡ˆä¾‹1çš„ MNISTä¸€æ¨¡ä¸€æ ·ã€‚ åªè¦ç¨ç¨ä¿®æ”¹ datasets.MNIST ==&gt; datasets.CIFAR10 å³å¯ï¼Œ ç®€å•çš„ä¸å¿ç›´è§†~~ ä»£ç å¦‚ä¸‹ï¼š æ¨¡å‹å®šä¹‰éƒ¨åˆ†ï¼š class MyModel(nn.Module): # æ¸©é¦¨æç¤ºï¼Œ è¿™æ˜¯ Mmodule, ä¸æ˜¯model def init(self): &quot;&quot;&quot; å…ˆæ³¨æ˜ä¸€ä¸‹ï¼š TFä¸­è¾“å…¥å›¾ç‰‡å½¢çŠ¶ä¸º (æ ·æœ¬æ•°, é«˜ï¼Œå®½ï¼Œå›¾ç‰‡é€šé“) PyTorchä¸­è¾“å…¥å›¾ç‰‡å½¢çŠ¶ä¸º (æ ·æœ¬æ•°, å›¾ç‰‡é€šé“ï¼Œé«˜ï¼Œå®½) &quot;&quot;&quot; super().__init__() self.conv = nn.Sequential( # å†å¼ºè°ƒä¸€éï¼Œæ²¡æœ‰ [] nn.Conv2d( in_channels=3, # å¯¹åº”TF å›¾ç‰‡é€šé“æ•°ï¼ˆæˆ–è€…ä¸Šä¸€å±‚é€šé“ï¼‰ out_channels=8, # å¯¹åº”TF filters, å·ç§¯æ ¸æ•°é‡ kernel_size=3, # å·ç§¯æ ¸å¤§å° stride=1, # æ­¥é•¿, TF æ˜¯ stridesï¼Œ ç‰¹åˆ«æ³¨æ„ padding=0, # no padding, é»˜è®¤ ), nn.ReLU(), nn.MaxPool2d( kernel_size=3, # æ»‘åŠ¨çª—å£å¤§å° stride=None, # é»˜è®¤ä¸ºNoneï¼Œ æ„ä¸ºå’Œ kernel_sizeç›¸åŒå¤§å° ), nn.Conv2d( in_channels=8, # å¯¹åº”TF å›¾ç‰‡é€šé“æ•°ï¼ˆæˆ–è€…ä¸Šä¸€å±‚é€šé“ï¼‰ out_channels=16, # å¯¹åº”TF filters, å·ç§¯æ ¸æ•°é‡ kernel_size=3, # å·ç§¯æ ¸å¤§å° stride=1, # æ­¥é•¿, TF æ˜¯ stridesï¼Œ ç‰¹åˆ«æ³¨æ„ padding=0, # no padding, é»˜è®¤ ), nn.ReLU(), nn.MaxPool2d( kernel_size=2, # æ»‘åŠ¨çª—å£å¤§å° stride=None, # é»˜è®¤ä¸ºNoneï¼Œ æ„ä¸ºå’Œ kernel_sizeç›¸åŒå¤§å° ), ) self.dense = nn.Sequential( nn.Linear(16*4*4, 128), # å¯¹åº”TF Dense nn.Linear(128, 64), nn.Linear(64, 10), ) def forward(self, x): conv_output = self.conv(x) # (16, 16, 4.4) conv_output_reshape = conv_output.view(-1, 16*4*4) dense_output = self.dense(conv_output_reshape) return dense_output æ¨¡å‹è®­ç»ƒï¼ˆæ¨¡å‹è°ƒç”¨+æ¨¡å‹è®­ç»ƒçš„å®šä¹‰ï¼‰ def main(): vis = visdom.Visdom() epochs = 100 device = torch.device('cuda') # é¢„å®šä¹‰ GPU æ§½ä½ï¼ˆä¸€ä¼šå¾€é‡Œé¢å¡ æ¨¡å‹å’Œæ•°æ®ã€‚ï¼‰ model = MyModel().to(device) # æ¨¡å‹è½¬ä¸º GPU è®¡ç®— # CrossEntropyLoss ä¼šè‡ªåŠ¨æŠŠä¸‹é¢çš„ dense_output ï¼Œä¹Ÿå°±æ˜¯y_predict åŠ ä¸€å±‚ softmax loss_ = nn.CrossEntropyLoss().to(device) optimizer = optim.Adam( model.parameters() ) for epoch in range(epochs): for step, (x_train, y_train) in enumerate(train): x_train, y_train = x_train.to(device), y_train.to(device) dense_output = model(x_train) loss = loss_(dense_output, y_train) optimizer.zero_grad() # ä¸Šä¸€ä¸ªä¾‹å­æåˆ°è¿‡ï¼Œæ¢¯åº¦æ¸…é›¶ loss.backward() # åå‘ä¼ æ’­ï¼Œ å¹¶å°†æ¢¯åº¦ç´¯åŠ åˆ° optimizerä¸­ optimizer.step() # ç›¸å½“äºåšäº† w = w - lr * æ¢¯åº¦ print(loss.item()) # item() æ„æ€å°±æ˜¯ tensorè½¬numpy,TFä¸­çš„ APIæ˜¯ xx.numpy() sample_correct_numbers = 0 sample_total_numbers = 0 with torch.no_grad(): # æµ‹è¯•éƒ¨åˆ†ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œå› æ­¤å¯ä»¥åŒ…è£¹åœ¨ä¸Šä¸‹æ–‡ä¸­ã€‚ for x_test, y_test in test: x_test, y_test = x_test.to(device), y_test.to(device) # softmax çš„ y_predict ä¸ y_testçš„ one-hotåšäº¤å‰ç†µ y_predict = model(x_test).argmax(dim=1) sample_correct_numbers += torch.eq(y_predict, y_test).float().sum().item() sample_total_numbers += x_test.size(0) # æ¯æ‰¹æ ·æœ¬çš„æ€»æ•°åŠ åœ¨ä¸€èµ· acc = sample_correct_numbers / sample_total_numbers print(acc) main() æ¡ˆä¾‹3ï¼šCIFAR10+ResNet-18 ###ç»“æ„å›¾ä½“ç³»ï¼š ä¸Šè¿°ç»“æ„è¯´æ˜ï¼š 1conv + (2+2+2+2)*2 + 1 fc = 18å±‚ 1conv + (3+4+6+3)*2 + 1 fc = 34å±‚ 1conv + (3+4+6+3)*3 + 1 fc = 50å±‚ 1conv + (3+4+23+3)*3 + 1 fc = 101å±‚ 1conv + (3+8+36+3)*3 + 1 fc = 152å±‚ ä»£ç å®ç° æ¨¡å—å¯¼å…¥ import cv2 import torch from torch import nn, optim from torchvision import datasets, transforms from torch.utils.data import DataLoader import visdom import torch.nn.functional as F æ•°æ®å¯¼å…¥é¢„å¤„ç† data_preprocess = transforms.Compose([ transforms.Resize(32,32), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]) train_dataset = datasets.CIFAR10( '.', train=True, download=True, transform=data_preprocess, ) test_dataset = datasets.CIFAR10( '.', train=False, # Falseä»£è¡¨æµ‹è¯•é›† download=True, transform=data_preprocess, ) train = DataLoader( train_dataset, batch_size=16, shuffle=True, ) test = DataLoader( test_dataset, batch_size=16, shuffle=True, ) åŸºç¡€å—å®šä¹‰ï¼ˆBasicBlockï¼‰ï¼š class BasicBlock(nn.Module): &quot;&quot;&quot;å•ä¸ªæ®‹å·®å— 2ä¸ªå·ç§¯+2ä¸ªBN&quot;&quot;&quot; def init(self, input_channel, output_channel, stride=1): super().init() self.major = nn.Sequential( # ç¬¬ä¸€ä¸ªConvçš„æ­¥é•¿ä¸ºæŒ‡å®šæ­¥é•¿ï¼Œå…è®¸é™é‡‡æ ·ï¼Œå…è®¸è¾“å‡ºè¾“å‡ºé€šé“ä¸ä¸€è‡´ nn.Conv2d(input_channel,output_channel,kernel_size=3,stride=stride, padding=1), nn.BatchNorm2d(output_channel), nn.ReLU(inplace=True), # ç¬¬äºŒä¸ªConvçš„æ­¥é•¿ä¸ºå®šé•¿1ï¼Œ è¾“å…¥è¾“å‡ºé€šé“ä¸å˜ï¼ˆç¼“å†²è¾“å‡ºï¼‰ nn.Conv2d(output_channel, output_channel, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(output_channel), # ç¬¬äºŒä¸ªConvå°±ä¸ç”¨ReLUäº†ï¼Œ å› ä¸ºä¸€ä¼šéœ€è¦å’Œ xåŠ åœ¨ä¸€èµ·ï¼Œæœ€åæœ€ä¸€å±‚å¤§çš„Relu ) # è‹¥è¾“å…¥é€šé“==è¾“å‡ºé€šé“ï¼Œä¸”æ­¥é•¿ä¸º1ï¼Œæ„å‘³ç€å›¾ç‰‡æœªè¢«é™é‡‡æ ·ï¼Œåˆ™æ®‹å·®ç½‘ç»œè¯¾ç›´æ¥ä¸ºæ™®é€šç½‘ç»œ self.shortcut = nn.Sequential() # è‹¥è¾“å…¥è¾“å‡ºé€šé“ä¸åŒ¹é…ï¼Œè¿™æ—¶éœ€è¦å°†å›¾ç‰‡åšåŒæ ·çš„å˜æ¢ï¼Œæ‰èƒ½åŠ åœ¨ä¸€èµ·ã€‚ if input_channel != output_channel or stride != 1: self.shortcut = nn.Sequential( nn.Conv2d( input_channel, output_channel, kernel_size=(1,1), stride = stride ), nn.BatchNorm2d(output_channel) ) def forward(self, x): major_out = self.major(x) # ä¸»å¹²ç½‘ç»œçš„è¾“å‡º shotcut_out = self.shortcut(x) # æ®‹å·®ç½‘ç»œçš„è¾“å‡º # ä¸Šé¢è¿™ä¸¤ä¸ªç½‘ç»œæ˜¯å¹³è¡Œçš„å…³ç³»ï¼Œ å› ä¸º å®ƒä»¬çš„è¾“å‡ºä¸æ˜¯é“¾å¼çš„ï¼Œ è€Œæ˜¯ éƒ½æ˜¯åŒæ ·çš„ xã€‚ # æ‹¼æ¥ä¸»å¹²ç½‘ç»œ+æ®‹å·®ç½‘ç»œï¼ŒF ç›¸å½“äºTF20çš„ tf.nn é‡Œé¢å•ç‹¬æœ‰å„ç§ losså‡½æ•° return F.relu(major_out + shotcut_out) # æœ€ååœ¨æ‹¼æ¥åçš„ç½‘ç»œå¤–é¢åŠ ä¸€å±‚relu ResNet+ResBlockå®šä¹‰ï¼š class ResNet(nn.Module): def init(self, layers): # layersç”¨æ¥æ¥å—ï¼Œç”¨æˆ·æƒ³è¦æŒ‡å®š ResNetçš„å½¢çŠ¶ super().init() self.conv1 = nn.Sequential( nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True), ) self.res_net = nn.Sequential( *self.ResBlock(32,64, layers[0],stride=2), # 16 *self.ResBlock(64,128, layers[1],stride=2), # 8 *self.ResBlock(128,256, layers[2],stride=2), # 4 *self.ResBlock(256,512, layers[3],stride=2), # 2 ) # å› ä¸ºæˆ‘ä»¬ä¸€ä¼šéœ€è¦å±•å¹³ï¼Œé‡Œé¢å¡«&quot;é€šé“*å®½åº¦*é«˜åº¦&quot;, &quot;è¾“å‡ºé€šé“&quot; self.dense = nn.Linear(512 * 2 * 2, 10) def forward(self, x): out = self.conv1(x) out = self.res_net(out) out = out.view(x.size(0), -1)# å·ç§¯å±•å¹³æ“ä½œ ï¼Œ torchä¸­æ²¡æœ‰flattenæ‰€ä»¥æˆ‘ä»¬å°±å¾—æ‰‹å·¥ out = self.dense(out) return out def ResBlock(self, input_channel, output_channel, block_nums=2, stride=2): # è‡ªå®šä¹‰è§„å®šï¼Œç¬¬ä¸€ä¸ªblockç¼©å°çš„(å¯¹åº”é€šé“ç¿»å€)ï¼Œå…¶ä½™blockå¤§å°ä¸å˜ # é€šé“ç¿»å€ï¼Œæ­¥é•¿*2ï¼Œç‰¹å¾å‡åŠ all_block = [BasicBlock(input_channel, output_channel,stride=stride)] for x in range(1,block_nums): all_block.append(BasicBlock(output_channel, output_channel,stride=1)) return all_block # resnet = ResNet(layers=[2,2,2,2]) # out = resnet(torch.randn(4,3,32,32)) # print(out.shape) æ¨¡å‹è®­ç»ƒï¼š def main(): vis = visdom.Visdom() epochs = 5 device = torch.device('cuda') model = ResNet(layers=[2,2,2,2]).to(device) # ä¼šè‡ªåŠ¨æŠŠä¸‹é¢çš„ dense_output ï¼Œä¹Ÿå°±æ˜¯y_predict åŠ ä¸€å±‚ softmaxï¼Œy_trueåšone-hot loss_ = nn.CrossEntropyLoss().to(device) optimizer = optim.Adam( model.parameters(), lr=0.0001) for epoch in range(epochs): total_loss = 0.0 for step, (x_train, y_train) in enumerate(train): x_train, y_train = x_train.to(device), y_train.to(device) dense_output = model(x_train) loss = loss_(dense_output, y_train) optimizer.zero_grad() # ä¸Šä¸€ä¸ªä¾‹å­æåˆ°è¿‡ï¼Œæ¢¯åº¦æ¸…é›¶ loss.backward() # åå‘ä¼ æ’­ï¼Œ å¹¶å°†æ¢¯åº¦ç´¯åŠ åˆ° optimizerä¸­ optimizer.step() # ç›¸å½“äºåšäº† w = w - lr * æ¢¯åº¦ total_loss += loss.item() # item()å°±æ˜¯ tensorè½¬numpy, TFä¸­çš„ APIæ˜¯ xx.numpy() if step % 50 == 49: print('epoch:',epoch, 'loss:', total_loss / step) sample_correct_numbers = 0 sample_total_numbers = 0 with torch.no_grad(): # æµ‹è¯•éƒ¨åˆ†ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œå› æ­¤å¯ä»¥åŒ…è£¹åœ¨ä¸Šä¸‹æ–‡ä¸­ã€‚ for x_test, y_test in test: x_test, y_test = x_test.to(device), y_test.to(device) # softmax çš„ y_predict ä¸ y_testçš„ one-hotåšäº¤å‰ç†µ y_predict = model(x_test).argmax(dim=1) sample_correct_numbers += torch.eq(y_predict, y_test).float().sum().item() sample_total_numbers += x_test.size(0) # æ¯æ‰¹æ ·æœ¬çš„æ€»æ•°åŠ åœ¨ä¸€èµ· acc = sample_correct_numbers / sample_total_numbers print(acc) torch.save(model, 'model.pkl') # ä¿å­˜æ•´ä¸ªæ¨¡å‹ main() æµ‹è¯•æ•°æ®é¢„å¤„ç†(æˆ‘éšä¾¿åœ¨ç½‘ä¸Šä¸‹è½½ä¸‹æ¥çš„ 1 å¼ å›¾ç‰‡)ï¼š # è¿™æ˜¯Cifar-10æ•°æ®çš„æ ‡å‡†æ ‡ç­¾ label = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'] plane = cv2.imread('plane.jpg') # æˆ‘ç”¨çš„opencv plane = cv2.cvtColor(plane, cv2.COLOR_BGR2RGB) # opencvè¯»çš„æ•°æ®æ ¼å¼æ˜¯BGRï¼Œæ‰€ä»¥è½¬ä¸ºRGB plane = (plane - 127.5) / 127.5 # äºŒè¯ä¸è¯´ï¼Œä¿æŒæ¨¡å‹è¾“å…¥æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå…ˆåšå½’ä¸€åŒ– plane = cv2.resize(plane, (32,32)) # å›¾ç‰‡ç¼©å°åˆ°32x32,å’Œæ¨¡å‹çš„è¾“å…¥ä¿æŒä¸€è‡´ plane = torch.Tensor(plane) # è½¬æ¢æˆ tensor plane = plane.view(1,32,32,3) # å¢åŠ ä¸€ä¸ªç»´åº¦ plane = plane.repeat(16,1,1,1) # æˆ‘å°±ç”¨ä¸€å¼ å›¾ç‰‡ï¼Œä¸ºäº†æ»¡è¶³æ¨¡å‹çš„å½¢çŠ¶16ï¼Œæˆ‘å¤åˆ¶äº†16æ¬¡ plane = plane.permute([0,3,1,2]) # è™½ç„¶torchä¹Ÿæœ‰ åƒTFé‚£æ ·çš„transposeï¼Œä½†æ˜¯åªèƒ½æ“ä½œ2D device = torch.device('cuda') # å…ˆå®šä¹‰ä¸€ä¸ªcudaè®¾å¤‡å¯¹è±¡ plane = plane.to(device) # æˆ‘ä»¬è®­ç»ƒé›†ç”¨çš„cudaï¼Œ æ‰€ä»¥é¢„æµ‹æ•°æ®ä¹Ÿè¦è½¬ä¸ºcuda æ­£å¼è¾“å…¥æ¨¡å‹é¢„æµ‹ï¼š model = torch.load('model.pkl') # è¯»å–å‡º æˆ‘ä»¬è®­ç»ƒåˆ°æœ€åæ•´ä¸ªæ¨¡å‹ # è¯´æ˜ä¸€ä¸‹ï¼Œå¦‚æœä½ çš„é¢„æµ‹æ˜¯å¦ä¸€ä¸ªè„šæœ¬ä¸­ï¼Œclass ResNet çš„ä»£ç å®šä¹‰éƒ¨åˆ†ä¹Ÿè¦å¤åˆ¶è¿‡æ¥ out = model(plane) # é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ä¸º[16,10] 16ä¸ªæ ·æœ¬ï¼Œ10ä¸ªé¢„æµ‹æ¦‚ç‡ï¼Œ label_indexes = out.argmax(dim=1) # å–10ä¸ªæ¦‚ç‡æœ€å¤§å€¼çš„ç´¢å¼•ã€‚ ï¼ˆ1è½´ï¼‰ï¼Œå½¢çŠ¶ä¸º [16,1] print(label_indexes) for i in label_indexes: # iä¸ºæ¯ä¸ªæ ·æœ¬é¢„æµ‹çš„æœ€å¤§æ¦‚ç‡å€¼ çš„ ç´¢å¼•ä½ç½®ã€‚ print(label[i]) # æ‹¿ç€é¢„æµ‹æ ‡ç­¾çš„ç´¢å¼• å» çœŸå®æ ‡ç­¾ä¸­æ‰¾åˆ°çœŸå®æ ‡ç­¾ ","link":"https://cythonlin.github.io/post/ai-greater-pytorch-yu-tersorflow20-jian-dan-dui-bi/"},{"title":"AI => Tensorflow2.0è¯­æ³• - keras_APIçš„ä½¿ç”¨(ä¸‰)","content":"å‰è¨€ kerasæ¥å£å¤§éƒ½å®ç°äº† _call_ æ–¹æ³•ã€‚ æ¯ç±» _call_ è°ƒç”¨äº† call()ã€‚ å› æ­¤ä¸‹é¢è¯´çš„å‡ ä¹æ‰€æœ‰æ¨¡å‹/ç½‘ç»œå±‚ éƒ½å¯ä»¥åœ¨å®šä¹‰åï¼Œç›´æ¥åƒå‡½æ•°ä¸€æ ·è°ƒç”¨ã€‚ eg: æ¨¡å‹å¯¹è±¡(å‚æ•°) ç½‘ç»œå±‚å¯¹è±¡(å‚æ•°) æˆ‘ä»¬è¿˜å¯ä»¥å®ç°ç»§æ‰¿æ¨¡æ¿ å¯¼å…¥ from tensorflow import keras metrics (ç»Ÿè®¡å¹³å‡) é‡Œé¢æœ‰å„ç§åº¦é‡å€¼çš„æ¥å£ å¦‚ï¼šäºŒåˆ†ç±»ã€å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±å®¹å™¨ï¼ŒMSEã€MAEçš„æŸå¤±å€¼å®¹å™¨ï¼Œ Accuracyç²¾ç¡®ç‡å®¹å™¨ç­‰ã€‚ ä¸‹é¢ä»¥Accuracyä¼ªç ä¸ºä¾‹ï¼š acc_meter = keras.metrics.Accuracy() # å»ºç«‹ä¸€ä¸ªå®¹å™¨ for _ in epoches: for _ in batches: y = ... y_predict = ... acc_meter.update_state(y, y_predict) # æ¯æ¬¡æ‰”è¿›å»æ•°æ®ï¼Œå®¹å™¨éƒ½ä¼šè‡ªåŠ¨è®¡ç®—accuracyï¼Œå¹¶å‚¨å­˜ if times % 100 == 0: # ä¸€ç™¾æ¬¡ä¸€è¾“å‡º, è®¾ç½®ä¸€ä¸ªé˜ˆå€¼/é˜€é—¨ print(acc_meter.result().numpy()) # å–å‡ºå®¹å™¨å†…æ‰€æœ‰å‚¨å­˜çš„æ•°æ®çš„ï¼Œå‡å€¼å‡†ç¡®ç‡ acc_meterã€‚reset_states() # å®¹å™¨ç¼“å­˜æ¸…ç©ºï¼Œ ä¸‹ä¸€epochä»å¤´è®¡æ•°ã€‚ æ¿€æ´»å‡½æ•°+æŸå¤±å‡½æ•°+ä¼˜åŒ–å™¨ å¯¼å…¥æ–¹å¼ï¼š keras.activations.relu() # æ¿€æ´»å‡½æ•°ï¼šä»¥reluä¸ºä¾‹ï¼Œè¿˜æœ‰å¾ˆå¤š keras.losses.categorical_crossentropy() # æŸå¤±å‡½æ•°ï¼šä»¥äº¤å‰ç†µä¸ºä¾‹ï¼Œè¿˜æœ‰å¾ˆå¤š keras.optimizers.SGD() # ä¼˜åŒ–å™¨ï¼šä»¥éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ä¸ºä¾‹ keras.callbacks.EarlyStopping() # å›è°ƒå‡½æ•°ï¼š ä»¥â€˜æŒ‰æŒ‡å®šæ¡ä»¶æå‰æš‚åœè®­ç»ƒâ€™å›è°ƒä¸ºä¾‹ Sequential(ç»§æ‰¿è‡ªModel)å±äºæ¨¡å‹ æ¨¡å‹å®šä¹‰æ–¹å¼ å®šä¹‰æ–¹å¼1ï¼š model = keras.models.Sequential( [é¦–å±‚ç½‘ç»œ,ç¬¬äºŒå±‚ç½‘ç»œã€‚ã€‚ã€‚] ) å®šä¹‰æ–¹å¼1ï¼š model = keras.models.Sequential() model.add(é¦–å±‚ç½‘ç»œ) model.add(ç¬¬äºŒå±‚ç½‘ç»œ) æ¨¡å‹ç›¸å…³å›è°ƒé…ç½® logdir = 'callbacks' if not os.path.exists(logdir): os.mkdir(logdir) save_model_file = os.path.join(logdir, 'mymodel.h5') callbacks = [ keras.callbacks.TensorBoard(logdir), # å†™å…¥tensorboard keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=True), # æ¨¡å‹ä¿å­˜ keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3) # æŒ‰æ¡ä»¶ç»ˆæ­¢æ¨¡å‹è®­ç»ƒ # éªŒè¯é›†ï¼Œæ¯æ¬¡éƒ½ä¼šæå‡ï¼Œå¦‚æœæå‡ä¸åŠ¨äº†ï¼Œæå‡å°äºè¿™ä¸ªmin_deltaé˜ˆå€¼ï¼Œåˆ™ä¼šè€å¿ƒç­‰å¾…5æ¬¡ã€‚ # 5æ¬¡è¿‡åï¼Œè¦æ˜¯è¿˜æå‡è¿™ä¹ˆç‚¹ã€‚å°±æå‰ç»“æŸã€‚ ] # ä»£ç å†™åœ¨è¿™é‡Œï¼Œå¦‚ä½•ä¼ é€’è°ƒç”¨ï¼Œ ä¸‹é¢ â€œæ¨¡å‹ç›¸å…³é‡åº¦é…ç½®â€ ä¼šæåˆ° æ¨¡å‹ç›¸å…³é‡åº¦é…ç½®ï¼š(ï¼ˆæŸå¤±ï¼Œä¼˜åŒ–å™¨ï¼Œå‡†ç¡®ç‡ç­‰) è¯´æ˜ï¼Œä¸‹é¢çš„å„ç§é‡åº¦å±æ€§ï¼Œå¯é€šè¿‡å­—ç¬¦ä¸²æ–¹å¼ï¼Œä¹Ÿå¯é€šè¿‡ä¸Šé¢è®²çš„å¯¼å…¥å®ä¾‹åŒ–å¯¹è±¡æ–¹å¼ã€‚ model.compile( loss=&quot;sparse_categorical_crossentropy&quot;, # æŸå¤±å‡½æ•°ï¼Œè¿™æ˜¯å­—ç¬¦ä¸²æ–¹å¼ optimizer= keras.optimizers.SGD() # è¿™æ˜¯å®ä¾‹åŒ–å¯¹è±¡çš„æ–¹å¼ï¼Œè¿™ç§æ–¹å¼å¯ä»¥ä¼ å‚ metrics=['accuracy'] # è¿™é¡¹ä¼šåœ¨fit()æ—¶æ‰“å°å‡ºæ¥ ) # compile() æ“ä½œï¼Œæ²¡æœ‰çœŸæ­£çš„è®­ç»ƒã€‚ model.fit( x,y, epochs=10, # åå¤è®­ç»ƒ 10 è½® validation_data = (x_valid,y_valid), # æŠŠåˆ’åˆ†å¥½çš„éªŒè¯é›†æ”¾è¿›æ¥ï¼ˆfitæ—¶æ‰“å°losså’Œvalï¼‰ validation_freq = 5, # è®­ç»ƒ5æ¬¡ï¼ŒéªŒè¯ä¸€æ¬¡ã€‚ å¯ä¸ä¼ ï¼Œé»˜è®¤ä¸º1ã€‚ callbacks=callbacks, # æŒ‡å®šå›è°ƒå‡½æ•°ï¼Œ è¯·è¡”æ¥ä¸Šé¢â€˜æ¨¡å‹ç›¸å…³å›è°ƒé…ç½®â€™ ) # fit()æ‰æ˜¯çœŸæ­£çš„è®­ç»ƒ æ¨¡å‹ éªŒè¯&amp;æµ‹è¯• ä¸€èˆ¬æˆ‘ä»¬ä¼šæŠŠ æ•°æ®å…ˆåˆ†æˆä¸‰éƒ¨åˆ†ï¼ˆå¦‚æœç”¨ç›¸åŒçš„æ•°æ®ï¼Œèµ·ä¸åˆ°æµ‹è¯•å’ŒéªŒè¯æ•ˆæœï¼Œå‚è€ƒè€ƒè¯•ä½œå¼Šæ€æƒ³ï¼‰ï¼š è®­ç»ƒé›†: ï¼ˆå¤§æ‰¹é‡ï¼Œä¸»ä½“ï¼‰ æµ‹è¯•é›†: ï¼ˆæ¨¡å‹æ‰€æœ‰è®­ç»ƒç»“æŸåï¼Œ æ‰ç”¨åˆ°ï¼‰ éªŒè¯é›†: ï¼ˆè®­ç»ƒçš„è¿‡ç¨‹ç§å°±ç”¨åˆ°ï¼‰ è¯´æ˜1ï¼šï¼ˆå¦‚ä½•åˆ†ç¦»ï¼Ÿï¼‰ å®ƒä»¬çš„åˆ†ç¦»æ˜¯éœ€è¦ï¼ˆx,yï¼‰ç»„åˆåœ¨ä¸€èµ·çš„ï¼Œå¦‚æœæ‰‹åŠ¨å®ç°ï¼Œéœ€è¦éšæœºæ‰“æ•£ã€zipç­‰æ“ä½œã€‚ ä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ scikit-learnåº“ï¼Œçš„ train_test_split() æ–¹æ³•æ¥å®ç° ï¼ˆ2æ¬¡åˆ†éš”ï¼‰ å¯ä»¥ä½¿ç”¨ tf.split()æ¥æ‰‹åŠ¨å®ç° å…·ä½“åˆ†ç¦»æ¡ˆä¾‹ï¼šå‚è€ƒä¸Šä¸€ç¯‡æ–‡ç« ï¼š https://segmentfault.com/a/1190000020447666 è¯´æ˜2ï¼šï¼ˆä¸ºä»€ä¹ˆæˆ‘ä»¬æœ‰äº†æµ‹è¯•é›†ï¼Œè¿˜éœ€è¦éªŒè¯é›†ï¼Ÿï¼‰ æµ‹è¯•é›†æ˜¯ç”¨æ¥åœ¨æœ€ç»ˆï¼Œæ¨¡å‹è®­ç»ƒæˆå‹åï¼ˆå‚æ•°å›ºå®šï¼‰ï¼Œè¿›è¡Œæµ‹è¯•ï¼Œå¹¶ä¸”è¿”å›çš„æ˜¯é¢„æµ‹çš„ç»“æœå€¼ï¼ï¼ï¼ï¼ éªŒè¯é›†æ˜¯ä¼´éšç€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­è€ŒéªŒè¯ï¼‰ ä»£ç å¦‚ä¸‹ï¼š loss, accuracy = model.evaluate( (x_test, y_test) ) # åº¦é‡ï¼Œ æ³¨æ„ï¼Œè¿”å›çš„æ˜¯ç²¾åº¦æŒ‡æ ‡ç­‰ target = model.predict( (x_test, y_test) ) # æµ‹è¯•ï¼Œ æ³¨æ„ï¼Œè¿”å›çš„æ˜¯ é¢„æµ‹çš„ç»“æœï¼ å¯ç”¨å‚æ•° model.trainable_variables # è¿”å›æ¨¡å‹ä¸­æ‰€æœ‰å¯è®­ç»ƒçš„å˜é‡ # ä½¿ç”¨åœºæ™¯ï¼š å°±åƒæˆ‘ä»¬ä¹‹å‰è¯´è¿‡çš„ gradient ä¸­ç”¨åˆ°çš„ zip(æ±‚å¯¼ç»“æœ, model.trainable_variables) è‡ªå®šä¹‰Model Modelç›¸å½“äºæ¯ç‰ˆï¼Œ ä½ ç»§æ‰¿äº†å®ƒï¼Œå¹¶å®ç°å¯¹åº”æ–¹æ³•ï¼ŒåŒæ ·ä¹Ÿèƒ½ç®€ä¾¿å®ç°æ¨¡å‹çš„å®šä¹‰ã€‚ è‡ªå®šä¹‰Layer åŒModelï¼Œ Layerä¹Ÿç›¸å½“äºæ¯ç‰ˆï¼Œ ä½ ç»§æ‰¿äº†å®ƒï¼Œå¹¶å®ç°å¯¹åº”æ–¹æ³•ï¼ŒåŒæ ·ä¹Ÿèƒ½ç®€ä¾¿å®ç°ç½‘ç»œå±‚çš„å®šä¹‰ã€‚ æ¨¡å‹ä¿å­˜ä¸åŠ è½½ ###æ–¹æ³•1ï¼šä¹‹å‰callbackè¯´çš„ ###æ–¹æ³•2ï¼šåªä¿å­˜weight(æ¨¡å‹ä¸å®Œå…¨ä¸€è‡´) ä¿å­˜ï¼š model = keras.Sequential([...]) ... model.fit() model.save_weights('weights.ckpt') åŠ è½½ï¼š å‡å¦‚åœ¨å¦ä¸€ä¸ªæ–‡ä»¶ä¸­ã€‚ï¼ˆå½“ç„¶è¦æŠŠä¿å­˜çš„æƒé‡è¦å¤åˆ¶åˆ°æœ¬åœ°ç›®å½•ï¼‰ model = keras.Sequential([...]) # æ­¤æ¨¡å‹æ„å»ºå¿…é¡»å’Œä¿å­˜æ—¶å€™å®šä¹‰ç»“æ„çš„ä¸€æ¨¡ä¸€æ ·çš„ï¼ model.load_weights('weights.ckpt') model.evaluate(...) model.predict(...) ###æ–¹æ³•3ï¼šä¿å­˜æ•´ä¸ªæ¨¡å‹ï¼ˆæ¨¡å‹å®Œå…¨ä¸€è‡´ï¼‰ ä¿å­˜ï¼š model = keras.Sequential([...]) ... model.fit() model.save('model.h5') # æ³¨æ„ è¿™é‡Œå˜äº†ï¼Œæ˜¯ save åŠ è½½:ï¼ˆç›´æ¥åŠ è½½å³å¯ï¼Œä¸éœ€è¦é‡æ–°å¤åŸå»ºæ¨¡è¿‡ç¨‹ï¼‰ å‡å¦‚åœ¨å¦ä¸€ä¸ªæ–‡ä»¶ä¸­ã€‚ï¼ˆå½“ç„¶è¦æŠŠä¿å­˜çš„æ¨¡å‹è¦å¤åˆ¶åˆ°æœ¬åœ°ç›®å½•ï¼‰ model = keras.models.load_model('model.h5') # load_modelæ˜¯åœ¨ keras.modelsä¸‹ model.evaluate(...) model.predict(...) ###æ–¹æ³•4ï¼šå¯¼å‡ºå¯ä¾›å…¶ä»–è¯­è¨€ä½¿ç”¨ï¼ˆå·¥ä¸šåŒ–ï¼‰ ä¿å­˜ï¼š ï¼ˆä½¿ç”¨tf.saved_modelæ¨¡å—ï¼‰ model = keras.Sequential([...]) ... model.fit() tf.saved_model.save(model, 'ç›®å½•') åŠ è½½ï¼šï¼ˆä½¿ç”¨tf.saved_modelæ¨¡å—ï¼‰ model = tf.saved_model.load('ç›®å½•') ","link":"https://cythonlin.github.io/post/ai-greater-tensorflow20-yu-fa-keras_api-de-shi-yong-san/"},{"title":"AI => çŸ¥è¯†å›¾è°±ä¹‹Neo4j-Cypher","content":"CRUD åˆ›å»º æ™®é€šæ— å±æ€§åˆ›å»ºï¼ˆé»˜è®¤ç»™ä½ åˆ›å»ºä¸€ä¸ªIDï¼‰ create (p:person)-[:eat]-&gt;(f:food) å¸¦æœ‰å±æ€§çš„åˆ›å»ºï¼ˆ {} ï¼‰ create (p:person{name:'zhangsan'})-[:eat]-&gt;(f:food{name:'apple'}) ç»™ä¸¤ä¸ªå­¤ç‹¬çš„å®ä½“åˆ›å»ºå…³ç³»ï¼š match (a:animal),(c:color) create ï¼ˆå¦‚æœè¿™é‡Œæ”¹ä¸º merge åˆ™æ˜¯ â€œæœ‰åˆ™æŸ¥è¯¢ï¼Œæ— åˆ™åˆ›å»ºâ€ï¼‰ (a)-[h:have]-&gt;(c) return h å¯¹åº”æŸ¥è¯¢ï¼š match (a:animal),(c:color) return a,c åˆ é™¤ (delete) match (a:animal)-[h:have]-&gt;(c:color) delete a,h,c æ›´æ–°ä¿®æ”¹ï¼ˆsetï¼‰ match (f:food) set f.age=20 æŸ¥è¯¢ ä¸»ä½“æŸ¥è¯¢ç»“æ„ match (p:)-[:å…³ç³»å]-[åˆ«å2:å®ä½“å] return åˆ«å1,åˆ«å2 æ™®é€šæ¡ä»¶æŸ¥è¯¢1ï¼ˆwhreeï¼‰ match (n:User) where n.name='Tom' return n æ™®é€šæ¡ä»¶æŸ¥è¯¢2ï¼šï¼ˆ {} ï¼‰ match (p:person{name:'zhangsan'})-[:eat{level:1}]-&gt;(f:food{name:'apple'}) return p,f æ­£åˆ™æ¡ä»¶æŸ¥è¯¢(~) match (n:User) where n.name=~'T.*' return n åŒ…å«æ¡ä»¶æŸ¥è¯¢ï¼ˆcontainsï¼‰ match (n:User) where n.name contains 'T' return n å¤šåº¦æŸ¥è¯¢ match (t:teacher)-[]-(s:student)-[]-(ss:score) return t,s,ss # æ³¨æ„1ï¼š [] é‡Œé¢ä¸å†™ï¼Œä»£è¡¨æ‰€æœ‰å…³ç³» # æ³¨æ„2ï¼š - æ²¡æœ‰ç®­å¤´ï¼Œä»£è¡¨ä»»æ„æ–¹å‘ # æ³¨æ„3ï¼š åˆ«åä¸å¯ä»¥é‡å¤æŒ‡å®šï¼Œ æ‰€ä»¥æˆ‘è®¾ç½®äº† ss å¤šåº¦å…³ç³»ï¼š ï¼ˆé€šå¸¸æ˜¯åŸºäºäººè„‰æ¥è®²çš„ï¼‰ 1åº¦å…³ç³»ï¼šæˆ‘ -&gt; ä½  2åº¦å…³ç³»ï¼šæˆ‘ -&gt; ä½  -&gt; ä»– ç†è§£æŠ€å·§ï¼š ç®—å‡ åº¦å…³ç³»æ—¶ï¼ŒæŠŠè‡ªå·±ï¼ˆèŠ‚ç‚¹ï¼‰æ‚ä½ä¸çœ‹ï¼Œ ç„¶åå‰©ä¸‹å‡ ä¸ªäººå‘˜èŠ‚ç‚¹ï¼Œå°±æ˜¯å‡ åº¦å…³ç³» ç‰¹åˆ«æ³¨æ„ï¼š å¤šåº¦æŸ¥å…³ç³»æ—¶ï¼Œæ¯”å¦‚ä½ æŸ¥ 3åº¦å…³ç³»çš„ç»“æœã€‚ neo4jçš„å›¾å¯èƒ½ä¼šæŠŠï¼Œ 2åº¦å…³ç³»ä¹Ÿç”»å‡ºæ¥ï¼Œwhy? å› ä¸ºä»–é€šè¿‡2åº¦å…³ç³»ä¹Ÿå¯ç›´æ¥å¾—å‡ºç»“æœã€‚ ï¼ˆå¯ç†è§£ä¸º æ¡æ¡å¤§è·¯é€šç½—é©¬ã€‚ï¼‰ ï¼ï¼ï¼ä½†æ˜¯æœ€ç»ˆæœ‰æ•ˆçš„è¿”å›è·¯å¾„åªæ˜¯ä½ æœ€åˆæƒ³è¦çš„ 3åº¦ã€‚ ï¼ˆ2åº¦å°±ä¸ç®—äº†ï¼‰ æŸ¥è¯¢æœ€çŸ­è·¯å¾„ï¼š match (t:teacher), (s:student), p=shortestpath( (t)-[*..]-(s) ) return p # æ³¨æ„ï¼š p= ä¹‹å‰æœ‰ä¸ªé€—å· ï¼Œ æŸ¥è¯¢æ‰€æœ‰æœ€çŸ­è·¯å¾„ï¼š match (t:teacher), (s:student), p=allshortestpaths( (t)-[*..]-(s) ) return p # æ³¨æ„1ï¼š å‰é¢å¤šä¸ª all ï¼Œåé¢å¤šä¸ªs # æ³¨æ„2ï¼š æ‰€æœ‰æœ€çŸ­è·¯å¾„çš„éƒ½ä¼šåˆ—å‡ºæ¥ã€‚ äººäººå¹³ç­‰~ ç´¢å¼• åˆ›å»ºç´¢å¼• (create) create index on :food(name) # foodä¸ºå®ä½“åï¼Œnameä¸ºå±æ€§åï¼Œ åŒæ—¶æ³¨æ„è¿™ä¸ª : åˆ é™¤ç´¢å¼•ï¼ˆdropï¼‰ drop index on :food(name) çº¦æŸ åˆ›å»ºçº¦æŸ create constraint on (gf:girlfriend) assert (gf.name) is unique åˆ é™¤çº¦æŸ create constraint on (o:others) assert (o.name) is unique èšåˆ ç»Ÿè®¡ä¸ªæ•°ï¼ˆcountï¼‰ match ... return count(åˆ«å) é™åˆ¶å–å¤šå°‘æ¡ ï¼ˆlimitï¼‰ match ... return åˆ«å limit 5 # åªå–5æ¡ çŸ¥è¯†å›¾è°±æµç¨‹ æ•°æ®æŠ“å– çŸ¥è¯†æ¨¡å‹è®¾è®¡ NER ï¼ˆè¿œç¨‹ç›‘ç£ï¼‰ å…³ç³»æŠ½å–ï¼ˆBootstrapï¼‰ çŸ¥è¯†æ¨ç† å›¾è°±å­˜å‚¨ï¼ˆNeo4j Cypherï¼‰ æ£€ç´¢/é—®ç­”/æ¨è å®ä½“æŠ½å– BILSTM+CRF å…³ç³»æŠ½å– Bootstrapæ–¹æ³•ï¼š 1. æ„å»ºç§å­å®ä½“ï¼š &quot;çŒ«&quot;ï¼Œ &quot;è€é¼ &quot;ã€‚ 2. å¯»æ‰¾åŒ…å« &quot;çŒ«&quot; &quot;è€é¼ &quot; çš„ å¥å­ï¼š æ‰¾åˆ°å¥å­ï¼š&quot;çŒ«å’Œè€é¼ æ˜¯å¥½æœ‹å‹&quot; å¯æŠ½å–å…³ç³»: å’Œ...æ˜¯å¥½æœ‹å‹ 3. æ‹¿ç€æŠ½å–çš„å…³ç³»å†æ¬¡å¯»æ‰¾æ–°å¥å­ï¼š æ‰¾åˆ°æ–°å¥å­ï¼š&quot;å¼ ä¸‰å’Œé‡Œæå››æ˜¯å¥½æœ‹å‹&quot; æå–å‡ºæ–°å®ä½“: &quot;å¼ ä¸‰&quot;, &quot;æå››&quot; 4. å¯»æ‰¾åŒ…å« &quot;å¼ ä¸‰&quot; &quot;æå››&quot; çš„ å¥å­ï¼š æ‰¾åˆ°å¥å­ï¼š&quot;å¼ ä¸‰ç»å¸¸å’Œæå››ä¸€èµ·ç©&quot; å¯æŠ½å–å…³ç³»: ç»å¸¸å’Œ... ä¸€èµ·ç© 5. æ‹¿ç€æŠ½å–çš„å…³ç³»å†æ¬¡å¯»æ‰¾æ–°å¥å­ï¼š æ‰¾åˆ°æ–°å¥å­ï¼š&quot;ç‹äº”å’Œèµµå…­æ˜¯å¥½æœ‹å‹&quot; æå–å‡ºæ–°å®ä½“: &quot;ç‹äº”&quot;, &quot;èµµå…­&quot; ... ... å¾ªç¯åå¤ ","link":"https://cythonlin.github.io/post/ai-greater-zhi-shi-tu-pu-zhi-neo4j-cypher/"},{"title":"AI => NERä¹‹BIOè½¬BIOES","content":"BIO B: å‘½åå®ä½“çš„èµ·å§‹ æˆ– å•ä¸ªå­—å‘½åå®ä½“ I: å‘½åå®ä½“çš„ä¸­é—´ä½ç½® æˆ– ç»“æŸä½ç½® Oï¼šéå‘½åå®ä½“ BIOES B: å‘½åå®ä½“çš„èµ·å§‹æ ‡æ³¨ï¼ˆOnlyå“¦ï¼‰ I: å‘½åå®ä½“çš„ä¸­é—´æ ‡æ³¨ï¼ˆOnlyå“¦ï¼‰ E: å‘½åå®ä½“çš„ç»“å°¾æ ‡æ³¨ï¼ˆOnlyå“¦ï¼‰ O: éå‘½åå®ä½“ S: å•ä¸ªå­—å‘½åå®ä½“ BIOè½¬BIOESè§„åˆ™ ä¸ªäººä»£ç å®ç° ä¼ é€é—¨ï¼šhttps://github.com/hacker-lin/bio2bioes/ ","link":"https://cythonlin.github.io/post/ai-greater-ner-zhi-bio-zhuan-bioes/"},{"title":"AI => å®‰è£…neo4j (Linux)","content":"ä¾èµ–java,å…ˆè£…java å®˜ç½‘ï¼šhttps://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html æ‰¾åˆ°ï¼š jdk-8u231-linux-x64.tar.gz ä¸‹è½½ï¼ˆå¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œè¿˜éœ€è¦æ³¨å†Œï¼‰ ä¸ªäººç½‘ç›˜åˆ†äº«ï¼šhttps://pan.baidu.com/s/1EMFM_Y_HT3bHFwncKj2orw&amp;shfl=shareset æå–ç : w24a é€šè¿‡XFTPä¼ é€åˆ°æœåŠ¡å™¨ã€‚ ä»»æ„ç›®å½•ï¼ˆè‡ªå·±è®°ä½å³å¯ï¼‰ï¼š tar -zxvf jdk-8u231-linux-x64.tar.gz # è§£å‹å‡ºæ¥ä¸€ä¸ªç›®å½•ï¼Œè®°ä½æ‰¾ä¸ªåå­—ï¼Œå’Œå½“å‰è·¯å¾„ï¼Œä¸‹é¢ç”¨ # æˆ‘è¿™é‡Œæ˜¯ jdk1.8.0_181 ç›¸å…³é…ç½®: vi ~/.bashrc export JAVA_HOME=/root/kg/neo4j/java/jdk1.8.0_181/ export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH ä¿å­˜é€€å‡º æ¿€æ´»é…ç½®ï¼š source ~/.bashrc è‡³æ­¤ï¼Œjavaå®‰è£…å®Œæˆï¼ å®‰è£…Neo4j: ä¸‹è½½è¿æ¥ï¼šhttps://neo4j.com/download-center/ é€‰ä¸ªLinuxç‰ˆæœ¬çš„ï¼ˆéœ€è¦ä¸Šç½‘ï¼‰ï¼ˆè®°å¾—ä¸‹ç¤¾åŒºç‰ˆçš„ï¼‰ åŒæ ·ä¼ åˆ°Linuxè§£å‹å³å¯ã€‚ ä¸ªäººç½‘ç›˜åˆ†äº«ï¼šhttps://pan.baidu.com/s/1FnbZW0n2-w8yCZEXG3J6zw&amp;shfl=shareset æå–ç : 451c å› ä¸ºæˆ‘æ˜¯äº‘ç«¯è¿è¡Œã€‚æ‰€ä»¥éœ€è¦æ”¹ä¸‹é…ç½®ï¼Œæ”¯æŒè¿œç¨‹è®¿é—®ã€‚ è¿›å…¥è§£å‹åçš„ç›®å½•ï¼Œæˆ‘è¿™é‡Œæ˜¯ neo4j-community-3.5.11 cd neo4j-community-3.5.11 cd conf vi neo4j.conf æ·»åŠ å¦‚ä¸‹é…ç½®ï¼ˆæˆ–è€…ä½ èƒ½æ‰¾åˆ°è¿™è¡Œï¼Œç›´æ¥è§£é™¤æ³¨é‡Šä¹Ÿè¡Œï¼‰ï¼š dbms.connectors.default_listen_address=0.0.0.0 è‡³æ­¤ï¼Œneo4jå®‰è£…å®Œæˆã€‚ å¯åŠ¨neo4j: cd neo4j-community-3.5.11 cd bin ./neo4j console çœ‹å¯åŠ¨ä¿¡æ¯çš„url:portï¼Œ å¤åˆ¶å‡ºæ¥ç›´æ¥è®¿é—®å³å¯ã€‚ xxxxxxxx:7474 # è‹¥æ˜¯é˜¿é‡Œäº‘ï¼Œéœ€è¦æ”¾é€šé˜²ç«å¢™7474 å’Œ 7687 æˆåŠŸè¿›å»åï¼Œä¼šæç¤ºä½ è¾“å…¥é»˜è®¤ç”¨æˆ·å å’Œ å¯†ç ï¼š é»˜è®¤ç”¨æˆ·åä¸º ï¼šneo4j é»˜è®¤å¯†ç ä¹Ÿä¸º ï¼šneo4j å¯†ç å¿˜è®°äº†ï¼Ÿï¼Ÿ è¿›å…¥ xx/data/dbms åˆ é™¤ auth æ–‡ä»¶ï¼Œé‡å¯æœåŠ¡ ","link":"https://cythonlin.github.io/post/ai-greater-an-zhuang-neo4j-linux/"},{"title":"AI => CNNä¹‹kernel_size/strides/padding/same","content":"å‰è¨€ å…ˆå¼ºè°ƒä¸€ç‚¹ï¼š æ¶‰åŠåˆ°å‚æ•°ï¼Œéƒ½æ˜¯é’ˆå¯¹Tensorflowæ¥è®²çš„ã€‚ æœ¬æ–‡ä¸»è¦è¯´ä¸€äº›CNNæœ€å¸¸ç”¨çš„å‡ ä¸ªå‚æ•°ã€‚ ä»¥åŠå„ç§ç»„åˆæƒ…å†µä¸‹å·ç§¯ä¹‹åè®¡ç®—å½¢çŠ¶çš„è§„å¾‹å…¬å¼ã€‚ filters (å¿…å¡«ï¼Œ è¿™ä¸ªæœ¬æ–‡ä¸è¯´) kernel_size ï¼ˆå¿…å¡«ï¼‰ strides (é€‰å¡«ï¼Œ é»˜è®¤ä¸º (1,1) ) padding ï¼ˆé€‰å¡«ï¼Œé»˜è®¤ä¸º validï¼‰ è¿™é‡Œå…ˆæä¸€ä¸‹ï¼Œé€šç”¨å…¬å¼ï¼š (å®½é«˜éƒ½ç”¨è¿™ä¸ªå…¬å¼ï¼Œæˆ‘åªåˆ—å‡ºäº†é«˜åº¦çš„) hå›¾ç‰‡è¾“å‡º = ï¼ˆhå›¾ç‰‡è¾“å…¥ - hå·ç§¯æ ¸ + 2paddingï¼‰ / strides + 1 ä¹Ÿè®¸ä½ çœ‹èµ·æ¥æ²¡ä»€ä¹ˆé—®é¢˜ï¼Œä½†æ˜¯Tensorflowä¸­çš„APIå¯ä¸å‘Šè¯‰ä½ paddingæ˜¯å‡ ã€‚ è€Œæ˜¯æä¾›ç»™ä½ 2ä¸ªå¯é€‰å‚æ•°ï¼š padding='valid' (é»˜è®¤å‚æ•°) # ä»£è¡¨ä¸åšpaddingï¼Œæ»‘åŠ¨ä¸èƒ½è¶Šç•Œï¼Œå¤šä½™å°±è£å‰ªã€‚ padding='same' # sameæˆ‘ä¼šåœ¨ä¸‹é¢å±•å¼€è¯´æ˜ã€‚ æ— sameæƒ…å†µ strides = 1 ä½ å®Œå…¨å¯ä»¥æŒ‰ç…§ä¸Šé¢çš„é€šç”¨å…¬å¼è®¡ç®—ï¼Œä½†æ˜¯é€šå¸¸æƒ…å†µä¸‹æˆ‘ä¼šç”¨å¦ä¸€ä¸ªç®€ä¾¿çš„å…¬å¼ï¼š hå›¾ç‰‡è¾“å‡º = hå›¾ç‰‡è¾“å…¥ - hå·ç§¯æ ¸ + 1 strides != 1 è¿™ä¸ªå°±å¾—ä½¿ç”¨ä¸Šé¢çš„é€šç”¨å…¬å¼äº†ï¼š hå›¾ç‰‡è¾“å‡º = ï¼ˆhå›¾ç‰‡è¾“å…¥ - hå·ç§¯æ ¸ + 2paddingï¼‰ / strides + 1 æœ‰sameæƒ…å†µ åŠ äº†sameï¼Œæƒ…å†µå°±æ¯”è¾ƒå¤æ‚ä¸€äº›äº†ã€‚ same å°±æ˜¯ è®©ä½ åœ¨ä¸åŒçš„ stridesæ»‘åŠ¨æƒ…å†µä¸‹ï¼Œå¸®ä½ æŠŠåŸå›¾ç‰‡è™šæ‹Ÿè¡¥å…¨ã€‚ ä½¿å¾—filteråœ¨å›¾ç‰‡ä¸­å®Œå…¨æ»‘åŠ¨ï¼Œ(è€Œä¸è‡³äºï¼Œæœ€åå‰©ä¸‹ä¸€ç‚¹è¶Šç•Œæ»‘ä¸åˆ°ç»™æ— æƒ…çš„è£å‰ªæ‰)ã€‚ strides = 1ï¼ˆé‡ç‚¹ï¼‰ strides=1çš„æƒ…å†µä¸‹ï¼Œå¦‚æœä½ ä½¿ç”¨äº† sameã€‚ é‚£ä¹ˆsameä¼šå¸®ä½ è¡¥å…… padding, ä½¿å¾—ä½ æ»‘åŠ¨åçš„ç‰¹å¾å½¢çŠ¶ä¸æ»‘åŠ¨ä¹‹å‰çš„å½¢çŠ¶ &quot;ä¿æŒä¸€è‡´&quot;ã€‚ è¡¥å……çš„paddingå¤§å°ä¸º: (æ•²é»‘æ¿)ï¼š padding = hå›¾ç‰‡è¾“å…¥ % hå·ç§¯æ ¸ # çœ‹æ¸…æ¥šï¼Œæ˜¯å–æ¨¡è¿ç®— ä¸¾ä¸ªä¾‹å­ï¼ŒéªŒè¯ä¸€ä¸‹ï¼š å‡å¦‚: å›¾ç‰‡ï¼ˆè¾“å…¥ï¼‰ = 7 x 7, kernel_size = (5,5), strides = 1ã€‚ ï¼ˆé€šè¿‡æˆ‘ä»¬ä¸Šé¢ç»™å‡ºçš„å…¬å¼ï¼Œä½ å…ˆæ±‚ padding = 7 % 5ï¼‰ ï¼Œå¾ˆæ˜¾ç„¶æ˜¯2ã€‚ æˆ‘ä»¬å†ç”¨æœ€å¼€å§‹è®²çš„é€šç”¨å…¬å¼éªŒè¯ä¸€éï¼š hè¾“å‡ºé•¿åº¦ = (hè¾“å…¥ - hå·ç§¯æ ¸ + 2 * padding) / 1 + 1 = 7-5 + 2*2 + 1 = 7 å·§äº†ï¼Œæˆ‘ä»¬çš„è¾“å…¥é•¿åº¦ä¹Ÿæ˜¯ 7ã€‚ æ‰€ä»¥ç»¼ä¸Šæ‰€è¿°ï¼š padding = hå›¾ç‰‡è¾“å…¥ % hå·ç§¯æ ¸ã€‚ å¯ä»¥ä½¿å¾—ï¼šè¾“å…¥å½¢çŠ¶ ä¸å·ç§¯åçš„è¾“å‡ºå½¢çŠ¶ä¸€è‡´ strides != 1ï¼ˆé‡ç‚¹ï¼‰ å½“æ­¥é•¿stridesä¸ºå¤šæ­¥æ—¶ï¼Œå¦‚æœä½ ä½¿ç”¨äº† sameã€‚ æ•²é»‘æ¿ï¼šé‚£ä¹ˆsameä¼šå¸®ä½ è¡¥å…… padding, å¹¶ä¸”å·ç§¯åçš„ç‰¹å¾å›¾ç¼©å°ä¸ºåŸæ¥çš„ strideså€ã€‚ è¡¥å……çš„paddingå¤§å°ä¸º: (æ•²é»‘æ¿)ï¼š padding = hå›¾ç‰‡è¾“å…¥ % hå·ç§¯æ ¸ # çœ‹æ¸…æ¥šï¼Œæ˜¯å–æ¨¡è¿ç®— æˆ‘ä¸ºäº†æ¼”ç¤ºï¼Œ æˆ‘çªæ¥çµæ„Ÿï¼Œéšä¾¿æ‰¾äº†ä¸€ä¸ª äº”å­æ£‹æ£‹ç›˜ï¼ˆç¬‘äº†ï¼‰ï¼Œ è§ä¸‹å›¾ã€‚ å°æŠ€å·§ï¼ˆæœ‰æ— sameéƒ½é€‚ç”¨ï¼‰ å½“ä½ é¢„æœŸæƒ³è¦æŠŠç‰¹å¾å½¢çŠ¶å·ç§¯ä¹‹åå½¢çŠ¶å¤§å°&quot;æˆå€ç¼©å°&quot;æ—¶ï¼Œä½ å¯ä»¥ &quot;åŒæ—¶&quot; è®¾ç½®ï¼š kernel_size == strides == (n,n) # nå°±æ˜¯ç¼©å°çš„å€æ•° è¯´æ˜ï¼Œåªè¦ä½ æŠŠ kernel_size å’Œ strides è®¾ç½®ä¸ºç›¸ç­‰ï¼Œè®¾ç½®ä¸ºnã€‚é‚£ä¹ˆå›¾åƒä¸€å®šä¼šç¼©å°nå€ã€‚ ä¸¾ä¸ªæ —å­ï¼š nè®¾ä¸º3 kernel_size = (3,3) strides = (3,3) é‚£ä¹ˆ: ä½ å·ç§¯å‡ºæ¥çš„ç‰¹å¾å°ºå¯¸ï¼Œä¸€å®šæ¯”ä¸Šä¸€å±‚ç¼©å°3å€ã€‚ ç»“æŸè¯­ï¼ˆèŠä¸€ä¸‹Pooling2Dï¼‰ poolingçš„é€šç”¨å…¬å¼å’Œ CNNä¸­çš„æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚ Tensorflow ä¸­ xxxPooling APIå‚æ•°å¦‚ä¸‹ï¼š pool_size ï¼ˆé€‰å¡«ï¼Œé»˜è®¤ä¸º (2, 2) ï¼‰ strides ï¼ˆé€‰å¡«ï¼Œé»˜è®¤ä¸º Noneï¼‰ ï¼ˆè¿™é‡Œä½ ä¼šç–‘é—®ï¼ŒNoneæ˜¯ä»€ä¹ˆé¬¼ï¼Ÿï¼Ÿï¼Ÿï¼‰ æˆ‘ä¹Ÿä¸çŸ¥é“ï¼ŒAPIå‚æ•°ä¹Ÿæ²¡ç»™è¯´æ˜ã€‚å½“æˆ‘è·³è¿›æºç ï¼Œæˆ‘å‘ç°å¦‚ä¸‹ä»£ç ï¼Œç¬é—´è±ç„¶å¼€æœ—ï¼ if strides is None: strides = pool_size ï¼ˆè¿™åº”è¯¥å°±ä¸ç”¨æˆ‘è§£é‡Šäº†å§~ï¼‰ padding ï¼ˆé€‰å¡«ï¼Œé»˜è®¤ä¸º validï¼Œ é€šå¸¸æ²¡å¿…è¦ç”¨ same ï¼‰ æˆ‘ä»¬ä¸Šé¢è¯´è¿‡å°æŠ€å·§ï¼š å·ç§¯å±‚ä¸­ï¼š kernel_size == strides == (n,n) # nå°±æ˜¯ç¼©å°çš„å€æ•° æ± åŒ–å±‚ä¹ŸåŒç†ï¼š pool_size == strides == (n,n) # nå°±æ˜¯ç¼©å°çš„å€æ•° åˆå› ä¸ºåˆšæ‰åˆè¯´äº† ï¼Œ æ± åŒ–å±‚ä¸­ strides é»˜è®¤å€¼ç­‰äº pool_size çš„é•¿åº¦ã€‚ æ‰€ä»¥: æˆ‘ä»¬åªè®¾ç½®ä¸€ä¸ª pool_size = (n,n)ã€‚ å³å¯ç›´æ¥è®©åŸå›¾ç¼©å°nå€ã€‚ æ‰€ä»¥: æ± åŒ–å±‚é€šå¸¸ç”¨æ¥åšé™é‡‡æ ·ã€‚ (èµ·åˆ°å˜æ¢å½¢çŠ¶çš„ä½œç”¨ï¼Œæ— æƒé‡å‚æ•°æ›´æ–°) ","link":"https://cythonlin.github.io/post/ai-greater-cnn-zhi-kernel_sizestridespaddingsame/"},{"title":"AI => CNN-RNNï¼ˆNgï¼‰","content":"å‰è¨€ çœ‹Andrew Ngè§†é¢‘ï¼Œæ€»ç»“çš„å­¦ä¹ å¿ƒå¾—ã€‚ è™½ç„¶æœ¬ç¯‡æ–‡ç« å¯èƒ½ä¸æ˜¯é‚£ä¹ˆç»†è‡´å…¥å¾®ï¼Œç”šè‡³å¯èƒ½æœ‰äº†è§£åå·®ã€‚ ä½†æ˜¯ï¼Œæˆ‘å–œæ¬¢ç”¨æ›´ç›´ç™½çš„æ–¹å¼å»ç†è§£çŸ¥è¯†ã€‚ ä¸Šä¸€ç¯‡æ–‡ç« ä¼ é€é—¨ï¼š https://segmentfault.com/a/1190000020588580 ç«¯åˆ°ç«¯ é¦–å…ˆèŠä¸€ä¸ªé¢è¯•ç»å† æˆ‘æœ€å¼€å§‹æ¥è§¦çš„æ˜¯ML ï¼ˆä½†åªé™äºSklearnçš„ç®€å•åº”ç”¨ï¼Œå·¥ç¨‹åŒ–çš„å†…å®¹å½“æ—¶ä¸€ç‚¹éƒ½ä¸äº†è§£ã€‚ï¼‰ åæ¥æœ‰å¹¸äº†è§£åˆ°DL ï¼ˆè¿™ä¸ªäº†è§£æ¯”è¾ƒå¤šï¼‰ æˆ‘é¢çš„æ˜¯æ™®é€šPythonå²—ï¼Œ å› ä¸ºæˆ‘çš„å°é¡¹ç›®ä¸­æ¶‰åŠåˆ° ï¼ˆèŠå¤©æœºå™¨äººï¼‰ã€‚æ‰€ä»¥ç¬¬äºŒä¸ªé¢è¯•å®˜æªç€è¿™ä¸ªèŠäº†èŠã€‚ ä¸é¢è¯•å®˜äº¤è°ˆæ—¶ï¼Œæˆ‘ä¹Ÿç›´æ¥æŒ‘æ˜äº†ï¼Œæ¨¡å‹æ˜¯Githubæ‰¾çš„ï¼Œå½“æ—¶è‡ªå·±çˆ¬äº†äº›é—®ç­”å¯¹ï¼Œå¤„ç†åæ”¾å…¥æ¨¡å‹è‡ªå·±è®­ç»ƒçš„ã€‚ é¢è¯•å®˜ä¸€é¡¿(ç‰¹å¾æå–ï¼Œè¯­ä¹‰ï¼‰ç­‰å„ç§ ML-NLPå·¥ç¨‹åŒ–çš„è¿‡ç¨‹ï¼ŒæŠŠæˆ‘ç›´æ¥é—®æ‡µäº†ã€‚ã€‚ æ€ä¹ˆæå–ç‰¹å¾ï¼ˆé—®å·è„¸ï¼Œéš¾é“æ˜¯TF-IDFï¼Œåˆ†è¯ä¹‹ç±»çš„ï¼Ÿï¼Ÿï¼‰ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ æˆ‘ä¹Ÿä¸çŸ¥é“è¯´å•¥ï¼Œä»¥ä»…æœ‰çš„èƒ½åŠ›ï¼Œå’Œä»–èŠèŠï¼ˆLSTMã€Embedding, Seq2Seqçš„ Encoder-Vector-Decoderï¼‰ã€‚ã€‚ é¢è¯•å®˜è¯´ï¼šâ€œä½ è¯´äº†è¿™äº›ï¼Œ é‚£ä½ ç‰¹å¾å·¥ç¨‹æ˜¯æ€ä¹ˆåšçš„ï¼Ÿï¼Ÿï¼Ÿâ€ æˆ‘æ„Ÿè§‰å·²ç»æ²¡æœ‰ä»»ä½•åé©³çš„èƒ½åŠ›äº†ã€‚ã€‚ã€‚æ¥ä¸‹æ¥çš„äº‹æƒ…ï¼Œæˆ‘ä¸è¯´ï¼Œå¤§å®¶ä¹Ÿåº”è¯¥æ¸…æ¥šäº†ã€‚ åæ€ æˆ‘å›æ¥åä¹Ÿåæ€è¿‡ï¼Œ åšäº†ä»€ä¹ˆç‰¹å¾å·¥ç¨‹ï¼Ÿï¼Ÿ æˆ‘çœ‹è§†é¢‘ä¸­ ä¹Ÿæ˜¯ï¼Œæ•°æ®ç®€å•é¢„å¤„ç†ä¸‹ï¼Œç„¶ååˆ†è¯ï¼Œè¯é¢‘è¿‡æ»¤ï¼Œæ„å»ºè¯å…¸ ç„¶åï¼Œç›´æ¥å°±æ˜¯æ„å»ºNNå±‚ï¼ˆåŒ…æ‹¬Embeddingå±‚ï¼‰ã€‚ ç›´åˆ°æœ€åäº†è§£äº†&quot;ç«¯åˆ°ç«¯è¿™ä¸ªæ¦‚å¿µ&quot; ä¸ ä¼ ç»ŸMLçš„åŒºåˆ«ã€‚ æ‰æ¸…æ¥šï¼Œ å½“æ—¶é¢è¯•çš„åœºæ™¯æ˜¯æ€ä¹ˆä¸ªæƒ…å†µã€‚ã€‚ã€‚ æ­£å¼å¼€ç¯‡ç«¯åˆ°ç«¯ ä¼ ç»ŸMLï¼š åŸæ•°æ® -&gt; æ•°æ®ç‰¹å¾å·¥ç¨‹(å„ç§å¤æ‚çš„äººå·¥å¤„ç†) ---&gt; æ¨¡å‹ ç«¯åˆ°ç«¯DLï¼šåŸæ•°æ® -----------------------------------------------------&gt; æ¨¡å‹ ç«¯åˆ°ç«¯ï¼šï¼ˆä¸€æ­¥åˆ°ä½ï¼‰ï¼š ä¼ ç»Ÿçš„MLåšçš„ä¸­é—´å±‚äººå·¥&quot;æ‰‹åŠ¨&quot;ç‰¹å¾å·¥ç¨‹å¤„ç†å‡ºæ¥çš„ç‰¹å¾ã€‚ è¿™äº›ç‰¹å¾ï¼Œç«¯åˆ°ç«¯çš„NNéƒ½å¯èƒ½&quot;è‡ªåŠ¨å­¦ä¹ &quot;çš„åˆ°ã€‚ è¿™ä¹Ÿå¯èƒ½æ˜¯å½“æ—¶ä¸ºä»€ä¹ˆé¢è¯•å®˜ä¸€ç›´è¿½é—®æˆ‘&quot;ç‰¹å¾å¦‚ä½•å¤„ç†&quot;çš„åŸå› å§ã€‚ä¹Ÿè‚¯èƒ½ä»–å¦æœ‰ç›®çš„QAQ... æˆ–è€…æˆ‘ä»¬çœŸçš„ä¸åœ¨ä¸€ä¸ªé¢‘é“ä¸Šã€‚ã€‚ã€‚ä½†æ˜¯äº¤æµçš„è¿‡ç¨‹çœŸçš„ä½¿æˆ‘å—ç›ŠåŒªæµ…ï¼Œæœ‰äº†æ›´å¹¿é˜”çš„è§†é‡ï¼ˆ3Qï¼ï¼‰ å¼ºè°ƒä¸€ç‚¹ï¼š è™½ç„¶ç«¯åˆ°ç«¯ æ¨¡å‹å¾ˆä¾¿æ·ã€‚ä½†æ˜¯éœ€è¦å¤§é‡çš„æ•°æ®ï¼Œæ‰èƒ½è®­ç»ƒå‡ºå¥½çš„æ•ˆæœã€‚ CNN ï¼ˆå·ç§¯ç¥ç»ç½‘ç»œï¼‰ æ„æˆ å·ç§¯å±‚ï¼ˆæ¿€æ´»å‡½æ•°ï¼‰ + æ± åŒ–å±‚ + å…¨è¿æ¥å±‚ Convolution + Pooling + Dense è‡³äºä¸€äº›æœ¯è¯­: æœ‰äººå–œæ¬¢æŠŠ: å·ç§¯å±‚ + æ± åŒ–å±‚ ä½œä¸ºä¸€å±‚ç½‘ç»œ ï¼ˆå› ä¸ºæ± åŒ–å±‚æ— è®­ç»ƒè®­ç»ƒï¼Œåé¢ä¼šæåˆ°ï¼‰ ä¹Ÿæœ‰äººå–œæ¬¢æŠŠ: å·ç§¯å±‚ å’Œ æ± åŒ–å±‚ å„è‡ªå•ç‹¬ç®—ä¸€ä¸ªå±‚ï¼ˆä¹Ÿæ˜¯æ²¡é—®é¢˜çš„ã€‚Tensorflowçš„APIå°±æ˜¯è¿™æ ·è®¾è®¡çš„ï¼‰ å·ç§¯å±‚ï¼ˆConvolution Layerï¼‰ å·ç§¯è¿‡ç¨‹ å·ç§¯è®¡ç®—è¿‡ç¨‹å°±ä¸è¯´äº†ã€‚æ²¡æœ‰æ¡ˆä¾‹å›¾ã€‚ ä½†ä½ å¯ä»¥ç†è§£ä¸º: ä¸¤ä¸ª æ­£æ–¹ä½“ çš„ å¯¹åº”ä½ç½®çš„å…ƒç´  ï¼ˆç›¸ä¹˜å†ç›¸åŠ ï¼‰çš„ç»“æœã€‚ã€‚ã€‚ ï¼ˆäº’ç›¸å…³ï¼Œï¼Œï¼Œï¼‰ å·ç§¯çš„è¾“å‡ºè®¡ç®— è¾“å‡ºå›¾åƒå¤§å°è®¡ç®—å…¬å¼ï¼š hå›¾ç‰‡è¾“å‡º = ï¼ˆhå›¾ç‰‡è¾“å…¥ - hå·ç§¯æ ¸ + 2paddingï¼‰ / strides + 1 wå›¾ç‰‡è¾“å‡º = ï¼ˆwå›¾ç‰‡è¾“å…¥ - wå·ç§¯æ ¸ + 2paddingï¼‰ / strides + 1 é¦–å…ˆå£°æ˜: è¿™ä¸ªå¼å­ç”±äºä¸ä¸€å®šèƒ½å¤Ÿæ•´é™¤ï¼Œ å› æ­¤é™¤ä¸å°½çš„æƒ…å†µä¸‹ï¼Œå‘ä¸‹å–æ•´, ä¹Ÿå«åœ°æ¿é™¤ å› ä¸ºæœ‰ä¸ªåŸåˆ™: å·ç§¯æ ¸æ»‘åŠ¨çš„æ—¶å€™(é€šå¸¸æ˜¯ï¼Œæ­¥é•¿&gt;1çš„æƒ…å†µä¸‹) å¦‚æœè¶Šç•Œäº†ä¸€éƒ¨åˆ†ã€‚åˆ™èˆå¼ƒæ‰ æ ¹æ®ä¸Šé¢çš„å…¬å¼ï¼Œæ±‚ä¸€ä¸ªè¾“å‡ºå›¾åƒå¤§å°çš„ä¾‹å­(æ­¤å¤„ï¼Œä¸åšpadddingï¼Œ å¹¶ä¸”æ­¥é•¿ä¸º1) eg: è¾“å…¥8x8 çš„å›¾åƒ , å¹¶ä½¿ç”¨3x3çš„å·ç§¯æ ¸ è¾“å‡ºå›¾åƒé«˜åº¦ä¸º: hå›¾ç‰‡è¾“å‡º = (8-3 + 2x0) / 1 + 1 = 6 è¾“å‡ºå›¾åƒå®½åº¦ä¸º: wå›¾ç‰‡è¾“å‡º = (8-3 + 2x0) / 1 + 1 = 6 æ‰€ä»¥è¾“å‡ºå›¾åƒä¸º: 6x6 å¾ˆæ˜æ˜¾: å·ç§¯ä¸€æ¬¡ï¼Œå›¾åƒå˜å°äº†ã€‚ å¦‚æœå†å·ç§¯å‡ æ¬¡ï¼Œ å›¾åƒå°±çœ‹ä¸åˆ°äº†ã€‚ã€‚ã€‚ æ‰€ä»¥: æˆ‘ä»¬éœ€è¦è§£å†³è¿™ä¸ªé—®é¢˜ åŸåˆ™ä¸Š: å¢åŠ  padding èƒ½è§£å†³æ­¥é•¿ä¸º1æ—¶ï¼Œå·ç§¯åçš„å›¾ç‰‡ç¼©æ”¾é—®é¢˜ã€‚ å‡å¦‚æˆ‘ä»¬å¸Œæœ›è¾“å‡ºå›¾åƒçš„å¤§å° ç­‰äº è¾“å‡ºå›¾åƒçš„å¤§å°ï¼Œè€Œæˆ‘ä»¬æƒ³è¦æ±‚paddingéœ€è¦è®¾ç½®ä¸ºå¤šå°‘ã€‚ ä¸€èˆ¬è¿™ç§åœºæ™¯é€‚ç”¨äº æ­¥é•¿strides = 1, æ‰€ä»¥å‚è€ƒå¼€å§‹çš„å…¬å¼ï¼Œå¯å†™å‡ºå¦‚ä¸‹å…¬å¼ï¼š å› ä¸º: w å’Œ hæ˜¯ä¸€æ ·çš„å…¬å¼ï¼Œæ­¤å¤„åªå†™å‡ºä¸€ä¸ªh,æ¥æ¨å¯¼ï¼š hå›¾ç‰‡è¾“å‡º = ï¼ˆhå›¾ç‰‡è¾“å…¥ - hå·ç§¯æ ¸ + 2paddingï¼‰ / strides + 1 åŒ–ç®€: padding =ï¼ˆ hå›¾ç‰‡è¾“å‡º - hå›¾ç‰‡è¾“å…¥ + hå·ç§¯æ ¸ - 1 ï¼‰ / 2 å› ä¸ºæˆ‘ä»¬å¸Œæœ›çš„æ¡ä»¶: hå›¾ç‰‡è¾“å‡º ç­‰äº hå›¾ç‰‡è¾“å…¥ï¼Œ æ‰€ä»¥å¯ç»§ç»­åŒ–ç®€ï¼š padding =ï¼ˆ hå·ç§¯æ ¸ - 1 ï¼‰ / 2 æ‰€ä»¥æ­¥é•¿ä¸º1çš„æƒ…å†µä¸‹å·ç§¯, å¹¶ä¸”æƒ³è®©å›¾ç‰‡ä¸å˜å½¢ï¼Œä½ çš„paddingçš„å–å€¼ï¼Œå°±éœ€è¦å—åˆ° å·ç§¯æ ¸å¤§å°çš„å½±å“ã€‚ ç°åœ¨å¸¸ç”¨çš„å·ç§¯æ ¸å¤§å¤šéƒ½æ˜¯ 1x1ã€ 3x3ã€ 5x3 ã€‚æ‰€ä»¥çœ‹ä¸Šé¢åŒ–ç®€å¥½çš„å…¬å¼ï¼š padding =ï¼ˆ hå·ç§¯æ ¸ - 1 ï¼‰ / 2 &lt;============= 1x1, 3x3, 5x5 å¥‡æ•°-1æ€»ç­‰äºå¶æ•°ã€‚ æ‰€ä»¥ä¸ç”¨æ‹…å¿ƒé™¤ä¸å°½çš„æƒ…å†µ è¿˜éœ€è¦æ³¨æ„ä¸€ä¸‹: å¡«å……paddingä¸€èˆ¬æ˜¯ç¯å½¢å¡«å……ï¼Œ å‡å¦‚padding=1, é‚£ä¹ˆä¸Šä¸‹å·¦å³ éƒ½ä¼šæ·»åŠ ä¸€å±‚ã€‚ å½“ç„¶: tensorflowçš„paddingæ˜¯å¯ä»¥è®¾ç½®å½¢çŠ¶çš„ paddingçš„ç§ç±»ï¼ˆtensorflowï¼‰ valid: ä¸å¡«å…… same: è‡ªåŠ¨å»å¡«å……ï¼Œä½¿å¾—è¾“å…¥å›¾åƒ ä¸ è¾“å‡ºå›¾åƒ çš„å¤§å°ç›¸ç­‰ æ¸©é¦¨æç¤ºï¼šå…³äºä¸‰é€šé“å·ç§¯ å’Œ å¤šä¸ªå·ç§¯æ ¸çš„åŒºåˆ« ä¸‰é€šé“å·ç§¯ï¼š å‡å¦‚ä½ åªæœ‰ä¸€ä¸ªå·ç§¯æ ¸ å³ä½¿ä½ å›¾ç‰‡æ˜¯3é€šé“çš„ï¼ˆä¸‰å±‚ï¼‰ å³ä½¿ä½ å·ç§¯æ ¸ä¹Ÿæ˜¯ä¸‰é€šé“çš„ï¼ˆä¸‰å±‚ï¼‰ ä½†æ˜¯: å·ç§¯è¾“å‡ºç»“æœæ˜¯ä¾ç„¶æ˜¯ä¸€ä¸ª m x n çš„å½¢çŠ¶ (ä¸€å±‚&quot;è–„çº¸&quot;) ä½ çš„ç–‘æƒ‘: ä¸æ˜¯ä¸‰å±‚å˜›ï¼Ÿ æœ€åæ€ä¹ˆå˜æˆä¸€å±‚äº† ï¼Ÿï¼Ÿï¼Ÿ æˆ‘çš„è§£é‡Š: æ¯æ»‘åŠ¨ä¸€æ¬¡,3å±‚é€šé“ï¼Œå„è‡ªéƒ½ä¼šè®¡ç®—å„è‡ªå±‚çš„å·ç§¯ï¼Œç„¶åæ±‚æ€»å’Œï¼Œå¹¶å¡«å…¥ä¸€å±‚&quot;è–„çº¸&quot;çš„å¯¹åº”ä½ç½® å¤šä¸ªå·ç§¯æ ¸ï¼š ä¸Šé¢è¯´äº†: 1ä¸ªå·ç§¯æ ¸ï¼Œæ— è®ºå›¾ç‰‡æ˜¯ä»€ä¹ˆå½¢çŠ¶çš„ã€æœ‰å‡ ä¸ªé€šé“ï¼Œå·ç§¯åè¾“å‡ºçš„å½¢çŠ¶ æ˜¯ ä¸€å±‚è–„çº¸: m x n è€Œå¦‚æœä½ æœ‰å¤šä¸ªå·ç§¯æ ¸: é‚£ä¹ˆä½ å°±ä¼šæœ‰å¤šå±‚è–„çº¸æ‘èµ·æ¥ã€‚ å°±åƒ ä¸€ä¸ªé•¿æ–¹å½¢ æ‘æˆäº†ä¸€ä¸ª é•¿æ–¹ä½“ æ˜ç¡®ç‚¹: å‡å¦‚ä½ ç”¨äº† 6ä¸ªå·ç§¯æ ¸, é‚£ä¹ˆä½ çš„è¾“å‡ºå°±å˜æˆäº† m x n x 6 (ä¸‰ç»´çš„ä¸€ä¸ªé•¿æ–¹ä½“äº†) ä¸Šé¢è¯´çš„ï¼šå°±æ˜¯æˆ‘æœ€å¼€å§‹å­¦çš„CNNæ—¶å€™ç»å¸¸ç†è§£ä¸æ¸…æ¥šçš„åœ°æ–¹ã€‚æˆ‘ç›¸ä¿¡ä½ ä¹Ÿä¸€æ ·, qaq .... ä¸‹é¢åšä¸ªæ€»ç»“: Cä¸ªé€šé“: ä¸€ç‚¹éƒ½ä¸ä¼šå½±å“è¾“å‡ºç»´åº¦ã€‚ æ³¨æ„æˆ‘è¯´çš„æ˜¯ç»´åº¦ã€‚ å‡å¦‚ä½ çš„è¾“å…¥æ˜¯ m x n , é‚£ä¹ˆä½ çš„è¾“å‡ºä¾ç„¶æ˜¯ p x q ï¼ˆæ³¨æ„ç»´åº¦å³å¯ï¼Œç»´åº¦æ²¡å˜ï¼ŒäºŒç»´) fä¸ªå·ç§¯æ ¸: ä¼šå½±å“è¾“å‡ºçš„ç»´åº¦ã€‚ è¾“å‡ºçš„ç»´åº¦å°†ä¼šå¢åŠ ä¸€ä¸ªç»´åº¦f å‡å¦‚ä½ çš„è¾“å…¥æ˜¯ m x n ï¼Œ é‚£ä¹ˆä½ çš„è¾“å‡ºä¾ç„¶æ˜¯ p x q x f (å¢åŠ ä¸€ä¸ªç»´åº¦Fï¼Œå˜æˆäº†) ä¹Ÿè®¸ä½ å½“ä½ å­¦TFçš„æ—¶å€™ä¼šæœ‰å¦ä¸€ä¸ªç†è§£éšœç¢:é‚£å°±æ˜¯TFæ•°æ®æ ¼å¼ï¼ˆä»¥å›¾ç‰‡ä¸ºä¾‹ï¼‰ï¼š é€šå¸¸TFæ•°æ®æ ¼å¼æ˜¯è¿™æ ·çš„ï¼š [å›¾ç‰‡æ•°é‡B, å›¾ç‰‡é«˜åº¦H, å›¾ç‰‡å®½åº¦W, é€šé“æ•°C] å‡å¦‚ä½ ä½¿ç”¨ F ä¸ªå·ç§¯æ ¸åšäº†å·ç§¯ï¼š é‚£ä¹ˆä»–çš„å·ç§¯ç»“æœçš„ç‰¹å¾çš„å½¢çŠ¶å°±å˜å˜æˆï¼š [B, H, W, F] å‘ç°æ²¡è¾“å‡ºç»“æœå’Œé€šé“æ•°Cï¼Œæ²¡æœ‰å…³ç³»çš„ã€‚ åªå’Œ å·ç§¯æ ¸çš„ä¸ªæ•° fæœ‰å…³ç³»ã€‚ ä½†æ˜¯æ³¨æ„: è™½ç„¶ç»“æœå’ŒCæ²¡å…³ç³»ã€‚ä½†æ˜¯ éœ€è¦å·ç§¯æ ¸ä¸­å…·æœ‰ Cçš„æ•°é‡ï¼Œè¿˜åšå”¯ç‹¬åŒ¹é…ã€‚æ¡¥æ¢è¿ç®—ã€‚ å¯¹åº”ä¸Šä¾‹ï¼Œ æˆ‘ä»¬çš„å·ç§¯æ ¸çš„å½¢çŠ¶åº”è¯¥æ˜¯è¿™æ ·çš„ : [F, C, H, W] æ³¨æ„ä¸€ä¸‹ï¼š è¿™é‡Œé¢æœ‰ å·ç§¯æ ¸æ•°é‡fï¼Œ ä¹Ÿæœ‰é€šé“æ•°é‡Cã€‚ å¦‚æœæœ€åä¸€æ­¥çš„å·ç§¯æ ¸å½¢çŠ¶ä¸ç†è§£: æ²¡å…³ç³»ã€‚ä»¥åæ˜¯TF20çš„å¤©ä¸‹ã€‚ å¯¹åº”APIä¸éœ€è¦ä½ æŒ‡å®šå·ç§¯æ ¸çš„å½¢çŠ¶ã€‚ å› æ­¤ï¼Œä½ æ²¡å¿…è¦è®°ä½å·ç§¯æ ¸çš„å½¢çŠ¶ã€‚ ä½ åªéœ€è¦ ä¼ é€’ï¼Œå·ç§¯æ ¸çš„ä¸ªæ•°ï¼Œ å’Œ å®½é«˜ å’Œ æ­¥é•¿ å³å¯ã€‚ å½“ç„¶è¿™äº›éƒ½æ˜¯ç‹¬ç«‹çš„å‘½åå‚æ•°ã€‚ æ‘˜ä¸€å°æ®µConv2Dçš„æºç : def init(self, filters, # ä½ åªéœ€è¦ä¼ é€’è¿™ä¸ªå‚æ•°ï¼Œ å·ç§¯æ ¸çš„ä¸ªæ•° kernel_size, # å·ç§¯æ ¸çš„å®½é«˜ï¼Œå‡å¦‚ 3x3 ä½ åªéœ€å†™ [3,3] å³å¯ strides=(1, 1), # è¿™æ˜¯æ­¥é•¿ï¼Œ ä½ ä¸ä¼ ï¼Œä»–ä¹Ÿä¼šç»™ä½ å¡«é»˜è®¤å€¼, æ­¥é•¿ä¸º1 padding='valid', # è¿™æ—¶ paddingç­–ç•¥ï¼Œå‰é¢è¯´è¿‡ï¼Œè¿™ä¸ªä¸€èˆ¬éƒ½ä¼šè®¾ä¸º &quot;same&quot; æˆ–è®¸ä½ è¿˜æœ‰äº›ç–‘é—®: åˆšæ‰ä¸Šé¢ä¸æ˜¯æåˆ°äº†å·ç§¯æ ¸åº”è¯¥è®¾ç½® é€šé“æ•°Cä¹ˆã€‚ åŸåˆ™ä¸Šæ˜¯çš„ã€‚å› ä¸ºè¦å’Œ è¾“å‡ºçš„æ ·æœ¬åšå·ç§¯ã€‚è¦åŒ¹é…æ‰è¡Œã€‚ ä½†æ˜¯åœ¨Tensorflowä¸­ã€‚ ç‰¹åˆ«æ˜¯ Tenosrflow.Kerasä¸­ï¼Œå®šä¹‰æ¨¡å‹å±‚ æˆ‘ä»¬åªéœ€è¦æŠŠæ•´ä¸ªæ¨¡å‹ï¼Œä»ä¸Šåˆ°ä¸‹è¿æ¥èµ·æ¥ã€‚ï¼ˆå°±åƒå…ˆåæ’é˜Ÿä¸€æ ·ï¼‰ è€Œå¯¹äºä¸€äº›å‰åæµåŠ¨è´¯é€šçš„å‚æ•°ï¼Œæ¯”å¦‚åˆšæ‰æåˆ°çš„é€šé“Cã€‚ è¿™äº›å‚æ•°ï¼ŒTensorflowä¼šè‡ªåŠ¨å¸®æˆ‘ä»¬ä¸Šä¸‹æ–‡è¯†åˆ«ç®¡ç†ã€‚ æ‰€ä»¥æˆ‘ä»¬åšçš„åªæ˜¯éœ€è¦ï¼ŒæŠŠåŸå§‹æ•°æ®çš„å½¢çŠ¶è®¾ç½®å¥½ä¼  ç»™ç¬¬ä¸€å±‚ï¼ˆç»™æ’å¤´å‘æ•°æ®ï¼‰ è‡³äºä½ è¿™äº›åœ¨ä¸­é—´å±‚æµåŠ¨çš„å‚æ•°ï¼ŒTensorflowä¼šè‡ªåŠ¨å¸®ä½ è®¡ç®—ï¼Œä½ ä¸ç”¨ä¼ ã€‚ è™½ç„¶ä¸ç”¨ä¼ ï¼Œä½†ä½ æœ€å¥½æ¸…æ¥šæ¯å±‚æ˜¯ä»€ä¹ˆç»“æ„ï¼ˆå½“ç„¶è¿™æ—¶åè¯ï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ç†è§£ï¼‰ åˆ°æœ€åï¼Œæˆ‘å†ç»™ä½ è®¾ç½®ä¸€ä¸ªè¾“å‡ºå½¢çŠ¶ï¼Œä½ èƒ½ç»™æˆ‘è¾“å‡ºå‡ºæ¥å³å¯ ï¼ˆé˜Ÿå°¾æ¥æ•°æ®ï¼‰ åŸºæœ¬TFå‚æ•°æµåŠ¨æœºåˆ¶è®²åˆ°è¿™é‡Œï¼Œåˆšå¼€å§‹å­¦çš„æ—¶å€™ï¼Œä¹Ÿæ˜¯å„ç§è‹¦æ€å†¥æƒ³ï¼Œæƒ³ä¸æ˜ç™½qaq... é€è¿‡ç°è±¡çœ‹æœ¬è´¨ï¼ˆå·ç§¯ =&gt; çº¿æ€§ï¼‰ å…¶å®æˆ‘ä»¬åšçš„æ¯ä¸€æ­¥ (æ¯ä¸€ä¸ª)å·ç§¯å°±ç›¸å½“äºä¸€ä¸ªçŸ©é˜µçº¿æ€§æ“ä½œï¼š x1 @ w1 ä¹‹åï¼ŒåŸºäºå¸¸ç†è¯ï¼Œ æˆ‘ä¼šè¿˜ä¼šç»™å®ƒä¸€ä¸ªåå·®ï¼š b å˜æˆ ===&gt; x1 @ w1 + b æˆ‘ä»¬è¯´è¿‡ï¼Œå¯èƒ½ä¼šç»™å‡ºå¾ˆå¤šä¸ªå·ç§¯æ ¸è¿›è¡Œè¿ç®—ã€‚ ä¸Šé¢ x1 @ w1 + b æ˜¯æ¯ä¸€ä¸ªå·ç§¯æ ¸çš„å·ç§¯ç»“æœ æˆ‘ä»¬è¿˜éœ€è¦è®²æ‰€æœ‰å·ç§¯æ ¸è®¡ç®—ç»“æœå †å åœ¨ä¸€èµ·ï¼š è®°ä¸º X @ W + b # m x n x f æœ€åå°†å †å åœ¨ä¸€èµ·çš„ç»“æœï¼Œåšä¸€å±‚éçº¿æ€§å˜æ¢ relu ( X @ W + b ) # CNN é€šå¸¸ç”¨ relu egï¼š ç°æœ‰å›¾ç‰‡ 5 x 5 x 3 çš„å›¾åƒ ï¼ˆæš‚æ—¶ä¸è€ƒè™‘æ ·æœ¬ä¸ªæ•°ï¼Œå°±è®¤ä¸ºæ˜¯ä¸€ä¸ªæ ·æœ¬ï¼‰. æˆ‘ä»¬ç”¨çš„æ˜¯ 2 x 2 x 20 çš„å·ç§¯æ ¸ (æ­¥é•¿ä¸º1ï¼Œä¸åšpadding) é‚£ä¹ˆè¾“å‡ºç»“æœå°±æ˜¯ (5-2+1) x (5-2+1) x 20 === 4 x 4 x 20 å¿˜è®°è¯´äº†ï¼Œè¿˜æœ‰ä¸€ä¸ªå…¬å¼ï¼Œç”¨æ¥è®¡ç®— æ¯å±‚å·ç§¯çš„æƒé‡å‚æ•°é‡çš„ä¸ªæ•°çš„ï¼š å…¬å¼: æ¯å±‚æƒé‡å‚æ•°é‡(W) = å·ç§¯æ ¸ä¸ªæ•° x å·ç§¯æ ¸é«˜ x å·ç§¯æ ¸å®½ x å·ç§¯æ ¸é€šé“æ•° å…¬å¼: æ¯å±‚åå·®æ•°é‡(b) = 1 x å·ç§¯æ ¸çš„ä¸ªæ•° # å› ä¸ºæ¯ä¸ªå·ç§¯æ ¸åªæœ‰ä¸€ä¸ªåå·®b æ¸©é¦¨æç¤º: æœ‰å¤ªå¤šäººå–œæ¬¢æŠŠå·ç§¯æ ¸ä¸ªæ•° ä¸ å·ç§¯æ ¸é€šé“ç§°ä½œ:&quot;è¾“å…¥/è¾“å‡º&quot;é€šé“ã€‚ è¿™æ ·çš„ç§°å‘¼æ˜¯æ²¡é—®é¢˜çš„ï¼Œ ä½†æˆ‘åœ¨è®¡ç®—å‚æ•°é‡çš„æ—¶å€™ï¼Œä¸å–œæ¬¢è¿™æ ·çš„ç§°å‘¼ï¼Œæ˜“æ··æ·†ã€‚ å‰æƒ…å›é¡¾: è®°ä¸è®°å¾—æ™®é€šç¥ç»ç½‘ç»œäº†ã€‚æ¯ä¸ªç¥ç»å…ƒèŠ‚ç‚¹ï¼Œéƒ½æœ‰å®ƒä»¬è‡ªå·±çš„å‚æ•°ã€‚å› æ­¤å®ƒä»¬çš„å‚æ•°é‡æ˜¯å·¨å¤§çš„ å›å½’æ­£æ–‡: è€Œå·ç§¯æ ¸æ˜¯å…±äº«çš„ï¼Œ å› ä¸ºå®ƒæ˜¯åœ¨ä¸€å¼ å›¾ç‰‡ä¸Šæ»‘åŠ¨çš„ã€‚ï¼ˆæŒ¨ä¸ªæœåŠ¡ï¼‰æ‰€ä»¥æƒé‡å‚æ•°ä¹Ÿæ˜¯å…±äº«çš„ã€‚ æ± åŒ–å±‚ (Pooling Layer) å·ç§¯å±‚(æ¿€æ´»å‡½æ•°) =&gt; æ± åŒ–å±‚ æ± åŒ–å±‚ä¸»è¦åˆ†ä¸¤ç§ï¼š MaxPooling å’Œ AvgPooling æ± åŒ–å±‚è¾“å‡ºå›¾ç‰‡å½¢çŠ¶è®¡ç®—å…¬å¼ï¼š å£°æ˜ï¼š æ± åŒ–å±‚ä¹Ÿæœ‰æ»‘åŠ¨çª—å£ï¼Œå¹¶ä¸”è¾“å‡ºå½¢çŠ¶è®¡ç®—å…¬å¼ï¼Œå’Œ å·ç§¯çš„è¾“å‡ºå½¢çŠ¶è®¡ç®—å…¬å¼ä¸€æ ·ï¼š hå›¾ç‰‡è¾“å‡º = ï¼ˆhå›¾ç‰‡è¾“å…¥ - hå·ç§¯æ ¸ + 2paddingï¼‰ / strides + 1 wå›¾ç‰‡è¾“å‡º = ï¼ˆwå›¾ç‰‡è¾“å…¥ - wå·ç§¯æ ¸ + 2paddingï¼‰ / strides + 1 å› ä¸ºæ± åŒ–å±‚ï¼Œçš„åŸºæœ¬éƒ½æ˜¯æ”¾åœ¨å·ç§¯å±‚ä¹‹åï¼Œå› æ­¤æ± åŒ–å±‚çš„é€šé“æ•° ä¹Ÿå°±é¡ºç†æˆç« çš„ å’Œ å·ç§¯å±‚é€šé“ä¸€æ · ä¸¾ä¸ªä¾‹å­: å·ç§¯å±‚æ•°æ®å½¢çŠ¶ä¸º: m x n x f é‚£ä¹ˆæ± åŒ–å±‚å½¢çŠ¶åŒä¸º: p x q x f æˆ‘æƒ³ä¸»è¦å¼ºè°ƒçš„æ˜¯: é€šé“æ•°ä¸å˜ï¼Œå˜å¾—æ˜¯ å®½é«˜ã€‚ æ± åŒ–å±‚ æ»‘åŠ¨çª—å£å‚æ•°ç›¸å…³é…ç½® è¿˜æ˜¯ï¼ŒæŠŠTensorflow, æºç æ¬è¿‡æ¥ï¼Œæ ‡æ³¨ä¸€ä¸‹: def init(self, pool_size=(2, 2), # æ»‘åŠ¨çª—å£å¤§å° 2x2 strides=None, # æ­¥é•¿ï¼Œé€šå¸¸è®¾ä¸º2 padding='valid', # Maxpooling é€šå¸¸ä¸ç”¨padding ä¸€èˆ¬éƒ½æ˜¯ä½¿ç”¨ç»„åˆ pool_size=(2, 2) å’Œ stride = 2 æ‰€ä»¥ï¼Œå…¬å¼æ¥äº†: è¾“å…¥h æ»‘åŠ¨çª—å£h è¾“å‡ºh = (è¾“å…¥h - æ»‘åŠ¨çª—å£h) / stride + 1 = ---------- - -------- + 1 stride stride é€šå¸¸æˆ‘ä»¬æŠŠ poolingå±‚ä½œç§°ä½œæ•°æ®çš„é™é‡‡æ ·: æ‰€ä»¥å¤§å¤šæ•°ç»éªŒè€…ï¼Œéƒ½ä¼šæŠŠ æ»‘åŠ¨çª—å£ å’Œ strideæ­¥é•¿ è®¾ä¸ºç›¸ç­‰å¤§å°ã€‚ æ‰€ä»¥å¸¦å…¥ä¸Šé¢å…¬å¼ï¼š è¾“å…¥h 1 è¾“å…¥h è¾“å‡ºh = (è¾“å…¥h - æ»‘åŠ¨çª—å£h) / stride + 1 = ---------- - ----- + 1 = ------- stride 1 æ­¥é•¿ ç®€åŒ–ä¸€ä¸‹: ï¼ˆå½“ pool_size å’Œ strides è®¾ç½®ç›¸ç­‰å¤§å°æ—¶ï¼‰ï¼š è¾“å‡º = è¾“å…¥ / æ­¥é•¿ æ‰€ä»¥å½“æˆ‘ä»¬: æ­¥é•¿è®¾ä¸º2æ—¶ï¼Œ è¾“å‡ºå°±æ˜¯è¾“å‡ºçš„ä¸€åŠã€‚ æ­¥é•¿è®¾ä¸º3æ—¶ï¼Œ è¾“å‡ºå°±æ˜¯è¾“å‡ºçš„1/3ã€‚ ... ä¸çŸ¥é“æœ‰æ²¡æœ‰è¿™æ ·ä¸€ä¸ªç–‘é—®ï¼šâ€ä¸ºä»€ä¹ˆæ»‘åŠ¨çª—å£æ²¡æœ‰è®¾ç½® çª—å£æ•°é‡ ï¼ˆå°±åƒè®¾ç½®å·ç§¯æ ¸æ•°é‡ï¼‰â€œ å†æ¬¡è¯´ä¸€ä¸‹Tensorflowçš„åŸç†ã€‚ å› ä¸ºPoolingçš„ä¸Šä¸€å±‚åŸºæœ¬å®Œå…¨æ˜¯ Convå·ç§¯å±‚ï¼Œ å·ç§¯å±‚çš„ å·ç§¯æ ¸çš„ä¸ªæ•°å·²ç»è®¾ç½®å¥½äº†ã€‚ å·ç§¯å±‚å¯¹æ¥æ± åŒ–å±‚çš„æ—¶å€™ï¼Œ Tensorflowä¼šè‡ªåŠ¨åˆ¤æ–­ï¼Œå¹¶è®¾ç½®: æ± åŒ–å±‚æ»‘åŠ¨çª—å£çš„ä¸ªæ•°===å·ç§¯æ ¸ä¸ªæ•° æ± åŒ–å±‚é€šé“ä¸ªæ•°çš„ä¸ªæ•°===å·ç§¯å±‚é€šé“ä¸ªæ•°===å›¾ç‰‡çš„åŸå§‹é€šé“ä¸ªæ•° MaxPooling ï¼ˆæœ€å¤§æ± åŒ–ï¼Œå¸¸ç”¨ï¼‰ å·ç§¯æ“ä½œï¼šä¹‹å‰æˆ‘ä»¬å·ç§¯ä¸æ˜¯æ‹¿ç€æ»‘åŠ¨çª—å£ï¼Œå¯¹åº”å…ƒç´ ç›¸ä¹˜å†ç›¸åŠ ä¹ˆï¼Ÿ æ± åŒ–æ“ä½œï¼šæ± åŒ–å±‚ä¹Ÿæ˜¯æ‹¿ç€æ»‘åŠ¨çª—å£ä¸€æ ·æ»‘ï¼Œä½†æ˜¯ä¸åšè¿ç®—ï¼Œè€Œæ˜¯åªå–æ¯ä¸ªçª—å£å†…æœ€å¤§å€¼ã€‚æ”¾åœ¨ä¸€å±‚&quot;è–„çº¸&quot;ä¸Š AvgPooling ï¼ˆå¹³å‡æ± åŒ–ï¼Œä¸å¸¸ç”¨ï¼‰ ä¸€æ ·æ»‘åŠ¨çª—å£ï¼Œå„ç§æ»‘ï¼Œ ç„¶åå–æ¯ä¸ªçª—å£å†…çš„æ•°æ®çš„&quot;å¹³å‡å€¼&quot;, å…¶ä»–å°±ä¸è¯´äº†ï¼ŒåŒ MaxPooling é¢å¤–æé†’ï¼ˆæ± åŒ–å±‚çš„å‚æ•°æ˜¯å¦è®­ç»ƒï¼‰ æ± åŒ–å±‚çš„æ˜¯&quot;æ²¡æœ‰&quot;å‚æ•°å¯ä»¥è®­ç»ƒçš„ã€‚æ‰€ä»¥ï¼Œåå‘ä¼ æ’­ï¼Œä¹Ÿä¸ä¸ºæ‰€åŠ¨~~~ å…¨è¿æ¥å±‚ ï¼ˆDense Layerï¼‰ ä»€ä¹ˆæ˜¯å…¨è¿æ¥å±‚ï¼Ÿï¼Ÿ ä½ å¾ˆç†Ÿæ‚‰çš„ï¼Œ å…¨è¿æ¥å±‚å…¶å®å°±æ˜¯ä¹‹å‰è®²çš„æ™®é€šçš„NNï¼ˆç¥ç»ç½‘ç»œï¼‰ï¼Œæ‰€ä»¥å¹¶æ²¡æœ‰ä»€ä¹ˆå¥½è¯´çš„ã€‚ åªæ˜¯æ‹¼æ¥åœ¨æ± åŒ–å±‚ä¹‹åç½¢äº†ã€‚ ä½†å…¶å®è¿˜æ˜¯æœ‰ä¸€äº›ç»†èŠ‚éœ€è¦æ³¨æ„ã€‚å°¤å…¶ä¹‹å‰çš„ä¸œè¥¿æ²¡ææ‡‚ï¼Œé‚£ä¹ˆè¿™é‡Œçš„å‚æ•°å½¢çŠ¶ä½ ä¼šå®æ‰~~~ å±•å¹³ åŠ å‚æ•° ä¹‹å‰ä¸ºäº†å›¾æ–¹ä¾¿ï¼Œå‚æ•°æˆ‘éƒ½æ²¡æ€ä¹ˆæåˆ°æ ·æœ¬å‚æ•°ã€‚ ä¸‹é¢æˆ‘è¦æŠŠæ ·æœ¬å‚æ•°ä¹ŸåŠ è¿›æ¥ä¸€èµ·å” å” äº†ã€‚æˆ‘æ„Ÿè§‰è®²è¿™é‡Œï¼Œç›´æ¥ä¸Šä¾‹å­æ¯”è¾ƒç›´è§‚ã€‚ å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ä¸ªéœ€æ±‚ï¼Œ æƒ³è¦åšä¸€ä¸ª10åˆ†ç±»çš„ä»»åŠ¡ï¼š å·ç§¯å±‚-æ± åŒ–å±‚: è¿™ä¸ªç…§å¸¸åšï¼Œ è®¾ç½®ä½ è¿˜å¯ä»¥å †å  å·ç§¯å±‚1 + æ± åŒ–å±‚1 + å·ç§¯å±‚2 + æ± åŒ–å±‚2 ... ç­‰å †å çš„å·®ä¸å¤šäº†: (ä½ è‡ªæˆ‘æ„Ÿè§‰è‰¯å¥½äº†ã€‚ã€‚ã€‚)ï¼Œæˆ‘ä»¬éœ€è¦åšä¸€å±‚å±•å¹³å¤„ç†ï¼ å±•å¹³å¤„ç†ï¼ˆç‰¹æ„æ‹¿å‡ºæ¥è¯´ï¼‰ å‡å¦‚ä½ å åŠ åˆ°æœ€åä¸€å±‚æ± åŒ–å±‚æ•°æ®å½¢çŠ¶æ˜¯:(1000,4,4,8)==&gt; 1000ä¸ªæ ·æœ¬ï¼Œå®½é«˜8 x 8, è¾“å‡ºé€šé“ä¸º8 ä½ å±•å¹³åçš„å½¢çŠ¶ä¸º: (1000, 448) == (1000, 128) å±•å¹³æ“ä½œç¬¬ä¸€ç§API: tf.keras.Flatten() # tensorflow2.0çš„Flattenè¢«ä½œä¸ºç½‘ç»œå±‚ä½¿ç”¨ å±•å¹³æ“ä½œç¬¬ä¸€ç§API: tf.reshape(x, [-1, 128]) # æ‰‹åŠ¨å˜æ¢ï¼Œ -1æ˜¯è¡¥ä½è®¡ç®—çš„æ„æ€ ç„¶ååœ¨åŠ å…¨è¿æ¥å±‚ï¼Œå½¢çŠ¶ä¸º: (1000, 50) # 50ä»£è¡¨è¾“å‡ºï¼Œèµ·åˆ°è¿‡æ¸¡ä½œç”¨ ç„¶ååœ¨åŠ å…¨è¿æ¥å±‚ï¼Œå½¢çŠ¶ä¸º: (1000, 10) # æœ€ç»ˆï¼Œ10ä»£è¡¨è¾“å‡ºï¼Œå› ä¸ºæˆ‘ä»¬è¯´äº†ï¼Œè¦åš10åˆ†ç±»å˜› 1. å…¶å®ä½ ä¸­é—´å¯ä»¥åŠ å¾ˆå¤šå…¨è¿æ¥å±‚ï¼Œæˆ‘è¿™é‡ŒåªåŠ äº†ä¸€å±‚ï¼Œæ§åˆ¶æœ€åä¸€å±‚å…¨è¿æ¥æ˜¯ä½ æƒ³è¦çš„è¾“å‡ºå°±è¡Œã€‚ 2. ç‰¹åˆ«æ³¨æ„ï¼Œ è¿™é‡Œçš„æ¯ä¸€å±‚å…¨è¿æ¥è®¡ç®—ï¼Œæ˜¯éœ€è¦æœ‰æ¿€æ´»å‡½æ•°è·Ÿç€çš„ã€‚ é™¤äº†æœ€åä¸€å±‚å…¨è¿æ¥ï¼Œå…¶ä»–å±‚çš„å…¨è¿æ¥éƒ½è®¾ç½®ä¸º Relu æ¿€æ´»å‡½æ•°å³å¯ã€‚ 3. å› ä¸ºæˆ‘ä»¬åšçš„æ˜¯10åˆ†ç±»ï¼ˆå¤šåˆ†ç±»è‡ªç„¶åº”æƒ³åˆ° softmaxå‚æ•°ï¼Œ å¦‚æœæ˜¯å…¶ä»–ä¸šåŠ¡ï¼Œä½ ä¹Ÿå¯ä»¥ä¸åŠ æ¿€æ´»å‡½æ•°ï¼‰ æ²¡åšï¼Œä¹Ÿå°±æ˜¯æœ€åä¸€å±‚ã€‚æˆ‘ä»¬è¦å†æ·»åŠ ä¸€å±‚æ¿€æ´»å‡½æ•° Softmaxã€‚ 1 x 1 å·ç§¯çš„ä½œç”¨ é™é‡‡æ ·ï¼ˆæ§åˆ¶è¾“å‡ºé€šé“æ•°é‡ï¼‰ï¼š å‡å¦‚,å‰ä¸€ä¸ªå·ç§¯å±‚å‚æ•°ä¸º: (1000,32,32,256) å¦‚æœä½ ä¸‹ä¸€å±‚ä½¿ç”¨1x1x128çš„å·ç§¯ï¼Œåˆ™å¯¹åº”å‚æ•°ä¸º: (1000ï¼Œ32ï¼Œ32ï¼Œ128) # 256é€šé“å˜æˆäº†128é€šé“ CNNæ–‡æœ¬åˆ†ç±»ï¼ˆä¹Ÿè®¸ä½ çœ‹å®Œä¸‹é¢çš„RNNå†å›æ¥çœ‹è¿™ä¸ªä¼šæ›´å¥½ï¼‰ é€šå¸¸CNNå¤§å¤šæ•°éƒ½æ˜¯ç”¨æ¥åšCVå·¥ä½œã€‚å¯¹äºæŸäº›æ–‡æœ¬åˆ†ç±»ã€‚CNNä¹Ÿå¯ä»¥å®Œæˆã€‚å¦‚ä¸‹å˜é€šæ¦‚å¿µï¼š å¥å­çš„é•¿åº¦ çœ‹ä½œ (å›¾ç‰‡çš„é«˜åº¦) embeddingçš„ç»´åº¦ï¼Œ çœ‹ä½œ (å›¾ç‰‡çš„å®½åº¦) å·ç§¯æ ¸æ˜¯é“ºæ»¡ä¸€è¡Œ(æˆ–è€…å¤šè¡Œ)ï¼Œç„¶åæ²¿ç€é«˜åº¦ç«–ç€æ»‘ä¸‹æ¥çš„ã€‚ ä½ ä¹Ÿå¯ä»¥æœ‰å¤šä¸ªå·ç§¯æ ¸ eg: ä¸€ä¸ªå¥å­ 10ä¸ªè¯è¯­ï¼Œ20dimï¼Œ è¿™ä¸ªå¥å­çš„è¾“å…¥å½¢çŠ¶å°±æ˜¯ï¼ˆ10 x 20ï¼‰ æˆ‘ä»¬å‡†å¤‡3ä¸ªå·ç§¯æ ¸åˆ†åˆ«æ˜¯ï¼ˆ3x20),(2x20), (1x20ï¼‰ æ¯ä¸ªå·ç§¯æ ¸ç«–ç€æ»‘ä¸‹æ¥ï¼Œæœ€åæŒ‰æ¬¡åºå¾—åˆ°å‘é‡å½¢çŠ¶ä¸ºï¼ˆ10ï¼Œ3ï¼‰ ä½ å¯ä»¥çœ‹ä½œè¾“å‡ºä¸‰é€šé“ï¼ˆå¯¹åº”å·ç§¯æ ¸ä¸ªæ•°ï¼Œè¿™å’Œä¹‹å‰è®²çš„CNNåŸç†ä¸€æ¨¡ä¸€æ ·ï¼‰ æœ€ç»ˆæå–å‡ºæ¥è¿™ä¸ªï¼ˆ10ï¼Œ3ï¼‰æ˜¯ï¼Œä¸€ä¸ªå¥å­3ä¸ªé€šé“çš„ç‰¹å¾ä¿¡æ¯ã€‚ å°†10x3ç‰¹å¾çŸ©é˜µï¼Œé€šè¿‡maxpoolingå‹ç¼©æˆ ï¼ˆ1x3)çš„ç‰¹å¾çŸ©é˜µ æ”¾å…¥Denseå±‚ï¼Œæ„å»ºå¤šè¾“å‡ºå•å…ƒçš„nåˆ†ç±»æ¨¡å‹ã€‚ ResNet (æ®‹å·®ç½‘ç»œ Residual Networks) é—®é¢˜å¼•å…¥ï¼š æ˜¯å¦ç½‘ç»œå±‚æ•°è¶Šå¤šè¶Šå¥½ï¼Œè™½ç„¶å †å æ›´å¤šçš„ç½‘ç»œï¼Œå¯ä»¥ä½¿å¾—å‚æ•°ä¸°å¯Œï¼Œå¹¶ä¸”å¯ä»¥å­¦åˆ°æ›´å¤šæ›´å¥½çš„ç‰¹å¾ã€‚ ä½†æ˜¯å®é™…æ•ˆæœå¹¶éå¦‚æ­¤ï¼Œè€Œæ˜¯å‡ºç°ï¼Œè¿‡æ‹Ÿåˆç­‰ç°è±¡ã€‚ ResNetä½œè€… ä½•å‡¯æ˜ï¼šæœ‰æ„Ÿè€Œå‘ï¼šæŒ‰ç†è¯´æ¨¡å‹æ˜¯åº”è¯¥è¶Šä¸°å¯Œè¶Šå¥½çš„ã€‚å¯æ˜¯å‡ºç°äº†è¿‡æ‹Ÿåˆè¿™ç§ç°è±¡ã€‚ æœ€å°‘ï¼Œæ›´æ·±å±‚çš„ç½‘ç»œçš„æ•ˆæœï¼Œåº”è¯¥æ¯”æµ…å±‚ç½‘ç»œçš„æ•ˆæœå¥½å§ã€‚ä¸è‡³äºå·®äº†é‚£ä¹ˆå¤šã€‚ å› æ­¤ï¼Œä»–å°†æ­¤é—®é¢˜è½¬æ¢ä¸ºä¸€ä¸ªæ·±åº¦æ¨¡å‹ä¼˜åŒ–çš„é—®é¢˜ã€‚ ResNetç›¸å…³é…ç½® batch-size: 256 optimizer: SGD+Momentum(0.9) learning_rate: åˆå§‹åŒ–ä¸º0.1ï¼Œ éªŒè¯é›†å‡ºç°æ¢¯åº¦ä¸ä¸‹é™çš„æƒ…å†µä¸‹ï¼Œlearning_rateæ¯æ¬¡é™¤ä»¥10è¡°å‡ æ¯ä¸€å±‚å·ç§¯å±‚ä¹‹åï¼Œéƒ½åš Batch Normalization ä¸ä½¿ç”¨ Dropout ï¼ˆå…¶å®åº”è¯¥æ˜¯ç”¨äº† BN,æ‰€ä»¥å°±æ²¡æœ‰ Dropoutï¼‰ RNN (å¾ªç¯ç¥ç»ç½‘ç»œ) ###ç›´æ¥å¼•ç”¨ Andrew Ngçš„é™è§£å›¾ å¯ä»¥çœ‹åˆ°ï¼Œä¸Šå›¾ä¸­æœ‰ä¸€äº›è¾“å…¥å’Œè¾“å‡ºï¼šæ…¢æ…¢æ‹æ¸…ã€‚ ç¬¬ä¸€ä¸ªè¾“å…¥ x&lt;1&gt; ä»£è¡¨ ï¼ˆä½ åˆ†è¯åçš„æ¯ä¸€ä¸ªå¥å­ä¸­çš„ç¬¬ä¸€ä¸ªå•è¯ï¼‰ x&lt;2&gt;å°±æ˜¯ç¬¬äºŒä¸ªå•è¯å–½ ç¬¬äºŒä¸ªè¾“å…¥ a&lt;0&gt; ä»£è¡¨ åˆå§‹è¾“å…¥ï¼Œ ï¼ˆä¸€èˆ¬åˆå§‹åŒ–ä¸º0çŸ©é˜µï¼‰ å‰é¢ä¸¤ä¸ªè¾“å…¥ï¼Œ å„ä¼šä¹˜ä¸Šå„è‡ªçš„ æƒé‡çŸ©é˜µï¼Œç„¶åæ±‚å’Œ å¾—å‡º a&lt;1&gt; (è¿™æ˜¯ä¸´æ—¶è¾“å‡º) a&lt;1&gt; ä¹˜ä¸Š ä¸€ä¸ªæƒé‡å‚æ•° å¾—åˆ°è¾“å‡ºä¸€: y&lt;1&gt; ï¼ˆè¿™æ˜¯ç»ˆæè¾“å‡ºä¸€ï¼‰ ï¼ˆè¿™å°±æ˜¯å›¾ä¸­é»‘æ¡†é¡¶éƒ¨çš„è¾“å‡ºåˆ†æ”¯ï¼‰ a&lt;1&gt; ä¹˜ä¸Š åˆä¸€ä¸ªæ–°æƒé‡å‚æ•°åï¼Œ å†åŠ ä¸Š x&lt;2&gt; ä¹˜ä»¥è‡ªå·±çš„æƒé‡å‚æ•°å¾—åˆ° a&lt;2&gt; ......ä½ ä¼šå‘ç° 1-5æ­¥æ˜¯ä¸ªå¾ªç¯çš„è¿‡ç¨‹ï¼Œ åˆ°ç¬¬5æ­¥ï¼Œ a&lt;1&gt; å°±ç›¸å½“äº æœ€å¼€å§‹a&lt;0&gt;çš„åœ°ä½ï¼Œä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ é¢˜å¤–è¯ã€‚å…¶å®æ¯å±‚çš„è¾“å‡ºy1 ä¼šæ›¿ä»£ä¸‹ä¸€å±‚çš„xä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ã€‚ ï¼ˆæˆ‘ä¼šæ”¾åˆ°ä¸‹é¢&quot;é˜²å‘è§£é‡Š&quot;ä¸­è¯´ï¼‰ ç„¶åå°†ä¸Šè¿°é€”ä¸­æœ€å2è¡Œçš„å…¬å¼åŒ–ç®€ï¼Œå¯å¾—åˆ°å¦‚ä¸‹å½¢å¼ï¼š é˜²å‘è§£é‡Š (RNNè¯­è¨€æ¨¡å‹) å¦‚æœä½ çœ‹è¿‡äº†ä¸Šé¢çš„å›¾ï¼Œä½ ä¼šå¾ˆæ¸…æ¥šï¼Œ æœ‰å¤šå°‘ä¸ªx, å°±ä¼šè¾“å‡ºå¤šå°‘ä¸ªyã€‚ ä¸Šé¢ç¬¬7ç‚¹è¯´è¿‡ : &quot;å…¶å®æ¯å±‚çš„è¾“å‡ºy1 ä¼šæ›¿ä»£ä¸‹ä¸€å±‚çš„xä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥&quot;, è¯¥å¦‚ä½•ç†è§£è¿™å¥è¯ï¼Ÿï¼Ÿï¼Ÿ å‡å¦‚ä½ æœ‰è¿™æ ·ä¸€æ®µæ–‡æœ¬: &quot;æˆ‘ç²¾é€šå„ç§è¯­è¨€&quot; =&gt; åˆ†è¯åçš„ç»“æœä¼šå˜æˆ &quot;æˆ‘&quot;,&quot;ç²¾é€š&quot;,&quot;å„ç§&quot;,&quot;è¯­è¨€&quot; ä¸€èˆ¬çš„é—®ç­”å¯¹è¿™ç§çš„å¥å­ï¼Œå¤„ç†æµç¨‹æ˜¯: ï¼ˆè¿™é‡Œåªå…ˆè¯´ä¸€ä¸ªï¼‰ï¼š é‚£å°±æ˜¯ï¼šåœ¨å¥å­çš„æœ«å°¾æ·»åŠ ä¸€ä¸ª æ ‡è¯†ç¬¦ æ‰€ä»¥å¥å­å˜æˆäº†: &quot;æˆ‘&quot;,&quot;ç²¾é€š&quot;,&quot;å„ç§&quot;,&quot;è¯­è¨€&quot;, &quot;END&quot; è¿™äº›å•è¯éƒ½ä¼šé¢„å…ˆè½¬ä¸º ï¼ˆOne-Hotç¼–ç  æˆ–è€…Embeddingç¼–ç ï¼‰ x1(åˆå§‹å€¼0) =&gt; y1(æˆ‘) y1æœ‰ä¸€å®šæ¦‚ç‡è¾“å‡º &quot;æˆ‘&quot;ï¼Œ ä¸‹é¢æ‰€æœ‰çš„yåŒç†ï¼Œåªæ˜¯æ¦‚ç‡æ€§ã€‚ x2(y1) =&gt; y2(ç²¾é€š) å¦‚æ­¤æ¯ä¸€å±‚åµŒå¥—ä¸‹æ¥ï¼Œç›¸å½“äºæ¡ä»¶æ¦‚ç‡ P(ç²¾é€š|æˆ‘) x3(y2) =&gt; y3(å„ç§) P(å„ç§|(æˆ‘ï¼Œç²¾é€š)) x4(y3) =&gt; y4(è¯­è¨€) ... x5(y4) =&gt; y5(&lt;END&gt;) ... ä¸çŸ¥é“çœ‹äº†ä¸Šä¾‹ï¼Œä½ ä¼šä¸ä¼šæœ‰ä¸‹é¢ä¸€è¿ä¸²çš„é—®å·è„¸ï¼Ÿï¼Ÿï¼š ä¸ºä»€ä¹ˆy1-y5 è¾“å‡ºéƒ½æ˜¯ç²¾å‡†çš„æ–‡å­—ï¼Ÿ ç­”ï¼šæˆ‘åªæ˜¯æ–¹ä¾¿ä¹¦å†™è¡¨ç¤ºï¼Œå…¶å®æ¯ä¸ªè¾“å‡ºçš„Yéƒ½æ˜¯ä¸€ä¸ªä»è¯å…¸é€‰æ‹”å‡ºæ¥çš„è¯çš„æ¦‚ç‡ã€‚ï¼ˆå¤šåˆ†ç±»ï¼‰ ä¸æ˜¯è¯´x1-x5æ¯ä¸ªxåº”è¯¥è¾“å…¥å›ºå®šå¥å­çš„æ¯ä¸ªå•è¯ä¹ˆï¼Ÿï¼Ÿï¼Ÿä¸ºä»€ä¹ˆå˜æˆäº†è¾“å…¥y1-y5 ç­”ï¼šçš„ç¡®æ˜¯è¿™æ ·çš„ï¼Œä½†æ˜¯æˆ‘ä»¬çš„ y1-y5 éƒ½æ˜¯æœç€é¢„æµ‹x1-x5çš„æ–¹å‘å‰è¿›çš„ã€‚ï¼ˆè¿™ä¹Ÿæ˜¯æˆ‘ä»¬è¦è®­ç»ƒçš„ç›®æ ‡ï¼‰ æ‰€ä»¥: å¯ä»¥è¿‘ä¼¼æŠŠy1-y5ç­‰ä»·äºx1-x5ã€‚ æ‰€ä»¥ç”¨ y1-y5 æ›¿ä»£äº† x1-x5 è¿™æ ·: ä¹Ÿå¯ä»¥æŠŠå‰åå•è¯ä¸²è”èµ·æ¥ï¼Œè®©æ•´ä¸ªæ¨¡å‹å…·æœ‰å¾ˆå¼ºçš„å…³è”æ€§ã€‚ æ¯”å¦‚: ä½ ç¬¬ä¸€ä¸ªy1å°±é¢„æµ‹é”™äº†ã€‚é‚£ä¹ˆä¹‹åçš„yå¾ˆå¯èƒ½éƒ½é¢„æµ‹é”™ã€‚ï¼ˆæˆ‘çš„ä¾‹å­æ˜¯ï¼šåŒè‰²çƒæ¦‚ç‡ï¼‰ ä½†æ˜¯: å‡å¦‚æˆ‘ä»¬é¢„æµ‹å¯¹äº†ã€‚é‚£è¯´æ˜æˆ‘ä»¬çš„æ¨¡å‹çš„æ•ˆæœï¼Œå·²ç»ç‰¹åˆ«å¥½äº†ï¼ˆåŒè‰²çƒæ¯ä¸ªçƒéƒ½é¢„æµ‹å¯¹äº†~ï¼‰ é‚£æˆ‘ä»¬å°±é è¿™xå’Œyå°±èƒ½æŠŠå‰åè¯­ä¹‰éƒ½å…³è”èµ·æ¥å—ï¼Ÿï¼Ÿï¼Ÿ ç­”ï¼š å½“ç„¶ä¸ä»…äºæ­¤ã€‚ ä½ åˆ«å¿˜äº†æˆ‘ä»¬è¿˜æœ‰è´¯ç©¿æ¨ªå‘çš„è¾“å…¥å•Šï¼Œå¦‚æœ€å¼€å§‹RNNå›¾çš„ a&lt;0&gt;. a&lt;1&gt; è¿™äº› æ—¢ç„¶ä½ è¯´y æ˜¯ä»è¯å…¸é€‰æ‹”å‡ºæ¥çš„è¯çš„æ¦‚ç‡å±æ€§ã€‚ é‚£ä¹ˆè¿™ä¸ªæ¦‚ç‡æ€ä¹ˆç®—ï¼Ÿ ç­”ï¼š è¿™é—®å¾—å¤ªå¥½äº†~~~ å‰é¢è¯´äº†: ä¸€èˆ¬éƒ½ä¼šé¢„å…ˆç»™æ•°æ®åš One-Hotæˆ– Embeddingç¼–ç ã€‚ æ‰€ä»¥æ•°æ®æ ¼å¼ä¸º: [0,0,....,1,...] # åªæœ‰ä¸€ä¸ªä¸º1 åŸºæœ¬ä¸Šæˆ‘ä»¬æœ€åç»™è¾“å‡ºéƒ½ä¼šå¥—ä¸€å±‚: softmaxæ¿€æ´»å‡½æ•°ï¼Œ softmaxåº”è¯¥çŸ¥é“å§ï¼še^x /(ex1+..+ex) æ‰€ä»¥: softmaxç»“æœå°±æ˜¯ä¸€ä¸ª å’ŒOne-Hotå½¢çŠ¶ä¸€æ ·çš„æ¦‚ç‡åˆ—è¡¨é›†åˆ: [.....,æœ€é«˜æ¦‚ç‡,...] softmaxçš„ç»“æœï¼ˆæ¦‚ç‡åˆ—è¡¨ï¼‰ :ï¼ˆä»£è¡¨ç€é¢„æµ‹ åœ¨è¯å…¸ä¸­æ¯ä¸€ä¸ªå•è¯çš„å¯èƒ½æ€§ï¼‰ é‚£ä¹ˆæŸå¤±å‡½æ•°æ€ä¹ˆç®—å‘¢ï¼Ÿï¼Ÿ ç­”ï¼šæ²¡é”™ï¼ŒæŸå¤±å‡½æ•°ä¹Ÿæ˜¯æˆ‘ä»¬æœ€å…³æ³¨çš„ã€‚ å‰é¢:æˆ‘ä»¬å·²ç»æ±‚å‡ºäº†softmaxå¯¹åº”çš„ç»“æœåˆ—è¡¨ (....,æœ€é«˜æ¦‚ç‡ï¼Œ...) æŸå¤±å‡½æ•°: æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯äº¤å‰ç†µã€‚ äº¤å‰ç†µçŸ¥é“å§: -ï¼ˆ Î£plogq ï¼‰ # pä¸ºçœŸå®å€¼One-hot, qä¸ºé¢„æµ‹å€¼ ç®€å•ä¸¾ä¸ªä¾‹å­: å‡å¦‚ softmaxé¢„æµ‹ç»“æœåˆ—è¡¨ä¸º :[0.01,0.35, 0.09, 0.55] # æ¸©é¦¨æç¤ºï¼Œsoftmaxå’Œä¸º1 ä½ çš„çœŸå®æ ‡ç­¾One-Hotåˆ—è¡¨ä¸º: [0, 0, 0, 1] é‚£ä¹ˆäº¤å‰ç†µæŸå¤±å°±ç­‰äº: -( 0log0.01 + 0log0.35 + 0log0.09 + 1*log0.55 ) = ... åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬ç¬¬ä¸€å±‚NNçš„è¾“å‡ºçš„æŸå¤±å‡½æ•°å°±å·²ç»è®¡ç®—å®Œæ¯•äº†ã€‚ è€Œæˆ‘ä»¬è®­ç»ƒæ•´ä¸ªç½‘ç»œéœ€è¦è®¡ç®—æ•´ä½“çš„æŸå¤±å‡½æ•°ã€‚ æ‰€ä»¥ï¼Œæˆ‘ä»¬éœ€è¦æŠŠä¸Šé¢çš„äº¤å‰ç†µæŸå¤±æ±‚å’Œï¼Œ ä¼˜åŒ–æŸå¤±ã€‚ æ¢¯åº¦çˆ†ç‚¸ &amp; æ¢¯åº¦æ¶ˆå¤± RNN çš„æ¢¯åº¦æ˜¯ç´¯ä¹˜ï¼Œæ‰€ä»¥NNå±‚å¦‚æœå¾ˆå¤šï¼Œå¯èƒ½ä¼šè¾¾åˆ° æŒ‡æ•°çº§çš„æ¢¯åº¦ã€‚ ä½ åº”è¯¥å¬è¿‡ä¸€ä¸ªå°å…³äºæŒ‡æ•°çš„å°æ¡ˆä¾‹å§~~ (å­¦å¦‚é€†æ°´è¡ŒèˆŸï¼Œä¸è¿›åˆ™é€€~) &gt;&gt;&gt; 1.01 ** 365 37.78343433288728 # æ¯å¤©è¿›æ­¥0.01 ï¼Œä¸€å¹´å¯ä»¥è¿›æ­¥è¿™äº› ï¼ˆå¯¹åº”æ¢¯åº¦çˆ†ç‚¸ï¼‰ &gt;&gt;&gt; 0.99 ** 365 0.025517964452291125 # æ¯å¤©é€€æ­¥0.01 ï¼Œ ä¸€å¹´å¯ä»¥æ²¦è½è‡³æ­¤ï¼ˆå¯¹åº”æ¢¯åº¦æ¶ˆå¤±ï¼‰ æ¢¯åº¦çˆ†ç‚¸ï¼š å°±æ˜¯ä¸Šé¢ä¾‹å­çš„åŸç†ã€‚ å°±ä¸å¤šè¯´äº†ã€‚ è§£å†³æ–¹å¼ï¼šæ¢¯åº¦è£å‰ª æ¢¯åº¦æ¶ˆå¤±ï¼š åŒä¸Šä¾‹ï¼Œ ä¸å¥½è§£å†³ï¼ˆäºæ˜¯LSTMç½‘ç»œå‡ºç°ï¼Œ å’ŒLSTMï¼‰ Tensorflow2.0ï¼ˆStableï¼‰ API import tensorflow.keras as tk # æ³¨æ„æˆ‘ç”¨çš„æ˜¯TF20æ ‡å‡†ç‰ˆï¼Œæ‰€ä»¥è¿™æ ·å¯¼å…¥ tk.layers.SimpleRNN( units=å•å…ƒå±‚, # unitså•å…ƒæ•°ï¼Œå¯¹åº”ç€ä½ æ¯ä¸ªå•è¯çš„ä¸ªæ•° return_sequences=False # é»˜è®¤å€¼å°±æ˜¯False ) GRU GRUæ¯”RNNçš„æ¯ä¸€å±‚çš„å¤šäº†ä¸€ä¸ª è®°å¿†ä¿¡æ¯(ç›¸å½“äºRNNçš„ h)ï¼Œè¿™ä¸ªè®°å¿†ä¿¡æ¯å°±åƒä¼ é€å¸¦ä¸€æ ·ï¼Œä¸€ç›´æµé€šå„å±‚RNN ç„¶åè¿˜å¤šäº†2ä¸ªé—¨ (ré—¨å’ŒUé—¨)ï¼Œ è¿™2ä¸ªé—¨å°±æ˜¯è´Ÿè´£æ§åˆ¶ï¼ˆæ˜¯å¦ä»ä¼ é€å¸¦ä¸Šå–è®°å¿†ï¼Œ ä¸”å–å¤šå°‘è®°å¿†ï¼‰ ####æ³¨æ˜ï¼š GRU åªæœ‰ä¸€ä¸ª c(æ¨ªå‘ï¼Œ ä¼ é€å¸¦) ï¼Œ æ²¡æœ‰h ç®€åŒ–ç‰ˆï¼ˆåªæœ‰Ué—¨ï¼‰ï¼š Cæ–°' = tanh( w @ [Cæ—§, xæ–°] + b ) # æ ¹æ®ä¼ åŠ¨å¸¦çš„æ—§ä¿¡æ¯ï¼Œ ç”Ÿäº§å‡º ä¼ é€å¸¦çš„æ–°ä¿¡æ¯ ué—¨ = sigmoid (w @ [cæ—§, xæ–°] + b) # ä¸€ä¸ªé—¨æ§å•å…ƒï¼Œèµ·åˆ°è¿‡æ»¤ä¿¡æ¯çš„ä½œç”¨ Cæ–° = ué—¨ * Cæ–°' + (1-ué—¨) * Cæ—§ # ç»è¿‡ué—¨æ§å•å…ƒçš„æ§åˆ¶è¿‡æ»¤åï¼Œ æœ€ç»ˆæ”¾åˆ°ä¼ é€å¸¦çš„ä¿¡æ¯ å¦‚æœ: ué—¨ä¸º1ï¼Œåˆ™ä¼ é€å¸¦ä¸Šå…¨æ˜¯æ–°ä¿¡æ¯ï¼ˆæ—§çš„å…¨å¿˜æ‰ï¼‰ å¦‚æœ: ué—¨ä¸º0ï¼Œåˆ™ä¼ é€å¸¦ä¸Šå…¨æ˜¯æ—§ä¿¡æ¯ï¼ˆæ–°çš„ä¸è¦ï¼‰ å¼ºè°ƒä¸€ä¸‹: æˆ‘ä¸æ–¹ä¾¿å†™å…¬å¼è´Ÿå·ï¼Œäºæ˜¯ç”¨äº† &quot;æ–°&quot;,&quot;æ—§&quot; ä»£æ›¿ æ–°: ä»£è¡¨å½“å‰ t æ—§: ä»£è¡¨å‰ä¸€æ—¶åˆ» t-1 å®Œæ•´ç‰ˆï¼ˆåŒæ—¶å…·æœ‰ré—¨å’Œué—¨ï¼‰ æ·»åŠ è¿™ä¸€è¡Œï¼š ré—¨ = sigmoid (w @ [cæ—§, xæ–°] + b) # å’Œä¸‹é¢çš„Ué—¨å‡ ä¹ç›¸ä¼¼ï¼Œåªä¸è¿‡æ¢äº†ä¸€ä¸‹æƒé‡å’Œåå·® Cæ–°' = tanh( w @ [ré—¨ @ Cæ—§, xæ–°] + b ) # ä¿®æ”¹è¿™ä¸€è¡Œ: Cæ—§ å˜ä¸º=&gt; ré—¨ @ Cæ—§ ué—¨ = sigmoid (w @ [cæ—§, xæ–°] + b) # ä¸€ä¸ªé—¨æ§å•å…ƒï¼Œèµ·åˆ°è¿‡æ»¤ä¿¡æ¯çš„ä½œç”¨ Cæ–° = ué—¨ * Cæ–°' + (1-ué—¨) * Cæ—§ # ç»è¿‡ué—¨æ§å•å…ƒçš„æ§åˆ¶è¿‡æ»¤åï¼Œ æœ€ç»ˆæ”¾åˆ°ä¼ é€å¸¦çš„ä¿¡æ¯ Tensorflow2.0ï¼ˆStableï¼‰ API import tensorflow.keras as tk # æ³¨æ„æˆ‘ç”¨çš„æ˜¯TF20æ ‡å‡†ç‰ˆï¼Œæ‰€ä»¥è¿™æ ·å¯¼å…¥ tk.layers.GRU( # å‚æ•°åŒä¸Šé¢RNNæˆ‘å°±ä¸è§£é‡Šäº† units=64, return_sequences=False # è¿™äº›å‚æ•°çœ‹ä¸‹é¢LSTMæˆ‘ä¼šè®²åˆ° ) LSTM LSTMå’ŒGRUå¾ˆåƒï¼Œä½†æ˜¯æ¯”GRUå¤æ‚ã€‚ LSTMç»“æ„åŒ…æ‹¬: ué—¨ï¼ˆæ›´æ–°é—¨ï¼‰+ fé—¨ï¼ˆé—å¿˜é—¨ï¼‰+ oé—¨ï¼ˆè¾“å‡ºé—¨ï¼‰ æ³¨æ˜ï¼š LSTM ä¸ä»…æœ‰ä¸ªä¼ é€å¸¦Cï¼ˆæ¨ªå‘ï¼‰ ï¼Œ ä»–è¿˜æœ‰ä¸ªRNNçš„ h ä¿¡æ¯ï¼ˆæ¨ªå‘ï¼‰ fé—¨ = sigmoid (w @ [cæ—§, xæ–°] + b) # å’Œä¸‹é¢çš„Ué—¨å‡ ä¹ç›¸ä¼¼ï¼Œåªä¸è¿‡æ¢äº†ä¸€ä¸‹æƒé‡å’Œåå·® oé—¨ = sigmoid (w @ [cæ—§, xæ–°] + b) # å’Œä¸‹é¢çš„Ué—¨å‡ ä¹ç›¸ä¼¼ï¼Œåªä¸è¿‡æ¢äº†ä¸€ä¸‹æƒé‡å’Œåå·® Cæ–°' = tanh( w @ [Cæ—§, xæ–°] + b ) # æ³¨æ„ï¼Œè¿™é‡Œæ²¡æœ‰ré—¨äº† ué—¨ = sigmoid (w @ [cæ—§, xæ–°] + b) # ä¸€ä¸ªé—¨æ§å•å…ƒï¼Œèµ·åˆ°è¿‡æ»¤ä¿¡æ¯çš„ä½œç”¨ Cæ–° = ué—¨ * Cæ–°' + fé—¨ * Cæ—§ # &quot;(1-ué—¨)&quot; æ¢æˆäº† fé—¨ h = oé—¨ * tanh( Cæ–° ) Tensorflow2.0ï¼ˆStableï¼‰ API import tensorflow.keras as tk # æ³¨æ„æˆ‘ç”¨çš„æ˜¯TF20æ ‡å‡†ç‰ˆï¼Œæ‰€ä»¥è¿™æ ·å¯¼å…¥ keras.layers.LSTM( units=64, return_state=True # å å‘ï¼Œä¸‹é¢å‰–æ return_sequences=False # å å‘ï¼Œä¸‹é¢æºç å‰–æ recurrent_initializer='glorot_uniform', # å‡åŒ€åˆ†å¸ƒçš„æƒé‡å‚æ•°åˆå§‹åŒ– # stateful=True, # APIæ–‡æ¡£ï¼šè‹¥ä¸ºTrue,åˆ™æ¯ä¸€æ‰¹æ ·æœ¬çš„stateçš„çŠ¶æ€ï¼Œéƒ½ä¼šç»§ç»­èµ‹äºˆä¸‹ä¸€æ‰¹æ ·æœ¬ ) return_state å’Œ return_sequences è¿™ä¸¤ä¸ªå‚æ•°åˆ°åº•æœ‰ä»€ä¹ˆç”¨ï¼Ÿï¼Ÿï¼Ÿ æˆ‘çš„å¦ä¸€ç¯‡æ–‡ç« å•ç‹¬æºç åˆ†æè¿™ä¸¤ä¸ªå‚æ•°ï¼šhttps://segmentfault.com/a/1190000020603328 æ€»ç»“å¯¹æ¯” GRU å’Œ LSTM GRUæœ‰2ä¸ªé—¨: ué—¨ å’Œ ré—¨ LSTMæœ‰3ä¸ªé—¨: ué—¨ å’Œ fé—¨ å’Œ oé—¨ GRUæœ‰ä¸€ä¸ªC: # å°±æœ‰ä¸€æ¡ä¼ é€å¸¦c, ä»–çš„å‰åå•å…ƒä¿¡æ¯ä»…é è¿™ä¸€æ¡ä¼ é€å¸¦æ¥æ²Ÿé€šï¼ˆèˆå¼ƒä¸ä¿ç•™ï¼‰ LSTMæœ‰ä¸€ä¸ªCå’Œä¸€ä¸ªh: # ä¸ä»…æœ‰ä¼ é€å¸¦c, è¿˜æœ‰hï¼Œ ä»–çš„å‰åå•å…ƒä¿¡æ¯ é  c å’Œ h è”åˆæ²Ÿé€šã€‚ å†è¯´ä¸€ä¸‹æ¯ä¸ªé—¨æ§å•å…ƒ: ä¸ç®¡ä½ æ˜¯ä»€ä¹ˆé—¨ï¼Œ éƒ½æ˜¯ç”± Sigmoid() åŒ…è£¹ç€çš„ã€‚ æ‰€ä»¥: è¯´æ˜¯ 0 å’Œ 1 ï¼Œ ä½†ä¸¥æ ¼æ„ä¹‰ä¸Šï¼Œåªæ˜¯æ— ç©·æ¥è¿‘ã€‚ä½†æ˜¯å¾®ä¹å…¶å¾®ï¼Œæ‰€ä»¥æˆ‘ä»¬ç†è§£ä¸ºè¿‘ä¼¼ç›¸ç­‰0å’Œ1 RNN-LSTM-GRUæ‹“å±• åŒå‘ï¼ˆBidirectionï¼‰ é¦–å…ˆè¯´æ˜: åŒå‘æ¨¡å‹ï¼Œå¯¹äº RNN/LSTM/GRU å…¨éƒ¨éƒ½é€‚ç”¨ ç”±äºå•å‘çš„æ¨¡å‹ï¼Œä¸èƒ½å…³è”ä¹‹åä¿¡æ¯ã€‚æ¯”å¦‚ï¼šä½ åªèƒ½æ ¹æ®ä¹‹å‰çš„å•è¯é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚ è€ŒåŒå‘çš„æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®å‰åä¸Šä¸‹æ–‡çš„è¯­å¢ƒï¼Œæ¥é¢„æµ‹å½“å‰çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚ æˆ–è€…ä¸¾ä¸€ä¸ªæ›´ç›´ç™½çš„ä¾‹å­ï¼ˆæˆ‘è‡ªå·±è®¤ä¸ºï¼‰ï¼š æ¯”å¦‚è¯´: ä½ åšè‹±è¯­å®Œå‹å¡«ç©ºé¢˜ï¼Œ ä½ æ˜¯ä¸æ˜¯ éœ€è¦ æŠŠç©ºç¼ºéƒ¨åˆ†çš„ å‰é¢ å’Œ åé¢ éƒ½å¾—è¯»ä¸€éï¼Œæ‰èƒ½å¡«ä¸Šã€‚ å•å‘ä¸åŒå‘ç»“æ„å¯¹æ¯”å¦‚ä¸‹ï¼š å•å‘: 1 -&gt; 2 -&gt; 3 -&gt; 4 åŒå‘: 1 -&gt; 2 -&gt; 3 -&gt; 4 | 1 &lt;- 2 &lt;- 3 &lt;- 4 æ³¨æ„: ä¸Šä¸‹å¯¹é½ï¼Œä»£è¡¨ä¸€å±‚ã€‚ Tensorflow2.0ï¼ˆStableï¼‰ API import tensorflow.keras as tk # æ³¨æ„æˆ‘ç”¨çš„æ˜¯TF20æ ‡å‡†ç‰ˆï¼Œæ‰€ä»¥è¿™æ ·å¯¼å…¥ tk.layers.Bidirectional( # å°±åœ¨ä¸Šä¸Šé¢é‚£äº›APIçš„åŸºç¡€ä¸Š,å¤–é¢åµŒå¥—ä¸€ä¸ª è¿™ä¸ªå±‚å³å¯ã€‚ tk.layers.GRU( units=64, return_sequences=False ) ), æ¨¡å‹æ·±å±‚å †å ï¼ˆçºµå‘å †å ï¼‰ é¦–å…ˆè¯´æ˜: å±‚å æ¨¡å‹å¯¹äº RNN/LSTM/GRU åŒæ ·å…¨éƒ¨éƒ½é€‚ç”¨ ä¹‹å‰å•å±‚å•å‘æ¨¡å‹æ˜¯è¿™ç§ç»“æ„ 1 -&gt; 2 -&gt; 3 è®¡ç®—å…¬å¼æ˜¯: å•å…ƒ = tanh ( W @ (x, hå·¦) ) è€Œå¤šå±‚å•å‘æ˜¯è¿™ç§ç»“æ„ï¼ˆæˆ‘ä»¬ä»¥2å±‚ä¸ºä¾‹ï¼‰ï¼š y1 y2 y3 è¾“å‡ºå±‚ ^ ^ ^ | | | 7 -&gt; 8 -&gt; 9 äºŒå±‚å•å…ƒ ^ ^ ^ | | | 4 -&gt; 5 -&gt; 6 ä¸€å±‚å•å…ƒ ^ ^ ^ | | | x1-&gt; x2 -&gt;x3 è¾“å…¥å±‚ ä½  å¥½ å•Š è®¡ç®—å…¬å¼æ˜¯ï¼š ï¼ˆæˆ‘å†™çš„å¯èƒ½åªæŒ‰è‡ªå·±çš„æ„æ€äº†~ï¼‰ ä¸€å±‚æ¯ä¸ªå•å…ƒ = tanh ( W @ (x, hå·¦) ) # å› ä¸ºæ˜¯ç¬¬ä¸€å±‚å˜›ï¼šæ‰€ä»¥è¾“å…¥ä¸º x å’Œ å·¦è¾¹å•å…ƒh äºŒå±‚æ¯ä¸ªå•å…ƒ = tanh ( W @ (hä¸‹, hå·¦) ) # ç¬¬äºŒå±‚å°±æ²¡æœ‰xäº†:è€Œæ˜¯ä¸‹è¾¹å•å…ƒh å’Œ å·¦è¾¹å•å…ƒh è¯åµŒå…¥(Word Embedding) å•è¯ä¹‹é—´ç›¸ä¼¼åº¦è®¡ç®— c1 @ c2 ä½™å¼¦å®šç†ï¼Œæ±‚ cosÎ¸ = ------------------ ||c1|| * ||c2|| æˆ–è€…ä½ å¯ä»¥ä½¿ç”¨æ¬§æ°è·ç¦»ã€‚ åŸå§‹è¯åµŒå…¥å¹¶è®­ç»ƒ å‡å¦‚æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå¥å­çš„ä¸€éƒ¨åˆ†æ¥é¢„æµ‹ï¼Œè¿™ä¸ªå¥å­çš„æœ€åä¸€ä¸ªå•è¯ã€‚ æŠŠè¯å…¸çš„æ¯ä¸ªè¯åšæˆOne-Hotä¾¿æ˜¯å½¢å¼ï¼Œè®°ä½œçŸ©é˜µ O éšæœºé«˜ç»´æƒé‡çŸ©é˜µï¼Œ è®°ä¸º E E @ O çŸ©é˜µä¹˜ç§¯åè®°ä¸ºè¯å‘é‡ W å¯è§å¦‚ä¸‹æ¡ˆä¾‹ï¼š å¦‚æœ: æˆ‘ä»¬åˆ†è¯åè¯å…¸æ€»å¤§å°ä¸º1000 é‚£ä¹ˆ: ä»–çš„ One-Hot çŸ©é˜µå½¢çŠ¶ä¸º [6, 1000] ï¼ˆå‡å¦‚æˆ‘ä»¬è¿™é‡Œé€šè¿‡å¥å­6ä¸ªè¯æ¥é¢„æµ‹æœ€åä¸€ä¸ªè¯ï¼‰ å¹¶ä¸”: éšæœºé«˜ç»´æƒé‡çŸ©é˜µ å½¢çŠ¶ä¸º [1000, 300] ï¼ˆæ³¨æ„ï¼Œè¿™ä¸ª300æ˜¯ç»´åº¦ï¼Œå¯è‡ªè¡Œè°ƒæ•´é€‰æ‹©ï¼‰ æ³¨æ„: ä¸Šé¢æƒé‡çŸ©é˜µæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œ åé¢è®­ç»ƒè°ƒèŠ‚çš„ã€‚ æœ€å: E @ O åå¾—åˆ°è¯å‘é‡W çš„å½¢çŠ¶ä¸º [6, 300] é€è¿›NN(æ‰“æˆ1000ç±») ä½œä¸ºè¾“å‡º åŠ ä¸€å±‚ Softmax ï¼ˆç®—å‡º1000ä¸ªå•è¯çš„æ¦‚ç‡ï¼‰ ä½œä¸ºæœ€ç»ˆè¾“å‡ºy_predict y_predict ä¸ yçœŸæ­£çš„å•è¯æ ‡ç­¾ï¼ˆone-hotåçš„ï¼‰ åšäº¤å‰ç†µloss ä¼˜åŒ–lossï¼Œå¼€å§‹è®­ç»ƒã€‚ Word2Vec çš„ skip-grams(ä¸æ˜¯å¤ªæ‡‚ï¼Œ Pass) è¯´ä¸‹ä¸ªäººçš„ç†è§£ï¼Œå¯èƒ½ä¸å¯¹ skip-gramsï¼š æ‹¿å‡ºä¸­é—´ ä¸€ä¸ªè¯ï¼Œæ¥é¢„æµ‹è‹¥å¹²ï¼ˆè¿™æ˜¯è¯è·ï¼Œè‡ªå·±ç»™å®šï¼‰ä¸Šä¸‹æ–‡çš„å•è¯ã€‚ ä¾‹å­å¦‚ä¸‹ï¼š seq = ä»Šå¤©å»åƒé¥­ ç»™å®šå•è¯ æ ‡ç­¾å€¼ï¼ˆy_trueï¼‰ å» ä»Š å» å¤© å» åƒ å» é¥­ è®­ç»ƒè¿‡ç¨‹å°±æ˜¯ä¸Šé¢è¯´è¿‡çš„å°èŠ‚ &quot;åŸå§‹è¯åµŒå…¥å¹¶è®­ç»ƒ&quot;ï¼Œä½ åªéœ€æŠŠ y_trueæ”¹ä¸º &quot;ä»Š&quot;,&quot;å¤©&quot;,&quot;åƒ&quot;,&quot;é¥­&quot;è®­ç»ƒå³å¯ã€‚ Word2Vec é™¤äº† skip-grams, è¿˜æœ‰ CBOW æ¨¡å‹ã€‚ å®ƒçš„ä½œç”¨æ˜¯ ç»™å®šä¸Šä¸‹æ–‡ï¼Œæ¥é¢„æµ‹ä¸­é—´çš„è¯ã€‚ æ®è¯´æ•ˆç‡ç­‰æŸç§åŸå› (softmaxè®¡ç®—æ…¢ï¼Œå› ä¸ºåˆ†æ¯å·¨å¤§)ï¼Œè¿™ä¸¤ä¸ªéƒ½æ²¡çœ‹ã€‚ï¼ˆPass~ï¼‰ è´Ÿé‡‡æ ·ï¼ˆNegative Samplingï¼‰ è§£å†³Word2Vec çš„ softmaxè®¡ç®—æ…¢ã€‚ è´Ÿé‡‡æ ·è¯´æ˜ï¼ˆå‡å¦‚æˆ‘ä»¬æœ‰1000é•¿åº¦çš„è¯å…¸ï¼‰ï¼š ä»ä¸Šä¸‹æ–‡ï¼ˆæŒ‡å®šè¯è·ï¼‰: éšæœºï¼Œé€‰æ‹©ä¸€ä¸ªæ­£æ ·æœ¬å¯¹ï¼Œnä¸ªè´Ÿæ ·æœ¬å¯¹ï¼ˆ5-10ä¸ªå³å¯ï¼‰ ä¸»è¦æœºåˆ¶: å°† Word2Vecçš„ softmaxï¼ˆ1000åˆ†ç±»ï¼‰ æ¢æˆ 1000ä¸ª sigmoidåšäºŒåˆ†ç±»ã€‚ å› ä¸º: æ˜¯éšæœºé‡‡æ ·ï¼ˆå‡è®¾ï¼Œé‡‡æ ·1ä¸ªæ­£æ ·æœ¬ å’Œ 5ä¸ªè´Ÿæ ·æœ¬ï¼‰ã€‚ æ‰€ä»¥: 1000ä¸ª sigmoidäºŒåˆ†ç±»å™¨ï¼Œæ¯æ¬¡åªç”¨åˆ° 6 ä¸ªå¯¹åº”åˆ†ç±»å™¨ï¼ˆ1ä¸ªæ­£æ ·æœ¬åˆ†ç±»å™¨ï¼Œ5ä¸ªè´Ÿæ ·æœ¬åˆ†ç±»å™¨ï¼‰ è´Ÿé‡‡æ ·ï¼Œæ ·æœ¬éšæœºé€‰æ‹©å…¬å¼ï¼š å•ä¸ªè¯é¢‘ ^ (3/4) ----------------- Î£(æ‰€æœ‰è¯é¢‘ ^ (3/4)) ","link":"https://cythonlin.github.io/post/ai-greater-cnn-rnnng/"},{"title":"AI => TF20çš„LSTMä¸GRU(return_sequencesä¸return_state)å‚æ•°æºç ","content":"å‰è¨€ æ¸©é¦¨æç¤ºï¼š æœ¬æ–‡åªé€‚ç”¨äº: äº†è§£LSTM å’Œ GRUçš„ç»“æ„ï¼Œä½†æ˜¯ä¸æ‡‚Tensorflow20ä¸­LSTMå’ŒGRUçš„å‚æ•°çš„äºº) é¢å¤–è¯´æ˜ çœ‹æºç ä¸ç­‰äºé«˜å¤§ä¸Šã€‚ å½“ä½ å„ç§åšå®¢ç¿»çƒ‚ï¼Œå‘ç°å†…å®¹ä¸æ˜¯äº’ç›¸å¼•ç”¨ï¼Œå°±æ˜¯ç›¸äº’&quot;å€Ÿé‰´&quot;ã€‚ã€‚ã€‚ä¸”ç»æœ›æ—¶ã€‚ ä½ å¯èƒ½ä¼šç¿»ç¿»æ–‡æ¡£ï¼Œå…¶å®æœ‰äº›æ–‡æ¡£å†™çš„å¹¶ä¸æ˜¯å¾ˆè¯¦ç»†ã€‚ è¿™æ—¶ï¼Œçœ‹æºç æ˜¯ä½ æœ€å¥½çš„ç†è§£æ–¹å¼ã€‚ï¼ˆLSTM å’Œ GRU éƒ¨åˆ†æºç è¿˜æ˜¯æ¯”è¾ƒå¥½çœ‹çš„ï¼‰ æ ‡é¢˜å†™ä¸ä¸‹äº†: TF20 ==&gt; Tensorflow2.0ï¼ˆStableï¼‰ tk ===&gt; tensorflow.keras LSTM å’Œ GRU å·²ç»æ”¾åœ¨ tk.layersæ¨¡å—ä¸­ã€‚ return_sequences = True return_state = True è¿™ä¸¤ä¸ªå‚æ•°æ˜¯ä½¿ç”¨ç‡æœ€é«˜çš„ä¸¤ä¸ªäº†ï¼Œ å¹¶ä¸”LSTM å’Œ GRU ä¸­éƒ½æœ‰ã€‚ é‚£å®ƒä»¬ç©¶ç«Ÿæ˜¯ä»€ä¹ˆæ„æ€å‘¢??? æ¥ï¼Œå¼€å§‹å§ï¼ è¿›å…¥æºç æ–¹å¼ï¼š import tensorflow.keras as tk tk.layers.GRU() tk.layers.LSTM() ç”¨pycharm ctrl+å·¦é”® ç‚¹è¿›æºç å³å¯~~~ LSTMæºç  æˆ‘æˆªå–äº†éƒ¨åˆ†ä¸»å¹²æºç ï¼š ... ... states = [new_h, new_c] # å¾ˆæ˜¾ç„¶ï¼Œç¬¬ä¸€ä¸ªæ˜¯æ¨ªå‘çŠ¶æ€h, å¦ä¸€ä¸ªæ˜¯è®°å¿†ç»†èƒc if self.return_sequences: # å¦‚æœreturn_sequencesè®¾ä¸ºTrue output = outputs # åˆ™è¾“å‡ºå€¼ä¸ºæ‰€æœ‰LSTMå•å…ƒçš„ è¾“å‡ºyï¼Œæ³¨æ„è¿˜æ²¡return else: # å¦‚æœreturn_sequencesè®¾ä¸ºFalse output = last_output # åˆ™åªè¾“å‡ºLSTMæœ€åä¸€ä¸ªå•å…ƒçš„ä¿¡æ¯, æ³¨æ„è¿˜æ²¡return if self.return_state: # å¦‚æœreturn_stateè®¾ä¸ºTrue return [output] + list(states) # åˆ™æœ€ç»ˆè¿”å› ä¸Šé¢çš„output + [new_h, new_c] else: # å¦‚æœreturn_stateè®¾ä¸ºFalse return output # åˆ™æœ€ç»ˆè¿”å› åªè¿”å›ä¸Šé¢çš„output å°æŠ€å·§: ç„å‡† return å…³é”®è¯ã€‚ ä½ å°±ä¼šéå¸¸æ¸…æ™°ï¼Œå®ƒä¼šè¿”å›ä»€ä¹ˆäº†ã€‚ GRUæºç  ... ... ######## æˆ‘ä»¬ä¸»è¦çœ‹è¿™ä¸€éƒ¨åˆ† ######################################### last_output, outputs, runtime, states = self._defun_gru_call( inputs, initial_state, training, mask) ##################################################################### ... ... ######### ä¸‹é¢ä¸ç”¨çœ‹äº†ï¼Œ è¿™ä¸‹é¢ä»£ç å’Œ LSTMæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ ################### if self.return_sequences: output = outputs else: output = last_output if self.return_state: return [output] + list(states) else: return output ç°åœ¨æˆ‘ä»¬çš„å¯»æ‰¾å…³é”®ç‚¹åªåœ¨äºï¼Œ states æ˜¯æ€ä¹ˆå¾—åˆ°çš„ï¼Ÿï¼Ÿï¼Ÿ ä½ ç»§ç»­ç‚¹è¿›å» &quot;self._defun_gru_call&quot; è¿™ä¸ªå‡½æ•°çš„æºç ï¼Œ ä½ ä¼šå‘ç° states å°±ç›´æ¥æš´éœ²åœ¨é‡Œé¢ states = [new_h] return ..., states ç°åœ¨æºç å‡ ä¹å…¨éƒ¨åˆ†æå®Œæ¯•ã€‚ æˆ‘ä»¬å›å¤´æ€è€ƒæ€»ç»“ä¸€ä¸‹ï¼š LSTM å’Œ GRU ä¸­çš„ return_sequences å’Œ return_state éƒ¨åˆ†çš„æºç æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼ï¼ï¼ return_sequences: åªç®¡ç† outputå˜é‡çš„èµ‹å€¼ï¼Œï¼ˆæœ€åä¸€ä¸ªå•å…ƒ æˆ– å…¨éƒ¨å•å…ƒï¼‰ return_stateï¼š è´Ÿè´£è¿”å› outputå˜é‡ï¼Œå¹¶ä¸”æŒ‰æ¡ä»¶å†³å®šæ˜¯å¦å†ä¸€å¹¶å¤šè¿”å›ä¸€ä¸ª stateså˜é‡ è¿›è€Œæˆ‘ä»¬æŠŠé—®é¢˜å…³æ³¨ç‚¹è½¬æ¢åˆ° outputå˜é‡ï¼Œ å’Œ stateså˜é‡ï¼š LSTM å’Œ GRU çš„ outputå˜é‡: å¤§è‡´ç›¸ä¼¼ï¼Œä¸ç”¨ç®¡ã€‚ LSTM å’Œ GRU çš„ ststeså˜é‡ï¼š LSTMçš„ stateså˜é‡: [H, C] # å¦‚æœä½ äº†è§£LSTMçš„ç»“æ„ï¼Œçœ‹åˆ°è¿™é‡Œä½ åº”è¯¥å¾ˆæ¸…æ¥šï¼ŒLSTMæœ‰Cå’ŒH GRUçš„ stateså˜é‡: [H] # å¦‚æœä½ äº†è§£GRUçš„ç»“æ„ï¼Œçœ‹åˆ°è¿™é‡Œä½ åº”è¯¥å¾ˆæ¸…æ¥šï¼ŒGRUå°±ä¸€ä¸ªH æœ€ç»ˆä½¿ç”¨å±‚æ€»ç»“ï¼š LSTM: æœ‰å››ç§ç»„åˆä½¿ç”¨ï¼š return_sequences = False ä¸” return_state = False (é»˜è®¤) è¿”å›å€¼: åªè¿”å› æœ€åä¸€ä¸ª LSTMå•å…ƒçš„è¾“å‡ºY return_sequences = True ä¸” return_state = False è¿”å›å€¼: åªè¿”å› æ‰€æœ‰ LSTMå•å…ƒçš„è¾“å‡ºY return_sequences = False ä¸” return_state = True è¿”å›å€¼: è¿”å›æœ€åä¸€ä¸ªLSTMå•å…ƒçš„è¾“å‡ºY å’Œ C + H ä¸¤ä¸ªï¼ˆéšå±‚ä¿¡æ¯ï¼‰ return_sequences = True ä¸” return_state = True è¿”å›å€¼: è¿”å›æ‰€æœ‰LSTMå•å…ƒçš„è¾“å‡ºY å’Œ C + H ä¸¤ä¸ªï¼ˆéšå±‚ä¿¡æ¯ï¼‰ (é€‚ç”¨äºAtention) GRUï¼š æœ‰å››ç§ç»„åˆä½¿ç”¨ï¼š return_sequences = False ä¸” return_state = False (é»˜è®¤) è¿”å›å€¼: åŒLSTM return_sequences = True ä¸” return_state = False è¿”å›å€¼: åŒLSTM return_sequences = False ä¸” return_state = True è¿”å›å€¼: è¿”å› æœ€åä¸€ä¸ª LSTMå•å…ƒçš„è¾“å‡ºY å’Œ ä¸€ä¸ªHï¼ˆéšå±‚ä¿¡æ¯ï¼‰ return_sequences = True ä¸” return_state = True è¿”å›å€¼: è¿”å› æ‰€æœ‰ LSTMå•å…ƒçš„è¾“å‡ºY å’Œ ä¸€ä¸ªHï¼ˆéšå±‚ä¿¡æ¯ï¼‰ (é€‚ç”¨äºAtention) ","link":"https://cythonlin.github.io/post/ai-greater-tf20-de-lstm-yu-grureturn_sequences-yu-return_statecan-shu-yuan-ma/"},{"title":"AI => DeepLearning+Metricsï¼ˆNgï¼‰","content":"å‰è¨€ çœ‹Andrew Ngè§†é¢‘ï¼Œæ€»ç»“çš„å­¦ä¹ å¿ƒå¾—ã€‚ è™½ç„¶æœ¬ç¯‡æ–‡ç« å¯èƒ½ä¸æ˜¯é‚£ä¹ˆç»†è‡´å…¥å¾®ï¼Œç”šè‡³å¯èƒ½æœ‰äº†è§£åå·®ã€‚ ä½†æ˜¯ï¼Œæˆ‘å–œæ¬¢ç”¨æ›´ç›´ç™½çš„æ–¹å¼å»ç†è§£çŸ¥è¯†ã€‚ æ•°æ®åˆ’åˆ† ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ•°æ®çš„åˆ’åˆ† ä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¸€èˆ¬éƒ½æ˜¯å°è§„æ¨¡æ•°æ®ï¼ˆå‡ ä¸‡æ¡ï¼‰ é‚£ä¹ˆå¯ä»¥ è®­ç»ƒé›†ï¼šéªŒè¯é›†ï¼šæµ‹è¯•é›† = 6:2:2 è‹¥æ˜¯å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ ä¸€èˆ¬éƒ½æ˜¯å¤§è§„æ¨¡æ•°æ®ï¼ˆå‡ ç™¾ä¸‡æ¡ï¼‰ è®­ç»ƒé›†: éªŒè¯æœºï¼šæµ‹è¯•é›† = 9:0.5:0.5 åˆ’åˆ† éªŒè¯é›† å¯ä»¥è¿‡æ—©çš„ä¸ºæˆ‘ä»¬é¢„æµ‹ æŒ‡æ ‡å’Œç²¾åº¦ åå·® ä¸ æ–¹å·® é«˜åå·®ï¼š è®­ç»ƒé›†å’Œæµ‹è¯•é›† loss éƒ½æ¯”è¾ƒé«˜ ï¼ˆæ¯”äººé¢„æµ‹çš„lossé«˜å¾ˆå¤šï¼‰ ï¼ˆæ¬ æ‹Ÿåˆï¼‰ é«˜æ–¹å·®ï¼š è®­ç»ƒé›†Lossä½ï¼Œ æµ‹è¯•é›† Lossé«˜ã€‚ æ‰€ä»¥è®­ç»ƒé›†å’Œæµ‹è¯•é›† lossç›¸å·®å¤ªå¤§ï¼Œ ä¹Ÿæˆä¸ºï¼ˆè¿‡æ‹Ÿåˆï¼‰ é˜²æ­¢è¿‡æ‹Ÿåˆçš„å‡ ç§æ–¹æ³• æŸå¤±å‡½æ•° (æƒ©ç½šé¡¹ç³»æ•°) æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰ å¯åˆ†ä¸¤ç§ ï¼ˆL1æ­£åˆ™åŒ–æƒ©ç½š å’Œ L2æ­£åˆ™åŒ–æƒ©ç½šï¼‰ä¸‹é¢åªä»¥ L2ä¸ºä¾‹ï¼ŒL2ç”¨çš„ä¹Ÿæ˜¯æ¯”è¾ƒå¤šçš„ï¼‰ æ­£åˆ™åŒ–ç³»æ•°å…¬å¼ï¼š loss = ... new_loss = loss + (Î»/2m) * w^2 w = w - learning_rate * æ¢¯åº¦ ä¸Šé¢å…¬å¼çš„å•è°ƒå˜æ¢è§£é‡Šï¼š æ±‚æ¢¯åº¦çš„æ—¶å€™ Î»è¶Šå¤§ï¼Œ new_lossè¶Šå¤§ï¼Œ æ±‚å¾—çš„æ¢¯åº¦è¶Šå¤§ï¼ˆæ­£æ¯”ï¼‰ w å‡å»çš„å€¼å°±è¶Šå¤§ã€‚ wå˜å¾—å°±è¶Šå°ã€‚ w è¶Šå°ï¼Œ ä¸€å®šç¨‹åº¦ä¸Šç‰¹å¾å°±è¡°å‡äº†è®¸å¤šã€‚ å°±æœ‰æ•ˆçš„æ”¾ç½®äº†è¿‡æ‹Ÿåˆå“¦ å¯¹åº”APIï¼ˆæœ‰ä¸¤ç§æ–¹å¼ï¼‰ï¼š L1 = keras.regularizers.l2(0.01) # TF2 å½“ä½œ keras çš„ Layerså®šä¹‰æ¥ä½¿ç”¨ L1 = tf.nn.l2_loss(w_b) # çœ‹åˆ°é‡Œé¢ä¼ é€’ wå’Œbäº†å§ï¼Œ è¿™ç§æ˜¯åæ‰‹åŠ¨æ–¹å¼å®ç°çš„API å¦‚æœä½ æƒ³ä½¿ç”¨æ‰‹æ’•å®ç°ï¼Œä¸‹é¢æœ‰ä¸ªä¾‹å­ï¼ˆä¼ªä»£ç ï¼‰ï¼š for with tf.GradientTape() as tape: ... loss_reg = [tf.nn.l2_loss(w_b) for w_b in model.trainable_variables] # [w1,b1,w2,b2] print(tf.reduce_sum(loss_reg)) # tf.Tensor(2.98585, shape=(), dtype=float32) # å°±æ˜¯è¿™ä¸ªå½¢çŠ¶ loss = loss + loss_reg å¦ä¸€ç§æ­£åˆ™åŒ–æ–¹å¼ï¼ˆregularizationï¼‰ -- DropOut &quot;éšæœº&quot;å‰ªæï¼Œ ç•¥ï¼Œ TFæ¡†æ¶ä¸€æ­¥åˆ°ä½ è¿˜æœ‰ä¸€ç§é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹å¼ï¼ˆæ•°æ®å¢å¼ºï¼‰ é˜²æ­¢è¿‡æ‹Ÿåˆçš„å¦ä¸€ç§æ–¹å¼ï¼Œå°±æ˜¯éœ€è¦çš„å¤§é‡çš„æ•°æ®æ¥æ”¯æ’‘ï¼Œé‚£ä¹ˆæ•°æ®å°±é‚£ä¹ˆç‚¹ï¼Œæ€ä¹ˆåŠï¼Ÿ æ•°æ®å¢å¼ºï¼ˆ å…¶åŸç†å°±æ˜¯å¢å¤§æ ·æœ¬æ•°é‡ï¼Œå°å¹…åº¦ç¿»è½¬ç­‰ï¼‰ æŸç§ç¨‹åº¦ä¸Šï¼Œå°±æ˜¯å¢åŠ äº†æ ·æœ¬ã€‚ æœ€åä¸€ç§é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³• ï¼ˆearlystopping ï¼‰ earlystopping ï¼ˆtf.keras.callbackæ¨¡å—ä¸­ï¼Œæœ‰è¿™ä¸ª callbackå‡½æ•°ï¼Œæ³¨é‡Šéƒ¨åˆ†æœ‰è§£é‡Šï¼‰ callbacks = [ keras.callbacks.TensorBoard(logdir), keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=True), # åœ¨è¿™é‡Œ keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3) # éªŒè¯é›†ï¼Œæ¯æ¬¡éƒ½ä¼šæå‡ï¼Œå¦‚æœæå‡ä¸åŠ¨äº†ï¼Œå°äºè¿™ä¸ªmin_deltaé˜ˆå€¼ï¼Œåˆ™ä¼šè€æ€§ç­‰å¾…5æ¬¡ã€‚ # 5æ¬¡è¿‡åï¼Œè¦æ˜¯è¿˜æå‡è¿™ä¹ˆç‚¹ã€‚å°±æå‰ç»“æŸã€‚ ] æ•°æ®é¢„å¤„ç† æ ‡å‡†åŒ– å’Œ å½’ä¸€åŒ–èƒ½èµ·åˆ°ä»€ä¹ˆä½œç”¨ï¼š åšäº†æ ‡å‡†åŒ– å’Œ å½’ä¸€åŒ– å¯ä»¥ è®©å‡½æ•°æ”¶æ•›çš„ æ›´å¿«é€Ÿï¼ˆæ¢¯åº¦ä¸‹é™çš„å¿«ï¼‰ å‚è€ƒ ï¼ˆåœ†å½¢ä¸‹é™çš„å¿«ï¼Œ å’Œ æ¤­åœ†ä¸‹é™çš„æ…¢ï¼‰ å…¶æ¬¡ï¼Œåœ¨ç¥ç»ç½‘ç»œä¸­,BNå±‚è¿˜æœ‰é¢å¤–çš„æ•ˆæœã€‚æ¯å±‚ç½‘ç»œçš„ä¸åŒå‚æ•°ï¼Œå¯èƒ½ä¼šå¯¼è‡´&quot;æ•°æ®åˆ†å¸ƒ&quot;æ•£ä¹±ã€å˜å½¢ å› æ­¤ï¼ŒBNå¯ä»¥æœ‰æ•ˆ é˜²æ­¢æ•°æ®åˆ†å¸ƒå˜å½¢ã€‚ ï¼ˆå…¶å®è¯´ç™½äº†ä¹Ÿæ˜¯&quot;åŠ é€Ÿå‡½æ•°æ”¶æ•›&quot; ,åŠ é€ŸNNè®­ç»ƒï¼‰ æ³¨æ„ç‚¹ è®­ç»ƒé›† å’Œ æµ‹è¯•é›†çš„æ ·æœ¬ç‰¹å¾ ï¼ˆ&quot;è¦ä¹ˆéƒ½åšå¤„ç†ï¼Œè¦ä¹ˆéƒ½ä¸åšå¤„ç†&quot;ï¼‰ï¼ˆå°±æ˜¯ç›¸åŒå¾…é‡çš„æ„æ€ã€‚ã€‚ã€‚ï¼‰ ä¸“ä¸šç‚¹å«åš ï¼š&quot;ä¿è¯è®­ç»ƒé›† å’Œ æµ‹è¯•é›† ç›¸åŒåˆ†å¸ƒ&quot; æ•°æ® éšæœºåˆ†å¸ƒæœ‰ä»€ä¹ˆå½±å“ï¼ˆAndrew ngè§£é‡Šï¼‰ï¼Ÿ å‡å¦‚è®­ç»ƒé›†çš„æ•°æ®åˆ†å¸ƒ è®­ç»ƒçš„ç›®æ ‡æ˜¯æ­£ä¸­é¶å¿ƒã€‚ è€Œé¢„æµ‹æ—¶ï¼Œå‡å¦‚ä½ çš„é¢„æµ‹é›†æ•°æ®åˆ†å¸ƒ å’Œ è®­ç»ƒé›†æ•°æ®åˆ†å¸ƒçš„ä¸åŒã€‚ é‚£ä¹ˆå¾ˆå¯èƒ½ä¼š é¢„æµ‹é›† é¢„æµ‹çš„æ—¶å€™ï¼ˆæ˜¯å¦ä¸€ä¸ªé¶å¿ƒï¼‰ã€‚ æ‰€ä»¥ä½ è®­ç»ƒçš„å†å¥½ï¼Œåˆ°é¢„æµ‹é›†çš„é¶å­ä¸Š ä¹Ÿæ˜¯è„±é¶ã€‚ã€‚ã€‚ æ‰€ä»¥ è®­ç»ƒé›† å’Œ æµ‹è¯•é›† çš„ ç›¸åŒåˆ†å¸ƒå¾ˆé‡è¦ ###æ•°æ®é¢„å¤„ç†å¤§ä½“åˆ†2ç±»ï¼š 1. ä¸­å¿ƒåŒ–å¤„ç† 2. ç¼©æ”¾å¤„ç† zero-centered (ä¸­å¿ƒåŒ–å¤„ç†) å¹³ç§» --- å‡å»å›ºå®šå€¼ ###scale (ç¼©æ”¾å¤„ç†) å½’ä¸€åŒ–ï¼šé™¤ä»¥ æœ€å¤§å€¼-æœ€å°å€¼ æ ‡å‡†åŒ–ï¼šé™¤ä»¥ æ ‡å‡†å·® ä¸‹é¢çš„æ“ä½œéƒ½æ˜¯é€šè¿‡ ä¸­å¿ƒåŒ–å¤„ç†+ç¼©æ”¾å¤„ç† è”åˆç»„æˆçš„ normalizationï¼ˆå½’ä¸€åŒ–ï¼‰ sklearné‚£é‡Œä¹Ÿæåˆ°è¿‡ ç›®æ ‡ï¼š å°†æ•°æ®æ”¶æ•›åˆ° [0,1] å…¬å¼ x - min(x) # ä¸­å¿ƒåŒ– ------------------ max(x) - min(x) # ç¼©æ”¾å¤„ç† ###StandardScalerï¼ˆæ ‡å‡†åŒ–ï¼‰ ç›®æ ‡ï¼š å°†æ•°æ®è½¬åŒ–ä¸ºæ ‡å‡† æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰ å…¬å¼ï¼š x - å¹³å‡å€¼ ----------------- æ ‡å‡†å·® æ ‡å‡†åŒ– å’Œ å½’ä¸€åŒ– é€‰å“ªä¸ªï¼Ÿï¼Ÿï¼Ÿ è§†è§‰å›¾ç‰‡ï¼š å½’ä¸€åŒ– å…¶ä»–ï¼š æ ‡å‡†åŒ–è¾ƒå¥½ æ•°æ®é›†ä¸è¶³æ€ä¹ˆåŠï¼Ÿ æˆ‘è‡ªå·±ä¹Ÿé‡åˆ°è¿‡è¿™æ ·çš„é—®é¢˜ã€‚ æˆ‘ä¹‹å‰åšä¸€ä¸ªQAèŠå¤©æœºå™¨äººæ—¶ã€‚ æ•°æ®æ˜¯ç™¾åº¦çŸ¥é“çš„çˆ¬çš„ã€‚ ä½†æ˜¯ï¼ˆç”¨è¿‡çš„åº”è¯¥æ¸…æ¥šã€‚ ç™¾åº¦çŸ¥é“æœ‰å¾ˆå¤šç”¨æˆ·çš„åƒåœ¾å›ç­”ï¼Œæ˜¯ç”¨æˆ·åˆ·åˆ†çš„ã€‚ï¼‰ é—®äº†è§£å†³è¿™ä¸€é—®é¢˜ã€‚æˆ‘çš„è§£å†³æ€è·¯æ˜¯ï¼šé€šè¿‡Pandas, ç­›é€‰ç­”æ¡ˆé•¿åº¦è‡³æœ€å°ã€‚ ä½†æ˜¯è¿™æ ·ã€‚å°±å¯èƒ½ç­›é€‰é™¤äº† å¤§é‡å¤§é‡çš„ åŸç”Ÿæ•°æ® å†åŠ ä¸Šï¼ŒæŠŠï¼ˆåŸæ•°æ®ä¸­ &quot;æœ‰é—®æ— ç­”&quot; çš„é—®ç­”å¯¹ï¼‰è¿‡æ»¤æ‰”æ‰ã€‚ é‚£ä¹ˆå¼„ä¸‹æ¥çš„æºæ•°æ®ï¼Œå‡ ä¹æ²¡å‰©å¤šå°‘äº†ã€‚ã€‚ï¼ˆæˆ‘è®°å¾—æˆ‘å½“æ—¶å¼„äº†400W+é—®ç­”å¯¹ï¼‰ ç­›é€‰åˆ°æœ€åï¼ˆé—®ç­”é•¿åº¦ 15ä¸ªæ±‰å­—ï¼Œ ç­›é€‰æ‰ç©ºå›ç­”ï¼‰(åªå‰©ä¸‹ å‡ ä¸‡æ¡äº†ã€‚ã€‚ã€‚) åæ¥ï¼Œæˆ‘æ€¥ä¸­ç”Ÿæ™ºã€‚åœ¨ç½‘ä¸Šæ‰¾äº†ä¸€äº› ä¸­æ–‡è¯­æ–™åº“ï¼ˆæˆ‘ç”¨çš„é’äº‘ä¸­æ–‡è¯­æ–™åº“ï¼‰ æŠŠå®ƒèåˆåˆ° æˆ‘è‡ªå·±çš„ è¯­æ–™åº“ä¸­ã€‚ã€‚ã€‚ ä½†æ˜¯è®­ç»ƒåçš„ç»“æœï¼Œ å…¨æ˜¯äººå®¶ é’äº‘è¯­æ–™åº“çš„ é—®ç­”å†…å®¹ã€‚ã€‚ã€‚ åæ¥ä¹Ÿæ²¡å»ç»§ç»­æ·±ç©¶äº†ã€‚ã€‚ã€‚ åæ¥æ­£å¥½çœ‹åˆ° Ngã€‚æåˆ°è¿™ä¸€é—®é¢˜ï¼Œè®°å½•ä¸€ä¸‹ç›¸åº”çš„åº”å¯¹æªæ–½! è®­ç»ƒé›†ï¼šé’äº‘è¯­æ–™+ 1/2 è‡ªå·±çš„è¯­æ–™ æµ‹è¯•é›†: 1/4 è‡ªå·±çš„è¯­æ–™ éªŒè¯é›†ï¼š1/4 è‡ªå·±çš„è¯­æ–™ éšæœºåˆå§‹åŒ–æƒé‡ éšæœºåˆå§‹åŒ–è®¤çŸ¥ ä¸ºä»€ä¹ˆä¸æ˜¯åˆå§‹åŒ–ä¸º0ï¼Ÿï¼Ÿï¼Ÿ å› ä¸ºç¥ç»ç½‘ç»œä¸­ï¼Œ Wåˆå§‹åŒ–ä¸º0çš„è¯ï¼Œ ä¼šå¯¼è‡´åå‘ä¼ æ’­åï¼Œ æ‰€æœ‰ç¥ç»å…ƒä¼šè®­ç»ƒåŒä¸€ä¸ªç½‘ç»œã€‚ä¸€ç‚¹æ•ˆæœæ²¡æœ‰ ä¸ºä»€ä¹ˆä¸åˆå§‹åŒ–å¾ˆå¤§çš„å€¼æˆ–è€…å¾ˆå°çš„å€¼ï¼Ÿï¼Ÿï¼Ÿ è¿™æ˜¯åˆ†æƒ…å†µæ¥å®šçš„ã€‚ æ¯”å¦‚ä½ ç”¨çš„ tanh æˆ–è€… sigmoidå‡½æ•° ç”±è„‘æµ·ä¸­çš„å›¾åƒå¯çŸ¥ï¼ˆæ±‚å¯¼ æˆ– æ–œç‡ï¼‰ ï¼Œå½“ åˆå§‹å€¼è¿‡å¤§ï¼Œæˆ–è€…è¿‡å°ã€‚ éƒ½ä¼šå¯èƒ½å¯¼è‡´ï¼Œyç›´æ¥è½åœ¨ sigmoidçš„ é¡¶éƒ¨å’Œåº•éƒ¨ï¼ˆå°±æ˜¯æ–œç‡æ°´å¹³ï¼Œè¿‘ä¹ä¸º0ï¼‰ è½åœ¨äº†æ°´å¹³çš„æ¢¯åº¦ã€‚è¿™æ ·çš„æ¢¯åº¦ï¼ŒçŒ´å¹´é©¬æœˆä¹Ÿé™ä¸ä¸‹å»å•Šã€‚ã€‚ã€‚ã€‚ã€‚ å¦‚æœè½åœ¨äº† å€¾æ–œé™¡å³­çš„æ¢¯åº¦ã€‚ é‚£ä¹ˆæ¢¯åº¦ä¸‹é™çš„ä¸€å®šå¾ˆå¿«å•¦ã€‚ å¦‚æœåšäº†BatchNormalizationï¼Œé‚£ä¹ˆå¯ä½¿ç”¨ é«˜æ–¯ x 0.01 æ­£æ€åˆ†å¸ƒ * æ‹‰ä½å€¼ np.random.randn(2,2) * 0.01 # 2,2æ˜¯å½¢çŠ¶ï¼Œ è¿™ä¸ª0.01 å¯ä»¥è‡ªå·±è°ƒèŠ‚ã€‚ æ€»ä¹‹ï¼Œå°ä¸€ç‚¹ æœ€å¥½ï¼Œ ä½†ä¸è¦å¤ªå° å¦‚æœä½¿ç”¨äº†Reluæ¿€æ´»å‡½æ•°ï¼Œå¯¹åº” åˆå§‹åŒ–æ–¹æ³• np.random.randn(shapex, shapey) * np.sqrt( 2/shapex ) # ç³»æ•°ä¸º2 å¦‚æœä½¿ç”¨äº†Tanhæ¿€æ´»å‡½æ•°ï¼Œå¯¹åº” åˆå§‹åŒ–æ–¹æ³•ï¼ˆNGæ¨èï¼Œ ä¹Ÿå« Xavierï¼‰ np.random.randn(shapex, shapey) * np.sqrt( 1/shapex ) # ç³»æ•°ä¸º1 æ¿€æ´»å‡½æ•° æ¿€æ´»å‡½æ•°è®¤çŸ¥ å­¦ä¹ Andrew Ngè¯¾æ›´æ·±åˆ»äº†è§£äº†æ¿€æ´»å‡½æ•°ã€‚ ç¥ç»ç½‘ç»œä¸­ï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦æ¿€æ´»å‡½æ•°ï¼Œç”šè‡³éœ€è¦éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Ÿ é¦–å…ˆæŒ‘æ˜ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¥ç»ç½‘ç»œçš„ç›®çš„ï¼Œå°±æ˜¯æƒ³è®­ç»ƒå‡ºæ›´å¤šï¼Œæ›´ä¸°å¯Œçš„ç‰¹å¾ã€‚ æ‰€ä»¥ã€‚ ä¸€ç›´ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…ä¸ç”¨æ¿€æ´»å‡½æ•°ã€‚ä¼šä½¿å¾—ä½ æ•´ä¸ªç½‘ç»œè®­ç»ƒåˆ°å¤´ï¼Œè¿˜æ˜¯çº¿æ€§çš„ã€‚å°±æ²¡æ„æ€äº†ã€‚ å®ƒå­¦ä¸åˆ°ä¸°å¯Œçš„ç‰¹å¾çš„ã€‚ å› ä¸ºç¥ç»ç½‘ç»œå¤šå±‚æ˜¯éœ€è¦æ‹¿å‰ä¸€å±‚çš„ç»“æœä½œä¸ºä¸‹ä¸€å±‚çš„ xï¼Œæ‰€ä»¥æœ‰äº†å¦‚ä¸‹å…¬å¼ï¼š w3 (w2 (w1x+b) +b) +b å±•å¼€åï¼Œ w3 * w2 * w1 * x + ...... å¾ˆæ˜æ˜¾å®ƒä¾ç„¶æ˜¯çº¿æ€§çš„ã€‚ æ‰€ä»¥ï¼Œæ— è®ºä½ ç”¨å¤šå°‘å±‚ ç¥ç»ç½‘ç»œã€‚ åˆ°æœ€åå®ƒä¾ç„¶æ˜¯çº¿æ€§çš„ã€‚ã€‚ã€‚ã€‚ è¿™æ ·å€’ä¸å¦‚ ä¸€å±‚ç½‘ç»œä¹Ÿä¸ç”¨ã€‚ ç›´æ¥ä¸Šä¸ª é€»è¾‘å›å½’æ¨¡å‹ï¼Œæ•ˆæœä¼°è®¡ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ å½“ç„¶æœ‰ä¸€äº›åœºåˆä¹Ÿéœ€è¦ä½¿ç”¨ çº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œæ¯”å¦‚ æˆ¿ä»·é¢„æµ‹ã€‚èº«é«˜é¢„æµ‹ã€‚ï¼ˆè¿™äº›éƒ½æ˜¯çº¿æ€§å›å½’æ¨¡å‹ï¼‰ è¿™äº›æƒ…å†µï¼Œå°±å¯ä»¥ä½¿ç”¨ çº¿æ€§æ¿€æ´»å‡½æ•°äº†ã€‚ ä½†æ˜¯ä¸å¦¨æƒ³ä¸€æƒ³ï¼Œ å°±åƒä¸Šé¢ èº«é«˜é¢„æµ‹è¿™äº›ã€‚æ˜¯çº¿æ€§å›å½’ï¼Œå¹¶ä¸” yé¢„æµ‹éƒ½æ˜¯æ­£æ•°å€¼ã€‚ æŸç§ç¨‹åº¦ä¸Šï¼Œå…¶å®æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ reluæ¿€æ´»å‡½æ•°ï¼Œ ï¼ˆå› ä¸º reluçš„å³åŠä¾§ï¼ˆå°±æ˜¯å¤§äº0çš„éƒ¨åˆ†ï¼‰ ä¹Ÿæ˜¯çº¿æ€§çš„å“¦ï¼‰ æˆ‘ä»¬NNéšå±‚å°±å¤§å¤šæ•°éƒ½ä½¿ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚ éšå±‚ï¼š relu æˆ–è€… leakly relu æˆ–è€… tanh è¾“å‡ºå±‚ï¼š sigmoid æˆ–è€… softmax æˆ–è€… tanh ç­‰ç­‰ sigmoid å…¬å¼ 1 --------- 1 + e**(-x) æ¯ä¸ªout: (0, 1) äºŒåˆ†ç±»outä¹‹å’Œä¸º 1 å¯¹åº”APIï¼š 1. tf.sigmoid(y) 2. æˆ–å‡½æ•°å‚æ•° xxxxx (activations='sigmoid') 3. tf.keras.activations.sigmoid() softmax e**x --------------------------------- e**(x1) + e**(x2) + ... + e**(xn) æ¯ä¸ªout: (0,1) å¤šåˆ†ç±» outä¹‹å’Œä¸º 1 å¯¹åº”APIï¼š 1. tf.nn.softmax() 2. å‡½æ•°å‚æ•° xxxxx (activations='softmax') 3. tf.keras.activations.softmax() softmaxç‰¹ç‚¹ï¼š è¾“å‡ºçš„æ˜¯ä»€ä¹ˆå½¢çŠ¶çš„å¼ é‡ï¼Œè¾“å‡ºçš„å°±æ˜¯ä»€ä¹ˆå½¢çŠ¶çš„å¼ é‡ ä¹Ÿæ˜¯æœ‰çº¿æ€§å†³ç­–è¾¹ç•Œï¼ˆçº¿æ€§ å¤š åˆ†ç±»å™¨ï¼‰ tanh coshx ex - e(-x) ------------- 2 sinhx ex + e(-x) -------------- 2 tanhx ex - e(-x) ------------- ex + e(-x) æ¯ä¸ªout: (0,1) * 2 -1 ===&gt; (-1,1) LSTM å¯¹åº”APIï¼š 1. tf.tanh(y) 2. å‡½æ•°å‚æ•° xxxxx (activations='tanh') 3. tf.keras.activations.tanh() relu å…¬å¼ï¼š y = 0 if x &lt; 0 else x # å¤§äº0ï¼Œæ¢¯åº¦ä¸º1 å¯¹åº”API 1. tf.nn.relu() 2. æˆ–å‡½æ•°å‚æ•° xxxxx (activations='relu') 3. tf.keras.activations.relu() leaky_relu: (å°æ‰©å±•) y = kx if x &lt; 0 else x tf.nn.leaky_relu() æŸå¤±å‡½æ•° MSE ï¼ˆå‡æ–¹è¯¯å·®ï¼‰ å…¬å¼ Î£( (y-y_predict)**2 ) -------------------- n å¯¹åº”API å…¬å¼å®ç°ï¼š tf.reduce_mean( tf.square( y-y_predict ) ) tf.API: tf.reduce_mean( tf.loss.MSE(y, y_predict) ) CrossEntropy ï¼ˆäº¤å‰ç†µï¼‰ ç†µå…¬å¼ï¼š -Î£ï¼ˆplogpï¼‰ äº¤å‰ç†µå…¬å¼ï¼š-ï¼ˆ Î£plogq ï¼‰ pä¸ºçœŸå®å€¼One-hot, qä¸ºé¢„æµ‹å€¼ p: [1,0,0] q: [0.9, 0,0.1] H = -( 1log0.9 + 0log0 + 0*log0.1) = -log0.9 = -ln0.9 â‰ˆ 0.1053.... tfçš„ tf.math.logç›¸å½“äº ln äº¤å‰ç†µAPIï¼š äº¤å‰ç†µè¶Šå°ï¼ˆyä¸y-predictå·®è·è¶Šå°ï¼Œé¢„æµ‹è¾ƒå‡†ç¡®ï¼‰ äº¤å‰ç†µè¶Šå¤§ï¼ˆyä¸y_predictå·®è·è¶Šå¤§ï¼Œäº¤å‰ç›¸ä¹˜ç´¯åŠ åå€¼å¤§ï¼Œè¯´æ˜é¢„æµ‹é”™ä½äº†ã€‚ã€‚ã€‚æ‰€ä»¥äº¤å‰èµ·æ¥å˜å¤§äº†ï¼‰ tf.API: ï¼ˆæ–¹å¼1ï¼šç›´æ¥æ˜¯å‡½æ•°è°ƒç”¨ï¼‰ loss = tf.losses.categorical_crossentropy([1,0,0], [0.9, 0, 0.1],from_logits=True) # ç¬¬ä¸€ä¸ªå‚æ•°y, ç¬¬äºŒä¸ªå‚æ•° y_predict loss = tf.reduce_mean(loss) tf.API: ï¼ˆæ–¹å¼2ï¼šç”¨ç±»çš„callè°ƒç”¨ , è¿™æ¬¡ä»¥ äºŒåˆ†ç±»äº¤å‰ç†µä¸ºä¾‹ï¼‰ loss = tf.losses.BinaryCrossentropy(from_logits=True)( [1], [0.1] ) # ç»“æœä¸º2.+ ã€‚ å› ä¸º çœŸå®å€¼æ˜¯1ç±»ï¼Œ è€Œé¢„æµ‹å€¼æ¦‚ç‡æ˜¯0.1å¤ªå°äº†ã€‚æ‰€ä»¥è‚¯å®šé¢„æµ‹é”™äº†ã€‚ loss = tf.reduce_mean(loss) è¯´æ˜ï¼šcategorical_crossentropy( ) # ç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡» one_hot, ï¼ˆç¬¬äºŒä¸ªå‚æ•°æŒ‰ç†æ¥è¯´éœ€è¦åš softmaxï¼Œä½†æ˜¯ä½ ä¼ äº† from_logigs=Trueï¼Œå°±ä¸å¿…softmaxäº†ï¼‰ æ¢¯åº¦ SGDï¼ˆStochastic Gradent Descentï¼‰: è§£é‡Š å„ç§æ¢¯åº¦ä¸‹é™çš„åŒºåˆ«ï¼š Mini-Batch Gradent Descent: æŒ‡å®šæ¯æ¬¡ mini-batchä¸ª æ¥åšæ¢¯åº¦ä¸‹é™ ï¼ˆå°±æ˜¯æ¯æ¬¡æŒ‡å®šå¤šå°‘ä¸ªæ ·æœ¬ æ¥åšGDçš„æ„æ€ï¼‰ è¿™ç§ä»‹äº 1-å…¨éƒ¨æ ·æœ¬ä¹‹é—´çš„ã€‚ æ˜¯æœ€ä¼˜çš„ Batch gradent descent: mini-batch ä¸ºå…¨éƒ¨æ ·æœ¬ Stochastic gradent descent: mini-batch ä¸º 1ä¸ªæ ·æœ¬ ç¼ºç‚¹ï¼š æ¯æ¬¡ 1ä¸ªæ ·æœ¬åšSGDï¼Œ é‚£ä¹ˆå°±å¤±å»äº† å‘é‡åŒ–ï¼ˆçŸ©é˜µä¹˜ä»£æ›¿å¾ªç¯ï¼‰çš„ åŠ é€Ÿå¿«æ„Ÿã€‚ã€‚ã€‚ã€‚ã€‚ å‡å»æ¢¯åº¦ï¼Œä»£è¡¨æœç€æ¢¯åº¦æ–¹å‘èµ° wæ–° = wå½“å‰ - learning_rate * æ¢¯åº¦ ä½¿ç”¨æ–¹å¼ï¼š model.compile(..... ,optimizer=keras.optimizers.SGD(learning_rate=0.01)) å†è®°å½•å…¶ä»–ä¼˜åŒ–å™¨ä¹‹å‰ï¼Œ å…ˆè¡¥ä¸€ä¸ª æŒ‡æ•°åŠ æƒå¹³å‡ çš„çŸ¥è¯† å…¬å¼ï¼š y = Î² * Xä¹‹å‰ + ï¼ˆ1-Î²ï¼‰* Xå½“å‰ å›¾å½¢æ›²çº¿è¡¨ç°ï¼š Î²è¶Šå°ï¼šï¼ˆå°åˆ°0.5ï¼‰ ï¼šæ›²çº¿è¶ŠæŠ–åŠ¨é¢‘ç¹ï¼ˆé”¯é½¿ è¶Šå‰å®³ï¼‰ï¼ˆ0.5å·¦å³å·²ç»ï¼Œä¸¥é‡ä¸Šä¸‹è·³åŠ¨äº†ï¼‰ Î²è¶Šå¤§ï¼šï¼ˆå¤§è‡³1.0ï¼‰ ï¼šæ›²çº¿è¶Šå…‰æ»‘ï¼ˆæ— é”¯é½¿ï¼‰ æ‰€ä»¥ Î²ï¼š è¶Šå¤§è¶Šå¥½ ï¼ˆæ¶‰åŠåˆ°ä¸€ä¸ªæŠ€æœ¯--åå·®ä¿®æ­£ï¼Œ å¦‚æœä½ ä¸ä¿®æ­£ã€‚ å¯èƒ½è®­ç»ƒä¼šç¨å¾®æ…¢ä¸€äº›ã€‚æ— ä¼¤å¤§é›…ï¼‰ Momentumï¼ˆåŠ¨é‡ï¼‰ å…¬å¼å¤§æ¦‚ï¼š dw' = Î² * dw-1 + ( 1-Î² ) * dw # ç”¨ dw-1 æ°å¼¯ dw db' = Î² * db-1 + ( 1-Î² ) * db # ç”¨ db-1 æ°å¼¯ db å…¬å¼ç†è§£ï¼š åœ¨åŸæ¥çš„æ¢¯åº¦åŸºç¡€ä¸Šï¼Œ ç”¨ ä¸Šä¸€æ¬¡çš„æ¢¯åº¦æ–¹å‘ï¼Œ æŠŠå½“å‰å°†è¦è®¡ç®—çš„æ¢¯åº¦æ°å¼¯ RMSProp model.compile(..... ,optimizer=keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.9)) Adam(å¼ºçƒˆæ¨è) TF-API: é»˜è®¤åŸå‚æ•° model.compile(..... ,optimizer=keras.optimizers.Adam( learning_rate=0.001, beta_1=0.9, # å­¦ä¹ ç‡è¡°å‡å‚æ•° beta_2=0.999, epsilon=1e-7, ), ) å…¶å®è¿™ä¸ªAPIå‚æ•°ï¼Œæˆ‘ä»¬åªç¨å¾®è°ƒæ•´ä¸€ä¸‹ learning _ rate å³å¯ï¼Œå…¶ä»–ä¸ç”¨æ€ä¹ˆã€‚ å­¦ä¹ ç‡è¡°å‡ å…¶å®å¤§å¤šæ•° ä¼˜åŒ–å™¨å†…éƒ½æœ‰ å­¦ä¹ ç‡è¡°å‡å‚æ•°ï¼Œä¾‹å¦‚ï¼š SGD(decay) Adam(beta_1) å½“ç„¶ä½ ä¹Ÿå¯ä»¥è‡ªå·±å®ç°ï¼ˆæŒ‰ç…§æ ·æœ¬å·²è®­ç»ƒçš„æ‰¹æ¬¡ï¼ŒåŠ¨æ€è¡°å‡ï¼‰ learning rate = learning rate * 1/ï¼ˆepochè½®æ•° * è¡°å‡ç‡ + 1ï¼‰ å…¶å®è¿˜æœ‰æ›´å¤š å¯è°ƒèŠ‚å‚æ•°ï¼Œå°±åƒAdamä¸­çš„ é‚£ä¹ˆå¤šå‚æ•°ä¼¼ã€‚å½“ç„¶æˆ‘å‹æ ¹ä¹Ÿæ²¡æƒ³è‡ªå·±å®ç°è¡°å‡ã€‚ã€‚ å¯çŸ¥ decayè¶Šå°ï¼Œ å­¦ä¹ ç‡è¡°å‡çš„è¶Šæ…¢ï¼Œ å½“è¡°å‡ç‡ä¸º0æ—¶ã€‚ å­¦ä¹ ç‡å‹æ ¹å°±ä¸è¡°å‡ è€Œ decayè¶Šå¤§ï¼Œ å­¦ä¹ ç‡è¡°å‡çš„è¶Šå¿«ï¼Œ å½“è¡°å‡ç‡ä¸º1æ—¶ã€‚ é‚£è¡°å‡çš„å°±å¤ªå¤¸å¼ äº†~~ è¿ç§»å­¦ä¹  ï¼ˆæˆ‘æƒ³åˆ°ä¸€ä¸ªè¯ï¼šç§»èŠ±æ¥æœ¨ï¼‰ åº”ç”¨åœºæ™¯ å‡å¦‚å·²ç»æœ‰ç°æˆçš„ ç‹—ç±» è¯†åˆ«çš„ ç¥ç»ç½‘ç»œæ¨¡å‹ é‚£ä¹ˆå‡å¦‚ä½ ç°åœ¨æƒ³è¦ åšä¸€ä¸ª çŒ«ç±»çš„ è¯†åˆ« ä½ å®Œå…¨å¯ä»¥æŠŠ ç‹—è¯†åˆ« ç½‘ç»œæ¨¡å‹æ‹¿è¿‡æ¥ ç„¶åæŠŠæœ€å è¾“å‡ºå±‚ æ‰”æ‰ï¼Œè‡ªå·±åŠ ä¸€ä¸ªæ–°è¾“å‡ºå±‚ï¼ˆå½“ç„¶ä¸­é—´ä½ ä¹Ÿå¯ä»¥åŠ ä¸€äº›æ–°çš„NNå±‚ï¼‰ ç„¶å æ—æ•²ä¾§å‡»ï¼Œåªåœ¨æœ€åä¸€å±‚æä¾›è¾“å…¥ï¼Œåªå¯¹ æ–°çš„è¾“å‡ºå±‚ï¼ˆæˆ–è€…ä½ é¢å¤–åŠ çš„NNï¼‰å±‚è®­ç»ƒã€‚ åº”ç”¨æ¡ä»¶ å½“ä½ è¿ç§»åçš„æ•°æ®æœ‰ç‰¹åˆ«ç‰¹åˆ«å¤šçš„æ—¶å€™ï¼Œ é‚£ä¹ˆä½ å®Œå…¨å¯ä»¥æŠŠ æ¬è¿‡æ¥çš„ æ¨¡å‹å‚æ•° ä»å¤´åˆ°å°¾è®­ç»ƒä¸€éã€‚ å°±åƒä½  ç‹—æ¨¡å‹ï¼Œ å‰é¢çš„ç½‘ç»œå­¦åˆ°äº†å¾ˆå¤š æ¯›ï¼Œç‰¹å¾ã€‚ ï¼ˆè¿™çŒ«ä¹Ÿæœ‰å˜›ï¼Œæ‰€ä»¥æ­£å¥½å¯ä»¥ç”¨å¾—ä¸Šï¼‰ ç„¶åä½  åœ¨ç‹—æ¨¡å‹çš„åŸºç¡€ä¸Š ï¼Œè®­ç»ƒçŒ«æ¨¡å‹ ï¼ˆæˆ‘ä¸å¤ªäº†è§£çŒ«~~~ï¼Œ æ¯”å¦‚è¯´å¯ä»¥æ–°å­¦åˆ°çŒ«çš„èƒ¡é¡»ä¹‹ç±»çš„æ–°ç‰¹å¾ï¼‰ æ€»ç»“æ¥è¯´ï¼š æ–°æ¨¡å‹ = NNå±‚ï¼ˆç‹—ï¼‰å‚æ•° + NNå±‚ï¼ˆçŒ«ï¼‰å‚æ•° + è¾“å‡ºå±‚ï¼ˆçŒ«ï¼‰å‚æ•° å½“ç„¶ï¼Œ å¦‚æœä½ è¿ç§»æ”¯æŒçš„æ•°æ®ï¼Œåªæœ‰å¾ˆå°‘ï¼Œæ ¹æœ¬ä¸å¤Ÿå¼ºå¤§çš„ç¥ç»ç½‘ç»œè®­ç»ƒ é‚£ä¹ˆï¼Œä½ å°±å¯ä»¥ç›´æ¥æŠŠï¼Œæ¬è¿‡æ¥çš„æ¨¡å‹å‚æ•°å›ºå®šä½ï¼Œ ç›´æ¥åªåœ¨ æœ€åè¾“å‡ºå±‚ï¼Œæä¾›è¾“å…¥ï¼Œè¿›è¡Œè®­ç»ƒ æ€»ç»“æ¥è¯´ï¼š æ–°æ¨¡å‹ = NNå±‚ï¼ˆç‹—ï¼‰å‚æ•° + è¾“å‡ºå±‚ï¼ˆçŒ«ï¼‰å‚æ•° è¿ç§»å­¦ä¹ çš„ä¸»è¦ç›®çš„æ€æƒ³ï¼š å½“ä½  æœ‰å¾ˆå°‘çš„å°æ•°æ®é›†Aï¼Œ ä½†æ˜¯ä½ æƒ³è®­ç»ƒæˆä¸€ä¸ª NN æ¥ è¾¾åˆ°ç›®çš„ã€‚ å¯æƒ³è€ŒçŸ¥ï¼Œå°‘é‡æ•°æ®é›†A è¿˜ä¸å¤Ÿ NN å¡ç‰™ç¼çš„ã€‚ã€‚ã€‚ æ‰€ä»¥ï¼Œä½ éœ€è¦æ‰¾ä¸€äº›å…¶ä»–ç±»ä¼¼çš„æ•°æ®é›†Bï¼ˆé‡å¤šçš„ï¼Œå¥½æ”¶é›†çš„ï¼‰ ç„¶åè¿™äº›å¤§é‡æ•°æ®é›†Bï¼Œè¶³ä»¥ é©°éª‹äº NN ï¼Œ å¾—åˆ°ä¸€ä¸ªæ¨¡å‹ã€‚ï¼ˆå¹¶ä¸”å¸¦ç€ è®­ç»ƒå¥½çš„å‚æ•°ï¼‰ æ•°æ®é›†Aè¯´ï¼š &quot; å¤§å“¥ï¼Œä½ è®­ç»ƒå¥½çš„ç½‘ç»œå€Ÿæˆ‘ç”¨ç”¨å‘—ã€‚ ä½ ç”¨äº†é‚£ä¹ˆå¤šæ•°æ®ï¼Œè®­ç»ƒå‡ºçš„ç‰¹å¾ä¸€å®šæœ‰æˆ‘æƒ³è¦çš„ã€‚ æˆ‘æŠŠæ•´ä¸ªæ¨¡å‹æ‹¿è¿‡æ¥ï¼Œåªæ”¹ä¸€ä¸‹æœ€åä¸€å±‚çš„è¾“å…¥ã€‚ç„¶ååªè®­ç»ƒæœ€åä¸€å±‚çš„å‚æ•°ã€‚ å…¶ä»–å±‚çš„å‚æ•°éƒ½ç”¨ä½ çš„ã€‚ &quot;ã€‚ æ•°æ®é›†Bå¤§å“¥è¯´ï¼š &quot;å¯ä»¥&quot; è¿ç§»å­¦ä¹ API ï¼ˆTensorflow2.0ï¼‰ æ¸©é¦¨æç¤ºï¼š TF20çš„Keras Layers æ˜¯å¯ä»¥ ç”¨åˆ‡ç‰‡è¯­æ³• é€‰å–å…·ä½“ç½‘ç»œå±‚çš„ï¼Œä¸¾ä¸ªä¾‹å­ï¼š # from tensorflow import keras # cut_resnet = keras.applications.DenseNet121( # ä½¿ç”¨ç°æœ‰ResNetæ¨¡å‹ # include_top=False, # ä¸è¦æœ€åä¸€å±‚ï¼Œè€Œæ˜¯ä½¿ç”¨æˆ‘ä»¬è‡ªå·±å®šä¹‰çš„å…¨è¿æ¥å±‚ # pooling='avg', # weights='imagenet', # åˆå§‹åŒ–æƒé‡ï¼ˆä»imagenetè®­ç»ƒå¥½æ¨¡å‹å‚æ•°æ¥åˆå§‹åŒ–ï¼‰ # ) # for layer in cut_resnet.layers[0:-3]: # éƒ¨åˆ†å¯è®­ç»ƒï¼ˆfine-tuneåˆ†å‰²ï¼‰ # trainable=False # 0 åˆ° å€’æ•°ç¬¬ä¸‰å±‚ï¼Œå‚æ•°ä¸å¯è®­ç»ƒ # # new_model = keras.models.Sequential() # new_model.add(cut_resnet) # new_model.add(å…¶ä»–å±‚) è¿ç§»å­¦ä¹  é€‚ç”¨åœºæ™¯ ç»Ÿä¸€ä½¿ç”¨é¢†åŸŸï¼ˆè¦ä¹ˆæ–‡æœ¬è¿ç§»è¦æ–‡æœ¬ï¼Œ è¦é—¨å›¾åƒè¿ç§»åˆ°å›¾åƒã€‚ï¼‰ å‡å¦‚ A è¿ç§»åˆ° B ï¼ˆé‚£ä¹ˆ Açš„æ ·æœ¬æœ€å¥½è¿œå¤§äº Bçš„æ ·æœ¬ï¼‰ å‡å¦‚ A è¿ç§»åˆ° B ï¼ˆæœ€å¥½Açš„è®¸å¤šç‰¹å¾ä¿¡æ¯ï¼ŒBæ­£å¥½å¯ä»¥ç”¨å¾—åˆ°ã€‚æ¯”å¦‚ çŒ«ç‹—ï¼Œéƒ½æœ‰æ¯›å‘ï¼Œèƒ¡é¡»ï¼Œå››æ¡è…¿ï¼‰ å¤šä»»åŠ¡å­¦ä¹ ï¼ˆäº†è§£ï¼Œç”¨çš„å°‘ï¼‰ ç›´æ¥æ„Ÿè§‚ï¼šæˆ‘è®¤ä¸ºå°±åƒï¼ˆç±»çš„ç»§æ‰¿ ï¼Œ æˆ–è€…å°è£…ä¸ºä¸€ä¸ªå‡½æ•°ï¼Œ è¿™æ ·çš„æ¦‚å¿µã€‚ã€‚ï¼‰ ä½ æƒ³è®­ç»ƒ é¢„æµ‹ å„ç§å„æ ·ç±»åˆ«çš„å›¾ç‰‡ã€‚ ä½ å¯ä»¥é¦–å…ˆ ç”¨ä¸€ä¸ªä»»åŠ¡ è®­ç»ƒä¸€ä¸‹ å…±æœ‰ç‰¹å¾ çš„ NNã€‚ ç„¶åå…¶ä»–ä»»åŠ¡ ç”¨è¿™ä¸ª è®­ç»ƒå¥½çš„ å…±æœ‰çš„ç‰¹å¾çš„ NNã€‚ Ngæç¤ºï¼š ä½ éœ€è¦æœ‰åºå¤§çš„ç¥ç»ç½‘ç»œæ”¯æ’‘ï¼Œä¸ç„¶æ•ˆæœä¸å¥½ã€‚ ","link":"https://cythonlin.github.io/post/ai-greater-deeplearningmetricsng/"},{"title":"PY => Tensorflow2.0 GPUç®¡ç†ä¸åˆ†å¸ƒå¼","content":"Nvidiaå‘½ä»¤ nvidia-smi # æŸ¥çœ‹GPUå ç”¨æƒ…å†µ watch -n 0.1 -x nvidia-smi # åŠ¨æ€å®æ—¶0.1ç§’é—´éš”ï¼ŒæŸ¥çœ‹GPUå ç”¨æƒ…å†µã€‚ GPUç®¡ç† ä¸ºä»€ä¹ˆéœ€è¦ç®¡ç†GPUï¼Ÿ é»˜è®¤TFç¨‹åºè¿è¡Œä¼šæ²¾æ»¡è€—å°½GPU å¦‚ä½•ç®¡ç†GPU ä½¿ç”¨å†…å­˜å¢é•¿å¼ API å†…å­˜å¢é•¿è§£é‡Šï¼š æŒ‰éœ€åˆ†é… # æŸ¥çœ‹ç‰©ç†GPUä¿¡æ¯ gpus = tf.config.experimental.list_physical_devices('GPU') # è·å–æ‰€æœ‰ç‰©ç†GPUä¿¡æ¯ tf.config.experimental.set_visible_devices(gpus[2]) # åªä½¿ç”¨ ç¬¬3ä¸ªGPUï¼Œ é»˜è®¤ä¸è®¾ç½®å°±æ˜¯ä½¿ç”¨æ‰€æœ‰GPU for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True) # è¿™è¡Œä»£ç å¿…é¡»æ”¾åœ¨å‰é¢ print(len(gpus)) GPU é€»è¾‘åˆ‡åˆ† ï¼ˆåˆ†é…å¤§å°ï¼‰ å°±åƒåˆ’åˆ†CDEç›˜ç¬¦ä¸€æ ·ï¼Œå®é™…ä¸Šè¿˜æ˜¯ä¸€ä¸ªæ•´ä½“çš„GPU tf.config.experimental.set_virtual_device_configuration( gpus[2], # æ‹¿ç¬¬3å—ç‰©ç† GPUæ¥åˆ‡åˆ† [ tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048), # å®ä¾‹åŒ–ç¬¬ä¸€ä¸ªè›‹ç³•ï¼Œå¹¶åˆ†ä¸º2G tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048), # å®ä¾‹åŒ–ç¬¬äºŒä¸ªè›‹ç³•ï¼Œå¹¶åˆ†ä¸º2G ] ) ä½¿ç”¨é€»è¾‘åˆ‡åˆ†å¥½çš„GPU # æŸ¥çœ‹é€»è¾‘GPU logical_gpus = tf.config.experimental.list_logical_devices('GPU') # è·å–æ‰€æœ‰ç‰©ç†GPUä¿¡æ¯ print(len(logical_gpus)) c = [] for gpu in logical_gpus: with tf.device(gpu.name): # æŒ‡å®šGPUåå­—ä½œä¸ºä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œï¼ˆå°†æ­¤GPUåº”ç”¨åˆ°ä¸Šä¸‹æ–‡å˜é‡å½“ä¸­ï¼‰ a = xxx b = xxx c.append( a @ b ) # çŸ©é˜µä¹˜æ³•ï¼Œåº”ç”¨åˆ°äº†CPUï¼Œéå†ä¸€æ¬¡ï¼Œåˆ‡æ¢ä¸€ä¸ªGPU with tf.device('/CPU:0'): # æŒ‡å®šCPUåå­—ä½œä¸ºä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œï¼ˆå°†æ­¤CPUåº”ç”¨åˆ°ä¸Šä¸‹æ–‡å˜é‡å½“ä¸­ï¼‰ tf.add_n(c) åˆ†å¸ƒå¼ç­–ç•¥ MirroredStrategy é•œåƒå¼ç­–ç•¥ï¼š 0. ä¸€å°æœºå™¨ï¼Œ å¤šGPU å‚æ•°åŒæ­¥å¼ï¼Œåˆ†å¸ƒå¼è®­ç»ƒ åŒæ­¥çš„æ„æ€æ˜¯ï¼Œ æ¯ä¸ªGPUçš„ä¸åŒçš„å‚æ•°ä¼š æŒ‰æ¬¡åºåŒæ­¥å¤„ç†ã€‚ ä¸»è¦æœºåˆ¶ï¼š æ•°æ®é›† åˆ†å‘ ç»™ ä¸åŒçš„ GPUå¤„ç† ï¼ˆå‚è€ƒå¤šçº¿ç¨‹ï¼‰ CentralStorageStrategy MirroredStrategy å˜ç§ æ³¨æ„è¿™é‡Œï¼š å‚æ•°è½¬å˜ä¸º å­˜å‚¨åœ¨ä¸€ä¸ªè®¾å¤‡ä¸Šé›†ä¸­ç®¡ç†ï¼ˆå¯CPUï¼Œå¯GPUï¼‰ è€Œè®¡ç®—ï¼Œä¾ç„¶æ˜¯åœ¨æ‰€æœ‰GPUä¸Šè¿è¡Œ MultiWorkerMirroredStrategy åŒ MirroredStrategyï¼Œåªä¸è¿‡ å¯æ‰©å±•ä¸º åœ¨å¤šå°æœºå™¨ å‚æ•°åŒæ­¥å¼ ParameterServerStrategy å‚æ•°ï¼Œå¼‚æ­¥åˆ†å¸ƒ æœºå™¨åˆ†ä¸º Parameter Server å’Œ Workerä¸¤ç±» (å¯ç†è§£ä¸ºï¼Œç”Ÿäº§è€…ï¼Œæ¶ˆè´¹è€…) Parameter Serveï¼š è´Ÿè´£ç®¡ç†ï¼Œæ›´æ–° å‚æ•°å’Œæ¢¯åº¦ Worker: è´Ÿè´£è®¡ç®—ï¼Œè®­ç»ƒç½‘ç»œ å°†è¾“å…¥æ•°æ®è½¬å‘ç»™ å¤šä¸ª Worker Wokeræµç¨‹ï¼š 3.1 Workerä»¬ï¼Œ è®­ç»ƒå å°†å‚æ•° push å›ç»™ Server 3.2 Workerä»¬ï¼Œ è®­ç»ƒå å°† Serverçš„å‚æ•° pull æ‹‰è¿‡æ¥ Serveræµç¨‹ï¼š 3.1 æ¢¯åº¦èšåˆ 3.2 æ¢¯åº¦æ›´æ–° æ€»ç»“åŒæ­¥å¼ vs å¼‚æ­¥å¼ åŒæ­¥å¼ï¼š å°±åƒåˆ†å¸ƒå¼çˆ¬è™«ä¸€æ ·ï¼Œ åŒæ­¥å¼ï¼Œç›¸å½“äºåœ¨ Serverä¸­ åŠ äº†ä¸€ä¸ªç¼“å†²ç®¡é“ã€‚ ç­‰æ‰€æœ‰GPUé½äº†ï¼Œå†å…¨éƒ¨èšåˆæ›´æ–°ã€‚ ç¼ºç‚¹ï¼š æœ‰çš„æœºå™¨è®¡ç®—å¿«ï¼Œæœ‰çš„æœºå™¨è®¡ç®—æ…¢ï¼Œæµªè´¹æ—¶é—´ (çŸ­æ¿æ•ˆåº”ï¼Œï¼Œæ‹–åè…¿) é€‚ç”¨äºï¼š ä¸€å°æœºå™¨ï¼Œå¤šä¸ªGPUï¼Œ é¿å…è¿‡å¤šç½‘ç»œIOé€šä¿¡ å¼‚æ­¥å¼ï¼š ç¼ºç‚¹+ ä¹Ÿç®—æ˜¯ä¼˜ç‚¹ï¼š å°±åƒå¤šçº¿ç¨‹å¯¹å…¨å±€å˜é‡çš„ä¸å¯æ§ä¸€æ ·ã€‚å¯èƒ½å‚æ•°é”™ä¹±ã€‚ ä½†æ˜¯è¿™æ ·è®­ç»ƒå‡ºçš„æ¨¡å‹ï¼Œæ›´æœ‰æ³›åŒ–èƒ½åŠ›ï¼ˆæ›´èƒ½å®¹å¿é”™è¯¯ï¼Œ æ‰€ä»¥è¿™ä¹Ÿç®—æ˜¯ä¸ªå°ä¼˜ç‚¹ï¼‰ é€‚ç”¨äºï¼š å¤šæœºå™¨ï¼Œå¤šGPU åˆ†å¸ƒå¼å®ä¾‹ï¼ˆä»¥MirroredStrategyä¸ºä¾‹ï¼Œå…¶ä»–ä¹Ÿä¸€æ ·ï¼‰ kerasä¸­ä½¿ç”¨åˆ†å¸ƒå¼ï¼š strategy = tf.distribute.MirroredStrategy() with strategy.scope(): # åŒæ ·åˆ¶é€ ä¸€ä¸ªä¸Šä¸‹æ–‡ model = keras.models.Sequential([...]) # æ¨¡å‹å®šä¹‰éƒ¨åˆ†æ”¾åœ¨ä¸Šä¸‹æ–‡æ„å‘³ç€ï¼Œå‚æ•°éœ€è¦åˆ†å¸ƒå¼ç®¡ç† model.add() ... ... model.add() model.compile(...) # compile æ”¾åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œæ„å‘³ç€ï¼Œè®­ç»ƒç¯èŠ‚ï¼ŒåŒæ ·ä¹Ÿéœ€è¦åˆ†å¸ƒå¼è®­ç»ƒ # è‡³æ­¤ç»“æŸ estimatorä½¿ç”¨åˆ†å¸ƒå¼ åŸå§‹ï¼Œæ²¡æœ‰æ·»åŠ åˆ†å¸ƒå¼çš„ estimator ä»£ç  model = keras.Sequential([]) estimator = keras.estimator.model_to_estimator(model) # å·ä¸ªæ‡’ï¼Œç›´æ¥ç”¨Kerasè½¬è¿‡æ¥çš„ï¼Œ å…¶å®estimator æœ‰å¾ˆå¤šå†…ç½®æ¨¡å‹ï¼ˆæ¯”å¦‚çº¿æ€§å›å½’ï¼Œé€»è¾‘å›å½’ï¼‰ã€‚å’ŒSKlearnç”¨æ³•å·®ä¸å¤š # æ‰€ä»¥åœ¨è®­ç»ƒæ—¶ï¼ŒæŠŠ model.fitæ›¿æ¢ä¸º estimator.train from sklearn.linear_model.base import make_dataset estimator.train( input_fn= lambda: è‡ªå·±å¤„ç†æ•°æ®çš„å‡½æ•°(å‚æ•°), # æ­¤å‡½æ•°è¿”å›ç»“æœé€šå¸¸æ˜¯ tf.data.Datasetå¯¹è±¡() max_steps=1000 # æœ€å¤šè®­ç»ƒ1000æ­¥æ•° ) # è®­ç»ƒç»“æœçš„ç²¾åº¦å€¼ç­‰æŒ‡æ ‡ï¼Œé€šå¸¸è¾“å‡ºåˆ°ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œ å¯é€šè¿‡ tensorflow_board æ‰“å¼€æŸ¥çœ‹ ä½¿ç”¨ åˆ†å¸ƒå¼çš„ estimator ä»£ç ï¼š åªéœ€æŒ‰ç…§ä¸Šé¢ä¾¿è·Ÿå‡ è¡Œå³å¯ï¼š strategy = tf.distribute.MirroredStrategy() config = tf.estimator.RunConfig( # ä¸»è¦åŠ äº†è¿™é‡Œ train_distribute=strategy ) model = keras.Sequential([]) estimator = keras.estimator.model_to_estimator(model, config=config) ä¸‹é¢åŒä¸Š è‡ªå®šä¹‰æ¨¡å‹+è®­ç»ƒ çš„ åˆ†å¸ƒå¼æ”¹é€  åˆ†å¸ƒå¼æ•ˆæœä¸å¥½ï¼Ÿï¼Ÿ å¯ä»¥è€ƒè™‘ æŠŠ batch _ size å¢å¤§ å¯ä»¥å°è¯•æ•°æ®åˆ†å¸ƒå¼ æ•°æ®åˆ†å¸ƒå¼ä»£ç ï¼š strategy = tf.distribute.MirroredStrategy() with strategy.scope(): ... train_dataset = strategy.experimental_distribute_dataset(train_dataset) test_dataset = strategy.experimental_distribute_dataset(test_dataset) ","link":"https://cythonlin.github.io/post/py-greater-tensorflow20-gpu-guan-li-yu-fen-bu-shi/"},{"title":"PY => Tensorflow2.0æ¨¡å‹ä¿å­˜ä¸éƒ¨ç½²","content":"æ¨¡å‹ä¿å­˜ tf1: checkpointï¼ˆä¸»åŠ›ï¼‰ tf2: keras(hdf5) æˆ– SavedModel(tf2.0) æ¨èæ ¼å¼ æ¨¡å‹éƒ¨ç½² TFLite TFLite Converter å°†ä¸Šé¢çš„ hdf5 æˆ– SavedModel è½¬åŒ–ä¸º TFLiteæ ¼å¼ TFLite Interpreter ç”¨æ¥åŠ è½½ TFLite Converte è½¬åŒ–åçš„æ¨¡å‹ ï¼ˆæ”¯æŒ IOS Andriodï¼‰ ï¼ˆæ”¯æŒC++ç­‰å¤šç§è¯­è¨€ï¼‰ TFLite FlatBuffer TFLite æ˜¯ä¸€ç§ FlatBuffer æ ¼å¼ FlatBufferï¼š Googleå¼€æº è·¨å¹³å°æ•°æ®åºåˆ—åŒ–åº“ TFLite é‡åŒ– é‡åŒ–ï¼š å‚æ•°ä» float32 å˜ä¸º int8ã€‚ ï¼ˆæŸå¤±ç²¾åº¦ï¼Œæå‡é€Ÿåº¦ï¼‰ æ¨¡å‹å¯ä»¥é™ä½ä¸ºåŸæ¥çš„ 1/4 å®æˆ˜ ä¿å­˜æ¨¡å‹ tf2çš„æ¨¡å‹ä¿å­˜ï¼Œæœ‰ä¸¤å¤§æ´¾åˆ«ï¼š æ–¹å¼1. kerasçš„ä¿å­˜æ–¹å¼ æ–¹å¼2. saved _ modelçš„ä¿å­˜æ–¹å¼ æ–¹å¼1å…·ä½“ä½¿ç”¨ï¼š ä½¿ç”¨callback keras.callbacks.ModelCheckpoint( 'xxx.h5', save_best_only=True, save_weights_only=False # é»˜è®¤å°±æ˜¯False, æ„ä¸ºä¿å­˜ æ¨¡å‹+å‚æ•° ) æ–¹å¼2å…·ä½“ä½¿ç”¨ï¼š ä½¿ç”¨ tf.saved _ model() å°† kerasè½¬ä¸º saved _ model tf.saved_model.save(model, './æ–‡ä»¶å¤¹å') # ç»“æœç›®å½•é‡Œé¢æœ‰ä¸ª saved_model.pd æœ‰ç”¨ æ¨¡å‹ è½¬åŒ–ä¸º Liteæ ¼å¼ kerasæ ¼å¼çš„æ¨¡å‹å¯¹åº”APIï¼š keras_model = tf.lite.TFLiteConverter.from_keras_model(model) # æ™®é€š keras_tflite = keras_model.convert() with open('kerasç›®å½•', 'wb') as f: f.write(keras_tflite) saved _ model æ ¼å¼çš„æ¨¡å‹å¯¹åº”APIï¼š saved_model = tf.lite.TFLiteConverter.from_saved_model('./åŸå§‹æ¨¡å‹ä¿å­˜ç›®å½•') saved_model_tflite = saved_model.convert() with open('saved_modelç›®å½•', 'wb') as f: f.write(saved_model_tflite) TFLite Interpreterç»§ç»­æ“ä½œLite with open('kerasç›®å½•', 'rb') as f: # è¯»å– TFLite keras_model = f.read() interpreter = tf.lite.Interpreter( model_content=keras_model ) interpreter.allocate_tersors() # ç»™ TFLiteä¸­çš„æ‰€æœ‰ Tensor åˆ†é…å†…å­˜ æ¨¡å‹é‡åŒ– å®æ“ å…¶å®å°±æ˜¯åœ¨ä¸Šé¢çš„åŸºç¡€ä¸Šï¼Œä¸­é—´éƒ¨åˆ†åŠ ä¸€è¡Œä»£ç  keras_model = tf.lite.TFLiteConverter.from_keras_model(model) # æ™®é€š # å°±åœ¨è¿™é‡ŒåŠ  keras_model.optimizations = [ tf.lite.Optimize.OPTIMIZE_FOR_SIZE ] keras_tflite = keras_model.convert() æ¨¡å‹è½¬æ¢ï¼ˆè½¬æ¢ä¸º JSä¸ºä¾‹ï¼‰ é¦–å…ˆéœ€è¦ä¸‹è½½ä¸€ä¸ªå·¥å…· tensorflowjs pip install tensorflowjs -i https://pypi.douban.com/simple æ³¨æ„ä¸€ä¸‹ï¼Œ tensorflowjsç›®å‰æœ€é«˜åªæ”¯æŒ tf1.14 ã€‚ æ‰€ä»¥ä½ è¿è¡Œä¸Šè¿°å®‰è£…å‘½ä»¤ï¼Œä½ çš„tfä¼šè‡ªåŠ¨é™çº§åˆ° tf1.14...... æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£ï¼Œçœ‹çœ‹å‚æ•°ï¼š tensorflowjs_converter --help æ­£å¼è½¬æ¢ï¼š(CMD or Shellå‘½ä»¤è¡Œå¼è½¬æ¢æ–¹æ³•) ï¼ˆkerasä¿å­˜ç‰ˆï¼‰ tensorflowjs_converte --input_format keras --output_format tfjs_layers_model ./xxx/xxx.h5 ./keras_to_tfjs_layers # å€’æ•°ç¬¬äºŒä¸ªå‚æ•°æ˜¯ è¾“å…¥ # å€’æ•°ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ è¾“å‡º # è¿è¡ŒæˆåŠŸåï¼Œ JSä¿å­˜ç›®å½•ä¸­ ä¼šæœ‰2ä¸ªæ–‡ä»¶ 1. xx.bin # çœŸæ­£çš„æ¨¡å‹ 2. xx.json # æ¨¡å‹ç›¸å…³é…ç½®ä¿¡æ¯ ï¼ˆmodel _ savedä¿å­˜ç‰ˆï¼‰ tensorflowjs_converte --input_format tf_saved_model --output_format tfjs_graph_model ./xxx/xxx.h5 ./keras_to_tfjs_layers # ä¸Šé¢çš„ saved_model ç‰ˆæœ¬ ä¸»è¦æ”¹äº†è¿™ä¸¤ä¸ªå‚æ•°: --input_format tf_saved_model \\ --output_format tfjs_graph_model \\ å…¶æ¬¡è¿˜æœ‰ ä»£ç å¼ è½¬æ¢æ–¹æ³•ï¼š import tensorflowjs as tfjs model = ... tfjs.converters.save_keras_model(model,'æ–°JSè·¯å¾„') tfjs.converters.convert_tf_saved_model(model,'æ–°JSè·¯å¾„') JSç«¯è°ƒç”¨ éœ€è¦å®‰è£…Nodeç­‰å¯åŠ¨æœåŠ¡ã€‚ Nodeä¹Ÿéœ€è¦å®‰è£… tensorflowjs æ¨¡å—ã€‚ ä½¿ç”¨æ–¹æ³•ï¼Œç•¥ã€‚ã€‚ã€‚ã€‚ã€‚ï¼Œ ","link":"https://cythonlin.github.io/post/py-greater-tensorflow20-mo-xing-bao-cun-yu-bu-shu/"},{"title":"AI => Tensorflow2.0è¯­æ³• - datasetæ•°æ®å°è£…+è®­æµ‹éªŒåˆ‡å‰²ï¼ˆäºŒï¼‰","content":"è®­ç»ƒé›†-æµ‹è¯•é›†-éªŒè¯é›†åˆ‡å‰² ###æ–¹æ³•1ï¼šï¼ˆå€Ÿç”¨ä¸‰æ–¹sklearnåº“ï¼‰ å› ä¸ºsklearnçš„train_test_splitåªèƒ½åˆ‡2ä»½ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åˆ‡2æ¬¡ï¼š from sklearn.model_selection import train_test_split x_train, x_test, y_train, y_test = train_test_split( x, y, # x,yæ˜¯åŸå§‹æ•°æ® test_size=0.2 # test_sizeé»˜è®¤æ˜¯0.25 ) # è¿”å›çš„æ˜¯ å‰©ä½™è®­ç»ƒé›†+æµ‹è¯•é›† x_train, x_valid, y_train, y_valid = train_test_split( x_train, y_train, # æŠŠä¸Šé¢å‰©ä½™çš„ x_train, y_trainç»§ç»­æ‹¿æ¥åˆ‡ test_size=0.2 # test_sizeé»˜è®¤æ˜¯0.25 ) # è¿”å›çš„æ˜¯ äºŒæ¬¡å‰©ä½™è®­ç»ƒé›†+éªŒè¯é›† åˆ‡åˆ†å¥½çš„æ•°æ®ï¼Œä¸€èˆ¬éœ€è¦åš batch_sizeï¼Œ shuffleç­‰ï¼Œ å¯ä»¥ä½¿ç”¨ tf.kerasæ¨¡å‹çš„ fit() ä¸€æ­¥ä¼ é€’ï¼ eg: model.compile( loss=keras.losses.mean_squared_error, optimizer=keras.optimizers.SGD(), metrics=['acc'] # æ³¨æ„è¿™ä¸ªmetricså‚æ•°ï¼Œä¸‹é¢ä¸€ä¼šå°±æåˆ° ) history = model.fit( x_train, y_train, validation_data=(x_valid, y_valid), # éªŒè¯é›†åœ¨è¿™é‡Œç”¨äº†ï¼ï¼ï¼ epochs=100, batch_size = 32 # batch_size ä¸ä¼ ä¹Ÿè¡Œï¼Œå› ä¸ºé»˜è®¤å°±æ˜¯32 shuffle=True, # shuffle ä¸ä¼ ä¹Ÿè¡Œï¼Œå› ä¸ºé»˜è®¤å°±æ˜¯True # callbacks=callbacks, # ) åº¦é‡æŒ‡æ ‡ = model.evaluate(x_test, y_test) # è¿”å›çš„æ˜¯æŒ‡æ ‡ï¼ˆå¯èƒ½åŒ…æ‹¬loss,accï¼‰ # è¿™é‡Œè¯´ä¸€ä¸‹ï¼Œä¸ºä»€ä¹ˆæˆ‘è¯´å¯èƒ½åŒ…æ‹¬ã€‚ # å› ä¸ºè¿™ä¸ªè¿”å›ç»“æœå–å†³äº ä½ çš„ model.compile() ä¼ é€’çš„å‚æ•° # å¦‚æœä½ ä¼ äº† metrics=['acc']ï¼Œ é‚£ä¹ˆè¿™ä¸ªåº¦é‡æŒ‡æ ‡çš„è¿”å›ç»“æœå°±æ˜¯ (loss, acc) # å¦‚æœä½ æ²¡ä¼  metrics ï¼Œ é‚£ä¹ˆè¿™ä¸ªåº¦é‡æŒ‡æ ‡çš„è¿”å›ç»“æœå°±æ˜¯ä¸€ä¸ª loss y_predict = model.predict(x_test) # è¿”å›çš„æ˜¯é¢„æµ‹ç»“æœ ###æ–¹æ³•2ï¼šï¼ˆtf.splitï¼‰ è‡ªå·±å°è£…çš„ä»£ç ï¼šåŠŸèƒ½åŒ…æ‹¬ï¼š 3åˆ‡åˆ†ï¼Œä¹±åºæ•°æ®é›†ï¼Œåˆ†æ‰¹æ“ä½œ ä¸€ä½“åŒ–ï¼ï¼ï¼ ï¼ˆå¯èƒ½æœ‰ç‘•ç–µï¼‰ å·²ä¸Šä¼ è‡³Github : https://github.com/hacker-lin/train_test_valid_split å®šä¹‰éƒ¨åˆ†ï¼š class HandlerData: def init(self, x, y): &quot;&quot;&quot;æˆ‘å°è£…çš„ç±»ï¼Œæ•°æ®é€šè¿‡å®ä¾‹åŒ–ä¼ è¿›æ¥ä¿å­˜&quot;&quot;&quot; self.x = x self.y = y def shuffle_and_batch(self, x, y, batch_size=None): &quot;&quot;&quot;é»˜è®¤å®šæ­»ä¹±åºæ“ä½œï¼Œbatch_sizeå¯é€‰å‚æ•°ï¼Œ å…¶å®ä¹±åºå‚æ•°ä¹Ÿåº”è¯¥è®¾ç½®å¯é€‰çš„ã€‚æ‡’äº†&quot;&quot;&quot; data = tf.data.Dataset.from_tensor_slices((x, y)) # å°è£… datasetæ•°æ®é›†æ ¼å¼ data_ = data.shuffle( # ä¹±åº buffer_size=x.shape[0], # å®˜æ–¹æ–‡æ¡£è¯´æ˜ shuffleçš„buffer_size å¿…é¡»å¤§äºæˆ–ç­‰äºæ ·æœ¬æ•°é‡ ) if batch_size: data_ = data_.batch(batch_size) return data_ def train_test_valid_split(self, test_size=0.2, # æµ‹è¯•é›†çš„åˆ‡å‰²æ¯”ä¾‹ valid_size=0.2, # éªŒè¯é›†çš„åˆ‡å‰²æ¯”ä¾‹ batch_size=32, # batch_size é»˜è®¤æˆ‘è®¾ä¸ºäº†32 is_batch_and_shuffle=True # è¿™ä¸ªæ˜¯éœ€ä¸éœ€è¦ä¹±åºå’Œåˆ†æ‰¹ï¼Œé»˜è®¤è®¾ä¸ºä½¿ç”¨ä¹±åºå’Œåˆ†æ‰¹ ): sample_num = self.x.shape[0] # è·å–æ ·æœ¬æ€»ä¸ªæ•° train_sample = int(sample_num * (1 - test_size - valid_size)) # è®­ç»ƒé›†çš„ä»½æ•° test_sample = int(sample_num * test_size) # æµ‹è¯•é›†æµ‹ä»½æ•° valid_train = int(sample_num * valid_size) # éªŒè¯é›†çš„ä»½æ•° # è¿™ä¸‰ä¸ªä¸ºä»€ä¹ˆæˆ‘ç”¨intåŒ…è£¹èµ·æ¥äº†ï¼Œå› ä¸ºæˆ‘è°ƒè¯•è¿‡ç¨‹ä¸­å‘ç°ï¼Œæœ‰æµ®ç‚¹æ•°è®¡ç®—ç²¾åº¦ç¼ºå¤±ç°è±¡ã€‚ # æ‰€ä»¥å¿…é¡»è½¬æ•´å½¢ # tf.split() æ­¤è¯­æ³•ä¸Šä¸€ç¯‡æˆ‘è®²è¿‡ï¼Œåˆ†nä»½ï¼Œæ¯ä»½å¯ä¸åŒæ•°é‡ x_train, x_test, x_valid = tf.split( self.x, num_or_size_splits=[train_sample, test_sample, valid_train], axis=0 ) y_train, y_test, y_valid = tf.split( self.y, [train_sample, test_sample, valid_train], axis=0 ) # å› ä¸ºä»½æ•°æ˜¯æˆ‘åˆ‡å‰²x,yä¹‹å‰è®¡ç®—å‡ºæ¥çš„å…¬å…±å˜é‡ã€‚æ‰€ä»¥ä¸ç”¨æ‹…å¿ƒ x,yä¸åŒ¹é…çš„é—®é¢˜ã€‚ if is_batch_and_shuffle: # æ˜¯å¦ä½¿ç”¨ä¹±åºå’Œåˆ†æ‰¹ï¼Œé»˜è®¤æ˜¯ä½¿ç”¨çš„ï¼Œæ‰€ä»¥èµ°è¿™æ¡ return ( self.shuffle_and_batch(x_train, y_train, batch_size=batch_size), self.shuffle_and_batch(x_test, y_test, batch_size=batch_size), self.shuffle_and_batch(x_valid, y_valid, batch_size=batch_size), ) else: # å¦‚æœä½ åªæƒ³è¦åˆ‡å‰²åçš„åŸç”Ÿæ•°æ®ï¼Œé‚£ä¹ˆä½ æŠŠis_batch_and_shuffleä¼ Falseå°±èµ°è¿™æ¡è·¯äº† return ( (x_train, y_train), (x_test, y_test), (x_valid, y_valid) ) è°ƒç”¨æ¡ˆä¾‹ï¼š x = tf.ones([1000, 5000]) y = tf.ones([1000, 1]) data_obj = HandlerData(x,y) # xæ˜¯åŸç”Ÿçš„æ ·æœ¬æ•°æ®ï¼Œxæ˜¯åŸç”Ÿçš„labelæ•°æ® # æ–¹å¼1ï¼šä½¿ç”¨ä¹±åºï¼Œä½¿ç”¨åˆ†æ‰¹ï¼Œå°±æ˜¯ä¸€ä¸ªå‚æ•°éƒ½ä¸ç”¨ä¼ ï¼Œå…¨æ˜¯é»˜è®¤å€¼ train, test, valid = data_obj.train_test_valid_split( # test_size=0.2, # valid_size=0.2, # batch_size=32, # is_batch_and_shuffle=True ) # è¿™äº›å‚æ•°ä½ éƒ½å¯ä»¥ä¸ä¼ ï¼Œè¿™éƒ½æ˜¯è®¾ç½®çš„é»˜è®¤å€¼ã€‚ print(train) print(test) print(valid) # ç»“æœ &gt;&gt;&gt; &lt;BatchDataset shapes: ((None, 5000), (None, 1)), types: (tf.float32, tf.float32)&gt; &gt;&gt;&gt; &lt;BatchDataset shapes: ((None, 5000), (None, 1)), types: (tf.float32, tf.float32)&gt; &gt;&gt;&gt; &lt;BatchDataset shapes: ((None, 5000), (None, 1)), types: (tf.float32, tf.float32)&gt; # è™½ç„¶ä½ çœ‹è§äº†æ ·æœ¬æ•°ä¸ºNoneï¼Œä½†æ˜¯æ²¡å…³ç³»ï¼Œå› ä¸ºä½ è¿˜æ²¡ä½¿ç”¨ï¼Œéå†ä¸€ä¸‹å°±æ˜ç™½äº† for x_train,y_train in train: print(x_train.shape,y_train.shape) # ç»“æœ 600 // 32 == 18 ï¼ˆä½ å¯ä»¥æŸ¥ä¸€ä¸‹æ­£å¥½18ä¸ªï¼‰ # ç»“æœ 600 % 32 == 24 ï¼ˆä½ å¯ä»¥çœ‹ä¸€ä¸‹æœ€åä¸€ä¸ªå°±æ˜¯24ï¼‰ (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (32, 5000) (32, 1) (24, 5000) (24, 1) # 32ä¸ªä¸€æ‰¹ï¼Œæœ€åä¸€ä¸ªå°±æ˜¯ä½™æ•° 24ä¸ªäº†ã€‚ # æ–¹å¼2ï¼šä¸ä½¿ç”¨ä¹±åºï¼Œä½¿ç”¨åˆ†æ‰¹ï¼Œåªè¦åŸç”Ÿæ•°æ®ï¼Œ (x_train, y_train), (x_test, y_test), (x_valid, y_valid) = data_obj.train_test_valid_split( # test_size=0.2, # valid_size=0.2, # batch_size=32, is_batch_and_shuffle=False # è¿™ä¸ªæ”¹ä¸ºFalseå³å¯ï¼Œå…¶ä»–å‚æ•°å¯é€‰ ) print(x_train.shape, y_train.shape) print(x_test.shape, y_test.shape) print(x_valid.shape, y_valid.shape) # ç»“æœ &gt;&gt;&gt; (600, 5000) (600, 1) &gt;&gt;&gt; (200, 5000) (200, 1) &gt;&gt;&gt; (200, 5000) (200, 1) æ–¹å¼3ï¼ˆè®­éªŒåˆ†å‰²ï¼‰ history = model.fit( ..... validation_split=0.2 # è®­ç»ƒé›†åˆ†å‡º0.2ç»™éªŒè¯é›† ) æ•°æ®å¤„ç† ï¼ˆdatasetï¼‰ è¿™ä¸ªæ¨¡å—çš„ä½œç”¨å°±æ˜¯ï¼Œå°†æˆ‘ä»¬çš„æ•°æ®ï¼Œæˆ–è€… TFå¼ é‡ï¼Œå°è£…æˆæ•°æ®é›†ã€‚ è¿™ä¸ªæ•°æ®é›†å…·æœ‰æˆå“APIï¼Œæ¯”å¦‚ï¼šå¯ä»¥å¸®åŠ©æˆ‘ä»¬ï¼Œåˆ†æ‰¹ï¼Œä¹±åºï¼Œåˆ¶ä½œè¿­ä»£ï¼Œç­‰ä¸€äº›åˆ—æ“ä½œã€‚ åŸºæœ¬ç†è§£ dataset = tf.data.Dataset.from_tensor_slices(np.arange(16).reshape(4,4)) æŒ‰ç†æ¥è¯´ï¼ˆå…ˆä¸å–ï¼‰ï¼Œæ•°æ®å½¢çŠ¶åº”è¯¥æ˜¯è¿™æ ·çš„ã€‚ ï¼ˆä¸€ä¸ªå¤§åˆ—è¡¨é‡Œé¢ï¼Œæœ‰4ä¸ªå°åˆ—è¡¨ï¼‰ [ [0, 1, 2 ,3 ], [4, 5, 6 ,7 ], [8, 9, 10,11], [12,13,14,15], ] for data in dataset: # å°è£…çš„æ•°æ®é›†éœ€è¦éå†ï¼ˆæˆ–è€… iter() æ”¹å˜ä¸ºè¿­ä»£å™¨ç±»å‹ï¼‰ï¼Œæ‰èƒ½è¿”å›å€¼ print(data) # æ¯éå†ä¸€æ¡å°±æ˜¯é‡Œé¢çš„å°åˆ—è¡¨ã€‚ eg:ç¬¬ä¸€æ¡å½¢çŠ¶ï¼š [0, 1, 2 ,3 ] # ä½†æ˜¯åˆ«å¿˜äº†ã€‚æˆ‘ä»¬è¿™æ˜¯Tensorflowï¼Œå› æ­¤æ¯å±‚æ•°æ®é›†éƒ½è¢«å°è£…ä¸ºTensorã€‚ # å› æ­¤ï¼Œæˆ‘ä»¬æ¯éå†å‡ºä¸€æ¡æ•°æ®ï¼Œéƒ½æ˜¯ä¸€æ¡Tensor è¾“å‡ºï¼š &gt;&gt; tf.Tensor([0 1 2 3], shape=(4,), dtype=int32) tf.Tensor([4 5 6 7], shape=(4,), dtype=int32) tf.Tensor([ 8 9 10 11], shape=(4,), dtype=int32) tf.Tensor([12 13 14 15], shape=(4,), dtype=int32) å‰é¢è¯´äº†ï¼Œè¿™ä¸ªæ•°æ®çš„æ ¼å¼å°±æ˜¯ï¼ˆä¸€ä¸ªå¤§åˆ—è¡¨é‡Œé¢ï¼Œæœ‰4ä¸ªå°åˆ—è¡¨ï¼‰ å¯¹åº”æ¥çœ‹ï¼Œ ï¼ˆä¸€ä¸ªå¤§Tensoré‡Œé¢ï¼Œ æœ‰4ä¸ªå°Tensorï¼‰ã€‚ è®°ä½è¿™ä¸ªç†å¿µ æ•°æ®æ¥æºå‚æ•°ç±»å‹ å‚æ•°ä¼ å…ƒç»„ï¼š question = [[1, 0], [1, 1]] answer = ['encode', 'decoder'] dataset = tf.data.Dataset.from_tensor_slices( (question, answer) ) # ç”¨å…ƒç»„åŒ…èµ·æ¥äº† for data in dataset: print(data[0],'=&gt;' ,data[1]) è¾“å‡º: &gt;&gt; tf.Tensor([1 0], shape=(2,), dtype=int32) =&gt; tf.Tensor(b'encode', shape=(), dtype=string) tf.Tensor([1 1], shape=(2,), dtype=int32) =&gt; tf.Tensor(b'decoder', shape=(), dtype=string) ä½ å¯ä»¥çœ‹å‡ºå®ƒè‡ªåŠ¨æŠŠæˆ‘ä»¬ä¼ é€’çš„ question å’Œ answer ä¸¤ä¸ªå¤§åˆ—è¡¨ã€‚ &quot;ç›¸å½“äºåšäº†zip()æ“ä½œ&quot;ã€‚ # æˆ‘çš„å®éªŒç»å†ï¼šè®­ç»ƒ Encoder-Decoderæ¨¡å‹çš„ï¼Œ&quot;é—®ç­”å¯¹æ•°æ®&quot;ï¼Œåšç¼–ç åï¼Œå°±å¯ä»¥è¿™æ ·ç”¨å…ƒç»„ä¼ ã€‚ å‚æ•°ä¼ å­—å…¸ï¼š data_dict = { 'encoder': [1, 0], 'decoder': [1, 1] } dataset = tf.data.Dataset.from_tensor_slices(data_dict) for data in dataset: # å…¶å®æ¯ä¸€ä¸ªå…ƒç´ å°±æ˜¯ä¸€ä¸ªå­—å…¸ print(data) # å…¶å®å°±æ˜¯æŠŠä½ çš„ valueéƒ¨åˆ†ï¼Œè½¬æˆäº†Tensorç±»å‹ã€‚ æ€»ä½“ç»“æ„æ²¡å˜ é“¾å¼è°ƒç”¨ Dataset API å¤§å¤šæ•°æ“ä½œå‡ ä¹éƒ½æ˜¯é“¾å¼è°ƒç”¨ï¼ˆå°±åƒpythonå­—ç¬¦ä¸²çš„ replaceæ–¹æ³•ï¼‰ ç”¨ä¸Šé¢çš„æ•°æ®ä½œä¸ºæ¡ˆä¾‹æ•°æ®ï¼Œ ä»‹ç»å‡ ç§APIï¼š batch (åˆ†æ‰¹) for data in dataset.batch(2): # è‹¥è®¾ç½® drop_remainder=Trueï¼Œåˆ™æœ€åä½™ä¸‹ä¸€æ‰¹ä¼šè¢«ä¸¢å¼ƒ print(data) è¾“å‡ºï¼š &gt;&gt; tf.Tensor([[0 1 2 3] [4 5 6 7]], shape=(2, 4), dtype=int32) tf.Tensor([[ 8 9 10 11] [12 13 14 15]], shape=(2, 4), dtype=int32) ä¸Šé¢è¯´è¿‡ï¼Œé»˜è®¤å°±æ˜¯ éå†å‡ºçš„æ¯ä¸ªå­é¡¹ï¼Œå°±æ˜¯ä¸€ä¸ªTensorï¼Œ å¦‚ä¸Šæ•°æ®ï¼Œéå†å‡º 4ä¸ªTensor è€Œè°ƒç”¨ batch(2) åï¼Œ æŠŠ2ä¸ªå­é¡¹åˆ†æˆä¸€æ‰¹ï¼Œ ç„¶åå†åŒ…è£…æˆä¸ºTensorã€‚ so, 4/2 = 2æ‰¹ ï¼Œ åŒ…è£…æˆ2ä¸ªTensor repeatï¼ˆé‡å¤ä½¿ç”¨æ•°æ®ï¼šepochç†å¿µï¼Œ é‡å¤è®­ç»ƒnè½®æ¬¡ï¼‰ æ³¨æ„ï¼ˆä¼ çš„å°±æ˜¯æ€»é‡å¤æ•°ï¼Œç®—è‡ªèº«ï¼‰ï¼š 1. å¦‚æœrepeat() ä¸ä¼ å‚æ•°ï¼Œé‚£å°±æ˜¯æ— é™é‡å¤ã€‚ã€‚ã€‚ 2. å¦‚æœä¼ å‚æ•° = 0, é‚£ä¹ˆä»£è¡¨ä¸å–æ•°æ® 3. å¦‚æœä¼ å‚æ•° = 1, é‚£ä¹ˆä»£è¡¨ä¸€å…±å°±ä¸€ä»½æ•°æ® 4. å¦‚æœä¼ å‚æ•° = 2, é‚£ä¹ˆä»£è¡¨ä¸€å…±å°±2ä»½æ•°æ®ï¼ˆæŠŠè‡ªå·±ç®—ä¸Šï¼Œä¸€å…±2ä»½ï¼Œå°±è¿™ä¹ˆä¸ªé‡å¤çš„æ„æ€ï¼‰ for data in dataset.repeat(2).batch(3): # é‡å¤2æ¬¡ã€‚ 3ä¸ªä¸€ç»„ ï¼ˆè¿™å°±æ˜¯é“¾å¼è°ƒç”¨ï¼‰ print(data) ç»“æœ &gt;&gt; tf.Tensor([[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]], shape=(3, 4), dtype=int32) tf.Tensor([[12 13 14 15] [ 0 1 2 3] [ 4 5 6 7]], shape=(3, 4), dtype=int32) tf.Tensor([[ 8 9 10 11] [12 13 14 15]], shape=(2, 4), dtype=int32) åŸæ•°æ®æ˜¯4ä¸ªå­é¡¹ï¼Œ é‡å¤2æ¬¡ ï¼š 4*2=8 ç„¶åé“¾å¼è°ƒç”¨åˆ†3æ‰¹ï¼š 8/3=2 ..... 2 ï¼ˆæ•´æ‰¹3ä¸ªä¸€ç»„ï¼Œ æœ€åä¸€æ‰¹ä½™æ•°ä¸€ç»„ï¼‰ # è¿˜è¦æ³¨æ„ä¸€ä¸‹ï¼Œ å®ƒä»¬é‡å¤æ˜¯é¡ºåºé‡å¤æ‹¼æ¥ã€‚ åˆ†æ‰¹æ—¶ï¼Œå¯ä»¥é¦–å°¾ç›¸è¿çš„ ï¼ˆeg:å°±åƒå°æ—¶å€™åƒçš„ä¸€è¿ä¸²æ£’æ£’ç³–ï¼Œ æ‹½ä¸å¥½ï¼Œä¼šæŠŠä¸Šä¸€ä¸ªçš„ç³–çš®è¿ç€æ‹½ä¸‹æ¥ï¼‰ æœªå®Œå¾…ç»­ ","link":"https://cythonlin.github.io/post/ai-greater-tensorflow20-yu-fa-dataset-shu-ju-feng-zhuang-xun-ce-yan-qie-ge-er/"},{"title":"AI => Tensorflow2.0è¯­æ³• - å¼ é‡&åŸºæœ¬å‡½æ•°(ä¸€)","content":"å‰è¨€ TF2.0 æ˜¯ä¹‹å‰å­¦ä¹ çš„å†…å®¹ï¼Œå½“æ—¶æ˜¯å†™åœ¨äº†ç§æœ‰çš„YNoteä¸­ï¼Œé‡å†™äºSFã€‚ TF2.0-GPU å®‰è£…æ•™ç¨‹ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020304638 ä¹‹å‰æ¥è§¦è¿‡ TF1, æ‰‹åŠ¨sessionæœºåˆ¶ï¼Œçœ‹ç€å¾ˆæ˜¯å¤´ç–¼ã€‚ TF2.0ä¸éœ€è¦åšè¿™äº› TF2.0 ç†è§£èµ·æ¥æ›´å®¹æ˜“ï¼ˆé€æ¸ Pythonic and Numpicï¼‰ TF2.0 åç«¯é‡‡ç”¨kerasæ¥å£ (æ„å»ºç½‘ç»œå±‚)ï¼Œæ›´æ–¹ä¾¿ã€‚ TF2.0 çš„kerasæ¥å£å®šä¹‰çš„æ¨¡å‹å±‚ï¼Œéƒ½å®ç°äº† callæ–¹æ³•ã€‚æ„å‘³å¤§å¤šæ•°å®ä¾‹å¯¹è±¡å¯ä»¥å½“ä½œå‡½æ•°æ¥ç›´æ¥è°ƒç”¨ è¡Œåˆ—è½´ ä»¥åˆ—è¡¨ä¸ºä¾‹ï¼ˆæŠ½è±¡ä¸¾ä¾‹ï¼Œæ‘èµ·æ¥çš„é¢åŒ…ç‰‡ã€‚ã€‚ã€‚ã€‚ï¼‰ [ # æœ€å¤–å±‚ï¼Œæ— æ„ä¹‰ä¸ç”¨è®° [1,2,3], # é¢åŒ…ç‰‡1 (ç¬¬ä¸€ä¸ªæ ·æœ¬) [4,5,6], # é¢åŒ…ç‰‡2 (ç¬¬äºŒä¸ªæ ·æœ¬) ] æ¯ä¸ª æ¬¡å†…å±‚åˆ—è¡¨ ä»£è¡¨ä¸€ä¸ªæ ·æœ¬ï¼Œ æ¯”å¦‚ [1,2,3] æ•´ä½“ä»£è¡¨ ç¬¬ä¸€ä¸ªæ ·æœ¬ æœ€å†…å±‚å…ƒç´ ä»£è¡¨å±æ€§å€¼ã€‚ eg: 1,2,3 å•ä¸ªæ‹¿å‡ºæ¥éƒ½æ˜¯å±æ€§å€¼ã€‚ ä¾‹å­ï¼š å…ƒç´ 5 å•ç‹¬æ‹¿å‡ºæ¥ï¼Œå®ƒå°±è¢«çœ‹åš &quot;ç¬¬äºŒä¸ªæ ·æœ¬çš„ï¼Œå±æ€§å€¼5&quot; ï¼ˆå½“ç„¶æ¨ªçºµç´¢å¼•ä¾ç„¶éƒ½æ˜¯ä»0å–çš„ï¼‰ ä»¥åˆšæ‰çš„æ•°æ®ä¸ºä¾‹ï¼š t = tf.constant( [ [1., 2., 3.], [4., 5., 6.] ] ) print(tf.reduce_sum(t, axis=0)) # æ±‚å’Œæ“ä½œï¼Œä¸Šä¸‹å‹æ‰ï¼Œ èšåˆæ ·æœ¬ &gt;&gt; tf.Tensor([5. 7. 9.], shape=(3,), dtype=float32) print(tf.reduce_sum(t, axis=1)) # æ±‚å’Œæ“ä½œï¼Œå·¦å³å‹æ‰ï¼Œ èšåˆå±æ€§ &gt;&gt; tf.Tensor([ 6. 15.], shape=(2,), dtype=float32) æ³¨ï¼šNumpyè½´ä¹Ÿæ˜¯è¿™æ ·çš„ï¼Œæˆ‘æœ€åˆç”¨xï¼Œyè½´æ–¹å¼ æŠ½è±¡ å»è®°å¿†ï¼Œ åŸºæœ¬ä¸Šæ˜¯è®°ä¸ä½çš„ã€‚ã€‚å¤ªå¤šæ¦‚å¿µæ··æ·†ã€‚ ä½†å¦‚æœä½ è®°ä¸ä½ï¼Œä½ æ¯æ¬¡ä½¿ç”¨å„ç§æ“ä½œå’ŒèšåˆAPIæ—¶ï¼Œéƒ½ä¼šè‡ªå·±åœ¨å¿ƒç†é‡æ–°èŠ±å¤§é‡æ—¶é—´ç†ä¸€éã€‚æµªè´¹æ—¶é—´ã€‚ æ‰€ä»¥ä½ ä¸€å®šè¦ç»ƒä¹ ç†è§£ï¼Œè¦åšåˆ°ï¼šâ€œç„ä¸€çœ¼ï¼Œå°±èƒ½çŸ¥é“è¿™ç§ç»´åº¦çš„æ•°æ®çš„æ„ä¹‰ï¼Œä»¥åŠè½´æ“ä½œçš„æ„ä¹‰â€ æˆ‘è‡ªå·±çš„è®°å¿†æ–¹å¼ï¼ˆaxis=0, axis=1ï¼‰ï¼š 0è½´é€šå¸¸ä»£è¡¨ï¼Œæ ·æœ¬ï¼ˆä¸Šä¸‹å‹æ‰ï¼‰ 1è½´é€šå¸¸ä»£è¡¨ï¼Œå±æ€§ï¼ˆå·¦å³å‹æ‰ï¼‰ å¸¸éœ€è¦ç”¨ axiså‚æ•° çš„ç›¸å…³èšåˆå‡½æ•°ï¼š tf.reduce_sum() # æ±‚å’Œ tf.reduce_mean() # å¹³å‡å€¼ tf.reduce_max() # æœ€å¤§å€¼ tf.reduce_min() # æœ€å°å€¼ tf.square() # å¹³æ–¹ tf.concat() # æ‹¼æ¥ æ³¨ï¼š å¦‚æœ axiså‚æ•° &quot;ä¸ä¼ &quot;ï¼Œ é‚£ä¹ˆ&quot;æ‰€æœ‰ç»´åº¦&quot;éƒ½ä¼šè¢«æ“ä½œã€‚ å¸¸ç”¨å¯¼å…¥ # åŸºæœ¬ä¼šç”¨åˆ°çš„ import numpy as np import tensorflow as tf from tensorflow import keras # å¯é€‰å¯¼å…¥ import os, sys, pickle import scipy import pandas as pd import matplotlib.pyplot as plt from sklearn.preprocessing import StandardScaler # æ ‡å‡†åŒ– from sklearn.model_selection import train_test_split # è®­æµ‹åˆ†ç¦» å¼ é‡&amp;æ“ä½œç¬¦ å¸¸é‡ï¼ˆæ™®é€šçš„å¼ é‡ï¼‰ ###å®šä¹‰ï¼š c = tf.constant( [[1., 2., 3.], [4., 5., 6.]] ) # æ•°å­—åé¢åŠ ä¸ªç‚¹ä»£è¡¨ è½¬float32 ç±»å‹ print(c) &gt;&gt; tf.Tensor([[1. 2. 3.] [4. 5. 6.]], shape=(2, 3), dtype=float32) ###å…­åˆ™è¿ç®—ï¼ˆåŠ å‡ä¹˜é™¤ï¼ŒçŸ©é˜µä¹˜, çŸ©é˜µè½¬ç½®ï¼‰ å…ˆè¯´çŸ©é˜µä¹˜æ³•ï¼ˆå¤§å­¦éƒ½å­¦è¿‡çš„ï¼Œè¿ç®—è¿‡ç¨‹ä¸è¯´äº†ï¼‰ï¼š è¯­æ³•æ ¼å¼ï¼š a @ b æ¡ä»¶è¦æ±‚ï¼š açš„åˆ—æ•° === bçš„è¡Œæ•° ï¼ˆå¿…é¡»ç›¸ç­‰ï¼‰ eg: ï¼ˆ5è¡Œ2åˆ— @ 2è¡Œ10åˆ— = 5è¡Œ10åˆ—ï¼‰ ç‰¹ä¾‹ï¼š (ç¬¬0ç»´åº¦ï¼Œå¿…é¡»ç›¸ç­‰) t1 = tf.ones([2, 20, 30]) t2 = tf.ones([2, 30, 50]) print( (t1@t2).shape ) &gt;&gt; (2, 20, 50) # ç¬¬0ç»´æ²¡å˜ï¼Œ å2ç»´ç…§å¸¸æŒ‰ç…§çŸ©é˜µä¹˜æ³•è¿ç®— çŸ©é˜µè½¬ç½®ï¼š tf.transpose(t) # ä¸ä»…å¯ä»¥æ™®é€šè½¬ç½®ï¼Œè¿˜å¯ä»¥äº¤æ¢ç»´åº¦ t2 = tf.transpose(t,[1,0]) # è¡Œå˜åˆ—ï¼Œåˆ—å˜è¡Œã€‚ å’ŒåŸºæœ¬çš„è½¬ç½®å·®ä¸å¤šï¼ˆé€†åºç´¢å¼•ï¼Œè½´å˜é€†åºï¼‰ # æˆ–å‡å¦‚ä»¥ ï¼ˆ2,100ï¼Œ200ï¼Œ3ï¼‰å½¢çŠ¶ ä¸ºä¾‹ t = tf.ones([2, 100, 200, 3]) print(tf.transpose(t, [1, 3, 0, 2]).shape) # è½´äº¤æ¢ä½ç½® &gt;&gt; (100, 3, 2, 200) # åŸ1è½´ -&gt; æ”¾åœ¨ç°åœ¨0è½´ # åŸ3è½´ -&gt; æ”¾åœ¨ç°åœ¨1è½´ # åŸ0è½´ -&gt; æ”¾åœ¨ç°åœ¨2è½´ # åŸ2è½´ -&gt; æ”¾åœ¨ç°åœ¨3è½´ åŠ å‡ä¹˜é™¤éƒ½å…·æœ‰&quot;å¹¿æ’­æœºåˆ¶&quot; ï¼š å½¢è±¡ï¼ˆå¹¿æ’­æœºåˆ¶è§£é‡Šï¼‰è§£é‡Šï¼š æˆ‘å°è¯•ç”¨ç™½è¯è§£é‡Šä¸‹ï¼š 1. æˆ‘å½¢çŠ¶å’Œä½ ä¸ä¸€æ ·ï¼Œ ä½†æˆ‘å’Œä½ è¿ç®—çš„æ—¶å€™ï¼Œæˆ‘ä¼šå°½åŠ›æ‰©å¼ æˆ ä½ çš„å½¢çŠ¶ æ¥å’Œä½ è¿ç®—ã€‚ 2. æ‰©å¼ åå¦‚æœå‡ºç°ç©ºç¼ºï¼Œ é‚£ä¹ˆæŠŠè‡ªå·±å¤åˆ¶ä¸€ä»½ï¼Œå¡«è¡¥ä¸Š ï¼ˆå¦‚æœè¡¥ä¸å…¨ï¼Œå°±è¯´æ˜ä¸èƒ½è¿ç®—ï¼‰ 3. å°å½¢çŠ¶ æœä» å¤§å½¢çŠ¶ (æˆ‘æ¯”ä½ ç˜¦ï¼Œæˆ‘åŠ¨å°±è¡Œã€‚ ä½ ä¸ç”¨åŠ¨ã€‚ã€‚ã€‚) eg: t = tf.constant( [ [1, 2, 3], [4, 5, 6], ] ) t + [1,2,1] è¿‡ç¨‹åˆ†æï¼š [1,2,1] æ˜¾ç„¶æ˜¯ å°å½¢çŠ¶ï¼Œ å®ƒä¼šè‡ªåŠ¨å°è¯•å˜åŒ–æˆå¤§å½¢çŠ¶ -&gt; ç¬¬ä¸€æ­¥å˜å½¢ï¼ˆæœ€å¤–å±‚å¤§æ¡†æ¶æ»¡è¶³ï¼Œ é‡Œé¢è¿˜æœ‰ç©ºç¼ºï¼‰ï¼š [ [1,2,1], ] ç¬¬äºŒæ­¥å˜å½¢ (æŠŠè‡ªå·±å¤åˆ¶ï¼Œç„¶åå¡«è¡¥ç©ºç¼º)ï¼š [ [1,2,1], [1,2,1], # è¿™å°±æ˜¯å¤åˆ¶çš„è‡ªå·± ] ç¬¬ä¸‰æ­¥è¿ç®—ï¼ˆé€ä½ç›¸åŠ ï¼‰ [ + [ = [ [1,2,3], [1,2,1], [2,4,4], [4,5,6], [1,2,1], [5,7,7], ] ] [ æŠ½è±¡ï¼ˆå¹¿æ’­æœºåˆ¶ï¼‰æ¼”ç¤ºï¼š å‡å¦‚ t1 çš„ shapeä¸º [5,200,100,50] å‡å¦‚ t2 çš„ shapeä¸º [5,200] æ³¨æ„ï¼šæˆ‘ä»¥ä¸‹çš„æ•°æ®æ¼”ç¤ºï¼Œå…¨æ˜¯è¡¨ç¤º Tensorçš„å½¢çŠ¶ï¼Œå½¢çŠ¶ï¼Œå½¢çŠ¶ï¼ [5,200,1,50] # å¾ˆæ˜æ˜¾ï¼Œå¼€å§‹è¿™2è¡Œæ•°æ® ç»´åº¦æ²¡åŒ¹é…ï¼Œ å½¢çŠ¶ä¹Ÿæ²¡å¯¹é½ [5,1] ------------------------ [5,200,1,50] [5,50] # è¿™è¡Œå¯¹é½è¡¥50 ------------------------ [5,200,5,50] # è¿™è¡Œå¯¹é½è¡¥5 [5,50] ------------------------ [5,200,5,50] [1, 1, 5,50] # è¿™è¡Œæ‰©å¼ äº†2ä¸ªï¼Œ é»˜è®¤å¡«1 ------------------------ [5,200,5,50] [1,200, 5,50] # è¿™è¡Œå¯¹é½è¡¥200 ------------------------ [5,200,5,50] [5,200,5,50] # è¿™è¡Œå¯¹é½è¡¥5 æ³¨æ„ï¼š 1. æ¯ä¸ªç»´åº¦å½¢çŠ¶ï¼šäºŒè€…å¿…é¡»æœ‰ä¸€ä¸ªæ˜¯1ï¼Œ æ‰èƒ½å¯¹é½ã€‚ ï¼ˆä¸ç„¶ERRORï¼Œä¸‹ä¾‹ERROR-&gt;ï¼‰ [5,200,1,50] [5,20] # åŒç†å¼€å§‹å‘å³å¯¹é½ï¼Œä½†æ˜¯ 50ä¸20éƒ½ä¸æ˜¯1ï¼Œæ‰€ä»¥éƒ½ä¸èƒ½å¯¹é½ï¼Œæ‰€ä»¥ERROR 2. è‹¥ç»´åº¦ç¼ºå¤±ï¼š ä¾ç„¶æ˜¯å…¨éƒ¨è´´å³å¯¹é½ ç„¶åå…ˆä»å³é¢å¼€å§‹ï¼Œè¡¥æ¯ä¸ªç»´åº¦çš„å½¢çŠ¶ ç„¶åæ‰©å±•ç»´åº¦ï¼Œå¹¶é»˜è®¤è®¾å½¢çŠ¶ä¸º1 ç„¶åè¡¥æ‰©å±•åç»´åº¦çš„å½¢çŠ¶ï¼ˆå› ä¸ºé»˜è®¤è®¾ä¸º1äº†ï¼Œæ‰€ä»¥æ˜¯ä¸€å®šå¯ä»¥è¡¥é½çš„ï¼‰ å½“ç„¶ä¸Šé¢è¯´çš„éƒ½æ˜¯è¿ç®—æ—¶çš„è‡ªåŠ¨å¹¿æ’­æœºåˆ¶ ä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¹¿æ’­ï¼š t1 = tf.ones([2, 20, 1]) # åŸå§‹å½¢çŠ¶ ã€2ï¼Œ20ï¼Œ1ã€‘ print(tf.broadcast_to(t1, [5,2,20,30]).shape) # ç›®æ ‡å½¢çŠ¶ã€5ï¼Œ2ï¼Œ20ï¼Œ30ã€‘ [5,2,20,30] [2,20, 1] ----------- [5,2,20,30] [2,20,30] ----------- [5,2,20,30] [1,2,20,30] ----------- [5,2,20,30] [5,2,20,30] æ³¨ï¼šå› ä¸ºæ˜¯æ‰‹åŠ¨å¹¿æ’­ï¼Œæ‰€ä»¥åªèƒ½ åŸå§‹å½¢çŠ¶ è‡ªå·±å‘ ç›®æ ‡å½¢çŠ¶ â€è¡¥å……ç»´åº¦ï¼Œæˆ–è€…è¡¥å……å½¢çŠ¶â€œ è€Œç›®æ ‡å½¢çŠ¶æ˜¯ä¸€ç‚¹ä¹Ÿä¸èƒ½åŠ¨çš„ã€‚ æ‰©å……ç»´åº¦ï¼ˆf.expand_dimsï¼‰+ å¤åˆ¶ï¼ˆtileï¼‰ ä»£æ›¿ =&gt; å¹¿æ’­ï¼ˆtf.broadcastingï¼‰ åŒæ ·æ˜¯ä¸Šé¢çš„ä¾‹å­ï¼Œæˆ‘æƒ³æŠŠå½¢çŠ¶ [2,20,1] ï¼Œå˜æˆ [5ï¼Œ2ï¼Œ20ï¼Œ30] t1 = tf.ones([2, 20, 1]) a = tf.expand_dims(t1,axis=0) # 0è½´ç´¢å¼•å¤„æ’å…¥ä¸€ä¸ªè½´ï¼Œ ç»“æœ[1,2,20,1] print(tf.tile(a,[5,1,1,30]).shape) # ç»“æœ [5, 2, 20, 30] æµç¨‹ï¼š [5,2,20,30] [2,20,1] ----------- [5,2,20,30] # tf.expand_dims(t1,axis=0) [1,2,20,1] # 0å·ç´¢å¼•æ’å…¥ä¸€ä¸ªæ–°è½´ï¼ˆå¢ç»´ï¼‰ ----------- [5,2,20,30] # tf.tile(5,1,1,30) (å½¢çŠ¶å¯¹é½ï¼Œtileæ¯ä¸ªå‚æ•°ä»£è¡¨å¯¹åº”è½´çš„å½¢çŠ¶æ‰©å……å‡ å€) [5,2,30,30] 15 21 201 130 tile ä¸ broadcastingçš„åŒºåˆ«ï¼š tileæ˜¯ç‰©ç†å¤åˆ¶ï¼Œç‰©ç†ç©ºé—´å¢åŠ  è€Œbroadcastingæ˜¯è™šæ‹Ÿå¤åˆ¶ï¼Œï¼ˆä¸ºäº†è®¡ç®—ï¼Œéšå¼å®ç°çš„å¤åˆ¶ï¼Œå¹¶æ²¡æœ‰ç‰©ç†ç©ºé—´å¢åŠ ï¼‰ tileå¯ä»¥å¯¹ä»»æ„ï¼ˆæ•´æ•°å€å¤åˆ¶n*m, mnåŒä¸ºæ•´æ•°ï¼‰ è€Œbroadcastingï¼ˆåŸå§‹æ•°æ®å½¢çŠ¶åªèƒ½å­˜åœ¨1çš„æƒ…å†µä¸‹æ‰èƒ½æ‰©å¼ ã€‚ 1*n , nä¸ºæ•´æ•°ï¼‰ å‹ç¼©ç»´åº¦ï¼ˆtf.squeezeï¼‰ï¼š å°±æ˜¯æŠŠæ¯ä¸ªç»´åº¦ä¸º1çš„ç»´åº¦éƒ½åˆ é™¤æ‰ ï¼ˆå°±åƒæ•°å­¦ a * 1 = aï¼‰ print(tf.squeeze(tf.ones([2,1,3,1])).shape) (2, 3) å½“ç„¶ä½ ä¹Ÿå¯ä»¥æŒ‡å®šç»´åº¦å‹ç¼©ï¼ˆé»˜è®¤ä¸æŒ‡å®šï¼Œæ‰€æœ‰ç»´åº¦ä¸º1çš„å…¨éƒ¨å‹ç¼©ï¼‰ï¼š print(tf.squeeze(tf.ones([2,1,3,1]), axis=-1).shape) &gt;&gt;&gt; (2, 1, 3) ç´¢å¼•&amp;åˆ‡ç‰‡ çµé­‚è¯´æ˜ï¼šæ— è®ºç´¢å¼•è¿˜æ˜¯åˆ‡ç‰‡ï¼Œ ï¼ˆè¡Œåˆ— æ˜¯ä½¿ç”¨ é€—å· åˆ†éš”çš„ï¼‰ï¼Œ å¹¶ä¸”æ— è®ºè¡Œåˆ—ï¼Œç´¢å¼•éƒ½æ˜¯ä»0å¼€å§‹çš„ã€‚ ç´¢å¼•ï¼šå–ä¸€ä¸ªå€¼ print(t[1,2]) # é€—å·å‰é¢ä»£è¡¨è¡Œçš„ç´¢å¼•ï¼Œ é€—å·åé¢æ˜¯åˆ—çš„ç´¢å¼• &gt;&gt; tf.Tensor(6.0, shape=(), dtype=float32) åˆ‡ç‰‡ï¼šå–å­ç»“æ„ ï¼ˆæœ‰ä¸¤ç§æ–¹å¼ï¼‰ æ–¹å¼1ï¼ˆå†’å·åˆ‡ç‰‡ï¼‰ï¼š print(t[:, 1:]) # é€—å·å‰é¢æ˜¯è¡Œã€‚åªå†™: ä»£è¡¨å–æ‰€æœ‰è¡Œã€‚é€—å·åé¢æ˜¯åˆ—ã€‚ 1: ä»£è¡¨ç¬¬äºŒåˆ—åˆ°æœ€å &gt;&gt; tf.Tensor([[2. 3.] [5. 6.]], shape=(2, 2), dtype=float32) æ–¹å¼2ï¼ˆçœç•¥å·åˆ‡ç‰‡ï¼‰: ï¼ˆæˆ‘ç›¸ä¿¡ä¸äº†è§£Numpyçš„äººéƒ½æ²¡å¬è¯´è¿‡ pythonçš„ Ellipsis ï¼Œ å°±æ˜¯çœç•¥å·ç±»ï¼‰ å…ˆè‡ªå·±å»è¿è¡Œç©ç©è¿™è¡Œä»£ç ï¼š print(... is Ellipsis) &gt;&gt;&gt; True å›åˆ°æ­£é¢˜ï¼šï¼ˆçœç•¥å· ... åˆ‡ç‰‡ï¼Œæ˜¯é’ˆå¯¹å¤šç»´åº¦çš„ï¼Œ å¦‚æœæ˜¯äºŒç»´ç›´æ¥ç”¨:å³å¯ï¼‰ (æˆ‘ä»¬ä»¥ä¸‰ç»´ä¸ºä¾‹ï¼Œè¿™ä¸ªå°±ä¸é€‚åˆç§°ä½œè¡Œåˆ—äº†) # shape æ˜¯ (2, 2, 2) t = tf.constant( [ # ä¸€ç»´ [ # äºŒç»´ [1, 2], # ä¸‰ç»´ [3, 4], ], [ [5, 6], [7, 8], ], ] ) ä¼ªç ï¼št[1ç»´åˆ‡ç‰‡, äºŒç»´åˆ‡ç‰‡, ä¸‰ç»´åˆ‡ç‰‡] ä»£ç ï¼št[:, :, 0:1] # 1ç»´ä¸åŠ¨ï¼Œ 2ç»´ä¸åŠ¨ï¼Œ 3ç»´ å–ä¸€æ¡æ•°æ® ç»“æœ: shapeä¸º (2,2,1) [ # ä¸€ç»´ [ # äºŒç»´ [1], # ä¸‰ç»´ [3], ], [ [5], [7], ], ] çœ‹ä¸æ˜ç™½å°±å¤šçœ‹å‡ éã€‚ å‘ç°æ²¡ï¼Œå³ä½¿æˆ‘ä¸å¯¹ 1ç»´ï¼Œå’Œ 2ç»´åˆ‡ç‰‡ï¼Œæˆ‘ä¹Ÿè¢«è¿«è¦å†™ 2ä¸ª: æ¥å ä½ é‚£å‡å¦‚æœ‰100ä¸ªç»´åº¦ï¼Œæˆ‘åªæƒ³å¯¹æœ€åä¸€ä¸ªç»´åº¦åˆ‡ç‰‡ã€‚ å‰99ä¸ªéƒ½ä¸ç”¨åŠ¨ï¼Œ é‚£éš¾é“æˆ‘è¦å†™ 99ä¸ª : å ä½ï¼Ÿï¼Ÿ ä¸ï¼Œå¦‚ä¸‹ä»£ç å³å¯è§£å†³ï¼š print(t[..., 0:1]) # è¿™å°±æ˜¯ ... çš„ä½œç”¨ ï¼ˆæ³¨æ„ï¼Œåªåœ¨ numpy å’Œ tensorflowä¸­æœ‰ç”¨ï¼‰ tensor è½¬ numpy ç±»å‹ t.numpy() # tensor è½¬ä¸º numpy ç±»å‹ å˜é‡ å®šä¹‰ï¼š v = tf.Variable( # æ³¨æ„ï¼š Væ˜¯å¤§å†™ [ [1, 2, 3], [4, 5, 6] ] ) å˜é‡èµ‹å€¼(å…·æœ‰è‡ªèº«èµ‹å€¼çš„æ€§è´¨)ï¼š æ³¨æ„ï¼š å˜é‡ä¸€æ—¦è¢«å®šä¹‰ï¼Œå½¢çŠ¶å°±å®šä¸‹æ¥äº†ã€‚ èµ‹å€¼ï¼ˆåªèƒ½èµ‹ç»™åŒå½¢çŠ¶çš„å€¼ï¼‰ v.assign( [ [1,1,1], [1,1,1], ] ) print(v) &gt;&gt; &lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=array([[1, 1, 1],[1, 1, 1]])&gt; å˜é‡å–å€¼ï¼ˆç›¸å½“äºè½¬æ¢ä¸ºTensorï¼‰ï¼š ç‰¹åˆ«ï¼š å˜é‡æœ¬èº«å°±æ˜¯ Variableç±»å‹ï¼Œ å–å€¼å–å‡ºå¾—æ˜¯ Tensor ï¼ˆåŒ…æ‹¬åˆ‡ç‰‡å–å€¼ï¼Œç´¢å¼•å–å€¼ç­‰ï¼‰ print( v.value() ) &gt;&gt; tf.Tensor([[1 2 3] [4 5 6]], shape=(2, 3), dtype=int32) å˜é‡ ç´¢å¼•&amp;åˆ‡ç‰‡ èµ‹å€¼ï¼š å¸¸é‡:æ˜¯ä¸å¯å˜çš„ã€‚æ‰€ä»¥åªæœ‰å–å€¼ï¼Œæ²¡æœ‰èµ‹å€¼ã€‚ å˜é‡:å–å€¼ã€èµ‹å€¼éƒ½å¯ä»¥ v.assign(xx) ç±»ä¼¼äº pythonçš„ v=xx v[0, 1].assign(100) # ç´¢å¼•èµ‹å€¼, v.assign ç­‰ä»·äº v[0, :].assign([10, 20, 30]) # æ³¨æ„ï¼Œåˆ‡ç‰‡èµ‹å€¼ä¼ é€’çš„éœ€è¦æ˜¯å®¹å™¨ç±»å‹ ç‰¹åˆ«æ³¨æ„ï¼š å‰é¢è¯´è¿‡ï¼Œå˜é‡ ç»“æ„å½¢çŠ¶ æ˜¯ ä¸å¯å˜çš„ï¼Œèµ‹å€¼çš„èµ‹ç»™çš„æ˜¯æ•°æ®ã€‚ ä½†æ˜¯ä½ èµ‹å€¼çš„æ—¶å€™è¦æ—¶åˆ»æ³¨æ„ï¼Œä¸èƒ½æ”¹å˜å˜é‡åŸæœ‰å½¢çŠ¶ æ‹¿åˆ‡ç‰‡èµ‹å€¼ä¸ºä¾‹ï¼š ä½ åˆ‡å¤šå°‘ä¸ªï¼Œä½ å°±å¾—èµ‹å¤šå°‘ä¸ªã€‚ å¹¶ä¸”èµ‹çš„å€¼ç»“æ„è¦ä¸€è‡´ã€‚ ä¸¾ä¸ªæ —å­ï¼š ä½ ä»æ­£æ–¹ä½“é‡Œé¢æŒ–å‡ºæ¥ä¸€ä¸ªå°æ­£æ–¹ä½“ã€‚é‚£ä¹ˆä½ å¿…é¡»å¡«è¡¥ä¸€å—ä¸€æ¨¡ä¸€æ ·å½¢çŠ¶çš„å°æ­£æ–¹ä½“ï¼‰ è¿˜æœ‰ä¸¤ç§æ‰©å±•APIï¼š v.assign_add() # ç±»ä¼¼python çš„ += v.assign_sub() # ç±»ä¼¼python çš„ -= å˜é‡ ç´¢å¼•&amp;åˆ‡ç‰‡ å–å€¼ åŒ å¸¸é‡åˆ‡ç‰‡å–å€¼ï¼ˆç•¥ï¼‰ Variable è½¬ Numpy print(v.numpy()) ä¸è§„åˆ™å¼ é‡ï¼ˆRaggedTensorï¼‰ å®šä¹‰ï¼š rag_tensor = tf.ragged.constant( [ [1,2], [2,3,4,5], ] ) # å…è®¸æ¯ä¸ªç»´åº¦çš„æ•°æ®é•¿åº¦å‚å·®ä¸é½ æ‹¼æ¥ï¼šå‡å¦‚éœ€è¦&quot;æ‹¼æ¥ ä¸è§„åˆ™å¼ é‡&quot; ï¼ˆå¯ä½¿ç”¨ tf.concat(axis=) ï¼‰ 0è½´ï¼šç«–ç€æ‹¼æ¥ï¼ˆæ ·æœ¬ç«–ç€æ‘èµ·æ¥ï¼‰å¯éšæ„æ‹¼æ¥ã€‚ æ‹¼æ¥åçš„ä¾ç„¶æ˜¯&quot;ä¸è§„åˆ™å¼ é‡&quot; 1è½´ï¼šæ¨ªç€æ‹¼æ¥ï¼ˆå±æ€§æ°´å¹³æ‹¼èµ·æ¥ï¼‰è¿™æ—¶å€™éœ€è¦ä½ æ ·æœ¬ä¸ªæ•°å¿…é¡»ç›¸ç­‰ï¼Œ å¦åˆ™å¯¹ä¸ä¸Šï¼ŒæŠ¥é”™ æ€»ç»“ï¼š æ ·æœ¬ç«–ç€éšä¾¿æ‹¼ï¼Œ å±æ€§æ¨ªç€ï¼ˆå¿…é¡»æ ·æœ¬ä¸ªæ•°ç›¸ç­‰ï¼‰ æ‰èƒ½æ‹¼ RaggedTensor æ™®é€š Tensorï¼š è¯´æ˜ï¼šæ™®é€šTensoræ˜¯å¿…é¡»è¦æ±‚ï¼Œ é•¿åº¦å¯¹é½çš„ã€‚å…¥ å¯¹ä¸é½çš„ æœ«å°¾è¡¥0 tensor = rag_tensor.to_tensor() ç¨€ç–å¼ é‡ ï¼ˆSparse Tensorï¼‰ ç‰¹ç‚¹ï¼ˆå¯ç†è§£ä¸º è®°å½•ç´¢å¼•ï¼‰ï¼š åªè®°å½•é0çš„åæ ‡ä½ç½®ï¼Œ indiceså‚æ•°ï¼šæ¯ä¸ª å­åˆ—è¡¨ è¡¨ç¤º ä¸€ä¸ªåæ ‡ è™½ç„¶åªè®°å½•åæ ‡ï¼Œä½†æ˜¯è½¬ä¸ºæ™®é€šTensoråï¼Œåªæœ‰åæ ‡ä½ç½® æœ‰å€¼ï¼Œ å…¶ä»–ä½ç½®çš„å€¼å…¨æ˜¯0 å¡«å……èŒƒå›´ï¼Œå–å†³äº dense_shapeçš„è®¾å®š å®šä¹‰ï¼š s = tf.SparseTensor( indices=[[0, 1], [1, 0], [2, 3]], # æ³¨æ„ï¼Œè¿™ä¸ªç´¢å¼•è®¾ç½®éœ€è¦æ˜¯ï¼ˆä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹ï¼‰çš„é¡ºåºè®¾ç½® values=[1, 2, 3], # å°†ä¸Šé¢3ä¸ªåæ ‡å€¼åˆ†åˆ«è®¾å€¼ä¸º 1ï¼Œ2ï¼Œ3 dense_shape=[3, 4] # Tensoræ€»èŒƒå›´ ) print(s) SparseTensor(indices=tf.Tensor([[0 1], [1 0],[2 3]], shape=(3, 2), dtype=int64)ã€‚ã€‚ã€‚ è½¬ä¸ºæ™®é€š Tensor (è½¬ä¸ºæ™®é€šTensoråï¼Œçœ‹è§çš„æ‰æ˜¯å­˜å‚¨çœŸæ­£çš„å€¼) tensor = tf.sparse.to_dense(s) print(tensor) tf.Tensor([ [0 1 0 0],[2 0 0 0],[0 0 0 3] ], shape=(3, 4), dtype=int32) å¦‚æœä¸Šé¢ä½¿ç”¨ to_dense() å¯èƒ½ä¼šé‡åˆ°é”™è¯¯ï¼š error: is out of range è¿™ä¸ªé”™è¯¯çš„åŸå› æ˜¯åˆ›å»º tf.SparseTensor(indices=) ï¼Œå‰é¢ä¹Ÿè¯´äº†indicesï¼Œè¦æŒ‰ï¼ˆä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹ï¼‰é¡ºåºå†™ å½“ç„¶ä½ ä¹Ÿå¯ä»¥ç”¨æ’åºAPIï¼Œå…ˆæ’åºï¼Œç„¶åå†è½¬ï¼š eg: _ = tf.sparse.reorder(s) # å…ˆå°†ç´¢å¼•æ’åº tensor = tf.sparse.to_dense(_) # å†è½¬ tf.function è¿™ä¸ªAPIä½œä¸ºä¸€ä¸ªè£…é¥°å™¨ä½¿ç”¨ï¼Œ ç”¨æ¥å°† Python è¯­æ³•è½¬æ¢ å°½å¯èƒ½æœ‰æ•ˆçš„è½¬æ¢ä¸º TFè¯­æ³•ã€å›¾ç»“æ„ import tensorflow as tf import numpy as np @tf.function def f(): a = np.array([1, 2, 3]) b = np.array([4, 5, 6]) return a + b print( f() ) &gt;&gt;&gt; tf.Tensor([5 7 9], shape=(3,), dtype=int32) ä½ åº”è¯¥å‘ç°äº†ä¸€ä¸ªç‰¹ç‚¹ï¼Œæˆ‘ä»¬å®šä¹‰çš„ f()å‡½æ•°å†…éƒ¨ï¼Œä¸€ä¸ªtfè¯­æ³•éƒ½æ²¡å†™ã€‚ åªè£…é¥°äº†ä¸€è¡Œ @tf.function è€Œè°ƒç”¨ç»“æœè¿”å›å€¼å±…ç„¶æ˜¯ä¸ª tensor ã€‚ è¿™å°±æ˜¯ @tf.function è£…é¥°å™¨çš„ä½œç”¨äº†ï¼ å½“ç„¶å‡½æ•°é‡Œé¢ï¼Œä¹Ÿå¯ä»¥å†™ tfçš„æ“ä½œï¼Œä¹Ÿæ˜¯æ²¡é—®é¢˜çš„ã€‚ ä½†æ³¨æ„ä¸€ç‚¹ï¼Œ å‡½æ•°é‡Œé¢ä¸å…è®¸å®šä¹‰ å˜é‡ï¼Œ éœ€è¦å®šä¹‰çš„å˜é‡ åº” æ‹¿åˆ°å‡½æ•°å¤–é¢å®šä¹‰ a = tf.Variable([1,2,3]) # å¦‚éœ€tensorå˜é‡ï¼Œåº”è¯¥æ”¾åœ¨å¤–é¢ @tf.function def f(): # a = tf.Variable([1,2,3]) # è¿™é‡Œé¢ä¸å…è®¸å®šä¹‰å˜é‡! pass åˆå¹¶ç›¸åŠ ï¼ˆtf.concatï¼‰ æˆ‘çš„ç†è§£å°±æ˜¯ï¼ˆåŸºæœ¬æ•°å­¦çš„ åˆå¹¶åŒç±»é¡¹ï¼‰ # åˆå¹¶åŒç±»é¡¹çš„åŸåˆ™å°±æ˜¯æœ‰1é¡¹ä¸åŒï¼Œå…¶ä»–é¡¹å®Œå…¨ç›¸åŒã€‚ # å‰ææ¡ä»¶ï¼šï¼ˆæœ€å¤šï¼Œæœ‰ä¸€ä¸ªç»´åº¦çš„å½¢çŠ¶ä¸ç›¸ç­‰ã€‚ æ³¨æ„æ˜¯æœ€å¤šï¼‰ t1 = tf.ones([2,5,6]) t2 = tf.ones([6,5,6]) print( tf.concat([t1,t2],axis=0).shape ) # axis=0,ä¼ äº†0è½´ï¼Œé‚£ä¹ˆå…¶ä»–è½´ææ­»ä¸å˜ã€‚åªåˆå¹¶0è½´ &gt;&gt; (8,5,8) å †å é™ç»´ï¼ˆtf.stackï¼‰ æˆ‘çš„ç†è§£å°±æ˜¯ï¼ˆå°å­¦ç®—æœ¯çš„ï¼Œè¿›ä½ï¼Œï¼ˆè¿›ä½å°±æ˜¯æ‰©å……ä¸€ä¸ªç»´åº¦è¡¨ç¤ºä¸ªæ•°ï¼‰ï¼‰ # å‰ææ¡ä»¶ï¼šæ‰€æœ‰ç»´åº¦å½¢çŠ¶å¿…é¡»å…¨éƒ¨ç›¸ç­‰ã€‚ tf1 = tf.ones([2,3,4]) tf2 = tf.ones([2,3,4]) tf3 = tf.ones([2,3,4]) print(tf.stack([tf1,tf2,tf3], axis=0).shape) # ä½ å¯ä»¥æƒ³è±¡æœ‰3ç»„ [2,3,4]ï¼Œç„¶å3ç»„ä½œä¸ºä¸€ä¸ªæ–°ç»´åº¦ï¼Œæ’å…¥åˆ° axiså¯¹åº”çš„ç´¢å¼•å¤„ã€‚ &gt;&gt; (3, 2, 3, 4) # å¯¹æ¯”ç†è§£ï¼Œå¦‚æœè¿™æ˜¯tf.concat(), é‚£ä¹ˆç»“æœå°±æ˜¯ (6,3,4) æ‹†åˆ†é™ç»´ï¼ˆtf.unstackï¼‰ å’Œtf.stackæ­£å¥½æ˜¯äº’é€†è¿‡ç¨‹ï¼ŒæŒ‡å®šaxisç»´åº¦æ˜¯å‡ ï¼Œå®ƒå°±ä¼šæ‹†åˆ†æˆå‡ ä¸ªæ•°æ®ï¼ŒåŒæ—¶é™ç»´ã€‚ a = tf.ones([3, 2, 3, 4]) for x in tf.unstack(a, axis=0): print(x.shape) ç»“æœå¦‚ä¸‹ï¼ˆåˆ†æˆäº†3ä¸ª [2,3,4]ï¼‰ &gt;&gt;&gt; (2, 3, 4) &gt;&gt;&gt; (2, 3, 4) &gt;&gt;&gt; (2, 3, 4) æ‹†åˆ†ä¸é™ç»´ï¼ˆtf.splitï¼‰ ###è¯­æ³•ï¼š å’Œtf.unstackçš„åŒºåˆ«å°±æ˜¯ï¼Œtf.unstackæ˜¯å‡åˆ†é™ç»´ï¼Œ tf.stackæ˜¯æ€ä¹ˆåˆ†éƒ½ä¸ä¼šé™ç»´ï¼Œä¸”èƒ½æŒ‡å®šåˆ†éš”ä»½æ•° a = tf.ones([2,4,35,8]) for x in tf.split(a, axis=3,num_or_size_splits=[2,2,4]): print(x.shape) ç»“æœï¼š &gt;&gt; (2, 4, 35, 2) # æœ€åä¸€ç»´2 &gt;&gt; (2, 4, 35, 2) # æœ€åä¸€ç»´2 &gt;&gt; (2, 4, 35, 4) # æœ€åä¸€ç»´4 ###ä½¿ç”¨åœºæ™¯ï¼š å‡å¦‚æˆ‘ä»¬æƒ³åˆ‡åˆ†æ•°æ®é›†ä¸ºï¼ˆtrain-test-validï¼‰ 3åˆ†æ¯”ä¾‹ä¸º 6ï¼š2ï¼š2 æ–¹æ³•1ï¼šï¼ˆscikit-learn è¿ç»­åˆ†åˆ‡2æ¬¡ï¼‰ x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2) x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train,test_size=0.2) # æºç ä¸­æ˜¾ç¤º test_sizeå¦‚æœä¸ä¼ ã€‚é»˜è®¤ä¸º0.25ã€‚ # æ€è·¯ï¼Œå› ä¸º scikit-learn åªèƒ½åˆ‡å‡º2ä¸ªç»“æœï¼š æ‰€ä»¥æˆ‘ä»¬éœ€è¦åˆ‡2æ¬¡ï¼š # ç¬¬ä¸€æ¬¡ ä»å®Œæ•´è®­ç»ƒé›† åˆ‡å‡ºæ¥ ï¼ˆå‰©ä½™è®­ç»ƒé›†ï¼Œ æµ‹è¯•é›†ï¼‰ # ç¬¬äºŒæ¬¡ ä»å‰©ä½™æ•°æ®é›† åˆ‡å‡ºæ¥ ï¼ˆå‰©ä½™è®­ç»ƒé›†2ï¼Œ éªŒè¯é›†ï¼‰ æ–¹æ³•2ï¼š ï¼ˆtf.splitï¼‰ x = tf.ones([1000, 5000]) y = tf.ones([1000, 1]) x_train, x_test, x_valid = tf.split( x, num_or_size_splits=[600,200,200], # åˆ‡3ä»½ axis=0 ) y_train, y_test, y_valid = tf.split( y, num_or_size_splits=[600,200,200], # åŒæ ·åˆ‡3ä»½ axis=0 ) print(x_train.shape, y_train.shape) print(x_test.shape, y_test.shape) print(x_valid.shape, y_valid.shape) ç»“æœ &gt;&gt;&gt; (600, 5000) (600, 1) &gt;&gt;&gt; (200, 5000) (200, 1) &gt;&gt;&gt; (200, 5000) (200, 1) é«˜çº§ç´¢å¼•ï¼ˆtf.gatherï¼‰ numpyè¿™ç§ç´¢å¼•å«åš fancy indexing(å¦‚æœæˆ‘æ²¡è®°é”™çš„è¯) data = tf.constant([6,7,8]) # å½“ä½œçœŸå®æ•°æ® index = tf.constant([2, 1, 0]) # å½“ä½œç´¢å¼• print(tf.gather(data, index)) &gt;&gt; tf.Tensor([8 7 6], shape=(3,), dtype=int32) æ’åºï¼ˆtf.sortï¼‰ data = tf.constant([6, 7, 8]) print(tf.sort(data, direction='DESCENDING')) # 'ASCENDING' # é»˜è®¤æ˜¯ASCENDINGå‡åº tf.argsort() # åŒä¸Šï¼Œ åªä¸è¿‡è¿”å›çš„æ˜¯æ’åºåçš„ï¼Œå¯¹åº”æ•°æ®çš„index Top-K(tf.math.top_k) æŸ¥æ‰¾å‡ºæœ€å¤§çš„nä¸ªï¼ˆæ¯”å…ˆæ’åºç„¶ååˆ‡ç‰‡çš„æ€§èƒ½è¦å¥½ï¼‰ a = tf.math.top_k([6,7,8],2) # æ‰¾å‡ºæœ€å¤§çš„ä¸¤ä¸ªï¼Œè¿”å›æ˜¯ä¸ªå¯¹è±¡ print(a.indices) # å–å‡ºæœ€å¤§çš„ä¸¤ä¸ª ç´¢å¼• ï¼ˆï¼‰ print(a.values) # å–å‡ºæœ€å¤§çš„ä¸¤ä¸ª å€¼ &gt;&gt; tf.Tensor([2 1], shape=(2,), dtype=int32) &gt;&gt; tf.Tensor([8 7], shape=(2,), dtype=int32) tf.GradientTape ï¼ˆè‡ªå®šä¹‰æ±‚å¯¼ï¼‰ æ±‚åå¯¼ v1, v2 = tf.Variable(1.), tf.Variable(2.) # å˜é‡ ä¼š è¢«è‡ªåŠ¨ä¾¦æµ‹æ›´æ–°çš„ c1, c2 = tf.constant(1.), tf.constant(2.) # å¸¸é‡ ä¸ä¼š è‡ªåŠ¨ä¾¦æµ‹æ›´æ–° y = lambda x1,x2: x1**2 + x2**2 with tf.GradientTape(persistent=True) as tape: &quot;&quot;&quot;é»˜è®¤è¿™ä¸ª tapeä½¿ç”¨ä¸€æ¬¡å°±ä¼šè¢«åˆ é™¤ï¼Œ persistent=True ä»£è¡¨æ°¸ä¹…å­˜åœ¨ï¼Œä½†åç»­éœ€è¦æ‰‹åŠ¨é‡Šæ”¾&quot;&quot;&quot; # å› ä¸ºå¸¸é‡ä¸ä¼šè¢«è‡ªåŠ¨ä¾¦æµ‹ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨è°ƒç”¨ watch() ä¾¦æµ‹ tape.watch(c1) # å¦‚æœæ˜¯å˜é‡ï¼Œå°±ä¸ç”¨watchè¿™ä¸¤æ­¥äº† tape.watch(c2) f = y(c1,c2) # è°ƒç”¨å‡½æ•°ï¼Œè¿”å›ç»“æœ c1_, c2_ = tape.gradient(f, [c1,c2]) # å‚æ•°2:ä¼ é€’å‡ ä¸ªè‡ªå˜é‡ï¼Œå°±ä¼šè¿”å›å‡ ä¸ª åå¯¼ç»“æœ # c1_ ä¸º c1çš„åå¯¼ # c2_ ä¸º c2çš„åå¯¼ del tape # æ‰‹åŠ¨é‡Šæ”¾ tape æ±‚äºŒé˜¶åå¯¼ï¼ˆgradientåµŒå¥—ï¼‰ v1, v2 = tf.Variable(1.), tf.Variable(2.) # æˆ‘ä»¬ä½¿ç”¨å˜é‡ y = lambda x1,x2: x1**2 + x2**2 with tf.GradientTape(persistent=True) as tape2: with tf.GradientTape(persistent=True) as tape1: f = y(v1,v2) once_grads = tape1.gradient(f, [v1, v2]) # ä¸€é˜¶åå¯¼ # æ­¤åˆ—è¡¨æ¨å¯¼å¼è¡¨ç¤ºï¼šæ‹¿ç€ä¸€é˜¶åå¯¼ï¼Œæ¥ç»§ç»­æ±‚äºŒé˜¶åå¯¼ï¼ˆæ³¨æ„ï¼Œç”¨tape2ï¼‰ twice_grads = [tape2.gradient(once_grad, [v1,v2]) for once_grad in once_grads] # äºŒé˜¶åå¯¼ print(twice_grads) del tape1 # é‡Šæ”¾ del tape2 # é‡Šæ”¾ è¯´æ˜ æ±‚å¯¼æ•°ï¼ˆä¸€ä¸ªè‡ªå˜é‡ï¼‰ï¼štape1.gradient(f, v1) # gradientä¼  1ä¸ªè‡ªå˜é‡ æ±‚åå¯¼ï¼ˆå¤šä¸ªè‡ªå˜é‡ï¼‰ï¼štape1.gradient(f, [v1,v2]) # gradientä¼  1ä¸ªåˆ—è¡¨ï¼Œ åˆ—è¡¨å†…å¡«æ‰€æœ‰è‡ªå˜é‡ SGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰ æ–¹å¼1ï¼šæ‰‹æ’•ï¼ˆä¸ä½¿ç”¨ä¼˜åŒ–å™¨ï¼‰ v1, v2 = tf.Variable(1.), tf.Variable(2.) # æˆ‘ä»¬ä½¿ç”¨å˜é‡ y = lambda x1, x2: x1 ** 2 + x2 ** 2 # äºŒå…ƒäºŒæ¬¡æ–¹ç¨‹ learning_rate = 0.1 # å­¦ä¹ ç‡ for _ in range(30): # è¿­ä»£æ¬¡æ•° with tf.GradientTape() as tape: # æ±‚å¯¼ä½œç”¨åŸŸ f = y(v1,v2) d1, d2 = tape.gradient(f, [v1,v2]) # æ±‚å¯¼ï¼Œ d1ä¸º v1çš„åå¯¼ï¼Œ d2ä¸ºv2çš„åå¯¼ v1.assign_sub(learning_rate * d1) v2.assign_sub(learning_rate * d2) print(v1) print(v2) å®ç°æµç¨‹æ€»ç»“ï¼š 1. åå¯¼ è‡ªå˜é‡v1,v2æ±‚å‡ºæ¥çš„ã€‚ ï¼ˆd1, d2 = tape.gradient(f, [v1,v2])ï¼‰ 2. è‡ªå˜é‡v1,v2çš„è¡°å‡ æ˜¯å…³è” åå¯¼çš„ï¼ˆ è¡°å‡å€¼ = å­¦ä¹ ç‡*åå¯¼ï¼‰ 3. æˆ‘ä»¬æŠŠå‰2æ­¥å¥—äº†ä¸€ä¸ªå¤§å¾ªç¯ï¼ˆå¹¶è®¾å®šè¿­ä»£æ¬¡æ•°ï¼‰ï¼Œ 1-2-1-2-1-2-1-2-1-2 æ­¥éª¤å¾€å¤æ‰§è¡Œ æ–¹å¼2ï¼šå€Ÿç”¨ Tensorflow ä¼˜åŒ–å™¨(optimizer) å®ç°æ¢¯åº¦ä¸‹é™ v1, v2 = tf.Variable(1.), tf.Variable(2.) # æˆ‘ä»¬ä½¿ç”¨å˜é‡ y = lambda x1, x2: x1 ** 2 + x2 ** 2 # äºŒå…ƒäºŒæ¬¡å‡½æ•° , é€šå¸¸è¿™ä¸ªå‡½æ•°æˆ‘ä»¬ç”¨ä½œè®¡ç®—loss learning_rate = 0.1 # å­¦ä¹ ç‡ optimizer = keras.optimizers.SGD(learning_rate=learning_rate) # åˆå§‹åŒ–ä¼˜åŒ–å™¨ for _ in range(30): # è¿­ä»£æ¬¡æ•° with tf.GradientTape() as tape: f = y(v1,v2) d1, d2 = tape.gradient(f, [v1,v2]) # d1ä¸º v1çš„åå¯¼ï¼Œ d2ä¸ºv2çš„åå¯¼ optimizer.apply_gradients( # æ³¨æ„è¿™é‡Œä¸ä¸€æ ·äº†ï¼Œæˆ‘ä»¬ä¹‹å‰æ‰‹åŠ¨è¡°å‡ [ # è€Œç°åœ¨è¿™äº›äº‹æƒ…ï¼Œ optimizer.SGDå¸®æˆ‘ä»¬åšäº† (d1, v1), # æˆ‘ä»¬åªéœ€æŠŠåå¯¼å€¼ï¼Œå’Œè‡ªå˜é‡æŒ‰è¿™ç§æ ¼å¼ä¼ ç»™å®ƒå³å¯ (d2, v2), ] ) # é€šå¸¸è¿™ç§æ ¼å¼ï¼Œæˆ‘ä»¬ç”¨ zip() å®ç° # eg: # model = keras.models.Sequential([......]) # ....... # grads = tape.gradient(f, [v1,v2]) # optimizer.apply_gradients( # zip(grads, model.trainable_variables) # ) print(v1) print(v2) å®ç°æµç¨‹æ€»ç»“ï¼š 1. åå¯¼ æ˜¯è‡ªå˜é‡v1,v2æ±‚å‡ºæ¥çš„ ï¼ˆd1, d2 = tape.gradient(f, [v1,v2])ï¼‰ # æ­¤æ­¥éª¤ä¸å˜ 2. æŠŠåå¯¼ å’Œ è‡ªå˜é‡ ä¼ ç»™optimizer.apply_gradients() optimizer.SGD() è‡ªåŠ¨å¸®æˆ‘ä»¬è¡°å‡ã€‚ 3. æˆ‘ä»¬è¿˜æ˜¯æŠŠå‰2æ­¥å¥—äº†ä¸€ä¸ªå¤§å¾ªç¯ï¼ˆå¹¶è®¾å®šè¿­ä»£æ¬¡æ•°ï¼‰ï¼Œ 1-2-1-2-1-2-1-2-1-2 æ­¥éª¤å¾€å¤æ‰§è¡Œã€‚ æ³¨ï¼š å‡å¦‚ä½ ç”¨adamç­‰ä¹‹ç±»çš„å…¶ä»–ä¼˜åŒ–å™¨ï¼Œé‚£ä¹ˆå¯èƒ½æœ‰æ›´å¤æ‚çš„å…¬å¼ï¼Œå¦‚æœæˆ‘ä»¬æ‰‹æ’•ï¼Œè‚¯èƒ½æœ‰äº›è´¹åŠ²ã€‚ è¿™æ—¶å€™æˆ‘ä»¬æœ€å¥½ä½¿ç”¨ optimizer.Adam ...ç­‰å„ç§ æˆå“ï¼Œä¼˜åŒ–å™¨ã€‚é€šç”¨æ­¥éª¤å¦‚ä¸‹ 1. å…ˆå®ä¾‹åŒ–å‡ºä¸€ä¸ªä¼˜åŒ–å™¨å¯¹è±¡ 2. å®ä¾‹åŒ–å¯¹è±¡.apply_gradients([(åå¯¼,è‡ªå˜é‡)]) ","link":"https://cythonlin.github.io/post/ai-greater-tensorflow20-yu-fa-zhang-liang-andji-ben-han-shu-yi/"},{"title":"AI => Tensorflow2.0ï¼ˆstableï¼‰é™ä¸´","content":"å‰è¨€ å°±åœ¨ä»Šå¤©å‡Œæ™¨ï¼ŒTF20æ ‡å‡†ç‰ˆï¼Œé™ä¸´ï¼Œå¯å–œå¯è´ºã€‚ å› æ­¤ï¼Œæˆ‘è®¤ä¸ºï¼Œå€¼å¾—è®°å½•ã€‚ã€‚ã€‚ Github URL https://github.com/tensorflow/tensorflow/releases/tag/v2.0.0 &quot;goldiegadde released this 19 hours ago&quot; ~~ yeah å‚è€ƒBetaç¯å¢ƒ æˆ‘ä¹‹å‰å†™è¿‡ä¸€ç¯‡2.0-GPU Betaç¯å¢ƒï¼Œ ä½ è‹¥è¿Tensorflowéƒ½æ¯è£…è¿‡ï¼Œé‚£ä¹ˆç§»æ­¥ï¼š ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020304638 æ›´æ–°è‡³TF20-GPUå‘½ä»¤ pip install -U tensorflow-gpu -i https://pypi.douban.com/simple æŸ¥çœ‹ç‰ˆæœ¬ &gt;&gt;&gt; import tensorflow as tf # è¿è¡Œåï¼Œä¼šè¾“å‡ºä¸€æ®µå…³äºCUDAçš„ INFO &gt;&gt;&gt; tf.__version__ '2.0.0' Pycharmè¯­æ³•é«˜äº®é—®é¢˜ Pycharmå½“å‰æœ€é«˜å¯ç”¨ç‰ˆæ˜¯ v2ç‰ˆæœ¬ã€‚ ä½†æ˜¯TF20(Stable)æ˜¯æ–°å‡ºçš„ï¼Œ æ‰€ä»¥Pycharmä¸­æ˜¯æ²¡æœ‰TF20è¯­æ³•é«˜äº®çš„ã€‚ å…¶å®ä½ å¯ä»¥ç­‰ç­‰ã€‚Pychramç­‰æ›´æ–°åˆ° v3ç‰ˆæœ¬ï¼ˆ11æœˆä»½å·¦å³ï¼Œ Pycharmå‡ºæ ‡å‡†ç‰ˆï¼‰ å¦‚æœä½ ç­‰ä¸åŠäº†ï¼Œæ²¡é—®é¢˜ã€‚ ç»™ä½ ä¸ª v3é¢„å…ˆç‰ˆåœ°å€ï¼Œè‡ªå·±ä¸‹è½½ã€‚ ç»å¯¹æ”¯æŒ TF20è¯­æ³•é«˜äº®ï¼Œäº²æµ‹ï¼ Pycharm3.0+ä¼ é€é—¨ï¼šhttps://www.jetbrains.com/pycharm/nextversion/ å¼ºè°ƒå¯¼å…¥é—®é¢˜ TF2O çš„ Keras æ˜¯è¿™æ ·å¯¼å…¥çš„ï¼š ï¼ˆå› ä¸ºæ¯æ¬¡æ›´æ–°TFï¼ŒAdamå¾ˆå®¹æ˜“æ‰¾ä¸åˆ°ï¼Œæ‰€ä»¥ä»¥Adamå¯¼å…¥ä¸ºä¾‹ï¼‰ æ–¹å¼1ï¼š import tensorflow as tf import tensorflow.keras as tk tk.optimizers.Adam() æ–¹å¼2ï¼š import tensorflow as tf from tensorflow.keras import optimizers optimizers.Adam() è¯­æ³•é«˜äº®è¿™ä¸ªé—®é¢˜æ˜¯æˆ‘å»Stackæ‰¾çš„ï¼š åŸæ ‡å‡†å›ç­”ä¼ é€é—¨ï¼š https://stackoverflow.com/questions/58188704/unable-to-import-kerasfrom-tensorflow-2-0-in-pycharm/ ","link":"https://cythonlin.github.io/post/ai-greater-tensorflow20stablejiang-lin/"},{"title":"AI => Tensorflow2.0ï¼ˆwin10 & Beta & GPUç‰ˆ ï¼‰å®‰è£…","content":"å‰è¨€ python &amp; cuda &amp; cudnn &amp; æ˜¾å¡å‹ &amp; tensorflow ç‰ˆæœ¬å¦‚æœåŒ¹é…ä¸å¥½ï¼Œå¯èƒ½ä¼šè¸©å‘ã€‚ã€‚ æœ¬ç¯‡æ–‡ç« ï¼Œè®²è¿°äº† å…¨å¥—å®‰è£…è¿‡ç¨‹ ä¸ æˆ‘æ‰€è¸©è¿‡çš„å‘ã€‚ ç¯å¢ƒæ¨è æˆ‘ä¹Ÿä¸æ˜¯ä¸€æ¬¡æˆçš„ï¼Œå½“æ—¶ tf-13rcé—®ä¸–æ—¶ï¼Œå¼„äº†å¥½ä¹…ã€‚ ç¨å¾®æä¸€ä¸‹ï¼Œpythonå®˜ç½‘é¦–é¡µçš„python3.7æ˜¯ win32çš„ã€‚ æˆ‘ä¹‹å‰é‡è£…ç³»ç»Ÿå·æ‡’ä¸‹è½½çš„ã€‚ç”¨äº†å¾ˆä¹…æ‰å‘ç°æ˜¯32ä½çš„ã€‚ã€‚ã€‚ã€‚ Tensorflowå¿…é¡»æ˜¯éœ€è¦ win 64ä½çš„ã€‚ ï¼ˆç»ˆç«¯ä¸‹è¾“å…¥ pythonå°±èƒ½çœ‹åˆ°æ˜¯å¤šå°‘ä½çš„ xx bit ï¼‰ æ³¨ï¼š å®‰è£…è·¯å¾„ä¸€å¾‹ç”¨ è‹±æ–‡ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ æœ€åæˆåŠŸçš„é…å¥—ç‰ˆæœ¬å¦‚ä¸‹ï¼š win10 gtx1050 (å…¶ä»–å‹å·çš„ï¼Œä¸ä¿è¯ï¼Œåº”è¯¥ä¹Ÿèƒ½å·®ä¸å¤š) python3.7 (æ„Ÿè§‰pythoné—®é¢˜å¹¶ä¸æ˜¯ç‰¹åˆ«å¤§ã€‚ å»ºè®® 3.7) cuda: cuda_10.0.130_411.31_win10 cudnn: cudnn-10.0-windows10-x64-v7.4.2.24 tensorflow-gpu==2.0.0-beta0 èµ„æºåˆ†äº« ï¼ˆBaiduNetï¼‰ èµ„æºæ„æˆ: CUDA + CUDNN + 4ä¸ªvcç¯å¢ƒ ï¼ˆvcç¯å¢ƒå¹²å•¥çš„ï¼Œä¸‹é¢è¯´ï¼‰ æˆ‘çš„ç½‘ç›˜: https://pan.baidu.com/s/1Z6HaNUATvOjbyuCsUcshfw æå–ç : 2qut ä¸‹è½½ååˆ«ä¹±ç‚¹ï¼ŒæŒ‰é¡ºåºçœ‹ä¸‹é¢æ•™ç¨‹å®‰è£…ã€‚ æœ‰ä¾èµ–çš„ã€‚ å®‰è£…CUDA å®˜é“¾ï¼šhttps://developer.nvidia.com/cuda-downloads ï¼ˆå¦‚æœä½ ä¸æƒ³ç”¨æˆ‘çš„å·¥å…·åŒ…ï¼Œå¯ä»¥è‡ªè¡ŒCUDAå®˜é“¾ï¼‰ å¦‚æœä½ ç›´æ¥å»å®‰è£…CUDAæ—¶ï¼Œå¯èƒ½ä¼šæŠ›error, æç¤ºä½ ï¼Œéœ€è¦ä¾èµ– vs201+ ç¯å¢ƒã€‚ å…¶å®æˆ‘ä»¬å¤§å¯ä¸å¿…å®‰è£… é‚£ä¹ˆå¤§ä½“ç§¯çš„vsï¼Œ è€Œæ˜¯å®‰è£… vc_redist æ’ä»¶å³å¯ã€‚ å®‰è£…ç¯èŠ‚ï¼š ä½ å¯ä»¥çœ‹åˆ°æˆ‘åˆ†äº«çš„èµ„æºä¸­ï¼Œ æœ‰4ä¸ª vc_redistã€‚ ä¸‹è½½ä¸‹æ¥ï¼Œ é˜²æ¼ï¼Œä»ä¸Šåˆ°ä¸‹æŒ¨ä¸ªå®‰è£…ä¸€éã€‚ï¼ˆç¬è£…å¾ˆå¿«ï¼Œå¦‚æœæç¤ºä½ å·²å®‰è£…ï¼Œä¸ç”¨ç®¡ã€‚å…¨éƒ¨å®‰è£…ä¸€éï¼‰ ç„¶åå®‰è£… CUDAï¼ŒåŒå‡»å®‰è£…å³å¯ ï¼ˆé€‰ç²¾ç®€ç‰ˆå³å¯ï¼‰ï¼ˆè®°ä½å®‰è£…è·¯å¾„ï¼Œæˆ‘è®°å¾—å¥½åƒæ˜¯é»˜è®¤è‡ªåŠ¨è·¯å¾„ï¼Œå¿˜äº†ï¼‰ ä¸€è·¯ä¸‹ä¸€æ­¥ï¼Œå³å¯å®‰è£…æˆåŠŸ é…ç½®ç¯èŠ‚ï¼š é»˜è®¤è‡ªåŠ¨å®‰è£…çš„è·¯å¾„å¦‚ä¸‹ï¼š ï¼ˆå¦‚æœä½ é€‰çš„è‡ªå®šä¹‰å®‰è£…ï¼Œä½ è¦è®°ä½ä½ çš„è·¯å¾„ï¼‰ C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin å°†æ­¤è·¯å¾„é…ç½®åˆ° ç¯å¢ƒå˜é‡ ä¸­ å…³æ‰æ‰€æœ‰cmd, é‡æ–°æ‰“å¼€cmdï¼Œè¾“å…¥ nvcc -V æ²¡æŠ¥é”™è¯´æ˜å®‰è£…æˆåŠŸã€‚ å®‰è£…CUDNN å®˜é“¾ï¼šhttps://developer.nvidia.com/rdp/cudnn-downloadï¼ˆå¦‚æœä½ ä¸æƒ³ç”¨æˆ‘çš„å·¥å…·åŒ…ï¼Œå¯è‡ªè¡Œå®˜é“¾ï¼‰ (å®˜ç½‘ä¸‹ CUDNN è²Œä¼¼éœ€è¦ç™»å½•) æ“ä½œç¯èŠ‚ï¼š ä½ å¯ä»¥çœ‹åˆ°æˆ‘åˆ†äº«çš„èµ„æºä¸­ï¼Œæœ‰CUDNNï¼Œä¸‹è½½ä¸‹æ¥ï¼Œè§£å‹ï¼ˆä»»æ„ä½ç½®éƒ½å¯ï¼Œè®°ä½å°±è¡Œï¼‰ã€‚ è§£å‹åï¼Œè¿›å…¥è§£å‹çš„ç›®å½•ï¼Œä½ ä¼šçœ‹åˆ°æœ‰ä¸ªcudaç›®å½•ï¼Œè¿›å»ï¼ç„¶ååšå¦‚ä¸‹æ“ä½œï¼ï¼ï¼ 2.1. è¿›å…¥ bin ç›®å½•ï¼Œ æŠŠé‡Œé¢çš„æ–‡ä»¶ï¼ˆåº”è¯¥å°±ä¸€ä¸ªï¼‰ï¼Œå¤åˆ¶åˆ° C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin 2.2 è¿›å…¥ include ç›®å½•ï¼ŒæŠŠé‡Œé¢çš„æ–‡ä»¶ï¼ˆåº”è¯¥å°±ä¸€ä¸ªï¼‰ï¼Œå¤åˆ¶åˆ° C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include 2.3 è¿›å…¥ lib ç›®å½•, å†ç»§ç»­è¿›å…¥ x64 ç›®å½•ï¼ŒæŠŠé‡Œé¢çš„æ–‡ä»¶ï¼ˆåº”è¯¥å°±ä¸€ä¸ªï¼‰ï¼Œå¤åˆ¶åˆ° C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\lib\\x64 è¯´ä¸€ä¸‹ï¼š ä¸Šé¢3ä¸ªè·¯å¾„ï¼Œå®‰è£…cudaæåˆ°çš„ï¼ˆç²¾ç®€ç‰ˆçš„é»˜è®¤è·¯å¾„ï¼Œ ä½ çš„å’Œæˆ‘çš„æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œç›´æ¥å¤åˆ¶ï¼‰ å°†æ­¤è·¯å¾„æ·»åŠ åˆ°ç¯å¢ƒå˜é‡ ï¼ˆåŒæ ·æ˜¯é»˜è®¤è·¯å¾„ï¼Œç›´æ¥æ‹¿å»å¤åˆ¶ï¼Œé…äº†å°±è¡Œï¼‰ï¼š C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\lib\\x64 å®‰è£…Tensorflow æ¯ä¸ªäººæœ‰æ¯ä¸ªäººçš„ä¹ æƒ¯ï¼Œå»ºè®®ç”¨ç”¨è™šæ‹Ÿç¯å¢ƒå®‰è£…ä¸œè¥¿ã€‚ æˆ‘è¾ƒç†Ÿç»ƒ virtualenv + virtualenvwrapper-win å½“ç„¶ï¼Œä½ ç›´æ¥è£…ä¹Ÿæ˜¯æ²¡é—®é¢˜çš„ã€‚ å®‰è£…tensorflow-gpu2.0.0-beta0: pip install tensorflow-gpu2.0.0-beta0 -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com å¦‚æœä½ æ˜¯anacondaï¼ˆé‚£ä¹ˆéœ€è¦å…ˆæ‰“å¼€anaconda prompt pipï¼‰(ç§‘å­¦)ï¼š pip install tensorflow-gpu==2.0.0-beta0 å®‰è£… matplotlib (éå¿…é¡»ï¼Œä½† åæ­£ä¹Ÿæ˜¯ä¸ç¦»æ‰‹çš„ä¸œè¥¿ï¼Œç›´æ¥è£…äº†å§) pip install scipy matplotlib pandas sklearn -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com è‡³æ­¤ï¼Œå…¨éƒ¨å®‰è£…å®Œæˆï¼Œæ¥ä¸‹æ¥æµ‹è¯•ã€‚ æµ‹è¯•å®‰è£… &amp; æµ‹è¯•æ˜¯å¦ä½¿ç”¨GPU import tensorflow as tf print(tf.__version__) print(tf.test.gpu_device_name()) å°±è¿™3è¡Œä»£ç ï¼Œå³å¯ã€‚ çœ‹æ‰“å°ç»“æœï¼š 2.0.0-beta0 # è¿™æ˜¯ç‰ˆæœ¬ä¿¡æ¯ /device:GPU:0 # GPUå­—æ ·å°±è¯´æ˜å¯ä»¥ä½¿ç”¨GPUäº†ã€‚ å¼ºè¿«ç—‡çš„æŒ£æ‰ æ‰§è¡Œä¸Šé¢ä»£ç æµ‹è¯•çš„æ—¶å€™ï¼Œæˆ‘è¿™é‡Œæ˜¯æœ‰ä¸€å¤§ä¸² warningçš„ã€‚ å…³äºæ•°æ®ç±»å‹çš„ warningã€‚å…¶å®æ— ä¼¤å¤§é›…ã€‚ ä¸ï¼Œå¾ˆä¼¤ï¼Œæˆ‘å»githubæ‰¾äº†ä¸€ä¸‹ã€‚å…¶å®å°±æ˜¯ä½ çš„ numpyç‰ˆæœ¬å¤ªæ–°äº†ã€‚ é‡è£…æ¢ä¸€ä¸ª 1.17ä»¥ä¸‹ç‰ˆæœ¬ å°±è¡Œã€‚ CMDç›´æ¥ è¿è¡Œä»¥ä¸‹å‘½ä»¤å³å¯ï¼š pip uninstall -y numpy &amp;&amp; pip install numpy==1.16.4 å¼ºè¿«ç—‡å¸®åŠ©è€…é“¾æ¥ï¼šhttps://github.com/tensorflow/tensorflow/issues/30427#issuecomment-515770145 ç»“æŸè¯­ æˆ‘çš„æœºå­æ—©ä¸€é˜µä¹°çš„äº†ï¼Œ GTX1050çš„ï¼Œ æ¯ä¸ªäººçš„æ˜¾å‹éƒ½ä¸åŒã€‚ æ‰€ä»¥ä¹Ÿè®¸æˆ‘ç»™å‡ºçš„é…å¥—ç‰ˆæœ¬ï¼Œä¸èƒ½æ»¡è¶³æ‰€æœ‰äººéœ€æ±‚ã€‚ ä¸‹é¢è¯´ä¸€ä¸‹æˆ‘ä¹‹å‰è£…çš„æ—¶å€™é‡åˆ°çš„é—®é¢˜ï¼š è®°å¾—å®‰è£…è·¯å¾„å°½é‡å…¨éƒ¨ï¼Œç”¨è‹±æ–‡ã€‚ cudaå®‰ä¸ä¸Šï¼Œå› ä¸ºç¼ºå°‘ vs201+, ï¼ˆæˆ‘ä¸Šé¢è¯´è¿‡äº†ï¼Œå®‰è£…æˆ‘åˆ†äº«çš„é‚£4ä¸ªvc_redistå°æ–‡ä»¶å¯ä»£æ›¿å®‰è£… vsï¼‰ å¦‚æœåœ¨å®‰è£…tensorflowæ—¶ï¼Œæç¤ºä½ ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ¨¡å—ï¼š 3.1 å¯èƒ½æ˜¯ä½ çš„ python å’Œ pip ç‰ˆæœ¬è¿‡ä½ 3.2 å¯èƒ½æ˜¯ä½ çš„ pythonæ˜¯32ä½çš„ã€‚ ï¼ˆä¸è¦å·æ‡’å»å®‰è£…ä¸»é¡µçš„python3.7ï¼Œé‚£ä¸ªæ˜¯32ä½çš„ã€‚å¿…é¡»ç”¨64ä½ï¼‰ å¦‚æœåœ¨å®‰è£…tensorflow æˆ–è€… import tensorflow æ—¶ï¼Œç»™ä½ æŠ¥äº†ä¸€å¤§å †é”™è¯¯ï¼š 4.0 é¦–å…ˆçœ‹é”™è¯¯èƒ½ä¸èƒ½çœ‹æ‡‚ 4.1 å¯èƒ½æ˜¯æˆ‘ç»™çš„ é…å¥—ç‰ˆæœ¬ã€‚ å¹¶ä¸èƒ½æ»¡è¶³ä½ çš„ æœºå™¨ï¼Œæ˜¾å‹ã€‚ è¿™æ—¶å€™ä½ å°±å¾—è‡ªå·±å»æ‰¾å¯¹åº”ç‰ˆæœ¬äº† 4.2 æˆ‘ä¹‹å‰å¼„çš„æ—¶å€™ï¼Œæˆ‘è®°å¾—å¥½åƒæœ‰ Nvidiaæ˜¾å¡ &amp; cuda &amp; cudnn çš„å¯¹ç…§è¡¨ã€‚å¿˜è®°å½•äº†ã€‚å¯è‡ªè¡Œå¯»æ‰¾ã€‚ ","link":"https://cythonlin.github.io/post/ai-greater-tensorflow20win10-and-beta-and-gpu-ban-an-zhuang/"},{"title":"PY => HMM ä¸ CRF ä¸ Viterbi","content":"HMM(éšé©¬å°”å¯å¤«æ¨¡å‹) åˆå§‹æƒé‡çŸ©é˜µ Î  å½¢çŠ¶ï¼šnp.zeros(tag_size) # tag_sizeå°±æ˜¯å®ä½“æ ‡ç­¾çš„æ€»ä¸ªæ•° ç¬¬ä¸€ä¸ªå­—å‡ºç° è®¤åå®ä½“æ ‡ç­¾çš„æ¬¡æ•° è®¡ç®—å…¬å¼egï¼šq(äººå) --------------------------------- 5000ä¸ªå¥å­ è½¬ç§»çŸ©é˜µï¼ˆtransitionï¼‰ åŸç†ï¼šå‰é¢çš„éšå«çŠ¶æ€ =&gt; å½“å‰éšå«çŠ¶æ€ å½¢çŠ¶ï¼šnp.zeros([tag_size, tag_size]) # tag_sizeå°±æ˜¯å®ä½“æ ‡ç­¾çš„æ€»ä¸ªæ•° ï¼ˆæ­£æ–¹å½¢ï¼Œå¯»è·¯ï¼‰ å½“å‰å®ä½“æ ‡ç­¾ å’Œ ç›¸é‚»åä¸€ä¸ªå®ä½“æ ‡ç­¾è”åˆå‡ºç°çš„æ¬¡æ•° è®¡ç®—å…¬å¼egï¼št = -------------------------------------- å½“å‰å®ä½“æ ‡ç­¾åœ¨5000ä¸ªå¥å­ä¸­å‡ºç°çš„æ¬¡æ•° å‘å°„çŸ©é˜µ ( emission ) åŸç†ï¼šå½“å‰éšå«çŠ¶æ€ =&gt; å½“å‰é¢„æµ‹æ ‡ç­¾ï¼ˆå®ä½“æ ‡ç­¾ï¼‰ ï¼ˆçŸ©å½¢ï¼‰ å½¢çŠ¶ï¼šnp.zeros([tag_size, vocab_size]) # tag_sizeå°±æ˜¯å®ä½“æ ‡ç­¾çš„æ€»ä¸ªæ•° å½“å‰å®ä½“æ ‡ç­¾ å’Œ å½“å‰ï¼ˆlstmè¾“å‡ºå€¼yï¼‰è”åˆå‡ºç°çš„æ¬¡æ•° è®¡ç®—å…¬å¼egï¼še = ------------------------------------------------------- å½“å‰å®ä½“æ ‡ç­¾å‡ºç°çš„æ¬¡æ•° åç½®ï¼š é˜²æ­¢ä¹˜0ï¼Œæˆ–è€…é˜²æ­¢ log0 å–log: ä¹˜æ³•å˜åŠ æ³•ï¼Œ é˜²æ­¢å°æ•°è¢«ä¹˜åˆ°æœ€åå˜æˆäº†0 HMMæ€»ä½“å…¬å¼ï¼š q = argmax( P(å½“å‰å®ä½“æ ‡ç­¾|ä¸Šä¸€æ—¶åˆ»å®ä½“æ ‡ç­¾) * P(æ£€æµ‹åˆ°çš„æ±‰å­— | å½“å‰æ—¶åˆ»å®ä½“æ ‡ç­¾) ) æœæœæ‰€æœ‰å®ä½“æ ‡è®°ï¼Œæ‰¾åˆ°ä¸€ä¸ªæ ‡è®°ï¼Œä½¿å¾— qæœ€å¤§å³å¯ã€‚ CRF(æ¡ä»¶éšæœºåœº) å’ŒHMMç±»ä¼¼ï¼ŒCRFä¹Ÿæœ‰ç±»ä¼¼çš„ç»“æ„ï¼ˆè½¬ç§»çŸ©é˜µï¼Œå‘å°„çŸ©é˜µï¼‰ å‡å¦‚å½“å‰ä¸º Y è½¬ç§»çŸ©é˜µçš„ï¼šCRFç»„åˆå½¢å¼ï¼Œåˆ†ç°‡çš„ï¼š 1. ç¬¬ä¸€ç°‡ï¼šæ‰€æœ‰Xï¼Œ å½“å‰æ—¶åˆ»Y(t)ï¼Œ ä¸Šä¸€æ—¶åˆ»Y(t-1) 2. ç¬¬äºŒç°‡ï¼šæ‰€æœ‰Xï¼Œ å½“å‰æ—¶åˆ»Y(t)ï¼Œ ä¸Šä¸€æ—¶åˆ»Y(t-1) (æ³¨æ„ï¼Œå¯ç†è§£ä¸ºæ—¶é—´åºåˆ—æ˜¯æ»‘åŠ¨çš„ã€‚) 3. ç¬¬ä¸‰ç°‡ï¼šã€‚ã€‚ã€‚ æ ¸å¿ƒæ€»ç»“ï¼š CRFï¼š è½¬ç§»çŸ©é˜µ å’Œ å‘å°„çŸ©é˜µå‡ ä¹å’Œ HMMå·®ä¸å¤šã€‚ åªä¸è¿‡CRF æ¯ä¸€ç°‡ï¼ˆå›¢ï¼‰éƒ½ç”¨åˆ°äº†â€œæ‰€æœ‰çš„â€ lstmçš„è¾“å‡ºY HMM: æ²¡æœ‰ç°‡ï¼Œ æ¯æ¬¡ç”¨çš„åªæ˜¯ å½“å‰LSTMè¾“å‡ºçš„ y(t) æœ€ç»ˆï¼šåŒæ ·æ±‚çš„æ˜¯ argmax ( P(Y|X ) ) Viterbi(ç»´ç‰¹æ¯”ç®—æ³•) ä½¿ç”¨äº†åŠ¨æ€è§„åˆ’è§£å†³ HMM å’Œ CRFçš„é¢„æµ‹é—®é¢˜ ï¼ˆ&quot;è½¬ç§»&quot; æ—¶å¯æ‰¾åˆ°å…¨å±€æœ€ä¼˜ï¼‰ ï¼ˆè€Œ CRF ï¼ŒHMM åªèƒ½æ‰¾åˆ°å±€éƒ¨æœ€ä¼˜ï¼‰ ","link":"https://cythonlin.github.io/post/py-greater-hmm-yu-crf-yu-viterbi/"},{"title":"PY => NLP + ML","content":"æ–‡æœ¬ç›¸ä¼¼åº¦ï¼š 1. æ¬§æ°è·ç¦» (åæ¯”) 2. ä½™å¼¦ç›¸ä¼¼åº¦ x1@x2 / ( |x1| * |x2| ) ï¼ˆæ­£æ¯”ï¼‰ TF-IDF tf = æŸå•è¯ åœ¨æ‰€å¤„å¥å­ä¸­ å‡ºç°çš„ä¸ªæ•° ï¼ˆè¯é¢‘ï¼‰ idf (æ–‡æ¡£æ€»æ•° / å«æœ‰è¯¥å•è¯çš„æ–‡æ¡£æ•°) = è¯é¢‘ * æ¯ä¸ªå•è¯çš„é‡è¦æ€§ = è¯é¢‘ * log(æ–‡æ¡£æ€»æ•° / å«æœ‰è¯¥å•è¯çš„æ–‡æ¡£æ•°) # åˆ†æ¯åŒ…å«åº¦è¶Šé«˜ï¼Œä»£è¡¨è¶Šä¸ç›¸ä¼¼ï¼‰ Chain Rule P(A,B) = P(A}B) * P(B) = P(B|A) * P(A) P(A,B,C,D) = P(A) * P(B|A) * P(C|AB) * P(D|ABC) é©¬å°”å¯å¤«å‡è®¾ï¼š åŸºäºChain Ruleï¼š 1st: åªä¾èµ–å‰ä¸€ä¸ªæ¡ä»¶ P(A,B,C,D) = P(A) * P(B|A) * P(C|B) * P(D|C) å¯¹åº” 1-Gram ä¹Ÿå« ï¼š(unigram) 2st: åªä¾èµ–å‰ä¸¤ä¸ªæ¡ä»¶ P(A,B,C,D) = P(A) * P(B|A) * P(C|AB) * P(D|BC) å¯¹åº” 2-Gram ä¹Ÿå« ï¼šï¼ˆbigramï¼‰ 3st: åªä¾èµ–å‰ä¸‰ä¸ªæ¡ä»¶ å¯¹åº” 3-Gram ä¹Ÿå« :(trigram) å¦‚ä¸Šè¯­è¨€æ¨¡å‹éƒ½æœ‰ä¸€ä¸ªé—®é¢˜ï¼š é‚£ä¹ˆå‡å¦‚é¢„æµ‹ä¸€ä¸ªè¯è¡¨ä¸­æ²¡æœ‰çš„å•è¯ï¼Œé‚£ä¹ˆå°±Game Overäº†ï¼Œ ä¹˜ç§¯ç›´æ¥é¢„æµ‹ä¸º 0 äº† å¹³æ»‘å¤„ç† å¦‚æœä¸Šé¢N-Gramã€‚ä¸æƒ³å‡ºç°0ï¼Œè€Œæ˜¯å˜ä¸ºæ— ç©·å°ï¼Œé‚£ä¹ˆéœ€è¦ åšå¹³æ»‘å¤„ç† æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ add-one (B|A)æ¬¡æ•° + 1 P(B|A) = --------- Aå‡ºç°æ¬¡æ•° + è¯å…¸å¤§å°ï¼ˆä¸åŒ…æ‹¬é‡å¤çš„ï¼‰ add-K (B|A)æ¬¡æ•° + K P(B|A) = --------------------------- Aå‡ºç°æ¬¡æ•° + K * è¯å…¸å¤§å°ï¼ˆä¸åŒ…æ‹¬é‡å¤çš„ï¼‰ K æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œéœ€è¦ä¸æ–­ä¼˜åŒ– interpolation ä»…æœ‰çš„æ•°æ®é›†ï¼Œå¥å­ æ¡ä»¶æ¦‚ç‡ä¸º0ï¼Œ è€Œ æœªæ¥å…¶ä»–çš„æ•°æ®é›†ï¼Œå¯èƒ½æœ‰è¿™ä¸ªå¥å­ï¼Œäº§ç”Ÿè¶…æœªæ¥çš„æƒ…å†µ æ‰€ä»¥ï¼Œinterpolationå°±æ˜¯è§£å†³è¿™ä¸ªæƒ…å†µçš„ã€‚ åŒæ—¶ä½¿ç”¨ unigram å’Œ bigram å’Œ trigram å…¬å¼ï¼š Î»1 * unigram + Î»2 * bigram + Î»3 * trigram Î»1 + Î»2 + Î»3 = 1 æœ´ç´ è´å¶æ–¯ è´å¶æ–¯ P(A|B) = P(B|A) * P(A) -------------- P(B) p(åƒåœ¾|é‚®ä»¶å†…å®¹ ) = P(é‚®ä»¶å†…å®¹ | åƒåœ¾) * P(åƒåœ¾) # æ³¨æ„è¿™ä¸ªPï¼ˆåƒåœ¾ï¼‰å°±æ˜¯å…ˆéªŒæ¦‚ç‡ï¼Œ åƒåœ¾æ–‡ç« å æ€»æ–‡ç« çš„æ¯”ä¾‹ ---------------------------------- Pï¼ˆé‚®ä»¶å†…å®¹ï¼‰ åŒç†å¦ä¸€æ–¹é¢ï¼ˆæ­£å¸¸æ–¹ï¼‰ï¼š p(æ­£å¸¸|é‚®ä»¶å†…å®¹ ) = P(é‚®ä»¶å†…å®¹ | æ­£å¸¸) * P(æ­£å¸¸) # åŒæ ·ä¸ºå…ˆéªŒæ¦‚ç‡ ---------------------------------- Pï¼ˆé‚®ä»¶å†…å®¹ï¼‰ # æ³¨æ„1ï¼Œ p(åƒåœ¾|é‚®ä»¶å†…å®¹ ) å’Œ p(æ­£å¸¸|é‚®ä»¶å†…å®¹ ) çš„ åˆ†æ¯æ˜¯å¯ä»¥çº¦åˆ†çš„ # æ³¨æ„2ï¼Œ P(é‚®ä»¶å†…å®¹ | æ­£å¸¸) å’Œ P(é‚®ä»¶å†…å®¹ | åƒåœ¾) éƒ½æ˜¯æ¡ä»¶ç‹¬ç«‹æ¦‚ç‡ã€‚ å¯ç»§ç»­æ‹†åˆ†ä¸º Pï¼ˆå•è¯1ï¼‰ | Pï¼ˆæ­£å¸¸ï¼‰ # ä½ éœ€è¦é¦–å…ˆè®¡ç®—å‡ºæ¯ä¸ªå•è¯åœ¨æ­£å¸¸å†…å®¹é‡Œé¢çš„æ¦‚ç‡ è”åˆæ¦‚ç‡ P(X,Y) = P(x) * P(y|x) = P(y) * P(x|y) æ¡ä»¶ç‹¬ç«‹ P(x,y | z) = P(x|z) * P(y|z) å…ˆéªŒæ¦‚ç‡ å‡å¦‚ä½ è¦åˆ¤æ–­ ä¸€å°é‚®ä»¶é‡Œé¢çš„å¥å­ï¼Œæ˜¯å¦ä¸ºåƒåœ¾ä¿¡æ¯ã€‚ è¿™æ—¶ï¼Œä½ éœ€è¦è®¡ç®—å‡º å·²æœ‰ åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡ å’Œ æ­£å¸¸é‚®ä»¶çš„æ¦‚ç‡ã€‚ å‡†ç¡®ç‡ ç²¾ç¡®ç‡ å¬å›ç‡ F1-Score å‡†ç¡®ç‡ï¼ˆä¸å¯é ï¼‰ å‡†ç¡®ç‡ ä¾èµ–äº ï¼ˆæ­£ã€è´Ÿï¼‰å¹³è¡¡çš„æ ·æœ¬ 99999ä¸ªé»‘çŒ«ï¼Œ 1ä¸ªç™½çŒ«ï¼Œ ä½ æ€ä¹ˆé¢„æµ‹ï¼Œå‡ ä¹éƒ½æ˜¯é»‘çŒ«ï¼ˆ99999/100000ï¼‰çš„æ¦‚ç‡ ç²¾ç¡®ç‡ï¼ˆprecisionï¼‰ æ ‡ç­¾+é¢„æµ‹æ•°æ®ï¼š å®é™…æ ‡ç­¾ï¼š T F T T F F é¢„æµ‹æ ‡ç­¾ï¼š T F T F T T ä»¥æ­£æ ·æœ¬ä¸ºä¾‹ï¼š P(æ­£) = &quot;é¢„æµ‹æ ‡ç­¾ä¸­æœ‰4ä¸ªT&quot;ï¼Œ ä¸ &quot;å®é™…æ ‡ç­¾&quot;å¯¹åº”ä½ç½®åŒ¹é…åï¼Œå‘ç°åªæœ‰ &quot;2ä¸ªT&quot;å¯¹åº”ä¸Šäº†ã€‚ æ‰€ä»¥ç²¾ç¡®ç‡ä¸ºï¼š 2/4 å¬å›ç‡(recall) R(è´Ÿæ•°) = &quot;å®é™…æ ‡ç­¾ä¸­æœ‰3ä¸ªT&quot;ï¼Œ ä¸ &quot;é¢„æµ‹æ ‡ç­¾&quot;å¯¹åº”ä½ç½®åŒ¹é…åï¼Œå‘ç°åªæœ‰ &quot;2ä¸ªT&quot;å¯¹åº”ä¸Šäº†ã€‚ æ‰€ä»¥å¬å›ç‡ä¸ºï¼š 2/3 åæ¥åˆæƒ³äº†ä¸€ç§æ›´å¥½ç†è§£ ï¼ˆç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼‰çš„æ–¹å¼ ç›®æ ‡ï¼Œæ±‚å°ç™½é¼  â€œç”Ÿç—…â€ çš„ ç²¾ç¡®ç‡ ä¸ å¬å›ç‡ é¼ 1 é¼ 2 é¼ 3 é¼ 4 é¼ 5 é¼ 6 å®é™… ç—… é ç—… ç—… é é é¢„æµ‹ ç—… é ç—… é ç—… ç—… å…·ä½“ä¾‹å­ï¼š æˆ‘ é¢„æµ‹ç»“æœä¸­æœ‰æ ‡å‡º 4 ä¸ªç”Ÿç—…çš„ï¼Œ ä¸å®é™…å¯¹æ¯”åï¼Œ ä¸Šä¸‹å¯¹åº”ä¹‹å é¼ 1 å’Œ é¼ 3ï¼Œæ ‡å¯¹äº†ï¼Œä¹Ÿå°±æ˜¯é¢„æµ‹å¯¹äº†2ä¸ª æ‰€ä»¥ï¼Œ Pï¼ˆç²¾ç¡®ï¼‰ = 2 / 4 = 50% å®é™…æ ‡ç­¾æœ‰ 3ä¸ªæœ‰ç—…çš„è€é¼ ï¼Œ ä½†æ˜¯ï¼ˆçœ‹é¢„æµ‹labelï¼‰ï¼Œ åªæœ‰ é¼ 1 å’Œ é¼ 3 å¯¹é½äº†ï¼Œï¼ˆä¹Ÿå°±æ˜¯é¢„æµ‹æ­£ç¡®äº†ï¼‰ æ‰€ä»¥ï¼Œ Pï¼ˆå¬å›ï¼‰ = 2 / 3 = 66% ä¸Šé¢çš„ä¾‹å­ï¼Œæ˜¯æ¯”è¾ƒå®¹æ˜“æ‡‚çš„ï¼Œ å¦‚æœä¸æ‡‚ï¼Œå¯çœ‹ä¸‹é¢è®²æˆ‘çš„å¤æ‚ç†è§£æ–¹å¼ï¼š é¦–å…ˆå‡†å¤‡ &quot;çœŸå®label&quot; å’Œ &quot;é¢„æµ‹label&quot;ï¼š æŠŠè¿™äº› &quot;é¢„æµ‹label&quot; æ”¾åˆ° &quot;å®é™… label&quot; ä¸‹é¢ä¸€è¡Œ ä¸€ä¸€å¯¹é½ ä½ç½®åŒ¹é… ä¾‹å¦‚ï¼ˆçœ‹çœ‹ä½ç½®ç»“æ„å°±è¡Œï¼Œä¸‹é¢ç”¨å¾—åˆ°ï¼Œ 01éšä¾¿å†™çš„ä¸ç”¨ç†ä¼šï¼‰ ï¼š çœŸå®labelï¼š 10011 é¢„æµ‹label: 11001 ç²¾ç¡®ç‡ï¼šï¼ˆæˆ‘é¢„æµ‹çš„labelä¸­ï¼Œ é¢„æµ‹å¯¹äº†å¤šå°‘ï¼ˆå¯¹é½+äº¤é›†ï¼‰ ï¼Œ å¯ç†è§£ä¸ºé¢„æµ‹çš„å‡†ä¸å‡†ï¼‰ ï¼ˆæ³¨æ„ &quot;ä¸­&quot;å­—ï¼Œ è°å¸¦ä¸­ï¼Œè°å°±åšåˆ†æ¯ï¼‰ ç²¾ç¡®ç‡ä¸»è¦ä»¥æˆ‘çš„ &quot;é¢„æµ‹label&quot; ä¸ºä¸»ï¼Œ ï¼ˆä»¥è°ä¸ºä¸»ï¼Œè°å°±åšåˆ†æ¯ï¼‰ ï¼ˆä»¥è°ä¸ºä¸»ï¼Œå°±ä»è°å¼€å§‹çœ‹ï¼‰ï¼ˆç²¾ç¡®ç‡ä»¥&quot;é¢„æµ‹label&quot;ä¸ºä¸»ï¼Œæ ¹æ®ä¸Šé¢çš„ç»“æ„ï¼Œå…ˆä»ä¸‹é¢ä¸€è¡Œå¼€å§‹çœ‹ï¼‰ å…ˆä»ä¸‹é¢è¿™è¡Œï¼ˆä¹Ÿå°±æ˜¯æˆ‘ä»¬é¢„æµ‹çš„labelï¼‰ å¼€å§‹æŸ¥æ‰¾æ­£ä¾‹ï¼ˆä¹Ÿå°±æ˜¯æˆ‘ä»¬æ¢ç´¢çš„ç›®æ ‡--&quot;æœ‰ç—…&quot;ï¼‰ æŠŠæœ‰ç—…çš„ä¸ªæ•°ï¼Œä½œä¸ºåˆ†æ¯ï¼Œ ç„¶åæˆ‘ä»¬å¼€å§‹æŠŠä¸Šä¸‹2è¡Œçš„labelä¸€èµ·å¯¹é½æ¯”è¾ƒï¼Œ æŠŠä¸Šä¸‹éƒ½æœ‰ â€œæœ‰ç—…â€ çš„æ€»ä¸ª(åˆ—)æ•°ä½œä¸ºåˆ†å­ï¼ˆå°±æ˜¯äº¤é›†çš„æ„æ€ï¼‰ï¼Œ æœ€ç»ˆç²¾ç¡®ç‡å°±æ˜¯ï¼š åˆ†å­ ---- åˆ†æ¯ å¬å›ç‡ï¼šï¼ˆæ‰€æœ‰å®é™…labelä¸­ï¼Œæˆ‘é¢„æµ‹åˆ°äº†å¤šå°‘ï¼ˆå¯¹é½+äº¤é›†ï¼‰ï¼Œ å¯ç†è§£ä¸ºé¢„æµ‹çš„å…¨ä¸å…¨ï¼‰ ï¼ˆæ³¨æ„ &quot;ä¸­&quot;å­—ï¼Œ è°å¸¦ä¸­ï¼Œè°å°±åšåˆ†æ¯ï¼‰ å’Œä¸Šé¢ä¸åŒäº†ï¼Œ å¬å›ç‡å˜æˆä»¥ä¸»è¦ä»¥ &quot;å®é™…label&quot; â€œæœ‰ç—…â€çš„ä¸ªæ•° ä¸ºä¸» ï¼ˆä»¥è°ä¸ºä¸»ï¼Œè°å°±åšåˆ†æ¯ï¼‰ ï¼ˆä»¥è°ä¸ºä¸»ï¼Œå°±ä»è°å¼€å§‹çœ‹ï¼‰ï¼ˆç²¾ç¡®ç‡ä»¥&quot;é¢„æµ‹label&quot;ä¸ºä¸»ï¼Œæ ¹æ®ä¸Šé¢çš„ç»“æ„ï¼Œå…ˆä»ä¸‹é¢ä¸€è¡Œå¼€å§‹çœ‹ï¼‰ ç„¶åä»ä¸Šé¢è¿™è¡Œï¼ˆä¹Ÿå°±æ˜¯å®é™…çš„labelï¼‰ å¼€å§‹æŸ¥æ‰¾æ­£ä¾‹ï¼ˆä¹Ÿå°±æ˜¯æˆ‘ä»¬æ¢ç´¢çš„ç›®æ ‡--&quot;æœ‰ç—…&quot;ï¼‰ æŠŠæœ‰ç—…çš„ä¸ªæ•°ï¼Œä½œä¸ºåˆ†æ¯ï¼Œ ç„¶åæˆ‘ä»¬å¼€å§‹æŠŠä¸Šä¸‹2è¡Œçš„labelä¸€èµ·å¯¹é½æ¯”è¾ƒï¼Œ æŠŠä¸Šä¸‹éƒ½æœ‰ â€œæœ‰ç—…â€ çš„æ€»ä¸ª(åˆ—)æ•°ä½œä¸ºåˆ†å­ï¼ˆå°±æ˜¯äº¤é›†çš„æ„æ€ï¼‰ï¼Œ æœ€ç»ˆç²¾ç¡®ç‡å°±æ˜¯ï¼š åˆ†å­ ---- åˆ†æ¯ F1-Score ä¸Šé¢è¯´æ˜äº†ï¼ˆP-Rï¼‰æ˜¯äº’æ–¥å…³ç³»ã€‚ æ‰€ä»¥ä½œä¸ºæŒ‡æ ‡ï¼Œéœ€è¦è€ƒè™‘äºŒè€…ã€‚ä¸æ˜¯å¾ˆæ–¹ä¾¿ã€‚ é‚£ä¹ˆæœ‰æ²¡æœ‰ä¸€ä¸ªå”¯ä¸€çš„æŒ‡æ ‡æ¥ å¹³è¡¡äºŒè€…å‘¢ï¼Ÿ æœ‰---å®ƒå°±æ˜¯ F1-Score ï¼ˆè°ƒå’Œå¹³å‡å€¼ï¼‰ 1 1 1 1 -- = ---- * ï¼ˆ---------- + ----------ï¼‰ F1 2 precision recall 2 * precision * recall F1 = ------------------------------ precision + recall ç‰¹ç‚¹ï¼š æœ‰ä¸€ä¸ªå€¼ä½ï¼Œå¦ä¸€ä¸ªå€¼ç‰¹åˆ«é«˜ï¼Œç»“æœ F1 Scoreä¹Ÿä¼šç‰¹åˆ«çš„ä½ ï¼ˆæˆ–è€…ä¸¤ä¸ªå€¼éƒ½ä½ï¼Œ f1 scoreä¹Ÿä¼šå¾ˆä½ï¼‰ åªæœ‰äºŒè€…éƒ½éå¸¸é«˜çš„è¯ï¼ŒF1 Score æ‰ä¼šéå¸¸çš„é«˜ Logistic Regression(é€»è¾‘å›å½’) çº¿æ€§å›å½’ + Sigmoid 1 y_predict(ç±»åˆ«ä¸º1) = -------------- 1+ e^(wx+b) 1 e^(wx+b) y_predict(ç±»åˆ«ä¸º0) = 1- ------------ = ---------------- 1+ e^(wx+b) 1+ e^(wx+b) ç”¨1-0å¼€å…³å§ä¸Šé¢ä¸¤ä¸ªå¼å­åˆåœ¨ä¸€èµ· y_predict = y_predict(ç±»åˆ«ä¸º1)^(y) + y_predict(ç±»åˆ«ä¸º0)^(1-y) ä¸¤è¾¹åŠ ä¸Š logï¼ŒåŒ–ç®€ä¸€ä¸‹ï¼š log (p(y_predict)) = y * log y_predictç±»åˆ«ä¸º1 + (1-y) * log (1-y_predictç±»åˆ«ä¸º0) # ä¸Šé¢æ±‚å¾—æ˜¯é¢„æµ‹çš„æ¦‚ç‡ã€‚ æˆ‘ä»¬å®ƒå¸Œæœ›è¶Šå¤§è¶Šå¥½ã€‚ # æ‰€ä»¥é¢å¤–çš„æ•´ä½“å¤–é¢éœ€è¦åŠ ä¸€ä¸ª è´Ÿå· - # åŠ ä¸ªè´Ÿå·ï¼Œå°±åè¿‡æ¥äº†ã€‚ æˆ‘ä»¬å°±è½¬è€Œæ±‚ å¸Œæœ›ä»–è¶Šå°è¶Šå¥½ã€‚ (æˆ–è€…è¿™é‡Œä¸ç”¨ç†è§£ï¼Œæœ€ååŠ ä¸ªè´Ÿå·ï¼Œè®°ä½å³å¯) log (p(y_predict)) = - ( y * log y_predictç±»åˆ«ä¸º1 + (1-y) * log (1-y_predictç±»åˆ«ä¸º0) ) # æ³¨æ„ï¼Œä¸Šé¢è¯´çš„éƒ½æ˜¯é’ˆå¯¹æ¯ä¸€ä¸ªæ ·æœ¬çš„ ï¼ˆè®°ä½è¿™è¡Œï¼Œä¸‹é¢æœ€å¤§ä¼¼ç„¶ç”¨åˆ°ï¼‰ log (p(æ¯ä¸ªæ ·æœ¬)) = - ( y * log y_predictç±»åˆ«ä¸º1 + (1-y) * log (1-y_predictç±»åˆ«ä¸º0) ) æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼š æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå°±æ˜¯ è€ƒè™‘æ‰€æœ‰æ ·æœ¬æ»¡è¶³&quot;ç‹¬ç«‹åˆ†å¸ƒ&quot;ï¼š é‚£ä¹ˆå®ƒä»¬çš„ æ€»æ¦‚ç‡å¯å†™ä¸ºï¼š Pï¼ˆæ€»ï¼‰ = ç´¯ä¹˜( Pï¼ˆæ‰€æœ‰æ ·æœ¬ï¼‰) ä¸¤è¾¹å†å–å¯¹æ•°: log Pæ€» = log ç´¯ä¹˜( Pï¼ˆæ¯ä¸ªæ ·æœ¬ï¼‰) ç´¯æˆè½¬ç´¯åŠ ï¼š log Pæ€» = Î£ log ( Pï¼ˆæ¯ä¸ªæ ·æœ¬ï¼‰) log ( Pï¼ˆæ¯ä¸ªæ ·æœ¬ï¼‰)) å¸¦è¿›æ¥ï¼š log Pæ€» = æœ€å¤§ä¼¼ç„¶ä¼°è®¡ = - Î£( y * log y_predictç±»åˆ«ä¸º1 + (1-y) * log (1-y_predictç±»åˆ«ä¸º0) ) ä¸Šé¢å°±æ˜¯æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„å…¬å¼äº† å½“ç„¶ï¼Œæˆ‘ä»¬ä¸ä¼šç›´æ¥ç”¨æœ€å¤§ä¼¼ç„¶å½“ä½œæŸå¤±å‡½æ•°ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦æœ€å¤§ä¼¼ç„¶æ¦‚ç‡è¶Šå¤§è¶Šå¥½ã€‚ è€Œæ˜¯æŠŠè´Ÿå·å»æ‰ï¼Œå˜æˆæŸå¤±ï¼Œè®©æŸå¤±è¶Šå°è¶Šå¥½ã€‚ å¹¶ä¸”é™¤ä»¥æ ·æœ¬çš„æ€»æ•°ï¼Œæœ€åæŸå¤±å‡½æ•°å¦‚ä¸‹ï¼š Î£( y * log y_predictç±»åˆ«ä¸º1 + (1-y) * log (1-y_predictç±»åˆ«ä¸º0) ) loss = --------------------------------------------------------------------- m é€»è¾‘å›å½’æ˜¯çº¿æ€§åˆ†ç±»å™¨ï¼š ä¾æ®ï¼šçœ‹å†³ç­–è¾¹ç•Œï¼ˆdecision boundaryï¼‰ æ±‚å†³ç­–è¾¹ç•Œ ä¸Šé¢ä¸¤ä¸ªå¼å­y_predict(ç±»åˆ«ä¸º1) å’Œ y_predict(ç±»åˆ«ä¸º0) ç›¸ç­‰ï¼Œ æ±‚å‡ºçš„è¡¨è¾¾å¼ å°±æ˜¯å†³ç­–è¾¹ç•Œï¼ˆçº¯çº¿æ€§çš„ï¼‰ å½“ç„¶ï¼Œé™¤äº†Sigmoidï¼Œä½ ä¹Ÿå¯ä»¥ç”¨ Softmaxåšå¤šåˆ†ç±» Neural Network (ç¥ç»ç½‘ç»œ) ä¹‹å‰è¯´è¿‡ é€»è¾‘å›å½’ æ˜¯ çº¿æ€§å›å½’ + Sigmoidæ‹¼æ¥è€Œæˆã€‚ é‚£ä¹ˆç°åœ¨ï¼š æ¯ä¸ªé€»è¾‘å›å½’ çœ‹ä½œä¸€ä¸ª ç¥ç»å•å…ƒ é‚£ä¹ˆç¥ç»ç½‘ç»œå¯ä»¥è¯´æ˜¯ å¤šä¸ª é€»è¾‘å›å½’ æ‘èµ·æ¥çš„æ•ˆæœã€‚ ","link":"https://cythonlin.github.io/post/py-greater-nlp-ml/"},{"title":" PY => Sklearn","content":"æ•°æ®é¢„å¤„ç† å¤§ä½“åˆ†ä¸º ï¼ˆä¸­å¿ƒåŒ–å¤„ç†+ç¼©æ”¾å¤„ç†ï¼‰ ###zero-centered (ä¸­å¿ƒåŒ–å¤„ç†) å¹³ç§» --- å‡å»å›ºå®šå€¼ ###scale (ç¼©æ”¾å¤„ç†) å½’ä¸€åŒ–ï¼šé™¤ä»¥ æœ€å¤§å€¼-æœ€å°å€¼ æ ‡å‡†åŒ–ï¼šé™¤ä»¥ æ ‡å‡†å·® ä¸‹é¢çš„æ“ä½œéƒ½æ˜¯é€šè¿‡ ä¸­å¿ƒåŒ–å¤„ç†+ç¼©æ”¾å¤„ç† è”åˆç»„æˆçš„ ###normalizationï¼ˆå½’ä¸€åŒ–ï¼‰ ç›®æ ‡ï¼š å°†æ•°æ®æ”¶æ•›åˆ° [0,1] å…¬å¼ x - min(x) # ä¸­å¿ƒåŒ– ------------------ max(x) - min(x) # ç¼©æ”¾å¤„ç† sklearnä»£ç å¦‚ä¸‹ from sklearn.preprocessing import MinMaxScaler mm = MinMaxScaler( feature_range=[0,1] ) # æ³¨æ„ï¼Œè¿™é‡Œä¹Ÿå¯ä»¥å½’ä¸€åŒ–åˆ°å…¶ä»–åŒºé—´ [2,4] ï¼Œä¹Ÿæ˜¯æ²¡é—®é¢˜çš„ # mm.fit([[1,2,3],[40,60,70]]) # result = mm.transform([[1,2,3],[40,60,70]]) # è¿™æ­¥è¿”å›çš„ æ‰æ˜¯å½’ä¸€åŒ–åçš„æ•°æ® result = mm.fit_transform([[1,2,3],[40,60,70]]) raw_data = mm.inverse_transform(result) # å¯ä»¥è¿˜åŸå‡º å½’ä¸€åŒ–å‰çš„ åŸå§‹æ•°æ® # é¢å¤–æ³¨æ„ # å¦‚æœæ•°æ®é‡å¤ªå¤§ï¼Œ å¯¼è‡´ fit() æŠ¥é”™ï¼Œé‚£ä¹ˆå¯ä½¿ç”¨ partial_fit() ã€‚ ç”¨æ³•å’Œ fit() ä¸€æ ·çš„ mm.partial_fit(x) ###StandardScalerï¼ˆæ ‡å‡†åŒ–ï¼‰ ç›®æ ‡ï¼š å°†æ•°æ®è½¬åŒ–ä¸ºæ ‡å‡† æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰ å…¬å¼ï¼š x - å¹³å‡å€¼ ----------------- æ ‡å‡†å·® sklearnä»£ç å¦‚ä¸‹ from sklearn.preprocessing import StandardScaler standardscaler = StandardScaler() result = standardscaler.fit_transform([[1,2,3],[40,60,70]]) print(result) print(standardscaler.mean_) # å¯ä»¥æŸ¥çœ‹æ–¹å·®ï¼Œ æ³¨æ„æ˜¯ å®ä¾‹åŒ–å¯¹è±¡çš„å±æ€§ print(standardscaler.var_) # å¯ä»¥æŸ¥çœ‹å‡å€¼ # åŒæ ·å¯ä»¥ é€†å‘æ±‚åŸå§‹æ•°æ® raw_data = standardscaler.inverse_transform(result) # åŒæ ·ä¹Ÿå¯ä»¥ä½¿ç”¨ partial_fit standardscaler.partial_fit(x) æ ‡å‡†åŒ– å’Œ å½’ä¸€åŒ– é€‰å“ªä¸ªï¼Ÿï¼Ÿï¼Ÿ è§†è§‰å›¾ç‰‡ï¼š å½’ä¸€åŒ– å…¶ä»–ï¼š æ ‡å‡†åŒ–è¾ƒå¥½ æ•°æ®ç¼ºå¤±å€¼å¡«è¡¥ æ–¹å¼1ï¼š ç”¨pandasæ‰‹åŠ¨fillna è¿™ç§æ–¹å¼æ›´ç®€å• df[...].fillna( df.loc[:, 'åˆ—å'].mean() ) # ç”¨å‡å€¼æ¥å¡«è¡¥ ï¼Œ ä¸­ä½æ•° # median æ–¹å¼2ï¼š ç”¨ sklearn çš„Imputer å…ˆè¯´ä¸€ä¸‹æŸ¥çœ‹ç¼ºå¤±ï¼ˆé€šå¸¸å®åœ¨ pandasçš„dataframeä¸­ï¼‰ df.info() Imputerå¤„ç†å¦‚ä¸‹ # X é€šå¸¸æ˜¯ pandaså–å‡ºçš„æŸä¸€åˆ— from sklearn.impute import SimpleImputer im = SimpleImputer() # é»˜è®¤ strategy = 'mean'ï¼Œ ç”¨å‡å€¼å¡«è¡¥ im.fit_transform(X) im_meadian = SimpleImputer(strategy='median') # ç”¨ä¸­ä½æ•°å¡«è¡¥ im_meadian.fit_transform(X) im_meadian = SimpleImputer(strategy='most_frequent') # ç”¨ä¼—æ•°å¡«è¡¥ im_meadian.fit_transform(X) im_constant = SimpleImputer(strategy='constant', fill_value=0) # ç”¨å¸¸æ•°å¡«è¡¥ im_constant.transform(X) æ³¨æ„äº†ï¼Œå®ƒä»¬è¿˜æœ‰ä¸ª å‚æ•° missing _ values im = SimpleImputer(missing_values=np.nan) # é»˜è®¤ä¸ºå¡«è¡¥ np.nan # å…¶å®å¤§å¤šæ•°ä¹Ÿéƒ½æ˜¯åœ¨numpyç¯å¢ƒä¸‹çš„ã€‚ç©ºç¼ºå€¼å‡ ä¹éƒ½æ˜¯np.nan, æ‰€ä»¥è¿™ä¸ªå‚æ•°ä¸ç”¨åŠ¨ # å¦‚æœä½ çœŸçš„æœ‰ None ï¼Œé‚£ä¹ˆä½ ä¹Ÿå¯ä»¥è®¾ç½® missing_values=None æ ‡ç­¾ç¼–ç  ä½œç”¨æ•ˆæœ åŸå§‹æ ‡ç­¾ ['çŒ«', 'ç‹—', 'è€é¼ '] LabelEncoderä½œç”¨åçš„æ ‡ç­¾ [0,1,2] ä½¿ç”¨æ–¹æ³• from sklearn.preprocessing import LabelEncoder le = LabelEncoder() encode_label = le.fit_transform(y) print( le.classes_ ) # æŸ¥çœ‹æ‰€æœ‰ç±»åˆ« print( le.inverse_transform(encode_label) ) # è·å–åŸç”Ÿæ ‡ç­¾æ•°æ® ç‰¹å¾ç¼–ç  ä½œç”¨æ•ˆæœ åŸå§‹ç‰¹å¾æ•°æ® åŠ¨ç‰© å­¦å† çŒ« ä¸“ç§‘ ç‹— æœ¬ç§‘ è€é¼  é‡ç‚¹ LabelEncoderä½œç”¨åçš„æ ‡ç­¾ åŠ¨ç‰© å­¦å† 0 0 1 1 2 2 ä½¿ç”¨æ–¹æ³•ï¼ˆSklearnå‡ ä¹éƒ½æ˜¯ä¸€æ ·çš„ï¼‰ from sklearn.preprocessing import OrdinalEncoder oe = OrdinalEncoder() encode_feature = oe.fit_transform(X) # ä¼ è¿›æ¥çš„æ˜¯äºŒç»´ç‰¹å¾ print(oe.categories_) # æŸ¥çœ‹æ‰€æœ‰ç‰¹å¾ # ç»“æœï¼š [ array['çŒ«','ç‹—','è€é¼ '], array['ä¸“ç§‘','æœ¬ç§‘','é‡ç‚¹'] ] oe.inverse_transform(encode_feature) # è·å–åŸç”Ÿç‰¹å¾ One-Hotç‰¹å¾ç¼–ç (å“‘å˜é‡) ç‰¹å¾ç¼–ç å’Œ One-Hotç¼–ç æœ‰ä½•ä¸åŒï¼Ÿ One-Hotå…·æœ‰äº’æ–¥æ€§ï¼Œ è€Œç‰¹å¾ç¼–ç æ˜¯æ— è„‘ç¼–ç  ä½œç”¨æ•ˆæœ åŸå§‹ç‰¹å¾æ•°æ® åŠ¨ç‰© å­¦å† çŒ« ä¸“ç§‘ ç‹— æœ¬ç§‘ è€é¼  é‡ç‚¹ LabelEncoderä½œç”¨åçš„æ ‡ç­¾ (å®ƒä»¬æ˜¯æ‹¼æ¥åœ¨ä¸€èµ·çš„ï¼Œéœ€è¦è‡ªå·±ç”„åˆ«) 1,0,0, 1,0,0 0,1,0, 0,1,0, 0,0,1, 0,0,1, ä½¿ç”¨æ–¹æ³•ï¼ˆSklearnå‡ ä¹éƒ½æ˜¯ä¸€æ ·çš„ï¼‰ from sklearn.preprocessing import OneHotEncoder ohe = OneHotEncoder(categories='auto') # å›ºå®šå‚æ•°ï¼Œè¿™æ ·å†™å³å¯ encode_label = ohe.fit_transform(X).to_array() # fit_trainsformç»“æœä¸ºç¨€ç–çŸ©é˜µï¼Œéœ€è¦to_arrayè½¬ä¸ºDF ohe.inverse_transform(encode_label) # è·å–åŸç”Ÿç‰¹å¾ print( ohe.get_feature_names() ) # æŸ¥çœ‹æ‰€æœ‰ç‰¹å¾å¯¹åº”ä½ç½®çš„ OneHot # é€šå¸¸åšå®ŒOne-Hotçš„ç»“æœåï¼Œæˆ‘ä»¬éœ€è¦åšå–„åå·¥ä½œï¼š 1. æ‹¼æ¥åˆ° DFå°¾éƒ¨ 2. å¹¶ä¸”æŠŠåŸ ç‰¹å¾åˆ é™¤ 3. æŠŠOne-Hotåçš„6ä¸ªç‰¹å¾åˆ— æ”¹ä¸ªåˆ—å äºŒå€¼åŒ– from sklearn.preprocessing import Binarizer bi = Binarizer(threshold=30) # 30ä»¥ä¸‹è®¾ä¸º0ï¼Œ 30ä»¥ä¸Šè®¾ä¸º1 result = bi.fit_transform(X) ç½‘æ ¼æœç´¢ from sklearn.model_selection import GridSearchCV grid_search = GridSearchCV(knn_clf,dict,cv=3) # cvæ˜¯å‡ ï¼Œå°±è¿›è¡Œå‡ æŠ˜çš„äº¤å‰éªŒè¯ grid_search.fit(x_train,y_train) grid_search.best_estimator_ # å¾—å‡º æœ€ä½³å‚æ•° æ¨¡å‹ grid_search.best_score_ # å¾—å‡º æœ€ä½³å‡†ç¡®åº¦ grid_search.best_params_ # å¾—å‡º params å‚æ•° å¯¹åº”çš„ æœ€ä½³ å‚æ•°ç»„åˆ grid_search.cv_results_ # æ¯æ¬¡ æ¨¡å‹ çš„ ç»“æœ äº¤å‰éªŒè¯ from sklearn.model_selection import cross_val_score knn_clf = KNeighborsClassifier() scores = cross_val_score(knn_clf, x_train, y_train, cv=3ï¼‰ å†³ç­–æ ‘ åˆ†ç±»æ ‘ from sklearn import tree cls_tree = tree.DecisionTreeClassifier( criterion='gini', # é»˜è®¤ åŸºå°¼ç³»æ•° , æˆ– &quot;entropy&quot; ä¿¡æ¯ç†µï¼ˆä¿¡æ¯ç†µå¯èƒ½ä¼šè¿‡æ‹Ÿåˆï¼‰ max_depth=3, # é™åˆ¶æ ‘çš„æ·±åº¦ # min_samples_leaf=5, # åˆ†æ”¯åçš„ æ¯ä¸ªâ€˜å¶å­èŠ‚ç‚¹â€™ ä¸­å¿…é¡»åŒ…å«æ ·æœ¬æ•°å¿…é¡»éƒ½å¤§äº5.å¦åˆ™ä¸è®©åˆ†æ”¯ # min_samples_split=10, # å½“ å½“å‰èŠ‚ç‚¹ çš„æ ·æœ¬æ•° å¤§äº10 ï¼Œæ‰å…è®¸åˆ†æ”¯ ) cls_tree.fit() cls_tree.score() cls_tree.predict() print(cls_tree.feature_importances_) # è¾“å‡º æ¯ä¸ªç‰¹å¾å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒï¼Œè¿”å›ä¸ºæ•°ç»„ï¼Œéœ€è¦è‡ªå·±zipç‰¹è¯å å›å½’æ ‘ reg_tree = tree.DecisionTreeRegressor(random_state=0) # æ¯”åˆ†ç±»æ ‘å‚æ•°å°‘ ... # ä¸‹é¢åŒåˆ†ç±»æ ‘API é›†æˆç®—æ³• bagging ï¼ˆè£…è¢‹æ³•ï¼‰ æ¨¡å‹ç›¸äº’ç‹¬ç«‹ï¼Œæœ€åå–å¹³å‡æˆ–èšåˆç­‰ã€‚ ä»£è¡¨ï¼š éšæœºæ£®æ— åˆ†ç±»éšæœºæ£®æ— from sklearn.ensemble import RandomForestClassifier rf_clf = RandomForestClassifier( n_estimators = 50, # 50ä¸ªå­æ ‘æ¨¡å‹ random_state=666, oob_score=True, n_jobs=-1 ) rf_clf.fit() rf_clf.oob_score_ # æ±‚å‡†ç¡®ç‡ å›å½’éšæœºæ£®æ— rf_clf = RandomForestClassifier( n_estimators = 50, random_state=666, ) boosting (æå‡æ³•) ç­‰ èšç±»ç®—æ³• k-means å®¢æˆ·åˆ†ç±»ï¼ˆä¾æ®ç”¨æˆ·å„ç§ç‰¹å¾ï¼Œè‡ªåŠ¨åˆ†å †ï¼‰ ç°‡ï¼ˆå †ï¼‰ ä¸ è´¨å¿ƒ ç°‡ï¼šæ˜¯ä¸ç›¸äº¤çš„ã€‚ å¦‚æœæœ‰ç›¸äº¤çš„ç‚¹ï¼Œé‚£ä¹ˆä¸€å®šæ˜¯ä¸€ä¸ªæ–°ç°‡ è´¨å¿ƒï¼š ç›¸å½“äºæ¯ä¸ªç°‡çš„ä¸­å¿ƒä½ç½®åæ ‡ ï¼ˆæˆ‘ç†è§£ä¸º&quot;åœ†&quot;å¿ƒï¼‰ èšç±»æµç¨‹ éšæœºé€‰å–Kä¸ªæ ·æœ¬ç‚¹ä½œä¸º è´¨å¿ƒ while å¾ªç¯ ï¼ˆæ—§è´¨å¿ƒ != æ–°è´¨å¿ƒï¼‰ å°†Kä¸ªæ ·æœ¬ç‚¹å‘¨å›´çš„æ ·æœ¬ åˆ†é…åˆ° æœ€è¿‘çš„è´¨å¿ƒï¼Œå½¢æˆæ–°ç°‡ è®¡ç®—æ–°ç°‡çš„æ‰€æœ‰æ ·æœ¬ç‚¹çš„ ï¼ˆxyåæ ‡å’Œçš„å‡å€¼ ä½œä¸ºæ–°çš„è´¨å¿ƒï¼‰ è·³å›åˆ°ç¬¬äºŒç‚¹çš„ whileå¾ªç¯ èšç±»å½¢æˆæ–°ç°‡çš„å…¬å¼ä¸æŒ‡æ ‡ æ¯ä¸ªæ ·æœ¬ç‚¹ åˆ° è´¨å¿ƒè·ç¦»ï¼š distance = æ¯ä¸ªæ ·æœ¬ç‚¹ åˆ° è´¨å¿ƒè·ç¦» 1.æ¬§æ‹‰è·ç¦» ï¼ˆé»˜è®¤ä½¿ç”¨çš„æ˜¯æ¬§æ°è·ç¦»ï¼‰ # æ ¹æ®æ•°å­¦æ¨å¯¼ï¼Œè´¨å¿ƒä½ç½®æœ€ç»ˆå°±æ˜¯ å‡å€¼ ä½ç½® 2.æ›¼å“ˆé¡¿è·ç¦»ï¼ˆç»å¯¹å€¼ï¼‰ï¼Œ # æ ¹æ®æ•°å­¦æ¨å¯¼ï¼Œè´¨å¿ƒä½ç½®æœ€ç»ˆå°±æ˜¯ ä¸­ä½æ•° ä½ç½® 3.ä½™å¼¦è·ç¦» # æ ¹æ®æ•°å­¦æ¨å¯¼ï¼Œè´¨å¿ƒä½ç½®æœ€ç»ˆå°±æ˜¯ å‡å€¼ ä½ç½® Kmeansè¯„ä¼°æŒ‡æ ‡ï¼ˆé‡ç‚¹ï¼‰ ä¸€ã€æ‰€æœ‰ç‚¹åˆ° è´¨å¿ƒçš„è·ç¦»ä¹‹å’Œèƒ½ä¸èƒ½ ä½œä¸ºæŒ‡æ ‡ï¼Ÿï¼ˆè·ç¦»è¶Šå°ï¼Œæ•ˆæœè¶Šå¥½ï¼‰ è¿™æ˜¯ä¸¥æ ¼é”™è¯¯ï¼ï¼ å› ä¸º æ¯è°ƒæ•´ä¸€æ¬¡è´¨å¿ƒ å’Œ è°ƒæ•´ä¸€æ¬¡ç°‡ï¼Œ éƒ½å¯èƒ½ç¼©å°èŒƒå›´ã€‚å› æ­¤ è·ç¦»ä¹‹å’Œ è‡ªç„¶å°±å˜å°äº† æ‰€ä»¥ä½ å†ç”¨è·ç¦»åˆ¤æ–­ï¼Œå°±æ˜¯æ²¡æœ‰æ„ä¹‰çš„ äºŒã€æ­£å®—çš„æŒ‡æ ‡ --- è½®å»“ç³»æ•° (è¶Šé è¿‘1 è¶Šå¥½) a = å•ä¸ªç‚¹ï¼ˆæ³¨æ„ï¼Œåªæ˜¯ä¸€ä¸ªç‚¹ï¼‰ ä¸ ç°‡å†… å…¶ä»–ç‚¹çš„ è·ç¦»çš„å¹³å‡ b = å•ä¸ªç‚¹ï¼ˆæ³¨æ„ï¼Œåªæ˜¯ä¸€ä¸ªç‚¹ï¼‰ ä¸ ç°‡å¤– å…¶ä»–ç‚¹çš„ è·ç¦»çš„å¹³å‡ b - a s(è½®å»“ç³»æ•°) = --------------- max(a,b) Sklearn è½®å»“ç³»æ•°ï¼š æœ‰ä¸¤ç§æ–¹å¼ï¼ˆç”¨å“ªä¸ªéƒ½è¡Œï¼Œæ¨èç¬¬ä¸€ç§ï¼‰ï¼š æ–¹å¼1ï¼š from sklearn.metrics import silhouette_score print( silhouette_score(x, y_predict) ) æ–¹å¼2ï¼š from sklearn.metrics import silhouette_samples print( silhouette_samples(x, y_predict).mean() ) # è¿™è¿˜å¾—å†™ä¸ªæ±‚å‡å€¼ è½®å»“ç³»æ•°ç»˜å›¾: from sklearn.cluster import KMeans from sklearn.metrics import silhouette_samples, silhouette_score import matplotlib.pyplot as plt import matplotlib.cm as cm import numpy as np for n_clusters in [2,3,4,5,6,7]: n_clusters = n_clusters fig, (ax1, ax2) = plt.subplots(1, 2) fig.set_size_inches(18, 7) ax1.set_xlim([-0.1, 1]) ax1.set_ylim([0, X.shape[0] + (n_clusters + 1) * 10]) clusterer = KMeans(n_clusters=n_clusters, random_state=10).fit(X) cluster_labels = clusterer.labels_ silhouette_avg = silhouette_score(X, cluster_labels) print(&quot;For n_clusters =&quot;, n_clusters, &quot;The average silhouette_score is :&quot;, silhouette_avg) sample_silhouette_values = silhouette_samples(X, cluster_labels) y_lower = 10 for i in range(n_clusters): ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i] ith_cluster_silhouette_values.sort() size_cluster_i = ith_cluster_silhouette_values.shape[0] y_upper = y_lower + size_cluster_i color = cm.nipy_spectral(float(i)/n_clusters) ax1.fill_betweenx(np.arange(y_lower, y_upper) ,ith_cluster_silhouette_values ,facecolor=color ,alpha=0.7 ) ax1.text(-0.05 , y_lower + 0.5 * size_cluster_i , str(i)) y_lower = y_upper + 10 ax1.set_title(&quot;The silhouette plot for the various clusters.&quot;) ax1.set_xlabel(&quot;The silhouette coefficient values&quot;) ax1.set_ylabel(&quot;Cluster label&quot;) ax1.axvline(x=silhouette_avg, color=&quot;red&quot;, linestyle=&quot;--&quot;) ax1.set_yticks([]) ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1]) colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters) ax2.scatter(X[:, 0], X[:, 1] ,marker='o' ,s=8 ,c=colors ) centers = clusterer.cluster_centers_ # Draw white circles at cluster centers ax2.scatter(centers[:, 0], centers[:, 1], marker='x', c=&quot;red&quot;, alpha=1, s=200) ax2.set_title(&quot;The visualization of the clustered data.&quot;) ax2.set_xlabel(&quot;Feature space for the 1st feature&quot;) ax2.set_ylabel(&quot;Feature space for the 2nd feature&quot;) plt.suptitle((&quot;Silhouette analysis for KMeans clustering on sample data &quot; &quot;with n_clusters = %d&quot; % n_clusters), fontsize=14, fontweight='bold') plt.show() èšç±»æ—¶é—´å¤æ‚åº¦ Oï¼ˆk*n*Tï¼‰ ~= O(n) k: ç°‡æ•° ï¼ˆè¶…å‚æ•°ï¼‰ nï¼šæ ·æœ¬æ•°é‡ Tï¼šè¿­ä»£æ¬¡æ•° èšç±»API + å®æˆ˜ ç”Ÿæˆåˆ†å †ç‚¹ from sklearn.datasets import make_blobs # ç”Ÿæˆåˆ†å †ç‚¹çš„æ•°æ®API import matplotlib.pyplot as plt x,y = make_blobs( n_samples=1000, # 1000ä¸ªæ ·æœ¬ n_features=2, # 2ä¸ªç‰¹å¾ã€‚ ä¹Ÿå¯ä»¥æ›´å¤š eg:10ä¸ªæ»•å³¥ centers=4, # åˆå§‹åŒ–4ä¸ªè´¨å¿ƒ random_state=1 # éšæœºåŒ– ) # xæ˜¯æ ·æœ¬ï¼Œ yæ˜¯æ ‡ç­¾ï¼Œ è¿™é‡Œé¢yç”¨ä¸åˆ°ï¼Œå› ä¸ºæ˜¯æ— ç›‘ç£ fig, ax1 = plt.subplots(1) # ç”Ÿæˆ1ä¸ªå­å›¾ã€‚ figï¼šç”»å¸ƒï¼Œ axç»˜ç”»å¯¹è±¡ ax1.scatter( x[:, 0], x[:, 1], marker='o', # ç‚¹çš„å½¢çŠ¶, è¿™æ˜¯å­—æ¯oï¼Œ è€Œä¸æ˜¯æ•°å­—0, é’©å­å­—ç¬¦ä¸²äº†è§£ä¸€ä¸‹ s=6, # ç‚¹çš„å¤§å° # c='red' # ç‚¹çš„é¢œè‰² ) plt.show() èšç±»API from sklearn.cluster import KMeans clusters = KMeans( n_clusters=3, # è¦æ±‚æœ€å åˆ†3å † æ•°æ® random_state=0 ) clusters.fit(x) # fit() ä»£è¡¨æ±‚å®Œäº†æ‰€æœ‰è¿‡ç¨‹äº†ã€‚ è´¨å¿ƒ-åˆ†ç°‡-è´¨å¿ƒ-åˆ†ç°‡ # å…¶å®fit() è¿‡åï¼Œå°±å·²ç»è®­ç»ƒå‡ºæ¥äº†æ¨¡å‹çš„å‚æ•°ï¼ˆå…¶å®æœ€é‡è¦å‚æ•°çš„å°±æ˜¯ è´¨å¿ƒï¼‰ labels = clusters.labels_ # æŸ¥çœ‹æ¯ä¸ªæ•°æ® åˆ†å‡ºæ¥çš„ label center = clusters.cluster_centers_ # è¿”å›è´¨å¿ƒçš„åæ ‡ï¼ˆx,yï¼‰ã€‚ æœ‰å‡ ä¸ªç°‡ï¼ˆç±»åˆ«ï¼‰ï¼Œå°±æœ‰å‡ ä¸ªè´¨å¿ƒ all_distance = clusters.inertia_ # è¿”å›æ‰€æœ‰ç‚¹åˆ°è´¨å¿ƒçš„æ€»è·ç¦»å¹³æ–¹å’Œ y_predict = clusters.fit_predict(x) # æ‹¿ç€ä¸Šé¢è®­ç»ƒå¥½çš„è´¨å¿ƒå»æŠŠæ–°æ•°æ®è‡ªåŠ¨åˆ†å †ï¼Œå¹¶è¿”å›æ‰€æœ‰æ•°æ®çš„ç±»åˆ«label clusters.labels_ å’Œ y_predict çš„ç»“æœæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œç”¨å“ªä¸ªéƒ½è¡Œ èšç±»APIè¯´æ˜ï¼š å› ä¸ºèšç±»å¤æ‚åº¦ä¸º Oï¼ˆn)+ æ‰€ä»¥æ‰€æœ‰æ•°æ®å–‚è¿›å»ç›´æ¥ fit() è®­ç»ƒå¯èƒ½ä¼šå¾ˆæ…¢ å› æ­¤æˆ‘ä»¬å¯ä»¥å–éƒ¨åˆ†æ•°æ® fit() # å¾—åˆ°è´¨å¿ƒ ç„¶åå‰©ä½™æ•°æ® fit_predict() å»æ‹¿ç€ä¸Šé¢çš„è´¨å¿ƒï¼Œ é¢„æµ‹åˆ†å †, å¹¶è¿”å› label ç”»å‡ºæ•£ç‚¹å›¾ç»“æœ colors = ['pink', 'orange', 'gray'] fig1, ax2 = plt.subplots(1) for i in range(n_clusters): # ç›¸å½“äºåˆé›† ã€‚ã€‚ã€‚ï¼ˆy_predictå€¼æ˜¯æ¾æ•£çš„ï¼‰ ax2.scatter( x[y_predict==i, 0], # æ¯ä¸ªé¢„æµ‹å€¼å¯¹åº”çš„æ ·æœ¬ çš„ æ¨ªåæ ‡ x[y_predict==i, 1], # æ¯ä¸ªé¢„æµ‹å€¼å¯¹åº”çš„æ ·æœ¬ çš„ çºµåæ ‡ marker='o', s=6, c=colors[i] ) ax2.scatter( center[:, 0], center[:, 1], marker='x', s=6, # c='red' # ç‚¹çš„é¢œè‰² ) plt.show() ","link":"https://cythonlin.github.io/post/py-greater-sklearn/"},{"title":"PY => AIç¬”è®°","content":"æ¿€æ´»å‡½æ•° sigmoid å…¬å¼ 1 --------- 1 + e**(-x) æ¯ä¸ªout: (0, 1) äºŒåˆ†ç±»outä¹‹å’Œä¸º 1 å¯¹åº”APIï¼š 1. tf.sigmoid(y) 2. æˆ–å‡½æ•°å‚æ•° xxxxx (activations='sigmoid') 3. tf.keras.activations.sigmoid() softmax e**x --------------------------------- e**(x1) + e**(x2) + ... + e**(xn) æ¯ä¸ªout: (0,1) å¤šåˆ†ç±» outä¹‹å’Œä¸º 1 å¯¹åº”APIï¼š 1. tf.nn.softmax() 2. å‡½æ•°å‚æ•° xxxxx (activations='softmax') 3. tf.keras.activations.softmax() tanh coshx ex - e(-x) ------------- 2 sinhx ex + e(-x) -------------- 2 tanhx ex - e(-x) ------------- ex + e(-x) æ¯ä¸ªout: (0,1) * 2 -1 ===&gt; (-1,1) LSTM å¯¹åº”APIï¼š 1. tf.tanh(y) 2. å‡½æ•°å‚æ•° xxxxx (activations='tanh') 3. tf.keras.activations.tanh() relu å…¬å¼ï¼š y = 0 if x &lt; 0 else x # å¤§äº0ï¼Œæ¢¯åº¦ä¸º1 å¯¹åº”API 1. tf.nn.relu() 2. æˆ–å‡½æ•°å‚æ•° xxxxx (activations='relu') 3. tf.keras.activations.relu() leaky_relu: (å°æ‰©å±•) y = kx if x &lt; 0 else x tf.nn.leaky_relu() æŸå¤±å‡½æ•° MSE ï¼ˆå‡æ–¹è¯¯å·®ï¼‰ å…¬å¼ Î£( (y-y_predict)**2 ) -------------------- n å¯¹åº”API å…¬å¼å®ç°ï¼š tf.reduce_mean( tf.square( y-y_predict ) ) tf.API: tf.reduce_mean( tf.loss.MSE(y, y_predict) ) CrossEntropy ï¼ˆäº¤å‰ç†µï¼‰ ç†µå…¬å¼ï¼š -Î£ï¼ˆplogpï¼‰ äº¤å‰ç†µå…¬å¼ï¼š-ï¼ˆ Î£plogq ï¼‰ pä¸ºçœŸå®å€¼One-hot, qä¸ºé¢„æµ‹å€¼ p: [1,0,0] q: [0.9, 0,0.1] H = -( 1log0.9 + 0log0 + 0*log0.1) = -log0.9 = -ln0.9 â‰ˆ 0.1053.... tfçš„ tf.math.logç›¸å½“äº ln äº¤å‰ç†µAPIï¼š äº¤å‰ç†µè¶Šå°ï¼ˆyä¸y-predictå·®è·è¶Šå°ï¼Œé¢„æµ‹è¾ƒå‡†ç¡®ï¼‰ äº¤å‰ç†µè¶Šå¤§ï¼ˆyä¸y_predictå·®è·è¶Šå¤§ï¼Œäº¤å‰ç›¸ä¹˜ç´¯åŠ åå€¼å¤§ï¼Œè¯´æ˜é¢„æµ‹é”™ä½äº†ã€‚ã€‚ã€‚æ‰€ä»¥äº¤å‰èµ·æ¥å˜å¤§äº†ï¼‰ tf.API: ï¼ˆæ–¹å¼1ï¼šç›´æ¥æ˜¯å‡½æ•°è°ƒç”¨ï¼‰ loss = tf.losses.categorical_crossentropy([1,0,0], [0.9, 0, 0.1],from_logits=True) # ç¬¬ä¸€ä¸ªå‚æ•°y, ç¬¬äºŒä¸ªå‚æ•° y_predict loss = tf.reduce_mean(loss) tf.API: ï¼ˆæ–¹å¼2ï¼šç”¨ç±»çš„callè°ƒç”¨ , è¿™æ¬¡ä»¥ äºŒåˆ†ç±»äº¤å‰ç†µä¸ºä¾‹ï¼‰ loss = tf.losses.BinaryCrossentropy(from_logits=True)( [1], [0.1] ) # ç»“æœä¸º2.+ ã€‚ å› ä¸º çœŸå®å€¼æ˜¯1ç±»ï¼Œ è€Œé¢„æµ‹å€¼æ¦‚ç‡æ˜¯0.1å¤ªå°äº†ã€‚æ‰€ä»¥è‚¯å®šé¢„æµ‹é”™äº†ã€‚ loss = tf.reduce_mean(loss) è¯´æ˜ï¼šcategorical_crossentropy( ) # ç¬¬ä¸€ä¸ªå‚æ•°å¿…é¡» one_hot, ï¼ˆç¬¬äºŒä¸ªå‚æ•°æŒ‰ç†æ¥è¯´éœ€è¦åš softmaxï¼Œä½†æ˜¯ä½ ä¼ äº† from_logigs=Trueï¼Œå°±ä¸å¿…softmaxäº†ï¼‰ æ­£åˆ™åŒ–æƒ©ç½š L1 L1 = keras.regularizers.l1(0.01) L2 ä½¿ç”¨æ–¹å¼1: (æ‰‹æ’•æ–¹å¼)ï¼š for with tf.GradientTape() as tape: ... ... loss_reg = [tf.nn.l2_loss(w_b) for w_b in model.trainable_variables] # [w1,b1,w2,b2] print(tf.reduce_sum(loss_reg)) # tf.Tensor(2.98585, shape=(), dtype=float32) # å°±æ˜¯è¿™ä¸ªå½¢çŠ¶ loss = loss + loss_reg ä½¿ç”¨æ–¹å¼2: (kerasæ·»åŠ å±‚æ–¹å¼)ï¼š L2 = keras.regularizers.l2(0.01) keras.layers.Dense(....., kernel_regularizer=l2) # ä¸ºæ¯å±‚åŠ ä¸ŠL2 æ¢¯åº¦ SGD: å‡å»æ¢¯åº¦ï¼Œä»£è¡¨æœç€æ¢¯åº¦æ–¹å‘èµ° wæ–° = wå½“å‰ - learning_rate * æ¢¯åº¦ ä½¿ç”¨æ–¹å¼ï¼š model.compile(..... ,optimizer=keras.optimizers.SGD(learning_rate=0.01)) Momentumï¼ˆåŠ¨é‡ï¼‰ å…¬å¼å¤§æ¦‚ï¼š wæ–° = wå½“å‰ - learning_rate * (æ¢¯åº¦ + wæ—§) # å…¶ä¸­ ï¼ˆæ¢¯åº¦+wæ—§ï¼‰å’Œä¸ºçŸ¢é‡å’Œï¼Œ ç»“æœå’Œä¸ºï¼ˆå¹³è¡Œå››è¾¹å½¢å¯¹è§’çº¿æ³•åˆ™ï¼‰çš„æ–¹å‘ å…¬å¼æ¢ç®—è¿˜ç­‰ä»·äºï¼ˆå¦ä¸€ç§æ€æƒ³ï¼‰ï¼š wæ–° = (wå½“å‰ - learning_rate * æ¢¯åº¦) - learning_rate * wæ—§ # åœ¨ç›´æ¥ç›´å»æ¢¯åº¦çš„åŸºç¡€ä¸Š------------æ°å¼¯ï¼ˆå°±æ˜¯å‡å»äº†ä¸ªä¸œè¥¿ï¼Œæ”¹å˜æ–¹å‘ï¼‰ RMSProp model.compile(..... ,optimizer=keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.9)) Adam(æ¨è) model.compile(..... ,optimizer=keras.optimizers.Adam(learning_rate=0.01)) RNN ###LSTM 3ä¸ªé—¨ æœ‰ä¸¤ä¸ªè®°å¿†ä¿¡æ¯ï¼ˆh c ï¼‰ ###GRU æœ‰ä¸¤ä¸ªé—¨ åªæœ‰ä¸€ä¸ªè®°å¿†ä¿¡æ¯ c NMSï¼ˆéæå¤§æŠ‘åˆ¶ï¼‰ å€™é€‰å‡å¦‚æœ‰ABCDå››ä¸ªå€™é€‰æ¡†ï¼ï¼ï¼ï¼ï¼ï¼ 1. åˆ†ç±»ä¹‹åï¼Œå–å‡ºæœ€å¤§æ¦‚ç‡å€™é€‰æ¡†Aã€‚ 2. å°†å…¶ä½™å€™é€‰æ¡†ï¼Œä¸è¿™ä¸ªæœ€å¤§çš„å€™é€‰æ¡†ï¼Œåš IOU äº¤é›†/å¹¶é›† 3. å¦‚æœäº¤é›†/å¹¶é›†çš„ ç»“æœå¤§äºé˜ˆå€¼ï¼Œï¼ˆç­›é€‰å‡ºäº†Bï¼Œå¹¶åˆ é™¤ï¼‰ï¼ˆè¿™æ ·æ“ä½œæ˜¯ç­›é€‰å‡º æœ€å¤§æ¦‚ç‡çš„ç‚¹ çš„ é™„è¿‘çš„ç‚¹ï¼Œå¹¶åˆ é™¤ï¼‰ ä¸ºä»€ä¹ˆè¦åˆ é™¤å‘¢ã€‚ å› ä¸ºä½ æœ‰äº†è¿™ä¸ªæœ€å¤§æ¦‚ç‡çš„ç‚¹ï¼Œå…¶ä»–ç›¸ä¼¼çš„ç‚¹éƒ½æ˜¯å¼Ÿå¼Ÿäº†ã€‚ å¯ä»¥æ‰”äº†ã€‚ 4. å‰©ä¸‹çš„å°±æ˜¯ CDäº†ï¼Œ CDè¿˜æ˜¯é‡å¤123æ“ä½œã€‚ é€‰ä¸€ä¸ªè€å¤§ï¼ˆå¤§æ¦‚ç‡æ¡†æ¡†ï¼‰ é€šè¿‡é˜ˆå€¼ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè®¤ä¸ºï¼Œ ABæ˜¯åŒä¸€å±‚é¢çš„ä¸œè¥¿ï¼Œ è€Œ CDæ˜¯é¢„æµ‹äº†å¦ä¸€å±‚é¢çš„ä¸œè¥¿ã€‚ æ‰€ä»¥æ¯ä¸ªå±‚é¢é€‰å‡ºä¸€ä¸ªè€å¤§å³å¯ã€‚ï¼ R-CNN 0. å¤„ç†å›¾ç‰‡ï¼ˆcrop + wrapï¼‰ 1. å›¾ç‰‡-&gt;SS(é€‰æ‹©æ€§æœç´¢ï¼ˆéšä¾¿ç”»æ¡†ï¼‰)-&gt;NN-&gt;å€™é€‰åŒºåŸŸï¼ˆFine-Tuneï¼‰ (1æ­£æ ·æœ¬ï¼š3è´Ÿæ ·æœ¬) 2. SVMåˆ†ç±»ï¼ˆå‡†ç¡®ç‡é«˜ï¼‰ 3. NMSç­›é€‰ï¼ˆIOU äº¤/å¹¶ï¼Œç­›é€‰ï¼‰ 4. BoundingBoxRegè¾¹æ¡†å›å½’ å­˜åœ¨é—®é¢˜ï¼š 1. ç¥ç»ç½‘ç»œ æ…¢ 2. å›¾ç‰‡ å˜å½¢ SPPNet å›¾ç‰‡æ˜ å°„ R-CNNæ˜¯ä¸€å¤§å †å›¾ç‰‡çš„ é€‰æ‹©æ€§æœç´¢ï¼ˆç”»æ¡†ï¼‰ï¼Œ ç„¶åå¡å…¥ CNNï¼Œ å¾—å‡ºç‰¹å¾å‘é‡ã€‚ SPP æ˜¯åªæŠŠä¸€å¼ å›¾ç‰‡ å¡å…¥CNN è®­ç»ƒæå–å‡º ä¼—å¤š &quot;ç‰¹å¾å‘é‡&quot;ã€‚ ç„¶åå†é€‰æ‹©æ€§æœç´¢ï¼ˆSSç”»æ¡†ï¼‰ å¾—å‡ºä¼—å¤š&quot;å€™é€‰åŒºåŸŸ&quot;ã€‚ ç„¶åå°† &quot;å€™é€‰åŒºåŸŸ&quot; ä¸ &quot;ç‰¹å¾å‘é‡&quot; ä¸€ä¸€æ˜ å°„ã€‚ s = strideså·ç§¯ * stridesæ± åŒ– å·¦ä¸Šè§’ï¼š xç‰¹å¾ = xåŸå›¾å€™é€‰/s + 1 yåŒç† å³å°è§’ï¼š xç‰¹å¾ = xåŸå›¾å€™é€‰/s - 1 yåŒç† æ³¨ï¼š æ˜ å°„åçš„ç‰¹å¾å‘é‡å¤§å°ä¸å›ºå®š æ‰€ä»¥è¿™äº›ç‰¹å¾å‘é‡ éœ€è¦äº¤ç»™ SPPå±‚å¤„ç† spatial pyramid pooling (ç©ºé—´é‡‘å­—å¡”æ± åŒ–å±‚) æ¯ä¸ª å€™é€‰åŒºåŸŸ ï¼Œéƒ½ä¼šç»è¿‡å¦‚ä¸‹å˜æ¢ï¼š ï¼ˆ256å–å†³äº æ¯ä¸ªä¸åŒçš„CNNç½‘ç»œæ¨¡å‹è¾“å‡ºé€šé“ï¼‰ è¢«åˆ†è›‹ç³•ä¸º 4x4, 256é€šé“ ====&gt; (16ï¼Œ 256) è¢«åˆ†è›‹ç³•ä¸º 2x2, 256é€šé“ ====&gt; (4ï¼Œ 256) è¢«åˆ†è›‹ç³•ä¸º 1x1, 256é€šé“ ====&gt; (1ï¼Œ 256) ç»¼ä¸Šç›¸åŠ  ====&gt; (21, 256) æ€æƒ³ï¼ˆåˆ†éš”ï¼Œå†èšåˆï¼‰ æ”¹å–„äº†R-CNNçš„ä»€ä¹ˆï¼Ÿ å› ä¸ºç»Ÿä¸€ç”¨äº†SPPå±‚æ ¼å¼åŒ–ï¼ˆåˆ‡å‰²ï¼‰ï¼Œæ‰€ä»¥å°±ä¸ç”¨äº†ã€‚ Fast R-CNN æ”¹è¿› ç›¸æ¯”è¾ƒäºSPPï¼Œæœ‰å¦‚ä¸‹æ”¹åŠ¨ï¼š 1. æ–°å¢ ROI poolingå±‚ 2. SVM æ›¿æ¢ä¸º softmax( bounding box regresson ä¾ç„¶å­˜åœ¨) =&gt; softmaxè¾“å‡ºä¸ºï¼š Nä¸ªç±»åˆ«+1ä¸ªèƒŒæ™¯ 3. ROIPooling: 0. åŒæ ·å…ˆæ˜¯ SSå€™é€‰åŒºåŸŸ å’Œ CNNç‰¹å¾ çš„æ˜ å°„ 1. 4x4+2x2+1x1 æ›¿æ¢æˆå•ä¸ª MxN 2. å¦‚æœå’Œ fc å±‚è¾“å…¥ä¸åŒ¹é…ï¼Œé‚£ä¹ˆä¼šè‡ªåŠ¨åˆ’åˆ†ï¼ˆåˆ‡å‰²ï¼‰æˆåŒ¹é…çš„å¤§å°ã€‚ 3. èˆå¼ƒå°‘é‡ç²¾åº¦ï¼Œè·å–æ›´å¤§æ•ˆç‡ã€‚ 4. æŸå¤±å‡½æ•°ï¼Ÿï¼Ÿ åˆ†ç±»éƒ¨åˆ†=&gt; äº¤å‰ç†µ å›å½’éƒ¨åˆ†=&gt; MAE Faster R-CNN æ”¹è¿› ç›¸æ¯”è¾ƒäºFast R-CNNï¼Œæœ‰å¦‚ä¸‹æ”¹åŠ¨ï¼š 1. åŸå›¾ç‰‡ -&gt; CNN -&gt; ç‰¹å¾å›¾ 2.1 ç‰¹å¾å›¾ç»è¿‡RPNç”Ÿæˆå€™é€‰åŒºåŸŸ 2.2 å€™é€‰åŒºåŸŸ ä¸ ç‰¹å¾å›¾ ç»„åˆ è¾“å…¥åˆ° =&gt; Roi Pooling å¾—åˆ° æ¯ä¸ª å€™é€‰åŒºåŸŸ çš„ ç‰¹å¾å›¾ã€‚ RPNç½‘ç»œï¼š ç‰¹å¾å›¾ï¼š nxnçš„å¤§å°çª—å£å»æ‰«æç‰¹å¾å›¾ï¼Œ æ¯ä¸ªçª—å£æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´å‘é‡ã€‚ ä½ç»´å‘é‡ =&gt; è¾“å…¥åˆ°ä¸¤ä¸ªå¹¶è¡Œçš„ 1x1 å·ç§¯ä¸­ï¼Œå¾—å‡ºä¸¤ä¸ªç»“æœï¼š 1. regçª—å£å›å½’å±‚ï¼› (ç”¨äºä¿®æ­£ä½ç½®) 2. clsçª—å£åˆ†ç±»å±‚ï¼š ï¼ˆè¡¨ç¤ºå‰æ™¯ï¼Œå’Œ èƒŒæ™¯çš„æ¦‚ç‡ï¼‰ æ¯ä¸ªä» CNNå‡ºæ¥çš„ ç‰¹å¾å›¾æœ‰å¦‚ä¸‹å±æ€§ï¼ˆå¯èƒ½æœ‰ M*Nä¸ªç‰¹å¾å›¾ï¼‰ï¼š 9ä¸ªAnchor: å°ºåº¦ ï¼š {128ï¼Œ 256ï¼Œ 512} é•¿å®½æ¯”ï¼š {1ï¼š1ï¼Œ 1ï¼š2ï¼Œ 2ï¼š1} 9ä¸ªAnchorç›¸å½“äºï¼ˆ9ä¸ªç²—ç•¥çš„å€™é€‰åŒºåŸŸ-&gt; æ›¿ä»£äº†ä¹‹å‰ç”¨æ¡†æ¡†ç”»å‡ºçš„åŒºåŸŸï¼‰ RPNç½‘ç»œè®­ç»ƒï¼š è®­ç»ƒæ ·æœ¬æ ‡è®°ï¼š æ±‚Anchor ä¸ ground_truth boxçš„IOU: IOU&gt;0.7è®°ä¸ºæ­£æ ·æœ¬ï¼Œ 0.3&lt;IOU&lt;0.7 æ ‡è®°ä¸ºè´Ÿæ ·æœ¬ IOU &lt; 0.3çš„å…¨éƒ¨åˆ é™¤ RPN: æŸå¤± äºŒåˆ†ç±»ï¼š åŒºåˆ«å‡ºæ¥ ï¼ˆæ˜¯å¦æœ‰ç‰©ä½“ -&gt; å‰æ™¯ or èƒŒæ™¯ï¼‰ å›å½’ï¼š ä¿®æ­£å‰©ä½™ä¼˜ç§€ Anchorçš„ä½ç½®ä½œä¸ºæœ€ç»ˆå€™é€‰ç‰¹æŠ˜ Faster R-CNNæ­£å¼è®­ç»ƒï¼š å’Œ Fast R-CNNä¸€æ ·ï¼š 1. å¤šåˆ†ç±» softmax(N+1) 2. bounding box å›å½’ ä¼˜ç‚¹ï¼š æå‡ºRPNç½‘ç»œ ç«¯åˆ°ç«¯ç½‘ç»œæ¨¡å‹ ç¼ºç‚¹ï¼š è®­ç»ƒå‚æ•°è¿‡å¤§ çœŸå®äº§å“è¿˜æ˜¯æ…¢ YOLO GoogleNet+4 Conv + 2 Dense SSD VGG-16: 300 * 300 ","link":"https://cythonlin.github.io/post/py-greater-ai-bi-ji/"},{"title":"GO => è°ˆä¸€è°ˆGoland/Pycharm/Ideaå…¨å±€æœç´¢ä¸ºä½•å¶å°”å¤±çµçš„é—®é¢˜","content":"ä¼—æ‰€å‘¨çŸ¥ JetBrainså…¨å®¶æ¡¶ç³»åˆ—é»˜è®¤å…¨å±€æœç´¢å¿«æ·é”®ä¸º: ctrl + shift + f ä¸ºä½•ä¸Šè¿°å¿«æ·é”®å¶å°”å¤±çµ? ä¸æƒ³çœ‹åŸå› çš„å¯ä»¥ç›´æ¥è·³åˆ°æœ€åçœ‹2ç§è§£å†³åŠæ³• å¾®è½¯æ‹¼éŸ³åˆ‡æ¢ç®€ä½“/ç¹ä½“ï¼š ä¸€ç›´ä½¿ç”¨çš„æ˜¯Win10è‡ªå¸¦çš„å¾®è½¯æ‹¼éŸ³ï¼ˆå…¶ä»–è¾“å…¥æ³•æ²¡ç”¨è¿‡ï¼Œåº”è¯¥ç±»ä¼¼ï¼‰ ctrl + shift + f è¿™é‡Œåˆ‡æ¢ç®€ä½“/ç¹ä½“æœ‰ä¸ªæ¡ä»¶ï¼š åªæœ‰ä½ å½“å‰è¾“å…¥æ³•çŠ¶æ€ä¸º â€œä¸­æ–‡è¾“å…¥æ³•â€æ—¶ï¼Œ åˆ‡æ¢ç®€/ç¹ï¼ˆctrl+shift+fï¼‰å¿«æ·é”®æ‰ä¼šç”Ÿæ•ˆ å¦‚æœå½“å‰è¾“å…¥æ³•çŠ¶æ€ä¸º â€œè‹±æ–‡è¾“å…¥æ³•â€æ—¶ï¼Œ åˆ‡æ¢ç®€/ç¹ï¼ˆctrl+shift+fï¼‰å¿«æ·é”® ä¸èµ·ä½œç”¨ã€‚ åˆ°è¿™é‡Œåº”è¯¥å¯ä»¥æƒ³å‡ºpycharm/goland/...å…¨å±€æœç´¢ä¸ºä½•å¤±çµäº†å§~~ å¤±çµåŸå›  å› ä¸ºå†™ä»£ç æ—¶ï¼Œè¾“å…¥æ³•å¯èƒ½ä¼š ä¸­/è‹± åˆ‡æ¢ã€‚ å½“å‰æˆ‘ä»¬çš„è¾“å…¥æ³•çŠ¶æ€ä¸º â€œä¸­æ–‡â€ æ—¶ï¼š ctrl+shift+f çš„ä½œç”¨æ˜¯åˆ‡æ¢ ç¹/ç®€ è¾“å…¥æ³• å½“å‰æˆ‘ä»¬çš„è¾“å…¥æ³•çŠ¶æ€ä¸º â€œè‹±æ–‡â€ æ—¶ï¼š ctrl+shift+f çš„ä½œç”¨å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€Šå…¨å±€æœç´¢ã€‹ è§£å†³åŠæ³• è§£å†³åŠæ³•1ï¼ˆåˆ‡æ¢ä¹ æƒ¯ï¼‰ æ ¹æ®å¤±çµåŸå› ï¼Œæˆ‘ä»¬æƒ³è¦ä½¿ç”¨JetBrainsç³»åˆ—äº§å“å…¨å±€æœç´¢æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æ³¨æ„è‡ªå·±çš„è¾“å…¥æ³•æ˜¯å¦æ˜¯&quot;è‹±æ–‡çŠ¶æ€&quot;ï¼Œè‹¥ä¸æ˜¯ï¼Œåˆ™åˆ‡æ¢åˆ°è‹±æ–‡çŠ¶æ€ï¼š shift # å¾®è½¯æ‹¼éŸ³åˆ‡æ¢ ä¸­/è‹± æ˜¯ shift ï¼Œå…¶ä»–è¾“å…¥æ³•ä¸æ¸…æ¥š å¯¹æˆ‘è€Œè¨€ï¼Œè¿™æ˜¯ä¹ æƒ¯é—®é¢˜ï¼Œä¸å­˜åœ¨è¾“å…¥æ³•å†²çªï¼Œå¦‚æœæ²¡åˆ‡æ¢ä¸­/è‹±è¿™ä¸ªä¹ æƒ¯ï¼Œå¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ”¹å¿«æ·é”® è§£å†³åŠæ³•2ï¼ˆæ”¹å¿«æ·é”®ï¼‰ å¦‚æœæ‰§æ„è¦æ”¹å¿«æ·é”®ï¼Œå¯ä»¥æ”¹å¿«æ·é”® (å› ä¸ºæˆ‘å·²ç»ä¹ æƒ¯äº†ä¸­/è‹±è¾“å…¥æ³•åˆ‡æ¢æ–¹å¼)ï¼Œæ‰€ä»¥æˆ‘æ˜¯ä¸æ”¹çš„ã€‚ æŒ‰ç…§å¦‚ä¸‹é…ç½®æµç¨‹èµ°ï¼š File -&gt; Settings -&gt; Keymap -&gt; åœ¨æœç´¢å¿«æ·é”®çš„è¾“å…¥æ¡†è¾“å…¥ï¼š find in path åŒå‡» &quot;find in path&quot; -&gt; Add Keyboard Shortcutï¼ˆç„¶åé”®ç›˜æŒ‰ä¸‹ä½ åƒè®¾ç½®çš„å¿«æ·é”®ï¼‰ ï¼ˆæˆ‘ä¸ªäººæ¨èæ˜¯ ctrl+shift+|ï¼‰ï¼Œå› ä¸ºè¿™ä¸ªå¿«æ·é”®æœªè¢«å ç”¨ ~ ok -&gt; ok ","link":"https://cythonlin.github.io/post/ai-greater-ci-xing-biao-da-quan/"},{"title":"PY => Dockeré…ç½®daemon.jsonçš„hosté€‰é¡¹å¤±è´¥","content":"å½“æˆ‘é…ç½®Dockerè®©å¤–éƒ¨è¿æ¥çš„æ—¶å€™ æˆ‘å°è¯•åˆ›å»º /etc/docker/daemon.jsonæ–‡ä»¶ï¼Œ å¹¶å†™å¦‚ä¸‹å†…å®¹ï¼š { &quot;registry-mirrors&quot;: [&quot;https://rs3ab060.mirror.aliyuncs.com&quot;], &quot;hosts&quot;: [&quot;unix:///var/run/docker.sock&quot;, &quot;tcp://0.0.0.0:6006&quot;] } ç„¶åï¼Œé‡å¯dockeræœåŠ¡ï¼Œä¸€ç›´å¤±è´¥ã€‚ æ ¹æœ¬æ— æ³•å¯åŠ¨ã€‚ ç»æ’æŸ¥ï¼Œæ˜¯hostsè¿™ä¸ªé…ç½®é¡¹æœ‰é—®é¢˜ã€‚ ç»ˆæè§£å†³åŠæ³•ï¼š systemctl edit dockerd.service # å¤åˆ¶è¿™æ¡å‘½ä»¤æ‰§è¡Œï¼Œå¹¶å†™ç²˜è´´å¦‚ä¸‹å†…å®¹ [Service] ExecStart= ExecStart=/usr/bin/dockerd ctrl + s ä¿å­˜ ctrl + x é€€å‡º å¾ˆå¤šé—®é¢˜stack, github è§£å†³ä¸äº†çš„ï¼Œæˆ‘éƒ½ä¼šå»qiitaã€‚ï¼ˆäººå®¶å†™çš„è¨€ç®€æ„èµ…ï¼Œè§£å†³é—®é¢˜ä»ä¸åºŸè¯ï¼‰ ","link":"https://cythonlin.github.io/post/docker-pei-zhi-daemonjson-de-host-xuan-xiang-shi-bai/"},{"title":"PY => éŸ³å£°åˆ†ç¦»","content":"ç¯å¢ƒå®‰è£… è‡ªä¸»å®‰è£… FFmpeg pip install jupyter pip install spleeter æ€è·¯ spleeterå·¥å…·å¯åœ¨commandé€ä¸€åˆ†ç¦»,æœ‰äº›è´¹åŠ²ã€‚ å¹¶ä¸”æ–‡ä»¶åä¸è®¸æœ‰ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ã€‚ æœ¬æƒ³é€šè¿‡pyè„šæœ¬ï¼Œæ‰¹å¤„ç†ï¼ˆos.system/os.subprocessï¼‰åšäº›è„šæœ¬æ“ä½œã€‚ ä½†æ˜¯ spleeteréšå¼æœç´¢ FFmpegã€‚æ‰€ä»¥ï¼ˆos.system/os.subprocessï¼‰éƒ½æœä¸åˆ°FFmpeg å³ä½¿å†…/å¤–æ·»åŠ ç¯å¢ƒå˜é‡ä¹Ÿä¸è¡Œã€‚ åæ¥æ²¡åŠæ³•ï¼Œæƒ³ä¸ªæ­ªçš„ã€‚ ç”¨ jupyter notebook çš„ !æŒ‡ä»¤åµŒå¥—å¾ªç¯å®ç°ã€‚ Jupyter Notebookä»£ç  import re import os import shutil music_list = os.listdir('éŸ³ä¹') r1 = re.compile(r'(\\(.*?\\)|ï¼ˆ.*?ï¼‰|\\[.*?\\]|\\s*?|ã€.*?ã€‘|ã€Š.*?ã€‹)') new_music_list = [r1.sub('',per_music) for per_music in music_list] %cd éŸ³ä¹ name_map = zip(music_list, new_music_list) for old_name,new_name in name_map: try: os.rename(old_name,new_name) except: pass new_name_list = os.listdir('.') for filename in new_name_list: if filename.endswith('jpg'): continue print(filename) try: !spleeter separate -i {filename} -p spleeter:2stems -o output except: pass åˆ†ç¦»å¥½çš„éŸ³/å£°éƒ½æ”¾åœ¨å„è‡ªçš„æ­Œæ›²çš„æ–‡ä»¶å¤¹å†… ä¸ºäº†å¬ä¼´å¥ï¼ŒæŠŠæ‰€æœ‰ä¼´å¥æ”¾ä¸€èµ· music_list = os.listdir('éŸ³ä¹') # æ–¹ä¾¿å¤åˆ¶ï¼Œ output å’Œ pretrained_models ç§»åŠ¨äº†å‡ºæ¥ [shutil.copy(f'output/{music.rsplit(&quot;.&quot;,1)[0]}/accompaniment.wav', f'D:/music/acc/{music}') for music in music_list if music.rsplit(&quot;.&quot;,1)[1] != 'jpg' and music not in ['pretrained_models','output']] # æˆ‘åªå¬ä¼´å¥ï¼Œæ‰€ä»¥äººå£°å°±å…äº†ã€‚ã€‚ # [os.rename(f'output/{music.rsplit(&quot;.&quot;,1)[0]}/vocals.wav', f'D:/music/voice/{music}') for music in music_list if music.rsplit(&quot;.&quot;,1)[1] != 'jpg' and music not in ['pretrained_models','output']] os.rename å’Œ shutil.moveä½¿ç”¨åŒºåˆ«ï¼š shutil.move æ˜¯å…ˆå¤åˆ¶ååˆ é™¤ ï¼ˆæ ¹æœ¬ä¸æ˜¯cutï¼‰(æ…¢) os.rename å¯ä»¥è¾¾åˆ°å‰ªåˆ‡çš„æ•ˆæœ(ç¥é€Ÿ) ï¼ˆä¹Ÿå¯ä»¥ç”¨æ¥æ”¹åï¼‰ ","link":"https://cythonlin.github.io/post/py-greater-yin-sheng-fen-chi/"},{"title":"PY => PY38","content":"è¯´æ˜ æœ¬ç¯‡æ–‡ç« ä»‹ç»Python3.8çš„ä¸€äº›è¾ƒä¸ºå¥½ç”¨çš„æ–°ç‰¹æ€§ èµ‹å€¼è¡¨è¾¾å¼ è¯­æ³•æ ¼å¼ï¼š 2ç§æ ¼å¼çš„åŒºåˆ«å°±æ˜¯ï¼Œä¸€ä¸ªå¸¦æ‹¬å·ï¼Œä¸€ä¸ªä¸ç”¨å¸¦æ‹¬å· (a:=1) a:=1 å…¶å®è¿™ä¸¤ç§æ ¼å¼ç»“æœæ˜¯ä¸€æ ·çš„ï¼Œåªæ˜¯æœ‰äº›æƒ…å†µæ‹¬å·å¯ä»¥çœç•¥ä¸å†™è€Œå·²ã€‚ æ‹¬å·å¯çœçš„æƒ…å†µ #ä¸€ã€åºåˆ—ç±»å‹ä¸­ æ‹¬å·å¯çœ [a:=1, 2] äºŒã€ä½œä¸ºå‡½æ•°è°ƒç”¨çš„å‚æ•° æ‹¬å·å¯çœ # æ³¨æ„æˆ‘è¯´çš„æ˜¯å‡½æ•°è°ƒç”¨ï¼Œå‡½æ•°å®šä¹‰çš„æ—¶å€™å‹æ ¹å°±ä¸èƒ½ç”¨ := è¡¨è¾¾å¼ï¼Œæ›´åˆ«æå¯ä¸å¯çœäº† print(g:=1) ä¸‰ã€ä»¥åç¢°è§å†è¯´äº†ï¼Œåº”è¯¥ä¹Ÿæ²¡å•¥äº† æ‹¬å·ä¸å¯çœçš„æƒ…å†µ ä¸€ã€åœ¨while(), if(), for()è¯­å¥çš„æ¡ä»¶ä¸­ï¼ˆè™½å¯çœä½†ä¸è¦çœï¼‰ while ((b:=1) == 2): # ifï¼Œ for åŒç† print(2) print(b) # &gt;&gt; 1 å¼ºè°ƒ1 := æ­¤è¿ç®—ç¬¦ä¼˜å…ˆçº§æ¯” == è¿˜ä½ï¼Œè™½ç„¶å¯çœï¼Œæ‰€ä»¥è¿™é‡ŒåŒºåˆ†è¯­ä¹‰æ‹¬å·è¦åŠ ä¸Š å¼ºè°ƒ2 := å°±ç®—while æˆ–è€… if æ¡ä»¶ä¸æˆç«‹ï¼Œ bä¾ç„¶èµ‹å€¼æˆåŠŸ äºŒã€åœ¨ f-string ä¸­ï¼Œæ‹¬å·ä¸å¯çœ ï¼ˆæŸäº›æƒ…å†µå¯çœï¼Œè™½å¯çœä½†ä¸è¦çœï¼‰ f'{(p:=1)}' print(p) å‡å¦‚æ–°å˜é‡qæ˜¯æœªå®šä¹‰çš„ï¼Œä¸åŠ æ‹¬å·å°±ä¼šå‡ºç°å¦‚ä¸‹æƒ…å†µï¼ˆæ‰€ä»¥è¿™æ ·ç”¨å°±æ²¡æ„ä¹‰äº†ï¼Œ f-stringæ‹¬å·å¿…é¡»åŠ ï¼‰ f'{q:=1}' print(p) # NameError: name 's' is not defined ä¸‰ã€ä»¥åç¢°è§å†è¯´äº†ï¼Œä¹Ÿæ²¡å•¥äº† f-stringæ–°å¢åŠŸèƒ½ 3.8ä¹‹å‰è¿™ä¹ˆç”¨: f'{loss}, {acc}' #&gt;&gt; '0.0141, 0.98912' 3.8ä¹‹åè¿™ä¹ˆç”¨: f'{loss=}, {acc=}' #&gt;&gt; 'loss=0.0141, acc=0.98912' è¿˜æœ‰ä¸ªåŠŸèƒ½(è‡ªå·±çœ‹ç»“æœå¯¹æ¯”çš„æ•ˆæœæŠŠ): name = 'zhang' f'{name}' # 'zhang' f'{name=}' # &quot;name='zhang'&quot; # æ–°å¢åŠŸèƒ½1 f'{name=!s}' # 'name=zhang' # æ–°å¢åŠŸèƒ½2 æ¬§æ°è·ç¦» import math math.dist([1,2,3,4],[5,6,7,8]) f-stringå›é¡¾(3.6å°±å·²ç»å‡ºäº†ï¼Œä¸€ç›´åœ¨ç”¨) æ–¹å¼0: æå‰è¯´æ˜(æ–¹å¼6 å’Œ æ–¹å¼7ä¸Šæ¡£æ¬¡, å¥½ç”¨) æ–¹å¼1ï¼šå˜é‡æ›¿æ¢ name = 'zhang' print( f'{name}' ) #&gt;&gt; zhang æ–¹å¼2ï¼šå†…åµŒè¡¨è¾¾å¼è®¡ç®— name = 'zhang' print( f'{name.upper()}' ) #&gt;&gt; ZHANG æ–¹å¼3ï¼šä¸€è¡Œå†™ä¸ä¸‹ï¼Œå¯ä»¥å¤šè¡Œ f'' (æ³¨æ„ï¼Œä¸éœ€è¦é€—å·åˆ†éš”)ï¼Œå¹¶ä¸”è¦ç”¨å°æ‹¬å·æ‰©èµ·æ¥ name = 'zhang' age = 18 gender = 'man' a = ( f'name={name} ' f'age={age} ' f'gender={gender} ' ) print(a) #&gt;&gt; name=zhang age=18 gender=man æ–¹å¼4ï¼šè½¬ä¹‰ {} # æ³¨æ„ä¸€ä¸‹ï¼Œ # f'{ ' è¿™ç§ä¼šæŠ¥é”™çš„ # å› ä¸º { åœ¨ f''è¯­å¥é‡Œé¢å·²ç»ä¸æ˜¯å­—ç¬¦ä¸²äº†ï¼Œ è€Œæ˜¯è¯­æ³•ç¬¦å· # å¦‚æœæˆ‘ä»¬æƒ³è¦ {} è¿™ç§å­—ç¬¦ä¸²ï¼Œ å¦‚ä¸‹è§£å†³åŠæ³• # ç”¨ { æ¥è½¬ä¹‰ { # ç”¨ } æ¥è½¬ä¹‰ } eg: f'{{' è¾“å‡ºä¸º&gt;&gt; '{' f'}}' è¾“å‡ºä¸º &gt;&gt; '}' æ–¹å¼5ï¼šç¬¦å·æ ¼å¼ æ­£å·ï¼š import random b = random.randint(0,5) f'{b:+}' #&gt;&gt; +0 æ–¹å¼6ï¼šæ—¥æœŸç¬¦å·æ ¼å¼ï¼ˆç‰¹åˆ«å¥½ç”¨ï¼Œé€‚ç”¨äº time,date,datetimeå¯¹è±¡ï¼‰ from datetime import datetime e = datetime.now() # å¹´æœˆæ—¥æ—¶åˆ†ç§’ f'{e:%Y}' # '2020' è¡¨ç¤º2020å¹´ (æ³¨æ„æ˜¯å¤§å†™çš„Y) f'{e:%m}' # '09' è¡¨ç¤º9æœˆä»½ ï¼ˆè‡ªåŠ¨è¡¥0ï¼‰(æ³¨æ„æ˜¯å°å†™m) f'{e:%d}' # '02' è¡¨ç¤º2å· f'{e:%H}' # '21' è¡¨ç¤º21ç‚¹äº† (24å°æ—¶åˆ¶) f'{e:%M}' # '43' è¡¨ç¤º43åˆ†äº† (æ³¨æ„æ˜¯å¤§å†™çš„M) f'{e:%S}' # '50' è¡¨ç¤º50ç§’äº† (æ³¨æ„æ˜¯å¤§å†™çš„S) # é»˜è®¤ç»„åˆæ ¼å¼(åˆ†éš”ç¬¦æ˜¯å›ºå®šçš„) f'{e:%F}' # '2020-09-02' å¹´-æœˆ-æ—¥, åˆ†å‰²ç¬¦æ˜¯å›ºå®šçš„ '-' f'{e:%T}' # '21:58:39' æ—¶:åˆ†:ç§’, åˆ†å‰²ç¬¦æ˜¯å›ºå®šçš„ ':' (å¤§å†™çš„Xä¸€æ‘¸ä¸€æ ·) # åŸºäºä¸Šé¢2è¡Œè‡ªå·±ç»„è£…ä¸€ä¸‹,å½¢æˆå®Œæ•´æ—¶é—´ f'{e:%F %T}' # '2020-09-02 22:02:29' ä¸Šé¢2ç§ç»„è£…ä¸€ä¸‹ # æ˜ŸæœŸå‡ + æ¯å¹´çš„ç¬¬å‡ å¤© + æ¯å¹´çš„ç¬¬å‡ å‘¨ f'{e:%j}' # '246' è¡¨ç¤ºä¸€å¹´ä¸­çš„ç¬¬ 246 å¤©, ä¸ªä½æ•°å‰é¢è¡¥0,è‡³3ä½ f'{e:%u}' # '3' è¡¨ç¤ºæ˜ŸæœŸ3 ï¼ˆæ˜ŸæœŸæ—¥æ˜¯7ï¼‰ f'{e:%W}' # '35' è¡¨ç¤ºä¸€å¹´ä¸­çš„ç¬¬ 35å‘¨, ä¸ªä½æ•°å‰é¢è¡¥0,è‡³2ä½(æ³¨æ„æ˜¯å¤§å†™çš„W) æ–¹å¼7: ç²¾åº¦å ä½ç¬¦å·(:åé¢ä¸è¦æœ‰ç©ºæ ¼)(è¿™ä¸ªè¾ƒéš¾ç†è§£) æƒ…å†µä¸€ã€:.n ä»£è¡¨åªä¿ç•™å‰nä½ (å¹¶ä¸”å››èˆäº”å…¥)(æ€»ä½“ä½æ•°ä¸ç®—å°æ•°ç‚¹æ‰€åœ¨çš„ä½æ•°) f&quot;{1234.5678:.6}&quot; # .6 è¡¨ç¤ºä¿ç•™6ä½ (ä¸ç®—å°æ•°ç‚¹, æ•´æ•°+å°æ•°=6ä½) #&gt;&gt; '1234.57' æƒ…å†µäºŒã€:m ä»£è¡¨åªåœ¨&quot;æœ€å‰é¢&quot;æ‰©å……&quot;è‡³&quot;mä½(æ³¨æ„è¿™ä¸ª&quot;è‡³&quot;å­—) f&quot;{1234.5678:15}&quot; # æ‰©å……è‡³15ä½(å°æ•°ç‚¹ä¹Ÿç®—ä½æ•°) é»˜è®¤ç”¨ç©ºç™½å­—ç¬¦ä»£æ›¿ #&gt;&gt; ' 1234.5678' æƒ…å†µä¸‰ã€:må‰é¢å¸¦0ï¼Œ è¡¥å……ç©ºå­—ç¬¦ä¸² æ”¹ä¸º &quot;è¡¥0&quot; f&quot;{1234.5678:015}&quot; # 0ä»£è¡¨æ‰©å……çš„å¤šä½™ä½æ•°è¡¥0 (å°æ•°ç‚¹ä¹Ÿç®—ä½æ•°)15ä»£è¡¨æœ€å‰é¢æ‰©å……è‡³15ä½ #&gt;&gt; '0000001234.5678' ç»¼åˆæƒ…å†µã€:m.n ç»“åˆ(åªèƒ½æ˜¯ m.n è¿™ç§é¡ºåºçš„æ ¼å¼) f&quot;{1234.5678:015.6}&quot; # 15å°±æ˜¯ä¸Šé¢è¯´çš„m, 0å°±æ˜¯må‰é¢è¡¥çš„0, 6å°±æ˜¯ä¸Šé¢è¯´çš„n #&gt;&gt; '000000001234.57' # é‡ç‚¹è§£è¯»ä¸Šé¢è¿™ä¸ªç»¼åˆè¯­å¥(æŒ‰ç…§ä¸‹é¢çš„é¡ºåºæ‰èƒ½æ­£ç¡®è§£æ): 1. å…ˆçœ‹.åé¢çš„ n, næ˜¯6, åˆ™ æ•´ä½“(æ•´æ•°+å°æ•°)(ä¸åŒ…æ‹¬å°æ•°ç‚¹)ä¿ç•™6ä½ ===&gt; '1234.57' 2. ç„¶åæ‰çœ‹ m, mæ˜¯15, åˆ™åœ¨æœ€å‰é¢æ‰©å……&quot;è‡³&quot;15ä½ç½®(åŒ…æ‹¬å°æ•°ç‚¹çš„ä½æ•°) ===&gt; ' 1234.57' 3. æœ€åæŠŠç¬¬2æ­¥çš„ç©ºç™½å­—ç¬¦è¡¥0 =====&gt; '000000001234.57' æƒ…å†µå››ã€:m.nf (æ¨è, ä¸Šé¢&quot;æƒ…å†µä¸€&quot; å’Œ &quot;ç»¼åˆæƒ…å†µçš„å»¶ç”³ç‰ˆ&quot;, é’ˆå¯¹.nè®¾è®¡çš„, å¤šäº†ä¸ªf,å¥½ç”¨å¤šäº†!) '''åŠ äº†f, æ ¸å¿ƒå°±æ˜¯ .nè§„åˆ™å˜ä¸º å°æ•°ç‚¹åä¿ç•™nä½,å…¶ä½™æ²¡å˜ ''' eg1: .nfçš„æƒ…å†µ (è¿™ç§æ˜¯æœ€å¸¸ç”¨çš„!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!) f&quot;{1234.5678:.6f}&quot; # å°æ•°ç‚¹åä¿ç•™6ä½, å…¶ä½™è¿˜æ˜¯é‚£æ · #&gt;&gt; '1234.567800' eg2: m.nfçš„æƒ…å†µ f&quot;{1234.5678:015.6f}&quot; # è¿˜æ˜¯å‰é¢&quot;ç»¼åˆæƒ…å†µ&quot;, å…ˆçœ‹n, næ˜¯6, æ‰€ä»¥ &quot;å°æ•°ç‚¹å&quot; ä¿ç•™6ä½(å››èˆäº”å…¥), # ç„¶åä»å‰é¢æ‰©å¼ æ•´ä½“ä½æ•° &quot;è‡³&quot;15ä½, ç©ºç¼ºçš„è¡¥0å³å¯ '00001234.567800' æƒ…å†µäº”: ç™¾åˆ†ä½(ä½œä¸ºè®­ç»ƒacc, ä¹Ÿç®—æ¯”è¾ƒå¸¸ç”¨) &quot;&quot;&quot; åˆ†ææ ¸å¿ƒæ€æƒ³: 1. å…ˆå°†åŸæ•°æ‰©å¤§100å€(ä¹Ÿå°±æ˜¯å°æ•°ç‚¹å‘åç§»2ä½), 2. ç„¶åå…³æ³¨ .n , ä¿ç•™å°æ•°ç‚¹åçš„nä½(å››èˆäº”å…¥) 3. æœ€ååŠ ä¸ªç™¾åˆ†å·%, å³å¯) &quot;&quot;&quot; f&quot;{1234.5678:.1%}&quot; #&gt;&gt; '123456.8%' f&quot;{1234.5678:.6%}&quot; #&gt;&gt; '123456.780000%' # å¦‚æœæƒ³å¸¦m,ä¹Ÿå¯ä»¥,å’Œä¸Šé¢é›†ä¸­æƒ…å†µ,ä»¥åŠè§£æé¡ºåºä¸€æ‘¸ä¸€æ ·,mä¸å¤ªå¸¸ç”¨, æˆ‘è¿™é‡Œå°±ä¸åˆ—äº† ","link":"https://cythonlin.github.io/post/py-greater-py38/"},{"title":"GO => JetBrainså…¨å®¶æ¡¶åˆå§‹åŒ–é»˜è®¤é…ç½®","content":"å£°æ˜ æˆ‘åªç”¨è¿‡ Pycharm å’Œ Golandä¸”æœ‰æ•ˆã€‚ å…¶ä»–åƒ IDEA, WS ç­‰è¡€ç¼˜äº§å“åº”è¯¥åŒæ ·æœ‰æ•ˆ~~~~ã€‚ åŸå›  æ”¹è¯­æ³•æç¤ºç»„åˆé”®ï¼Œæ”¹å´©äº†ã€‚ æ¢å¤é»˜è®¤é…ç½® File -&gt; Manage IDE Settings -&gt; Restore Default Settings æ’æ›² &quot;æ‰¾é…ç½®æ–‡ä»¶,å¹¶åˆ é™¤&quot; if &quot;ä½ ä¸å«Œéº»çƒ¦&quot; else &quot;è€è€å®å®æŒ‰ç…§ä¸Šé¢åš&quot; ","link":"https://cythonlin.github.io/post/go-greater-jetbrains-quan-jia-tong-chu-shi-hua-mo-ren-pei-zhi/"},{"title":"Sublime-Pyæ’ä»¶","content":"Sublime-Pyæ’ä»¶ localizeMenu # æ±‰åŒ–æ’ä»¶ å¸®åŠ©-&gt; languageä¸­å°±èƒ½æ‰¾åˆ° autofilename # æ–‡ä»¶è·¯å¾„æç¤º SublimeCodeIntel # åŸºæœ¬æ ¼å¼è¡¥å…¨ SublimeLinter # ä»£ç pep8æ ¼å¼æ£€æŸ¥ Python PEP8 Autoformat æ’ä»¶ # ctrl + shift + R è‡ªåŠ¨æ ¼å¼åŒ– anaconda # çœŸæ­£çš„ä»£ç è¡¥å…¨ å»é™¤ç™½æ¡†ï¼š Anacondaçš„settingsé‡Œé¢é…ç½® {&quot;anaconda_linting&quot;:false} å³å¯ Vue+Stylusæ’ä»¶ï¼ˆä¹‹å‰ç”¨çš„ï¼‰ Vuejs Snippets Vue Syntax Highlight VueFormatter Vuetify Stylus-Snippets Stylus ","link":"https://cythonlin.github.io/post/sublime-py-cha-jian/"},{"title":"PY => RabbitMQ/Pikaä½¿ç”¨è®°å½•","content":"å®‰è£… https://github.com/docker-library/docs/tree/master/rabbitmq docker run -d --hostname my-rabbit -p 5672:5672 --name some-rabbit rabbitmq:3 æ— äº¤æ¢æœº åŸºæœ¬æœºåˆ¶ï¼šç”Ÿäº§è€… - ç®¡é“ - æ¶ˆæ¯é˜Ÿåˆ— - ç®¡é“ - æ¶ˆè´¹è€… consume.py import pika import time def callback(channel, method, properties, body): time.sleep(1) print(channel, body) channel.basic_ack(delivery_tag=method.delivery_tag) with pika.BlockingConnection(pika.ConnectionParameters(host='39.107.86.223')) as connection: channel = connection.channel() queue_name = 'myqueue' channel.queue_declare( # å£°æ˜é˜Ÿåˆ— queue=queue_name, durable=True, # æŒä¹…åŒ–ï¼Œä½†åªæ˜¯é˜Ÿåˆ—ä¸æ¶ˆå¤±ï¼Œé˜Ÿåˆ—é‡Œé¢çš„æ•°æ®ä¸ä¸€å®šã€‚ durable=Trueé˜Ÿåˆ—æŒä¹…åŒ– exclusive=False, # åªèƒ½ä¸€ä¸ªè¿æ¥ä½¿ç”¨ï¼Œå¹¶ä¸”è¿æ¥åï¼Œé˜Ÿåˆ—é›„å®‰æ˜¯ auto_delete=False, # æ¶ˆè´¹è€…ä¸å†ä½¿ç”¨é˜Ÿåˆ—æ—¶ï¼Œè‡ªåŠ¨åˆ é™¤é˜Ÿåˆ— ) channel.basic_qos(prefetch_count=10) # ä¸€æ¬¡æ€§ å–‚ç»™æ¶ˆè´¹è€…10æ¡ï¼Œæ¶ˆè´¹è€…è‡ªå·±ä¸€ç‚¹ä¸€ç‚¹æ¶ˆè´¹ï¼Œ10æ¡è¿‡åï¼Œå›å¤ç¡®è®¤ channel.basic_consume( queue_name, callback, auto_ack=False # auto_ack è®¾ä¸º False å°±æ„å‘³ç€ï¼Œéœ€è¦æ‰‹åŠ¨å›å¤ç¡®è®¤, éœ€è¦è®¾ç½®callbacké‡Œçš„ channel.basic_ack ï¼ˆé»˜è®¤ä¸ºFalseï¼‰ # æ”¶åˆ°ä¸€æ¡ï¼Œç¡®è®¤åï¼Œå†å‘ä¸‹ä¸€æ¡ï¼Œ è‹¥ä¸­æ–­ï¼Œåˆ™ ä¾ç„¶ä» ackæ ‡è¯†å¤„ï¼Œç»­ä¼  # auto_ack è®¾ä¸º True å°±æ„å‘³ç€ï¼Œ ç³»ç»Ÿå¸®åŠ©æ¶ˆè´¹è€…è‡ªåŠ¨å›å¤ç¡®è®¤ï¼Œå³ï¼ˆè‡ªåŠ¨æ¸…ç©º é˜Ÿåˆ—ä¸­ ç”Ÿäº§è€…çš„æ•°æ®ï¼‰ ) channel.start_consuming() product.py import pika with pika.BlockingConnection(pika.ConnectionParameters(host='39.107.86.223',port=5672)) as connection: channel = connection.channel() queue_name = 'myqueue' channel.queue_declare( queue=queue_name, durable=True, # æŒä¹…åŒ–ï¼Œä½†åªæ˜¯é˜Ÿåˆ—ä¸æ¶ˆå¤±ï¼Œé˜Ÿåˆ—é‡Œé¢çš„æ•°æ®ä¸ä¸€å®šã€‚ durable=Trueé˜Ÿåˆ—æŒä¹…åŒ– exclusive=False, # åªèƒ½ä¸€ä¸ªè¿æ¥ä½¿ç”¨ï¼Œå¹¶ä¸”è¿æ¥åï¼Œé˜Ÿåˆ—é›„å®‰æ˜¯ auto_delete=False, # æ¶ˆè´¹è€…ä¸å†ä½¿ç”¨é˜Ÿåˆ—æ—¶ï¼Œè‡ªåŠ¨åˆ é™¤é˜Ÿåˆ— ) for x in range(50): channel.basic_publish( exchange='', routing_key=queue_name, body=str(x), properties=pika.BasicProperties( delivery_mode=2 # è®¾ä¸º2è¡¨ç¤ºï¼Œé˜Ÿåˆ—é‡Œé¢çš„ æ¶ˆæ¯ çš„ æŒä¹…åŒ– ) ) æœ‰äº¤æ¢æœº åŸºæœ¬æœºåˆ¶ï¼šç”Ÿäº§è€… - ç®¡é“ - routing_key - äº¤æ¢æœº - binding_key - æ¶ˆæ¯é˜Ÿåˆ— - ç®¡é“ - æ¶ˆè´¹è€… ç”Ÿäº§è€…ä¸ç”¨è¿æ¥é˜Ÿåˆ—ï¼Œå› ä¸ºè¢«äº¤æ¢æœºè¿æ¥ã€‚ æ¶ˆè´¹è€…å¿…é¡»è¿æ¥é˜Ÿåˆ—ã€‚ ç›´è¿äº¤æ¢æœº (direct - routing_keyå’Œ binding_keyä¸¥æ ¼åŒ¹é…) æ³¨æ„æƒ…å†µï¼Œè‹¥binding_key å¯¹åº”çš„é˜Ÿåˆ—æ˜¯ä¸´æ—¶é˜Ÿåˆ—ï¼Œ é‚£ä¹ˆ éœ€è¦å…ˆå¯åŠ¨æ¶ˆè´¹è€…ï¼Œå†å¯åŠ¨ç”Ÿäº§è€… å¦‚æœå…ˆå¯åŠ¨çš„æ˜¯ç”Ÿäº§è€…ï¼Œé‚£ä¹ˆå‘å‡ºåˆ°äº¤æ¢æœºçš„æ•°æ® æ‰¾ä¸åˆ°åŒ¹é…çš„æ¶ˆè´¹è€…ï¼Œ é‚£ä¹ˆæ•°æ®å°±ä¼šä¸¢å¤±ï¼Œå› ä¸ºäº¤æ¢æœºæ˜¯ä¸´æ—¶çš„ consume.py import pika import time def callback(channel, method, properties, body): time.sleep(1) print(body) channel.basic_ack(delivery_tag=method.delivery_tag) with pika.BlockingConnection(pika.ConnectionParameters(host='39.107.86.223')) as connection: channel = connection.channel() exchange_name = 'direct' channel.exchange_declare( exchange_name, exchange_type='direct', durable=True, # æŒä¹…åŒ–ï¼Œä½†åªæ˜¯é˜Ÿåˆ—ä¸æ¶ˆå¤±ï¼Œé˜Ÿåˆ—é‡Œé¢çš„æ•°æ®ä¸ä¸€å®šã€‚ durable=Trueé˜Ÿåˆ—æŒä¹…åŒ– ) queue_name = 'queue' channel.queue_declare(queue_name,exclusive=True) # exclusive ä»£è¡¨å½“å‰è¿æ¥ç‹¬äº«é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—éšç€è¿æ¥æ¶ˆå¤± binding_keys = ['debug', 'info', 'warning'] # productçš„routing_keyè¦åŒ…å«åœ¨è¿™é‡Œé¢ for binding_key in binding_keys: channel.queue_bind( queue_name, # å³è¿é˜Ÿåˆ— exchange_name, # å·¦è¿äº¤æ¢æœº routing_key=binding_key ) channel.basic_qos(prefetch_count=10) # ä¸€æ¬¡æ€§ å–‚ç»™æ¶ˆè´¹è€…10æ¡ï¼Œæ¶ˆè´¹è€…è‡ªå·±ä¸€ç‚¹ä¸€ç‚¹æ¶ˆè´¹ï¼Œ10æ¡è¿‡åï¼Œå›å¤ç¡®è®¤ channel.basic_consume( queue_name, callback, auto_ack=False # auto_ack è®¾ä¸º False å°±æ„å‘³ç€ï¼Œéœ€è¦æ‰‹åŠ¨å›å¤ç¡®è®¤, éœ€è¦è®¾ç½®callbacké‡Œçš„ channel.basic_ack ï¼ˆé»˜è®¤ä¸ºFalseï¼‰ # æ”¶åˆ°ä¸€æ¡ï¼Œç¡®è®¤åï¼Œå†å‘ä¸‹ä¸€æ¡ï¼Œ è‹¥ä¸­æ–­ï¼Œåˆ™ ä¾ç„¶ä» ackæ ‡è¯†å¤„ï¼Œç»­ä¼  # auto_ack è®¾ä¸º True å°±æ„å‘³ç€ï¼Œ ç³»ç»Ÿå¸®åŠ©æ¶ˆè´¹è€…è‡ªåŠ¨å›å¤ç¡®è®¤ï¼Œå³ï¼ˆè‡ªåŠ¨æ¸…ç©º é˜Ÿåˆ—ä¸­ ç”Ÿäº§è€…çš„æ•°æ®ï¼‰ ) channel.start_consuming() product.py import pika with pika.BlockingConnection(pika.ConnectionParameters(host='39.107.86.223',port=5672)) as connection: channel = connection.channel() exchange_name = 'direct' channel.exchange_declare( exchange_name, exchange_type='direct', durable=True, # æŒä¹…åŒ–ï¼Œä½†åªæ˜¯é˜Ÿåˆ—ä¸æ¶ˆå¤±ï¼Œé˜Ÿåˆ—é‡Œé¢çš„æ•°æ®ä¸ä¸€å®šã€‚ durable=Trueé˜Ÿåˆ—æŒä¹…åŒ– ) routing_key = 'debug' for x in range(50): channel.basic_publish( exchange=exchange_name, routing_key=routing_key, body=str(x) ) ä¸»é¢˜äº¤æ¢æœº (topic - routing_keyå’Œ binding_keyæ¨¡ç³ŠåŒ¹é…) åŸºæœ¬æœºåˆ¶ï¼š å’Œç›´è¿åŸºæœ¬ä¸€æ ·ï¼Œtopic - routing_keyå’Œ binding_key æ¨¡ç³ŠåŒ¹é…æˆåŠŸåï¼Œæ‰èƒ½æ­£ç¡®é€šä¿¡ ä»£ç éƒ¨åˆ†ï¼Œåªä¿®æ”¹ exchange_name = 'topic' exchange_type = 'direct' å…¶ä»–åŸºæœ¬ä¸€è‡´ï¼Œ binding_key æ”¹ä¸ºæ¨¡ç³Šè¯­æ³•å³å¯ è¯­æ³•æ ¼å¼ï¼š * åŒ¹é…ä¸€ä¸ªä»£è¯ # åŒ¹é… 0ä¸ªæˆ–å¤šä¸ªå•è¯ eg: a.b å¯å¯¹åº”ä¸º a.* a.b.c å¯å¯¹åº”ä¸º a.# æ‰‡å½¢äº¤æ¢æœº (fanout -- å¹¿æ’­æœºåˆ¶) åŸºæœ¬æœºåˆ¶ï¼šå¼€å¯å¤šä¸ª æ¶ˆè´¹è€…ç­‰å¾…ï¼Œ ç„¶åå¼€å¯ä¸€ä¸ªç”Ÿäº§è€…ï¼Œæ‰€æœ‰é˜Ÿåˆ—éƒ½ä¼šå¼€å§‹æ¶ˆè´¹ ç®€å•æ¥è¯´ï¼Œå°±æ˜¯ ä¸€ä¸ªæä¾›æ•°æ®ï¼Œ å¤šä¸ªé˜Ÿåˆ—æ¶ˆè´¹æ­¤æ•°æ® èµ„æºä»å“ªé‡Œå¼€å§‹åˆ†é…ï¼Œå–å†³äº channel.basic_qos(prefetch_count=10) çš„è®¾ç½® ä¸ä¾èµ– routing_key å’Œ binding_keyã€‚ å°† exchange_type æ”¹ä¸º fanout consume.py import pika import time def callback(channel, method, properties, body): time.sleep(1) print(body) channel.basic_ack(delivery_tag=method.delivery_tag) def main(): with pika.BlockingConnection(pika.ConnectionParameters(host='39.107.86.223')) as connection: channel = connection.channel() exchange_name = 'fanout' channel.exchange_declare( exchange_name, # exchange_type='direct', exchange_type='fanout', durable=True, # æŒä¹…åŒ–ï¼Œä½†åªæ˜¯é˜Ÿåˆ—ä¸æ¶ˆå¤±ï¼Œé˜Ÿåˆ—é‡Œé¢çš„æ•°æ®ä¸ä¸€å®šã€‚ durable=Trueé˜Ÿåˆ—æŒä¹…åŒ– ) queue_name = 'queue' channel.queue_declare(queue_name) # exclusive ä»£è¡¨å½“å‰è¿æ¥ç‹¬äº«é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—éšç€è¿æ¥æ¶ˆå¤± channel.queue_bind( queue_name, # å³è¿é˜Ÿåˆ— exchange_name, # å·¦è¿äº¤æ¢æœº, æ³¨æ„ï¼Œå› ä¸ºä¸ä¾èµ– routing_key å’Œ binding_key ï¼Œæ‰€ä»¥ä¸ç”¨å†™routing_keyå‚æ•° ) channel.basic_qos(prefetch_count=10) # ä¸€æ¬¡æ€§ å–‚ç»™æ¶ˆè´¹è€…10æ¡ï¼Œæ¶ˆè´¹è€…è‡ªå·±ä¸€ç‚¹ä¸€ç‚¹æ¶ˆè´¹ï¼Œ10æ¡è¿‡åï¼Œå›å¤ç¡®è®¤ channel.basic_consume( queue_name, callback, auto_ack=False # auto_ack è®¾ä¸º False å°±æ„å‘³ç€ï¼Œéœ€è¦æ‰‹åŠ¨å›å¤ç¡®è®¤, éœ€è¦è®¾ç½®callbacké‡Œçš„ channel.basic_ack ï¼ˆé»˜è®¤ä¸ºFalseï¼‰ # æ”¶åˆ°ä¸€æ¡ï¼Œç¡®è®¤åï¼Œå†å‘ä¸‹ä¸€æ¡ï¼Œ è‹¥ä¸­æ–­ï¼Œåˆ™ ä¾ç„¶ä» ackæ ‡è¯†å¤„ï¼Œç»­ä¼  # auto_ack è®¾ä¸º True å°±æ„å‘³ç€ï¼Œ ç³»ç»Ÿå¸®åŠ©æ¶ˆè´¹è€…è‡ªåŠ¨å›å¤ç¡®è®¤ï¼Œå³ï¼ˆè‡ªåŠ¨æ¸…ç©º é˜Ÿåˆ—ä¸­ ç”Ÿäº§è€…çš„æ•°æ®ï¼‰ ) channel.start_consuming() main() product.py import pika def main(): with pika.BlockingConnection(pika.ConnectionParameters(host='39.107.86.223',port=5672)) as connection: channel = connection.channel() exchange_name = 'fanout' channel.exchange_declare( exchange_name, exchange_type='fanout', durable=True, # æŒä¹…åŒ–ï¼Œä½†åªæ˜¯é˜Ÿåˆ—ä¸æ¶ˆå¤±ï¼Œé˜Ÿåˆ—é‡Œé¢çš„æ•°æ®ä¸ä¸€å®šã€‚ durable=Trueé˜Ÿåˆ—æŒä¹…åŒ– ) for x in range(50): channel.basic_publish( exchange=exchange_name, routing_key='', body=str(x) ) main() ","link":"https://cythonlin.github.io/post/py-greater-rabbitmqpika-shi-yong-ji-lu/"},{"title":"PY => Gitå¸¸ç”¨å‘½ä»¤/ç»„åˆå¥—è·¯","content":"å…¨éƒ¨é…ç½®ä¸ªäººä¿¡æ¯ï¼ˆæœ¬æœºæ‰€æœ‰ä»“åº“ï¼‰ git config --global user.name &quot;ç”¨æˆ·å &quot; git config --global user.email &quot;é‚®ç®±&quot; æŸ¥çœ‹ä¸ªäººä¿¡æ¯ git config --list ç”ŸæˆSSHå¯†é’¥ ssh-keygen pub_key - &gt; github æ–°å»ºä»“åº“åŸºæ“äº”éƒ¨æ›² git init git add xxxï¼ˆæ·»åŠ åˆ°ç¼“å­˜åŒºï¼‰ &lt;===äº’é€†===&gt; git reset HEAD ï¼ˆä»ç¼“å­˜åŒºæ‹¿å›æ¥ï¼‰ git commit -m 'æè¿°ä¿¡æ¯' git remote add origin git@github.com:hacker-lin/test.git # ä½ çš„github ä»“åº“å…‹éš†åœ°å€ git push -u origin master å¼€å‘åˆ†æ”¯æ“ä½œNéƒ¨æ›² å‡å¦‚çº¿ä¸Šæœ‰é¡¹ç›®ï¼Œä½ æœ¬åœ° æ²¡æœ‰ ä»“åº“ï¼Œé‚£ä¹ˆä½ å°±é¦–å…ˆéœ€è¦ï¼š git clone xxx # ç¬¬ä¸€æ¬¡ cd ç›®å½• git checkout -b new_bug # åˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯ echo new_bug&gt;new_bug git add . git commit -m 'new_bug' git push -u origin new_bug # è¿æ¥å åˆ†æ”¯å å¯é€šè¿‡ï¼ˆgit remoteï¼Œ git branchï¼‰æŸ¥çœ‹ # è¿™æ­¥çš„ç›®çš„æ˜¯ï¼Œè‡ªå·±çš„åˆ†æ”¯å†™å®Œä¹Ÿè¦pushä¿å­˜ä¸€ä¸‹ï¼Œé˜²æ­¢ä¸¢å¤± git checkout master # å›åˆ°ä¸»åˆ†æ”¯ git merge new_bug # æŠŠ new_bugåˆ†æ”¯åˆå¹¶åˆ° master åˆ†æ”¯ git push # å°†åˆå¹¶å®Œäº‹çš„masteré‡æ–°æ¨ä¸Šå» ï¼ˆè¿™æ ·å°±å®Œäº‹ä¸€æ¬¡äº§å“çš„è¿­ä»£ï¼‰ å‡å¦‚çº¿ä¸Šæœ‰é¡¹ç›®ï¼Œä½ æœ¬åœ°ä¹Ÿæœ‰ä»“åº“ï¼Œé‚£ä¹ˆä½ å°±ä¸éœ€è¦git cloneäº† ä½ åªéœ€è¦ git pull git pull # pullç­‰ä»·äº fetch + merge git checkout -b new_bug01 echo new_bug01 &gt; new_bug01 git add . git commit -m 'new_bug01' git push -u origin new_bug01 # è¿™æ­¥çš„ç›®çš„æ˜¯ï¼Œè‡ªå·±çš„åˆ†æ”¯å†™å®Œä¹Ÿè¦pushä¿å­˜ä¸€ä¸‹ï¼Œé˜²æ­¢ä¸¢å¤± git checkout master # åˆ‡æ¢åˆ°master git merge new_bug01 # æŠŠ new_bug01åˆ†æ”¯åˆå¹¶è¿›æ¥ï¼ˆåˆå¹¶åˆ°masterï¼‰ git push # å°†åˆå¹¶å®Œäº‹çš„masteré‡æ–°æ¨ä¸Šå» ï¼ˆè¿™æ ·å°±å®Œæˆåˆä¸€æ¬¡äº§å“çš„è¿­ä»£ï¼‰ åŒºåŸŸä¿¡æ¯ git status # æœªè¢«git addçš„-ï¼ˆçº¢è‰²ï¼‰ # å·²ç»git addçš„-ï¼ˆç»¿è‰²ï¼‰ # å·²ç» git commitçš„-ï¼ˆæ— ä¿¡æ¯ï¼‰ git log # æŸ¥çœ‹ç‰ˆæœ¬commitå†å²ä¿¡æ¯ åˆ†æ”¯ä¿¡æ¯ git branch è¿œç¨‹è¿æ¥ä¿¡æ¯ git remote åˆ é™¤æœ¬åœ° rm xxxxx git rm xxxxx git commit -m 'æè¿°' ","link":"https://cythonlin.github.io/post/py-greater-git-chang-yong-ming-ling-zu-he-tao-lu/"},{"title":"PY => Anaconda-Jupyterç›¸å…³é…ç½®","content":"Condaè™šæ‹Ÿç¯å¢ƒå‘½ä»¤ æŸ¥çœ‹æ‰€æœ‰è™šæ‹Ÿç¯å¢ƒï¼ˆ2ç§ï¼Œç»“æœä¸€æ‘¸ä¸€æ ·ï¼‰ conda info --e æˆ– conda env list åˆ›å»º conda create -n rs python=3.8.5 æ¿€æ´»ï¼š conda activate rs é€€å‡ºï¼š conda deactivate åˆ é™¤è™šæ‹Ÿç¯å¢ƒï¼š conda remove -n rs --all æŸ¥çœ‹å½“å‰è™šæ‹Ÿç¯å¢ƒæ‰€å®‰è£…çš„åŒ… conda list æœç´¢æŸåŒ…çš„ä¿¡æ¯ï¼ˆåŒ…æ‹¬channelï¼‰ conda search requests å‡çº§å½“å‰conda conda update conda æŸ¥çœ‹é•œåƒ conda config --show channels æ›´æ”¹é•œåƒ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes åˆ é™¤é•œåƒ conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ æ›´æ–° æŸç¯å¢ƒçš„ æŸä¸ªåŒ… conda update -n rs requests åˆ é™¤ æŸç¯å¢ƒ çš„ æŸä¸ªåŒ… conda remove -n rs requests ç”ŸæˆJupyteré…ç½®æ–‡ä»¶ jupyter notebook --generate-config è¿™æ¡å‘½ä»¤è¿‡åï¼Œä¼šæç¤ºä½  xxxè·¯å¾„ä¸‹ï¼Œåˆ›å»ºäº†ä¸€ä¸ªxxxé…ç½®æ–‡ä»¶ï¼Œè®°ä¸‹æ¥ã€‚ æ›´æ¢JupyteråŸºç›®å½• æ‰“å¼€ä¸Šé¢çš„é…ç½®æ–‡ä»¶ï¼ˆwindowsç”¨Sublimeæˆ–æ™®é€šçš„notebookï¼‰ï¼ˆlinuxç”¨vimå³å¯ï¼‰ æœç´¢å…³é”®è¯ c.NotebookApp.notebook_dir # æŠŠåé¢å­—ç¬¦ä¸²è®¾æˆä½ çš„è·¯å¾„å³å¯ ä¿å­˜é€€å‡ºï¼Œé‡æ–°æ‰“å¼€ Jupyterã€‚ è°ƒé«˜Jupyterçš„IOé¢‘ç‡ï¼ˆè‹¥ä¸è°ƒ å¯èƒ½ä¼šè¶Šç•Œï¼‰ æ‰“å¼€ä¸Šé¢çš„é…ç½®æ–‡ä»¶ï¼ˆwindowsç”¨Sublimeæˆ–æ™®é€šçš„notebookï¼‰ï¼ˆlinuxç”¨vimå³å¯ï¼‰ æœç´¢å…³é”®è¯ c.NotebookApp.iopub_data_rate_limit # æŠŠåé¢çš„æ•°å­—è°ƒå¤§ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰ ä¿å­˜é€€å‡ºï¼Œé‡æ–°æ‰“å¼€ Jupyterã€‚ ä¿®æ”¹Jupyterä¸»é¢˜æ ·å¼ å®‰è£… pip install jupyterthemes ï¼ˆAnaconda-prompt çš„pipï¼‰ åˆ—å‡ºæ‰€æœ‰æ ·å¼åç§° jt -l ä¿®æ”¹æ ·å¼ jt -t monokai å¦‚æœæ„Ÿè§‰éƒ½ä¸å¥½çœ‹ï¼Œå¯æ¢å¤(ä½¿ç”¨å®Œè®°å¾—é‡å¯jupyter)ï¼š jt -r åˆ«äººæ¨èçš„æ ·å¼ï¼ˆä¸»é¢˜+å­—ä½“+ç•Œé¢å®½åº¦ä¸€æ°”å‘µæˆï¼‰ï¼š jt -t chesterish -f fira -fs 13 -nf ptsans -nfs 11 -N -kl -cursw 5 -cursc r -cellw 95% -T å®˜æ–¹æ ·å¼è¯´æ˜ï¼š https://github.com/dunovank/jupyter-themes æˆ–è€…è¿™ç¯‡æ•™ç¨‹ï¼š https://towardsdatascience.com/bringing-the-best-out-of-jupyter-notebooks-for-data-science-f0871519ca29 ipykernel å¤šä¸ªè™šæ‹Ÿç¯å¢ƒå…±ç”¨ä¸€ä¸ªä¸»ä½“jupyter åˆ›å»ºæ–°çš„ipynbæ—¶ä¹Ÿå¯ä»¥é€‰æ‹©ç”¨å“ªä¸ªè™šæ‹Ÿç¯å¢ƒçš„jupyter kernel å®‰è£… ipykernel pip install ipykernel å°†è™šæ‹Ÿç¯å¢ƒæ·»åŠ åˆ°jupyterä¸­ python -m ipykernel install --name=torch ç»“æœä¼šç”Ÿæˆä¸€ä¸ªæ–‡ä»¶: /home/user/.local/share/jupyter/kernels/myenv/kernel.json åœ¨æ€»jupyteråˆ—å‡ºæ‰€æœ‰è™šæ‹Ÿç¯å¢ƒ jupyter kernelspec list ä»jupyterä¸­ç§»é™¤æŸè™šæ‹Ÿç¯å¢ƒ jupyter kernelspec uninstall torch Jupyterå…¨å±ç¼–è¾‘ è¿™ä¸ªæˆ‘ä¹‹å‰æŸ¥è¿‡ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶çš„éƒ½ä¸å¥½ç”¨ ï¼ˆä¸Šé¢æ”¹ä¸»é¢˜çš„æ—¶å€™å¯ä»¥è¯¥å®½åº¦ï¼Œä½†è²Œä¼¼å¿…é¡»ä¿®æ”¹ä¸»é¢˜ï¼Œæ‰èƒ½ä¿®æ”¹ç•Œé¢å®½åº¦ï¼Œå¦åˆ™ä¸å¯ä»¥ï¼‰ åªåœ¨StackOverflowä¸Šæ‰¾åˆ°äº†ä¸€ç§ç®€é™‹çš„è§£å†³åŠæ³• æ¯ä¸ªipynbæ–‡ä»¶å¤´éƒ¨åŠ ä¸Šå›ºå®šçš„2æ¡è¯­å¥å³å¯ï¼š from IPython.core.display import display, HTML display(HTML(&quot;.container { width:100% !important; }&quot;)) æœ‰è¶£çš„æ‰©å±•ï¼ˆä¸æ˜¯å¾ˆå®ç”¨ï¼‰ å†…åµŒdataframeè¡¨æ ¼æ“ä½œ: ï¼ˆç©ç©å¯ä»¥ï¼Œæ…ç”¨ï¼Œ å°å‹æ•°æ®å°±æ’‘ä¸ä½äº†ï¼Œå¯¼è‡´æ•´ä¸ªkernelå´©æºƒï¼‰ å®‰è£…ï¼š pip install qgrid jupyter nbextension enable --py --sys-prefix qgrid å¯¼å…¥ï¼š from qgrid import show_grid as s ä½¿ç”¨æ¡ˆä¾‹ï¼š df = pd.DataFrame([['bac', 'bcd'],['åº”ç”¨','åšå®¢']]) s(df, show_toolbar=True) ç»“æœå¦‚ä¸‹: ç¬”è®°æ— æ³•æ’å…¥æœ¬åœ°å›¾ç‰‡ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚å¾ˆæ˜“æ‡‚çš„ç»“æœã€‚ å†…åµŒå°æµè§ˆå™¨ï¼š from IPython.display import IFrame IFrame('https://www.baidu.com/s?ie=UTF-8&amp;wd=fsd', width=1200, height=1000) Condaå„ç§ç–‘éš¾æ‚ç—‡å®‰è£… æ‰€æœ‰åŒ…å‡ ä¹éƒ½å¯ä»¥ç”¨ Anaconda-prompt ä¸­çš„ pipï¼Œè¿™ç§ å®‰è£…æ–¹æ³•æ˜¯&quot;ä¸‹ä¸‹ç­–&quot;ã€‚ å› ä¸ºæœ‰æ—¶ç”¨è¿™ä¸ªè£…å¯èƒ½å‡ºé—®é¢˜ã€‚ Opencv conda: conda install -c menpo opencv pip: pip install opencv-python ","link":"https://cythonlin.github.io/post/py-greater-anaconda-jupyter-xiang-guan-pei-zhi/"},{"title":"PY => è¶…çº§é¹°æ‰“ç ï¼ˆPythonï¼‰+æŠ¥é”™å›æ‰£","content":"ç»†å¾®å¦‚ä¸‹æ”¹åŠ¨ å…¼å®¹Python3 1å…ƒåŒ…è°ƒè¯•è¯•ç”¨ï¼ˆ8001ï¼‰ 4-6ä½ è‹±æ–‡+æ•°å­—éªŒè¯ç  æ‰“ç ä¸é¢„æœŸç»“æœä¸ç¬¦ï¼Œè°ƒç”¨æŠ¥é”™æç¤ºï¼Œå°†å›¾ç‰‡IDä¼ å›ï¼Œå¯å°†å¤±è¯¯æ¬¡æ•°è¿”å› ä»£ç å¯¹ç…§è¡¨å¦‚ä¸‹ https://www.chaojiying.com/price.html è„šæœ¬ä»£ç å¦‚ä¸‹ import requests from hashlib import md5 class Chaojiying_Client(object): def __init__(self, username, password, soft_id): self.username = username password = password.encode('utf8') self.password = md5(password).hexdigest() self.soft_id = soft_id self.base_params = { 'user': self.username, 'pass2': self.password, 'softid': self.soft_id, } self.headers = { 'Connection': 'Keep-Alive', 'User-Agent': 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)', } def PostPic(self, im, codetype): &quot;&quot;&quot; im: å›¾ç‰‡å­—èŠ‚ codetype: é¢˜ç›®ç±»å‹ å‚è€ƒ http://www.chaojiying.com/price.html &quot;&quot;&quot; params = { 'codetype': codetype, } params.update(self.base_params) files = {'userfile': ('ccc.jpg', im)} r = requests.post('http://upload.chaojiying.net/Upload/Processing.php', data=params, files=files, headers=self.headers) return r.json() def ReportError(self, im_id): &quot;&quot;&quot; im_id:æŠ¥é”™é¢˜ç›®çš„å›¾ç‰‡ID &quot;&quot;&quot; params = { 'id': im_id, } params.update(self.base_params) r = requests.post('http://upload.chaojiying.net/Upload/ReportError.php', data=params, headers=self.headers) return r.json() if __name__ == '__main__': chaojiying = Chaojiying_Client('ä½ çš„ç”¨æˆ·å', 'ä½ çš„å¯†ç ', 'è½¯ä»¶ID') # è¿›å…¥ä¸»é¡µ-&gt;è½¯ä»¶ID -&gt; ç”Ÿæˆä¸€ä¸ªè½¯ä»¶IDï¼ˆä¸Šé¢å°å­—ï¼‰ im = open('a.jpg', 'rb').read() result = chaojiying.PostPic(im, 8001) print(result) if result['pic_str'] != 'n1wtu': print(chaojiying.ReportError(result['pic_id'])) ","link":"https://cythonlin.github.io/post/py-greater-chao-ji-ying-da-ma-pythonbao-cuo-hui-kou/"},{"title":"PY => import_module å’Œ __import__ åŒºåˆ«","content":"é—®é¢˜å¼•å…¥åŸå›  ä»Šå¤©ç”¨åå°„å†™é…ç½®æ—¶ï¼Œå‘ç° import() ä¸èƒ½å°†å¤šçº§æ¨¡å—å¯¼å…¥ï¼Œè€Œimport_moduleå¯ä»¥ æ¡ˆä¾‹ä¸€ (æˆ‘æœ€å¼€å§‹æ¥è§¦å°±æ˜¯è¿™ä¹ˆæµ‹è¯•ç”¨æ³•çš„ã€‚ã€‚) _import_ random = __import__('random') random.randint() # æ­£å¸¸è¿è¡Œ import_module from importlib import import_module random = import_module('random') random.randint() # æ­£å¸¸è¿è¡Œ æ¡ˆä¾‹äºŒ _import_ parse = __import__('urllib.parse') parse.urlencode('a=1') # æŠ¥é”™ï¼šmodule 'urllib' has no attribute 'urlencode' import_module from importlib import import_module parse = import_module('urllib.parse') parse.urlencode({'a':1}) # æ­£å¸¸è¿è¡Œ åˆ†æ 1. é€šè¿‡å¯¼å…¥çš„ from importlib import _import_ å’Œ å†…å»ºå‡½æ•° _import_ æˆ‘éƒ½è¯•è¿‡ï¼Œä»–ä¿©çš„ä½œç”¨æ˜¯ä¸€æ ·çš„ 2. _import_() å‚æ•°åªèƒ½å†™ä¸€ä¸ªå•è¯æ¨¡å—ï¼Œ å¦‚æœå†™æˆå½¢å¦‚ aa.bb.ccï¼Œ å®ƒåªä¼šå¯¼å…¥ aa 2. import_module() å®ƒçš„ç”¨æ³•å°±å¾ˆåˆäººæ„äº†ã€‚ é‡Œé¢å†™å•¥ä»–å°±ä¼šåƒ import ä¸€æ ·éƒ½å¯¼å…¥è¿›æ¥ ","link":"https://cythonlin.github.io/post/py-greater-import_module-he-__import__-qu-bie/"},{"title":"PY => Celeryä½¿ç”¨è®°å½•","content":"å‰ç½®ç¯å¢ƒ pip install redis pip install gevent config.py broker_url = 'redis://ip/0' result_backend = 'redis://ip/1' # tasksè¿”å›ç»“æœå­˜å‚¨åœ°å€ result_expires = 10 * 60 # è¿‡æœŸæ—¶é—´ imports = ('tasks') tasks.py import requests from celery import Celery app = Celery() app.config_from_object('config') @app.task(ignore_result=False) def crawl(url): response = requests.get(url) return {'data': response.text} # è¿”å›å¹¶å‚¨å­˜çš„ç»“æœ spider.py import tasks def main(url_list): for per_url in url_list: tasks.crawl.delay(per_url) if __name__ == '__main__': main( ['http://www.baidu.com','http://www.douyu.com/'] ) worker.py import os os.system('celery worker -A tasks -l info -P gevent') # -A tasks å³ä¸º tasks.pyå¯¹åº”æ¨¡å— # -P gevent å³ä¸ºå¼‚æ­¥æŒ‡å®šç¯å¢ƒä¸º gevent ä½¿ç”¨ å…ˆæ‰§è¡Œ spider.py å°†ä»»åŠ¡å­˜å…¥åˆ°redisé˜Ÿåˆ—ä¸­ï¼Œ ç„¶åæ‰§è¡Œ worker.pyï¼Œæ­£å¼å¯åŠ¨ä»»åŠ¡ æ€»ç»“ celery å¤§ä½“åˆ†ä¸º 3ç§ æ¨¡å— task ï¼š ä¸“é—¨å®šä¹‰å‡½æ•°ï¼Œç”¨è£…é¥°å™¨è£…é¥°ä½œä¸ºä¸€ä¸ªä»»åŠ¡ï¼ˆç±»ä¼¼äºflaskçš„è§†å›¾ï¼‰ brokerï¼š ä¸­é—´äººé˜Ÿåˆ—ï¼Œå­˜å‚¨ä»»åŠ¡ ï¼ˆä¾‹å¦‚ rabbitmq, redisç­‰ï¼‰ workerï¼š ä»brokeré˜Ÿåˆ—æ‹¿å‡ºä»»åŠ¡æ¥ æ­£å¼è¿è¡Œ ï¼ˆå¯å¤šä¸ªï¼‰ ç›¸å…³é…ç½®å‚æ•°å‚è€ƒåœ°å€ https://www.cnblogs.com/cwp-bg/p/8759638.html ","link":"https://cythonlin.github.io/post/py-greater-celery-shi-yong-ji-lu/"},{"title":"PY => è‡ªç¼–é­”æ³•é¬¼å¥","content":"é¬¼å¥1ï¼š æˆ‘ = type('A',(), {'__eq__': lambda _,__: 'True' if _ is not __ else 'False', '__ne__': lambda _,__: 'True' if _ is __ else 'False'})() ä½  = type('ä½ ') print(æˆ‘ == æˆ‘) print(æˆ‘ != æˆ‘) print(æˆ‘ == ä½ ) print(æˆ‘ != ä½ ) é¬¼å¥2ï¼šæ•°åˆ— import math æ•°åˆ— = type('æ•°åˆ—', (), {'__getitem__': lambda self,_: list(range(_[0], _[4]+1, _[1]-_[0])) if _[1]-_[0]==_[2]-_[1] else (lambda a1,e: [a1 * e**(_) for _ in range(0,int(math.log(_[4]/a1, e))+1)])(_[0],_[1]/_[0])})() print(æ•°åˆ—[1,3,9,...,729]) print(æ•°åˆ—[1,3,5,...,21]) ","link":"https://cythonlin.github.io/post/py-greater-zi-bian-mo-fa-gui-ju/"},{"title":"PY => CentOSå·æ‡’å®‰è£…Python3.7.4","content":"ä¾èµ–ï¼š yum install gcc make zlib zlib-devel openssl openssl-devel libffi-devel bzip2-devel ncurses-devel gdbm-devel readline-devel xz-devel sqlite-devel tk-devel -y ä¸‹è½½åŒ…ï¼ˆå¤ªæ…¢ï¼Œä¸€èˆ¬æˆ‘é€‰æ‹©æ‰‹åŠ¨ï¼Œç„¶åxftpä¸Šä¼ ï¼‰ wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz è§£å‹ tar -zxvf Python-3.7.4.tgz &amp;&amp; cd Python-3.7.4/ æŒ‡å®šå®‰è£…ç¯å¢ƒï¼š ./configure prefix=/usr/local/python3 ç¼–è¯‘+å®‰è£…ï¼š make &amp;&amp; make install åˆ é™¤åŸæœ‰è½¯è¿æ¥ï¼ˆpythonåŸæ¥é“¾çš„æ˜¯python2çš„ï¼Œæˆ‘åŸºæœ¬ä¸ç”¨python2ï¼Œæ‰€ä»¥åˆ äº†ï¼‰ rm -rf /usr/bin/python &amp;&amp; rm -rf /usr/bin/pip æ·»åŠ è½¯è¿æ¥ï¼ˆè¿™å°±æ˜¯æˆ‘ä»¬python3çš„è½¯è¿æ¥ï¼‰ ln -s /usr/local/python3/bin/python3 /usr/bin/python &amp;&amp; ln -s /usr/local/python3/bin/pip3 /usr/bin/pip (å¯é€‰)è‹¥è½¯è¿æ¥ä¸å¥½ä½¿ã€‚å¯ä»¥ä½¿ç”¨ alias: vi /etc/profile: alias pip=/usr/local/python3/bin/pip3 alias python=/usr/local/python3/bin/python3 source /etc/profile ","link":"https://cythonlin.github.io/post/py-greater-centos-tou-lan-an-zhuang-python374/"},{"title":"PY => Modin(Ray)åŠ é€ŸPandaså¤§ç†ŠçŒ«","content":"å‰è¨€ ç”¨è¿‡Pandasçš„éƒ½çŸ¥é“ï¼Œæ•°æ®å¤§äº†åï¼Œå¤„ç†å¾ˆæ…¢ã€‚so, modinåœ¨PandasåŸºç¡€ä¸Šå°è£…ä¸€å±‚é€æ˜å£³ã€‚ å¹¶ä¸”ä¾èµ–rayèƒ½å®ç°å¤šè¿›ç¨‹pandasæ“ä½œã€‚ ç‰¹è‰²ï¼šä¸€è¡Œä»£ç å®ç°PandasåŠ é€Ÿã€‚ã€‚ã€‚ å®‰è£…ä¾èµ–ç¯å¢ƒ åŸç”Ÿwindows(ä¸æ”¯æŒ) WSL(æ”¯æŒ) WSLå°±æ˜¯ (Windows Sub Linuxï¼‰ windowså†…åµŒçš„linuxå­ç³»ç»Ÿï¼Œè‡ªè¡Œç™¾åº¦ sudo pip3 install psutil sudo pip3 install setproctitle pip install modin[ray] WSL ä¸å»ºè®®æ¥è§¦ï¼Œæˆ‘æ˜¯æ„Ÿè§‰æ²¡å•¥ç”¨ã€‚ï¼ˆå°å¿ƒä½ çš„Cç›˜~~~ï¼‰ é™¤éä½ Aliyun, TencentCloud, VirtualBox, VMWareï¼Œéƒ½æ‡’å¾—ç”¨ã€‚ã€‚ã€‚ Linux/kaggle(æ”¯æŒ) modin ä¾èµ– ray ï¼ˆæ‰€ä»¥ç”¨äº†pipçš„ [] è¯­æ³•ï¼‰: ä¸€æ¡å‘½ä»¤å³å¯ pip install modin[ray] ä¸äº†è§£pipæ–°é²œè¯­æ³•çš„ï¼Œå¯ä»¥è§å®˜æ¡£ï¼š https://pip.pypa.io/en/stable/reference/pip_install/ MacOS(æ”¯æŒï¼Œä¹°ä¸èµ·) å¯¼å…¥ import ray import modin.pandas as pd # è¿™ä¸ªå¯¼å…¥å¾ˆçœ¼ç†Ÿä¸ï¼Œ æ²¡é”™,å°±æ˜¯ å¤šäº†ä¸ª &quot;modin.&quot;ï¼Œ ç”¨æ³•å’ŒåŸç”Ÿpandasæ²¡ä»€ä¹ˆåŒºåˆ« ä½¿ç”¨ ray.init(num_cpus=4, ignore_reinit_error=True) # ç¬¬ä¸€ä¸ªå‚æ•°å……åˆ†åˆ©ç”¨4æ ¸CPUã€‚ # ç¬¬äºŒä¸ªå‚æ•° ignore_reinit_error=Trueï¼Œ å¿½ç•¥é‡å¤åˆå§‹åŒ–çš„ è€Œäº§ç”Ÿçš„æŠ¥é”™ã€‚ # å¦‚æœä¸å¿½ç•¥ï¼Œé‚£ä¹ˆä½ ç”¨Jupyterè¿è¡Œæ—¶ï¼š # ç¬¬ä¸€æ¬¡ä¼šè°ƒç”¨æ­£å¸¸è¿è¡Œã€‚ # è€Œä¹‹åæ¯æ¬¡é‡å¤è°ƒç”¨å°±ä¼šæŠ¥é”™ã€‚ æ‰€ä»¥è¿™ä¸ªå‚æ•°æœ€å¥½è®¾ä¸ºTrue pd.DataFrame() ... ... æŒ‰åŸç”Ÿpandasçš„è¯­æ³•æ­£å¸¸ä½¿ç”¨å³å¯ã€‚ã€‚ã€‚ Modinå®˜æ¡£ https://modin.readthedocs.io/en/latest/using_modin.html ","link":"https://cythonlin.github.io/post/py-greater-modinrayjia-su-pandas-da-xiong-mao/"},{"title":"PY => æ·±æ‹·è´/æµ…æ‹·è´å¤šç§è¯­æ³•è§£æ","content":"åˆ—è¡¨ä¸ºä¾‹ï¼ˆå¯å˜ç±»å‹å®¹å™¨ï¼‰ï¼Œç›´æ¥ä¸Šä»£ç ï¼š ç¬¬ä¸€ç§ï¼š a = [[1,2], [3,4]] [_.append(666) for _ in a] # åŸç”Ÿåˆ—è¡¨ ï¼ˆfor ä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œå›¾ä¸ªæ–¹ä¾¿ï¼Œç”¨äº†æ¨å¯¼å¼ï¼‰ print(a) &gt;&gt; [[1, 2, 666], [3, 4, 666]] ç¬¬äºŒç§ï¼š a = [[1,2], [3,4]] [_.append(666) for _ in a[:]] # æ–°å¢æ“ä½œï¼š å¯¹æ•´ä¸ªåˆ—è¡¨åˆ‡ç‰‡è‡ªçˆ† print(a) &gt;&gt; [[1, 2, 666], [3, 4, 666]] ç¬¬ä¸‰ç§ï¼š a = [[1,2], [3,4]] [_.append(666) for _ in copy.copy(a)] # æ–°å¢æ“ä½œï¼š å¯¹æ•´ä¸ªåˆ—è¡¨ä½¿ç”¨æµ…æ‹·è´API print(a) &gt;&gt; [[1, 2, 666], [3, 4, 666]] #------------------ åˆ†å‰²çº¿------------------------- ç¬¬å››ç§ï¼š a = [[1,2], [3,4]] [_.append(666) for _ in copy.deepcopy(a)] # æ–°å¢æ“ä½œï¼š æ•´ä¸ªåˆ—è¡¨ä½¿ç”¨æ·±æ‹·è´API print(a) &gt;&gt; [[1, 2], [3, 4]] ç¬¬äº”ç§ï¼šï¼ˆæ³¨æ„ å’Œ ç¬¬äºŒç§ å¯¹æ¯”ï¼‰ a = [[1,2], [3,4]] [_[:].append(666) for _ in a] # æ–°å¢æ“ä½œï¼šå¯¹å³å°†æ“ä½œçš„å­åˆ—è¡¨åˆ‡ç‰‡è‡ªçˆ† print(a) &gt;&gt; [[1, 2], [3, 4]] ç¬¬å…­ç§ï¼šï¼ˆæ³¨æ„ å’Œ ç¬¬ä¸‰ç§ å¯¹æ¯”ï¼‰ a = [[1,2], [3,4]] [copy.copy(_).append(666) for _ in a] # æ–°å¢æ“ä½œï¼šå¯¹å³å°†æ“ä½œçš„å­åˆ—è¡¨ ä½¿ç”¨æµ…æ‹·è´API print(a) &gt;&gt; [[1, 2], [3, 4]] æé†’0 å¤šçº§å®¹å™¨éœ€è°¨æ… ï¼ˆè™½ç„¶å¤šçº§ çº¯ å…ƒç»„æ˜¯ä¸å¯å˜ç±»å‹ï¼Œä½ æƒ³å¼„ä¹Ÿå¼„ä¸åŠ¨å®ƒ~~~ï¼‰ ä½†æ˜¯è¿™ç§æƒ…å†µï¼Œä½ è¿˜æ˜¯éœ€è¦æ³¨æ„ï¼š a = ([1,2], [3,4]) # é‡Œé¢çš„åˆ—è¡¨ä¾ç„¶æ˜¯å¯å˜çš„ï¼Œ è¿™ç®—æ˜¯åˆšå…¥é—¨çš„åŸºç¡€ã€‚ä½†è¿˜åº”è¯¥ç•™æ„ æé†’ä¸€ é™¤äº† deepcopyï¼Œ å…¶ä»–æ“ä½œéƒ½æ˜¯æµ…æ‹·è´ã€‚ å¦‚æœä½ å–œæ¬¢ä½¿ç”¨ [::] ï¼Œ [:] è¿™ç§åˆ‡ç‰‡æ‹·è´ï¼Œ é‚£ä¹ˆæ›´åº”è¯¥æ³¨æ„ä¸€ä¸‹ä¸Šè¿°æ¡ˆä¾‹é—®é¢˜ã€‚ æé†’äºŒ ä¹Ÿè®¸ä½ çœ‹ä¸Šè¿°ä»£ç å¾ˆä¸€èˆ¬ã€‚ç”šè‡³æ²¡æœ‰ä»»ä½•æ„Ÿè§‰ã€‚ ä½†æ˜¯å½“ä½ æŠŠå­åˆ—è¡¨å½“ä½œä¸­é—´å€¼ï¼ˆä»»æ„æ“ä½œå˜æ¢ï¼‰ï¼Œ å†æé†’ä¸€æ¬¡ ===&gt; ä½œä¸º ä¸­é—´å€¼ï¼ˆæˆ–è€…è¯´ä¸´æ—¶å€¼ï¼‰ä½¿ç”¨æ—¶ã€‚ ä½ çš„BUGå¯èƒ½åœ¨å‘ä½ æ‹›æ‰‹ï¼ é™„èµ ï¼šæ±‚ å­é›† æ¡ˆä¾‹ import copy def f(sub): temp_list = [[]] for x in sub: for y in copy.deepcopy(temp_list): y.append(x) temp_list.append(y) return temp_list print(f(list(range(4)))) ","link":"https://cythonlin.github.io/post/py-greater-shen-kao-bei-qian-kao-bei-duo-chong-yu-fa-jie-xi/"},{"title":"PY => docker-composeéƒ¨ç½²ä»¥åŠscrapyd+scrapyd-deployä¸Šä¼ ä»£ç è¸©å‘","content":"å‰è¨€ è¸©äº† 5-6ä¸ªå°æ—¶çš„å‘ï¼Œå„ç§æµ‹è¯•ã€‚äººè¦æ²¡äº†ã€‚ä¸è¿‡ç»“æœæˆ‘å·²ç»æ»¡æ„äº†ã€‚ è¿™ç¯‡æ–‡ç« æ˜¯å¯¹ https://segmentfault.com/a/1190000020388794 çš„å®Œå–„ä¸æ’åˆBUG! å¤§å‘1ï¼ˆscrapydæœåŠ¡bind_addressï¼‰ï¼š æˆ‘ç”¨çš„Docker (æˆ‘è®°å¾—ä¹‹å‰ä¸ç”¨dockerçš„æ—¶å€™scrapydçš„é…ç½®æ–‡ä»¶å¥½åƒæ˜¯é»˜è®¤çš„ 0.0.0.0) ä½†æ˜¯æˆ‘å‘ç° Dockerå®¹å™¨é‡Œé¢ é»˜è®¤æ˜¯ bind 127.0.0.1 ï¼ˆçœŸæ˜¯ f--käº†.. å¼„äº†å¥½å‡ ä¸ªå°æ—¶æ²¡å‘ç°ï¼‰ å¦‚æœä½ ç”¨çš„dockerï¼Œ å…ˆåœ¨Docker åŒçº§ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ª default_scrapyd.conf ç„¶åå†™å…¥å¦‚ä¸‹é…ç½®ï¼ˆä¸ç”¨çŠ¹è±«ï¼Œå…¨éƒ¨å¤åˆ¶è¿›å»å³å¯ï¼‰ï¼š [scrapyd] eggs_dir = eggs logs_dir = logs items_dir = jobs_to_keep = 5 dbs_dir = dbs max_proc = 0 max_proc_per_cpu = 4 finished_to_keep = 100 poll_interval = 5.0 bind_address = 0.0.0.0 http_port = 6800 debug = off runner = scrapyd.runner application = scrapyd.app.application launcher = scrapyd.launcher.Launcher webroot = scrapyd.website.Root [services] schedule.json = scrapyd.webservice.Schedule cancel.json = scrapyd.webservice.Cancel addversion.json = scrapyd.webservice.AddVersion listprojects.json = scrapyd.webservice.ListProjects listversions.json = scrapyd.webservice.ListVersions listspiders.json = scrapyd.webservice.ListSpiders delproject.json = scrapyd.webservice.DeleteProject delversion.json = scrapyd.webservice.DeleteVersion listjobs.json = scrapyd.webservice.ListJobs daemonstatus.json = scrapyd.webservice.DaemonStatus æœ€ååœ¨ä½ çš„Dockerfileä¸­æœ«å°¾å†™å…¥ï¼ˆè§†æƒ…å†µè€Œå®šã€‚ æ¯ä¸ªäººçš„ç›®å½•ç»“æ„éƒ½ä¸åŒï¼‰ COPY default_scrapyd.conf /usr/local/lib/python3.6/site-packages/scrapyd/default_scrapyd.conf å¤§å‘2 (docker-compose: çš„commandå¤šå‘½ä»¤é—®é¢˜) scrapydéƒ¨ç½²éœ€è¦ä¸¤æ­¥ï¼š å…ˆå¼€å¯ scrapyd æœåŠ¡ (scrapyd å‘½ä»¤å³å¯) å†æŠŠçˆ¬è™«ç¨‹åºé€šè¿‡ scrapyd-deploy æ¨é€åˆ° scrapydæœåŠ¡ä¸Š å¾ˆæ˜æ˜¾ï¼š2 æ˜¯ä¾èµ– 1 çš„ã€‚ é”™è¯¯è§£å†³æ–¹å¼ï¼š ä½†æ˜¯ï¼Œdocker-compose command: åªèƒ½è¿è¡Œä¸€æ¡å‘½ä»¤ã€‚ æˆ‘æŒ‰ç…§å¸¸ç†ä½¿ç”¨Nç§æ€æƒ³æƒ³è®©ä»–æ”¯æŒå¤šæ¡å‘½ä»¤ï¼š èµ·åˆ ç”¨ &amp;&amp; ç”¨ shè„šæœ¬ è¿™ä¸ªå‘½ä»¤æ˜¯æœ€è’å”çš„ã€‚ã€‚ã€‚ ç½‘ä¸Šåƒç¯‡ä¸€å¾‹çš„åšå®¢ã€‚ ç™¾åˆ†ä¹‹80éƒ½æ˜¯äº’ç›¸æŠ„è¢­çš„ã€‚ï¼ˆç„¶åæˆ‘è¿˜çœŸç”¨äº†ã€‚ã€‚ï¼‰ æœ€è’å”çš„å‘½ä»¤å¦‚ä¸‹ï¼šï¼ˆæˆ‘ä¸€ç›´çªƒå–œï¼Œä»¥ä¸ºæ‰¾åˆ°è§£å†³åŠæ³•äº†ï¼Œå°±ä¸€ç›´ä»¥è¿™ä¸ªå‘½ä»¤ä¸ºè½´åšè°ƒè¯•ï¼Œæµ‹è¯•ã€‚ã€‚ã€‚ã€‚ï¼‰ command: - /bin/bash - -c - | scrapyd scrapyd-deploy Cython_lin -p Baidu è¿™ä¸ªå‘½ä»¤æœ‰ä¸¤ç§ç»“æœï¼ˆè¿™ä¸¤ç§ç»“æœè¿˜tmæ˜¯éšæœºçš„ã€‚ ç”Ÿæ— å¯æ‹ï¼‰ï¼š scrapydå…ˆæ‰§è¡Œï¼Œç›´æ¥å µå¡ã€‚åé¢å‘½ä»¤å¤±æ•ˆï¼ˆå³ä½¿ä½ ç”¨&amp; ä¹Ÿè§£å†³ä¸äº†éšæœºå¯åŠ¨é¡ºåºé—®é¢˜ï¼‰ scrapyd-deploy Cython_lin -p Baidu å…ˆæ‰§è¡Œ ï¼ˆç›´æ¥æŠ¥é”™ï¼Œä»¥ä¸ºscrapydè¿˜æ²¡èµ·æ¥å‘¢ï¼‰ åˆ°æ­¤ä¸ºæ­¢ï¼šï¼šï¼šï¼šï¼šï¼šï¼š æˆ‘ä¸Šé¢è¯´çš„éƒ½æ˜¯é”™è¯¯çš„æ–¹å¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ ï¼ˆå·®ç‚¹ä¸€æ£µæ ‘ä¸Šå‹’åˆ°æ­»ï¼Œ æ—¢ç„¶docker-composeæ–‡ä»¶å†…éƒ¨åªèƒ½è¿è¡Œä¸€æ¡å‘½ä»¤ã€‚é‚£ä¹ˆæˆ‘ä»¬æ‹¿å¤–é¢å»è¿è¡Œå•Šï¼ï¼ï¼‰ ï¼ˆæ€æƒ³å·²ç»ç»æœ›åƒµåŒ–çš„æˆ‘ï¼Œ è¿™æ¬¡æ˜¯çœŸçš„çœ‹è§äº†å¸Œæœ›ï¼Œæ›™å…‰ï¼‰ æ­£ç¡®è§£å†³æ–¹å¼: docker-compose.ymlæ–‡ä»¶é‡Œé¢åªå†™ï¼š command: scrapyd ç„¶åä¿å­˜é€€å‡ºï¼Œ ç„¶åæ‰§è¡Œ ï¼š docker-compose up -d # æˆ‘ä»¬éœ€è¦è®© scrapydå¯åŠ¨ä¸€ä¼šï¼Œæ‰å¯ä»¥å¯åŠ¨ scrapy-deployçš„ï¼ˆç­‰ä¸€å°ä¼šå°±è¡Œäº†ï¼‰ ç„¶åç»§ç»­æ‰§è¡Œï¼š docker-compose exec crawl scrapyd-deploy Cython_lin -p Baidu ç‰¹åˆ«æ³¨æ„ï¼è¯´æ˜ä»¥ä¸‹ï¼ï¼ˆdocker-composeå‘½ä»¤æœ‰ä¸¤ç§æ–¹å¼ï¼‰ï¼š docker-compose exec æ­£ç¡® docker-compose run é”™è¯¯ (åœ¨å¤–é¢åƒä¸‡ä¸è¦ç”¨è¿™ç§ ï¼ˆå½“ç„¶æˆ‘æ˜¯è¯´æˆ‘è¿™ä¸ªä¸šåŠ¡ï¼‰) ç»“æŸè¯­ ä¹Ÿè®¸æœ‰äº›é”™è¯¯å¾ˆå°ï¼Œ ä½†æ˜¯å½“ä½ æ€€ç–‘å˜å¤šçš„æ—¶å€™ï¼Œè„‘æµ·ä¼šå‡ºç°æµ·é‡è§£å†³é—®é¢˜çš„åˆ†æ”¯ã€‚ ç„¶åæœºæ¢°æ’BUGï¼Œ æœ€ç»ˆç”Ÿæ— å¯æ‹ã€‚ã€‚ã€‚ã€‚ã€‚ å…¶å®æœ‰æ—¶ä¸å¦¨å…ˆå†·é™ä¸‹æ¥ï¼Œ ç„¶åä¸“æ³¨ï¼Œä¸€é”¤å®šéŸ³ã€‚æ‰¾å‡ºBUGï¼ï¼ï¼ ","link":"https://cythonlin.github.io/post/py-greater-docker-compose-bu-shu-yi-ji-scrapydscrapyd-deploy-shang-chuan-dai-ma-cai-keng/"},{"title":"PY => Scrapydéƒ¨ç½²çˆ¬è™«+å°è£…Django-Viewæ¥å£è°ƒç”¨","content":"å‰è¨€ æˆ‘ä¹‹å‰åšçš„é¡¹ç›®ï¼šä¸€ç›´ç”¨çš„ Linuxçš„Screenä¼šè¯å·¥å…·+ Scrapyçš„JOBDIRæ¥æ§åˆ¶çˆ¬è™«å¼€å…³ã€‚ ä½†æ˜¯æœ‰åæ¥æƒ³åˆ°ç”¨ Web æ¥æ§åˆ¶çˆ¬è™«çš„å¼€å…³ã€‚æ‰€ä»¥æˆ‘æƒ³åˆ°äº†ç”¨ScrapydæœåŠ¡å®ç°ã€‚ éƒ¨ç½²çˆ¬è™«é¡¹ç›® å®‰è£…scrapydæœåŠ¡ pip install scrapyd å¯åŠ¨scrapydæœåŠ¡ scrapyd # å°±è¿™ä¸€æ¡shellå‘½ä»¤å³å¯å¯åŠ¨æœåŠ¡ å¦‚æœä½ ç›¸å¯¹çˆ¬è™«æœåŠ¡åšä¸€äº›é…ç½®ï¼Œï¼ˆæ¯”å¦‚ logç›®å½•ï¼Œç»‘å®šåœ°å€ï¼Œç»‘å®šç«¯å£ã€‚ã€‚ç­‰ï¼Œå¯ä¿®æ”¹å¦‚ä¸‹é…ç½®æ–‡ä»¶ï¼‰ï¼š vi /usr/lib/python3.6/site-packages/scrapyd/default_scrapyd.conf å°†çˆ¬è™«ç¨‹åºæ¨é€åˆ°æœåŠ¡ä¸­ é¦–å…ˆç¡®ä¿ä½ çš„çˆ¬è™«ç¨‹åºå•æµ‹å¯ä»¥æ— è¯¯è¿è¡Œï¼ æƒ…å†µ1ï¼šï¼ˆçˆ¬è™«ç¨‹åºåœ¨linuxï¼Œ ä¸Šé¢è®²çš„scrapydæœåŠ¡ä¹Ÿåœ¨linuxï¼‰ é¦–å…ˆå®‰è£…ä¸ªæ¨¡å—ï¼š pip install scrapyd-client ä¿®æ”¹scrapyçš„scrapy.cfgæ–‡ä»¶ï¼š [deploy:Cython_lin] # è¿™ä¸ª Cython_lin æ˜¯æœåŠ¡åï¼Œå¯è‡ªå®šä¹‰ï¼Œä½†åé¢è¿˜ä¼šç”¨åˆ° url = http://23.23.xx.xx:6800/ # è¿™æ˜¯ä½ ä¸Šé¢å¯åŠ¨çš„ScrapydæœåŠ¡çš„ URL+PORT project = Baidu # è¿™ä¸ªæ–‡ä»¶æ˜¯ä½ è¿è¡Œ scrapy startproject æ—¶ è‡ªåŠ¨åˆ›å»ºçš„æ–‡ä»¶ã€‚ åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œ å°±å« &quot;scrapy.cfg&quot;ï¼š æ­£å¼æ¨é€æœ¬æœºçˆ¬è™«ç¨‹åºåˆ°Scrapyd: å¦‚ä¸‹æœ‰3ä¸ªè¯´æ˜ï¼š 1. ä½ éœ€è¦åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ‰§è¡Œè¿™ä¸ªå‘½ä»¤ 2. Cython_lin å°±æ˜¯æˆ‘ä»¬ä¸Šé¢ scrapy.cfgæ–‡ä»¶ é…ç½®çš„æœåŠ¡å 3. Baidu å°±æ˜¯ scrapy.cfgæ–‡ä»¶ é‡Œé¢çš„é‚£ä¸ª projectå±æ€§çš„å€¼ï¼Œä¹Ÿæ˜¯ é¡¹ç›®å scrapyd-deploy Cython_lin -p Baidu æƒ…å†µ2ï¼Œç•ªå¤–ç¯‡ï¼ˆWindowså¼€å‘ï¼ŒLinuxéƒ¨ç½²ï¼‰ åŒæ ·å®‰è£…ä¸ªå®¢æˆ·ç«¯æ¨¡å—ï¼ˆwindowsï¼‰ï¼š pip install scrapyd-client ä¿®æ”¹scrapyçš„scrapy.cfgæ–‡ä»¶(windows)ï¼š [deploy:Cython_lin] # è¿™ä¸ª Cython_lin æ˜¯æœåŠ¡åï¼Œå¯è‡ªå®šä¹‰ï¼Œä½†åé¢è¿˜ä¼šç”¨åˆ° url = http://23.23.xx.xx:6800/ # è¿™æ˜¯ä½ ä¸Šé¢å¯åŠ¨çš„ScrapydæœåŠ¡çš„ URL+PORT project = Baidu å»ºç«‹ä¸€ä¸ªæ–‡ä»¶åä¸º scrapyd-deploy.batï¼Œ å†…å®¹ä½œä¸‹ï¼ˆwindowsï¼‰ï¼š æ³¨æ„ï¼šè¿™ä¸ªæ–‡ä»¶æ˜¯åˆ›å»ºåœ¨pythonçš„å®‰è£…è·¯å¾„ä¸‹ï¼ˆå¦‚æœä½ æ˜¯è™šæ‹Ÿç¯å¢ƒï¼Œé‚£ä¹ˆå°±å»è™šæ‹Ÿç¯å¢ƒçš„pythonè·¯å¾„ä¸­ï¼‰ @echo off &quot;D:\\Virtualenv_All\\scrapy\\Scripts\\python.exe&quot; &quot;D:\\Virtualenv_All\\scrapy\\Scripts\\scrapyd-deploy&quot; %1 %2 %3 %4 %5 %6 %7 %8 %9 éšåå°†åˆšæ‰çš„è·¯å¾„ï¼Œé…ç½®åˆ°ç¯å¢ƒå˜é‡ä¸­ï¼ˆå¦‚æœä¸æƒ³è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé‚£ä¹ˆæ¯æ¬¡éœ€è¦ç”¨ç»å¯¹è·¯å¾„ç”¨scrapyd-deployï¼‰ scrapyd-deploy Cython_lin -p Baidu è¿™æ¡å‘½ä»¤å’Œä¸Šé¢ï¼ˆlinuxç‰ˆæœ¬ï¼‰è®²çš„æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œ åŒæ ·è¦åœ¨scrapyæ ¹è·¯å¾„ä¸‹æ‰§è¡Œ è°ƒç”¨çˆ¬è™«ç¨‹åº å‰é¢æˆ‘ä»¬å·²ç»å®Œå…¨å°†çˆ¬è™«ScrapydæœåŠ¡éƒ¨ç½²å®Œæˆã€‚æ¥ä¸‹æ¥å°±æ˜¯å¼€å¯è°ƒç”¨çš„ç¯èŠ‚ï¼š scrapydé‡‡ç”¨ &quot;è¯·æ±‚æ¥å£&quot; çš„æ–¹å¼å–å¼€å¯æˆ–ç»ˆæ­¢çˆ¬è™«ï¼š æŸ¥çœ‹çˆ¬è™«çŠ¶å†µï¼š curl http://23.23.xx.xx:6800/daemonstatus.json æ­£å¼å¼€å¯çˆ¬è™«ç¨‹åºï¼š curl http://39.107.86.223:6800/schedule.json -d project=Baidu -d spider=zhidao # æ³¨æ„: &quot;Baidu&quot;æ˜¯é¡¹ç›®åï¼Œ è€Œ &quot;zhidao&quot; æ˜¯æ¯ä¸ª spiderçš„åå­— ï¼ˆå°±æ˜¯ä¸»ç¨‹åºçš„çˆ¬è™«åname=...ï¼‰ # æ³¨æ„: å¼€å¯çš„æ—¶å€™ä¼šç»™ä½ ä¸€ä¸ªIDï¼Œ ä½ è¦è®°ä½å®ƒ ï¼Œæ–¹ä¾¿æˆ‘ä»¬åœæ­¢ åœæ­¢çˆ¬è™«ç¨‹åºï¼š curl http://23.23.xx.xx:6800/cancel.json -d project=Baidu -d job=è¿è¡ŒID Djangoè§†å›¾å†…åµŒæ§åˆ¶çˆ¬è™«ç¨‹åº ä¸Šé¢æˆ‘ä»¬è¯´äº†ç”¨ curl å‘é€è¯·æ±‚å»æ“æ§çˆ¬è™«çš„å¼€å¯ä¸æš‚åœã€‚ä½†æ˜¯è¿™å¹¶ä¸æ˜¯ä¹ æƒ¯çš„åšæ³•ã€‚ æ›´å¥½çš„æ˜¯ï¼Œé€šè¿‡Qt æˆ–è€… é€šè¿‡Web, æ¥æ“æ§çˆ¬è™«ã€‚ pip install python-scrapyd-api # é¢„å…ˆå®‰è£…æ­¤æ¨¡å— from scrapyd_api import ScrapydAPI scrapyd = ScrapydAPI('39.107.xx.xx:6800') # å…ˆè·å– scrapydè¿œç¨‹æœåŠ¡çš„å®¢æˆ·ç«¯è¿æ¥ class SpiderView(View): # æˆ‘ä½¿ç”¨çš„æ˜¯ Djangoçš„ CBV def get(self, request): state_dict = scrapyd.list_jobs('Baidu') # åˆ—å‡ºé¡¹ç›®æ‰€æœ‰çˆ¬è™«ä»»åŠ¡ï¼Œè¿”å›å­—å…¸ if request.GET.get('tag') == 'start': # æ£€æµ‹çˆ¬è™«æ˜¯å¦ä¸ºè¿è¡ŒçŠ¶æ€ scrapyd.schedule('Baidu', 'zhidao') # 'project_name', 'spider_name' return HttpResponse('0') # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œç»™å‰ç«¯ä¸€ä¸ªå€¼ï¼ŒæŒ‰é’® if request.GET.get('tag') == 'stop': # å‰ç«¯ç‚¹ä¸‹æŒ‰é’®å¦‚æœgetä¼ å€¼ä¸ºstop try: state = state_dict['running'][0]['id'] # è‹¥å–ä¸åˆ°ï¼Œå°±æŠ›å¼‚å¸¸ except: return HttpResponse('-1') # éšä¾¿è¿”å›ä¸€ä¸ªå€¼ï¼Œä¸ç”¨å¤„ç† scrapyd.cancel('Baidu', state) # æ ¹æ® idå–æ¶ˆ çˆ¬è™«å…¥ä¼ return HttpResponse('0') # å¹¶è¿”å›0ï¼ˆè¿™ä¸ª0æ˜¯æˆ‘è‡ªå®šä¹‰çš„ï¼Œå‰ç«¯ä¹Ÿç”¨çš„0ï¼‰ return HttpResponse('') å‰ç«¯äº¤æ¥ å…¶å®åç«¯æ¥å£åšå¥½äº†ï¼Œå‰ç«¯å°±éšæ„äº†ã€‚æˆ‘ç”¨çš„ Nuxt+Vueï¼Œä¸»è¦è´´ä¸€ä¸‹æ ¸å¿ƒmethodå§ï¼š methods: { start() { axios.get('http://39.xx.xx:8000/spider', { # æ³¨æ„è¿™æ—¶è¯·æ±‚çš„Django params: { 'tag': 'start' } }).then( (response) =&gt; { this.tag = Number.parseInt(response['data']) if (this.tag === 0) { # å¦‚æœdjangoè¿”å›å€¼ä¸º0 this.start_msg = 'å¼€å¯æˆåŠŸï¼Œåˆ‡è®°ä¸è¦é‡å¤å¼€å¯' # ç”¨äºvueæ¨¡æ¿æç¤º this.start_unable = true # æŠŠæŒ‰é’®ç¦ç”¨ï¼Œé˜²æ­¢é‡å¤è¯·æ±‚ this.stop_unable = false # åŒæ—¶æŠŠåœæ­¢æŒ‰é’®ç”±ç¦ç”¨è®¾ç½®ä¸ºæ¿€æ´» this.start_layer() # è¿™ä¸ªå‡½æ•°å†…éƒ¨å®ç°äº†æ¶ˆæ¯å¼¹æ¡† // this.stop_unable = false } } ), stop() { axios.get('http://39.107.xx.xx:8000/spider', { # æ³¨æ„è¿™æ˜¯è¯·æ±‚çš„Django params: { 'tag': 'stop' } # å‘ä¸€ä¸ª stopå‚æ•°çš„getè¯·æ±‚ }).then( (response) =&gt; { this.tag = Number.parseInt(response['data']) if (this.tag === 0) { # å¦‚æœè¿”å›0, è¿™ä¸ª0æ˜¯æˆ‘åœ¨Djangoè‡ªå·±æŒ‡å®šçš„ã€‚ this.stop_msg = 'å…³é—­æˆåŠŸï¼Œåˆ‡è®°ä¸è¦é‡å¤å…³é—­' this.start_unable= false # è´Ÿè´Ÿå¾—æ­£ï¼Œå¼€å§‹æŒ‰é’®æ¿€æ´» this.stop_unable = true # åœæ­¢æŒ‰é’®ç¦ç”¨ this.stop_layer() # æ— å…³ç¦ç”¨çš„å¼¹çª—ä¿¡æ¯ } } ) }, }, Docker+docker-compose å¦‚æœä½ ä¹Ÿæƒ³è¿‡ä½¿ç”¨docker+docker-compose ï¼ˆå¼€å¯æœåŠ¡ï¼Œæ¨é€ä»£ç ä¸€ä½“åŒ–ï¼‰ è¯·çœ‹ä¸‹ç¯‡ï¼š https://segmentfault.com/a/1190000020424059 ç»“æŸè¯­ æˆ‘æ˜¯è®¾ç½®2ä¸ªæŒ‰é’®ï¼ˆå¼€å¯ã€å…³é—­äº’æ–¥ï¼Œç‚¹å“ªä¸ªå“ªä¸ªå°±è¢«ç¦ç”¨ï¼Œä¸æ­¤åŒæ—¶å¦ä¸€ä¸ªæŒ‰é’®å°±ä¼šè¢«æ¿€æ´»ï¼‰ã€‚ å½“ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨ å•æœºï¼ŒåŒå‡»ã€‚ç­‰ç”¨ä¸€ä¸ªæŒ‰é’®æ¥æ§åˆ¶å¼€å¯å’Œå…³é—­ã€‚ å½“ç„¶è¿™äº›åªæ˜¯æ ‡å¿—æ€§çš„åŠŸèƒ½ã€‚ æ ¸å¿ƒåŠŸèƒ½è¿˜æ˜¯ Djangoè§†å›¾ä¸­çš„ ScrapydAPI è¿™ä¸ªAPIçš„ä½¿ç”¨ python-scrapyd-apiå®˜æ¡£ï¼šhttps://pypi.org/project/python-scrapyd-api/ ","link":"https://cythonlin.github.io/post/py-greater-scrapyd-bu-shu-pa-chong-feng-zhuang-django-view-jie-kou-diao-yong/"},{"title":"PY => Python-loggingæ¨¡å—æ—¥å¿—åŸç†è§£æåŠä½¿ç”¨","content":"loggingæ¨¡å— logging æ¨¡å—æ˜¯ä¸€ä¸ªè¾ƒåºå¤§çš„æ¨¡å—ã€‚å…·æœ‰è¾ƒå®Œå¤‡çš„æ—¥å¿—ä½“ç³»ã€‚ ä¸»è¦åˆ†ä¸ºï¼šä¸»ä½“ Logger - å¤„ç†å™¨ - æ ¼å¼å™¨ logging ä¸º python å†…ç½®æ¨¡å—ï¼Œæ— éœ€å®‰è£…ã€‚ å¯¼å…¥æ–¹å¼ï¼š import logging å³å¯ æ—¥å¿—ç­‰çº§æ’åº (å¼± -&gt; å¼º) DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; FATAL DEBUG : å¼€å‘è°ƒè¯•çš„ä¸€äº›ä¿¡æ¯(printè°ƒè¯•ã€‚ã€‚ã€‚) INFO: ç¨‹åºè¿è¡Œè¿‡ç¨‹çš„é‡è¦ä¿¡æ¯ï¼ˆä¸å®œè¿‡å¤šï¼‰ WARNING: ä¸å½±å“ç¨‹åºè¿è¡Œçš„å°é—®é¢˜ï¼Œè­¦å‘Šä¸€ä¸‹ã€‚è®°å½•ä¸‹æ¥ä»¥å¤‡ä»¥åè§£å†³ã€‚ ERROR: å½±å“ç¨‹åº, æœ‰ç‚¹ä¸¥é‡ã€‚éœ€è¦å¤„ç†ï¼Œ ä¸ç„¶ç¨‹åº ï¼ˆå¯èƒ½ï¼Œå¯èƒ½ï¼‰å°±æŒ‚äº†ã€‚ FATAL: ä¸¥é‡å½±å“ç¨‹åºï¼Œç«‹åˆ»é‡æ–°æ’æŸ¥ï¼Œä¿®æ”¹ä»£ç å§ã€‚ loggingä½“ç³»ç»„ä»¶ å¸¸ç”¨åˆ†ä¸ºï¼š ï¼ˆç”±å¤–åˆ°é‡Œçš„åŒ…å«å…³ç³»ï¼‰ Logger ï¼ˆä¸»ä½“æ—¥å¿—ï¼‰ æœ€å¤§çš„å®¹å™¨ï¼Œé‡Œé¢è£… Handler Handler ï¼ˆå¤„ç†å™¨ç±»ï¼‰ é‡Œé¢è£… Formatter Formatter (æ ¼å¼å™¨ç±») é‡Œé¢å†™ä¸€äº›æ‰“å°ä¿¡æ¯çš„æ ¼å¼è¯­æ³• ä¸ºäº†æ–¹ä¾¿è¯´æ˜ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä¼šæŠŠä¸Šé¢çš„ç»„ä»¶â€œç”±é‡Œåˆ°å¤–â€è®²è§£ã€‚ Formatter(æ ¼å¼å™¨ç±») æ ¼å¼å™¨ï¼šç”¨æ¥å®šä¹‰ä¸€äº›æ‰“å°ä¿¡æ¯çš„å­—ç¬¦ä¸²æ ¼å¼åŒ–çš„è¯­æ³•ã€‚ åˆå§‹åŒ–ä¸€ä¸ª æ ¼å¼å™¨ï¼š fmt = '[%(asctime)s] [%(filename)s: %(lineno)d] [%(levelname)s] =&gt; %(message)s' # æ ¼å¼ console_formatter = logging.Formatter(fmt=fmt) # å®ä¾‹åŒ–æ ¼å¼å™¨ï¼Œå¹¶æŠŠæ ¼å¼ä¼ è¿›æ¥ ç†è§£æ–¹å¼ï¼š æˆ‘ç›¸ä¿¡ä½ åªæœ‰ â€œæ ¼å¼â€è¿™è¡Œ çœ‹ä¸æ˜ç™½ï¼Œè¿™æ ¼å¼ä½ å¯ä»¥éšä¾¿æ­é…çš„ï¼Œ è§ä¸‹æ–¹å®˜æ–¹æ–‡æ¡£æœ‰å‚æ•°å¤§å…¨ï¼š å®˜æ¡£æ ¼å¼å¤§å…¨ï¼šhttps://docs.python.org/3.7/library/logging.html#logrecord-attributes æ‰“å¼€å®˜æ¡£ï¼Œä½ ä¼šçœ‹è§è¡¨æ ¼çš„ç¬¬äºŒåˆ— Formatã€‚ é‡Œé¢çš„æ ¼å¼ç›´æ¥åŸå°ä¸åŠ¨å¤åˆ¶è¿‡æ¥å³å¯ eg: %(asctime)s ç„¶åï¼Œä½ æŠŠè¿™äº›æ ¼å¼ç”¨å­—ç¬¦ä¸²æ‹¼æ¥æˆè‡ªå·±å–œæ¬¢çš„ç¬¦å·æ ¼å¼å³å¯ï¼Œ eg: &quot;æ—¥æœŸä¸º =&gt; %(asctime)s&quot; ä¹Ÿè®¸ä½ ä¼šç–‘æƒ‘ï¼Œä¸ºä»€ä¹ˆè¿™ç§ %(..)s çš„æ ¼å¼èƒ½è¢«è¯†åˆ«ã€‚ è€Œä¸æ˜¯è¢«å½“ä½œåŸå§‹å­—ç¬¦ä¸²ï¼Ÿï¼Ÿï¼Ÿ æ³¨æ„ç¬¬äºŒè¡Œä»£ç ï¼Œ fmtæ ¼å¼å­—ç¬¦ä¸²åªæ˜¯ Formatter() çš„å‚æ•°ï¼Œå®ƒé‡Œé¢ä¼šè‡ªåŠ¨è¢«è§£æçš„ã€‚è¿™ä½ å°±åˆ«æ“å¿ƒäº†ã€‚ æˆ‘æŠŠä¸Šä¾‹ç»“æœè´´ä¸€ä¸‹ï¼Œä½ å¯èƒ½ä¼šçœ‹æ˜ç™½äº›ï¼š &gt;&gt;&gt; [2019-09-10 18:23:19,347] [logging11.py: 15] [WARNING] =&gt; å“ˆå“ˆå“ˆ asctime æ˜¯æ—¥æœŸ filename æ˜¯æ–‡ä»¶å lineno æ˜¯ä»£ç è¡Œ levelname æ˜¯æ—¥å¿—ç­‰çº§å ï¼ˆå°±æ˜¯ä¸Šé¢è¯´çš„ INFO WARNING ERRORä¹‹ç±»çš„ï¼‰ message æ˜¯ ä½ è¦æ‰“å°çš„æ—¥å¿—ä¿¡æ¯ ï¼ˆä¸‹é¢ä¼šè®²åˆ°ï¼Œè¿™é‡Œå…ˆå°å°åŸ‹ä¸€ä¸ªç‚¹ï¼‰ Handler(å¤„ç†å™¨ç±») å¤„ç†å™¨ï¼šç”¨æ¥è£…è½½ä¸Šé¢è¯´çš„ â€œæ ¼å¼å™¨â€ï¼Œå¹¶å¤„ç†æ—¥å¿— ï¼ˆå¤„ç†å™¨æœ‰å¾ˆå¤šç§ï¼ŒæŒ‰éœ€é€‰1ä¸ªå³å¯ï¼Œä¸‹é¢è¯´2ç§å¸¸ç”¨çš„ï¼‰ï¼š åˆå§‹åŒ–ä¸€ä¸ª â€œæµå¤„ç†å™¨â€ ï¼ˆæ¯”è¾ƒå¸¸ç”¨ï¼‰ï¼š handler = logging.StreamHandler() æˆ–åˆå§‹åŒ–ä¸€ä¸ª â€œæ–‡ä»¶å¤„ç†å™¨â€ ï¼ˆæºç æ˜ç¡®å†™äº†ï¼Œ å®ƒç»§æ‰¿çš„æ˜¯ ä¸Šé¢çš„ â€œæµå¤„ç†å™¨â€ã€‚é€šå¸¸ç”¨æ¥æ—¥å¿—æŒä¹…åŒ–ï¼‰ï¼š handler = logging.FileHandler('mylog.log', mode='a', encoding='utf-8') # ä¸å¿…è§£é‡Šäº†å§ã€‚ è¿™APIè¯­æ³•å¾ˆç†Ÿæ‚‰äº†å§ã€‚ è¿™ä¸å°±æ˜¯æˆ‘ä»¬å¸¸ç”¨çš„æ–‡ä»¶ open è¯­æ³•ä¹ˆã€‚ã€‚ã€‚ã€‚ è£…è½½â€œæ ¼å¼å™¨â€ ï¼ˆå·®ç‚¹å¿˜äº†å§ã€‚å®ä¾‹åŒ–çš„æ ¼å¼å™¨ï¼Œè¿˜æ²¡ç”¨å‘¢ï¼Œ å°±æ˜¯åœ¨è¿™é‡Œè£…è½½ï¼‰ handler.setFormatter(fmt=file_formatter) æ³¨æ„: è™½ç„¶ handlerå¯¹è±¡å°±å¯ä»¥ç”¨ setLevel()è®¾ç½®æ—¥å¿—ç­‰çº§ï¼Œä½†æˆ‘ä¸æ¨èåœ¨è¿™é‡Œè®¾ç½®ã€‚ç»§ç»­å¾€ä¸‹çœ‹ Logger(ä¸»ä½“æ—¥å¿—ç±») Loggerï¼š ç”¨æ¥è£…è½½ â€œå¤„ç†å™¨çš„â€ã€‚ å®ä¾‹åŒ–Loggeræœ‰ä¸¤ç§æ–¹æ³•ï¼š æ–¹æ³•1ï¼šï¼ˆéå…±äº«å¼åˆ›å»º, ä¸æ¨èï¼‰ log= logging.Logger(name='my_log', level='INFO') # name æ˜¯ç»™ Logger èµ·çš„å # levelæ˜¯ æ—¥å¿—ç­‰çº§ï¼ˆæ³¨æ„è¦å¤§å†™ï¼‰ï¼Œ å¼€ç¯‡æˆ‘ä»¬è®²åˆ°è¿‡ï¼Œ WARNING, INFO, ERROR è¿™äº›ã€‚ æ–¹æ³•2ï¼šï¼ˆLogæ± å…±äº«å¼åˆ›å»ºï¼Œ æ¨èï¼‰ log = logging.getLogger(name='console') # æœ‰åˆ™å–å‡ºï¼Œæ— åˆ™åˆ›å»º # nameå¦‚æœä¸ä¼ ï¼Œåˆ™å–å‡ºroot Logger ï¼ˆroot Loggeræ˜¯loggingé»˜è®¤ç»™æˆ‘ä»¬æä¾›çš„ï¼Œæˆ‘ä¸€èˆ¬ä¸ç”¨ï¼‰ è¯´ä¸€ä¸‹è¿™ä¸¤ç§æ–¹æ³•çš„åŒºåˆ«ï¼š éå…±äº«å¼ï¼š å³ä¸ºæ¯æ¬¡éƒ½éœ€è¦é‡æ–°åˆ›å»ºã€‚ä»0å¼€å§‹é…ç½® Logæ± å…±äº«å¼ï¼š ä»Logæ± å–å‡ºç´¢å¼•æ¥æ“ä½œï¼ˆå°±ç›¸å½“äºå‡½æ•°ä¼ ç´¢å¼•æ“ä½œï¼‰ ä½ æ¯å¯¹å–å‡ºçš„Logåšå‡ºé…ç½®æ—¶ï¼Œéƒ½ä¼šæ˜ å°„ä¿å­˜æ›´æ–°åˆ° Logæ±  ä¸­ã€‚ å½“ä¸‹æ¬¡ï¼ˆæˆ–å…¶ä»–æ–‡ä»¶ï¼Œ å½“ç„¶æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç¨‹åºï¼‰è°ƒç”¨ getLogger() å–å‡ºçš„ logï¼Œå°±æ˜¯ä¹‹å‰æˆ‘ä»¬é…å¥½çš„ã€‚ è£…è½½ &quot;å¤„ç†å™¨&quot; ï¼šï¼ˆå·®ç‚¹å¿˜äº†å§ï¼Œ ä¸Šé¢å®šä¹‰çš„ å¤„ç†å™¨ï¼Œè¿˜æ²¡ç”¨å‘¢ï¼Œ å°±æ˜¯åœ¨è¿™é‡Œç”¨çš„ï¼‰ï¼š log.addHandler(handler) è®¾ç½®æ—¥å¿—ç­‰çº§ ï¼ˆè¿™æ­¥å¯å¿½ç•¥ï¼‰ log.setLevel('ERROR') å…¶å®ä¸Šé¢æˆ‘ä»¬å®ä¾‹åŒ–Loggerçš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±å·²ç»ä¼ äº†ä¸€ä¸ª levelå‚æ•°ï¼Œè®¾ç½®å¥½äº† æ—¥å¿—ç­‰çº§ã€‚ æ‰€ä»¥ log.setLevel() è¿™ä¸ªå¯ä»¥ä¸è®¾ç½® ï¼ˆåŒ…æ‹¬å‰é¢æåˆ°ï¼Œhandlerä¹Ÿæœ‰ setLevelï¼‰ handler.setLevel() å¼€å§‹è¾“å‡ºæ—¥å¿—ä¿¡æ¯ï¼Œæœ‰ä»¥ä¸‹æ—¥å¿—ç­‰çº§ç›¸å¯¹åº”çš„APIï¼š log.debug (&quot;è¿™æ˜¯ä¸€æ¡ è°ƒè¯• æ—¥å¿—&quot;) log.info (&quot;è¿™æ˜¯ä¸€æ¡ æ˜¾ç¤ºä¸»è¦ä¿¡æ¯ æ—¥å¿—&quot;) log.warning('è¿™æ˜¯ä¸€æ¡ è­¦å‘Š æ—¥å¿—') log.error (&quot;è¿™æ˜¯ä¸€æ¡ é”™è¯¯ æ—¥å¿—&quot;) log.fatal (&quot;è¿™æ˜¯ä¸€æ¡ è‡´å‘½é”™è¯¯ æ—¥å¿—&quot;) ### å›é¡¾æˆ‘ä»¬å‰é¢è®²çš„ Formatter æ ¼å¼å™¨ æˆ‘ä»¬ç¬¬ä¸€ä¸ªè®²çš„å°±æ˜¯æ ¼å¼å™¨ï¼Œ å¹¶è¯´äº†ä¸€ä¸‹å¸¸ç”¨æ ¼å¼ã€‚ å…¶ä¸­æœ‰ä¸ª %(message)s, å®ƒå°±æ˜¯å ä½ä¸Šé¢è¿™äº›APIé‡Œé¢çš„å‚æ•° eg: log.info('å“ˆå“ˆå“ˆ') %(message)sæ ¼å¼ å ä½è¾“å‡ºçš„å°±æ˜¯ å“ˆå“ˆå“ˆ è¿˜æœ‰ä¸ª %(levelname)sï¼Œå®ƒå°±æ˜¯å ä½ä¸Šé¢è¿™äº›APIçš„æ–¹æ³•å eg: log.info('xxx') %(levelname)s æ ¼å¼å ä½è¾“å‡ºçš„å°±æ˜¯ info å¦‚æœä½ å¯¹æ—¥å¿—ç­‰çº§ä¸æ—¥å¿—çš„ä½œç”¨æ„Ÿåˆ°æ¨¡ç³Šï¼Œä½ ä¸€å®šè¦çœ‹æˆ‘æ¥ä¸‹æ¥çš„ä¾‹å­ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ å¼€ç¯‡æ—¶æˆ‘å°±æè¿‡ï¼š æ—¥å¿—ç­‰çº§æ’åº(å¼±=&gt;å¼º) =&gt; ï¼ˆDEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; FATALï¼‰ ä½ è®¾ç½®äº†ä¸€ä¸ªæ—¥å¿—ç­‰çº§ ã€‚é‚£ä¹ˆä½ æ‰€ç”¨ä¸Šé¢APIå¯¹åº”çš„ç­‰çº§è‹¥â€œå¼ºäºæˆ–ç­‰äºâ€ æ­¤è®¾å®šçš„ç­‰çº§ï¼Œæ—¥å¿—æ‰ä¼šè¢«å¤„ç† emmmmm, å¦‚æœæ²¡å¬æ‡‚ï¼Œå°±å½“æˆ‘æ”¾Päº†ã€‚ã€‚ã€‚ è¯´çš„è¶Šæ­£å¼ï¼Œè¶Šä¸å®¹æ˜“ç†è§£ã€‚ æˆ‘ä»¬è¿˜æ˜¯çœ‹ä¸‹é¢çš„ä¾‹å­å§~~ æ—¥å¿—ç­‰çº§ç†è§£çš„å°ä¾‹å­ï¼š log.setLevel('WARNING') ä½ çœ‹æˆ‘ä»¬è®¾ç½®çš„æ—¥å¿—ç­‰çº§æ˜¯ WARNING log.debug(&quot;è¿™æ˜¯ä¸€æ¡ è°ƒè¯• æ—¥å¿—&quot;) # è¿™ä¸ª debug(), ä½ å¯ä»¥å»å¼€ç¯‡åˆ—çš„&quot;æ—¥å¿—ç­‰çº§æ’åº&quot;é‚£é‡Œç…ä¸€çœ¼ã€‚ # debug æ¯” warning å¼±ï¼Œ æ‰€ä»¥ è¿™æ¡æ—¥å¿—æ˜¯ ä¸ä¼š è¢«å¤„ç†çš„ã€‚ # ï¼ˆç™½è¯ç†è§£ï¼š&quot;æˆ‘ç»™çš„ç•Œé™æ˜¯warning, ä½ ä¸€ä¸ª debugç­‰çº§å¤ªä½äº†ï¼Œé—®é¢˜ä¸ä¸¥é‡ã€‚ä¸é…è¢«è®°å½•ã€‚&quot;ï¼‰ log.info(&quot;è¿™æ˜¯ä¸€æ¡ æ˜¾ç¤ºä¸»è¦ä¿¡æ¯ æ—¥å¿—&quot;) # åŒç†ï¼Œ info ä¹Ÿæ¯” warning å¼±ï¼Œ æ­¤æ¡æ—¥å¿—ä¹Ÿ ä¸ä¼š è¢«å¤„ç† log.warning('è¿™æ˜¯ä¸€æ¡ è­¦å‘Š æ—¥å¿—') # warning == warning ï¼ˆæˆ‘å‰é¢è¯´äº†ï¼Œå¼ºäº æˆ– ç­‰äºï¼‰ æ‰€ä»¥æ­¤æ¡æ—¥å¿—ä¼šè¢«å¤„ç† log.error(&quot;è¿™æ˜¯ä¸€æ¡ é”™è¯¯ æ—¥å¿—&quot;) # error æ¯” warning å¼ºï¼Œ æ‰€ä»¥æ­¤æ¡æ—¥å¿— ä¼š è¢«å¤„ç† log.fatal(&quot;è¿™æ˜¯ä¸€æ¡ è‡´å‘½é”™è¯¯ æ—¥å¿—&quot;) # fatal æ¯” warning å¼ºï¼Œ æ‰€ä»¥æ­¤æ¡æ—¥å¿— ä¼š è¢«å¤„ç† # å†ç™½è¯ä¸€ä¸‹ï¼š&quot;ä½ ç»™æˆ‘çš„å®¹å¿ç¨‹åº¦æ˜¯ warning, è€Œä½ çš„è¿™æ¡æ—¥å¿—éƒ½è‡´å‘½é”™è¯¯äº†ï¼Œæˆ‘è‚¯å®šå¤„ç†ä½ å•Š&quot; æ€è€ƒï¼ä¸Šä¾‹æˆ‘ä¸€ç›´è¯´ä¸€å¥è¯ â€œxxxxx, æ­¤æ¡æ—¥å¿—æ‰ä¼šè¢«å¤„ç†â€ã€‚ é‚£ä¹ˆè¿™ä¸ªâ€œ å¤„ç†â€ ï¼Œåˆ°åº•æ˜¯å¤„ç†ä»€ä¹ˆå‘¢ï¼Ÿï¼Ÿï¼Ÿ è¿™æ—¶ä¸å¦¨å›å¤´çœ‹çœ‹ï¼Œä¸Šé¢è®²çš„ â€œå¤„ç†å™¨â€ï¼Œ å—¯ï¼Œ æ²¡é”™ã€‚ è¿™äº›æ—¥å¿—å°±æ˜¯ â€œå¤„ç†å™¨â€ å¤„ç†çš„ã€‚ ä½ è¦æ˜¯å®šä¹‰ä¸€ä¸ªæµå¤„ç†å™¨ï¼ˆlogging.StreamHandlerï¼‰, å®ƒå°±ä¼šæŠŠæ—¥å¿—è¾“å‡ºåˆ°ç»ˆç«¯ã€‚ ä½ è¦æ˜¯å®šä¹‰ä¸€ä¸ªæ–‡ä»¶å¤„ç†å™¨ï¼ˆlogging.FileHandlerï¼‰ï¼Œ å®ƒå°±ä¼šè‡ªåŠ¨æŠŠæ—¥å¿—ä¿å­˜åˆ°æ–‡ä»¶ä¸­ï¼ŒåšæŒä¹…åŒ– ç»¼åˆæ¡ˆä¾‹ï¼š ä¸šåŠ¡éœ€æ±‚å¦‚ä¸‹ï¼ˆéšä¾¿ä¸¾ä¸ªæ¡ˆä¾‹ï¼Œä¸ä¸€å®šæœ‰ç”¨ï¼‰ï¼š æ¯” DEBUG(å¼º)ï¼Œ ä½†åˆæ¯” WARNING(å¼±) ï¼Œ(ä¸åŒ…æ‹¬ WARNING) çš„è¿™ç±»æ—¥å¿—ï¼Œåªè¾“å‡ºåˆ°ç»ˆç«¯ã€‚ è¿™ç±»æ—¥å¿—è¾“å‡ºæ ¼å¼æ— è¦æ±‚ æ¯” WARNINGï¼ˆå¼ºï¼‰ (åŒ…æ‹¬ WARNING )çš„è¿™ç±»æ—¥å¿—ï¼Œ è¾“å‡ºåˆ° ç»ˆç«¯å’Œæ–‡ä»¶ å„ä¸€ä»½ã€‚ è¿™ç±»æ—¥å¿—è¾“å‡ºæ ¼å¼æœ‰è¦æ±‚ï¼Œæ ¼å¼ä¸ºï¼š [æ—¥æœŸ] [æ‰€åœ¨æ–‡ä»¶å: ä»£ç æ‰€åœ¨è¡Œ] [æ—¥å¿—çº§åˆ«] =&gt; æ—¥å¿—å†…å®¹ ä»£ç å¦‚ä¸‹ï¼ˆè‡ªå·±ä½¿ç”¨çš„è¯ï¼Œå°è£…ä¸€ä¸‹æ¯”è¾ƒå¥½ï¼‰ï¼š import logging # æ—¥å¿—ç­‰çº§æ’åºï¼ˆå¼±-&gt; å¼ºï¼‰ï¼š DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; FATAL fmt = '[%(asctime)s] [%(filename)s: %(lineno)d] [%(levelname)s] =&gt; %(message)s' # æ ¼å¼ file_formatter = logging.Formatter(fmt=fmt) # å®šä¹‰æ ¼å¼å™¨ï¼Œ æŠŠæ ¼å¼å¡è¿›æ¥ file_handler = logging.FileHandler('mylog.log', mode='a', encoding='utf-8') # å®šä¹‰æ–‡ä»¶å¤„ç†å™¨ file_handler.setFormatter(fmt=file_formatter) # ç»™æ–‡ä»¶å¤„ç†å™¨è®¾ç½® ä¸€ä¸ª æ ¼å¼å™¨ file_handler.setLevel('WARNING') # ç»™æ­¤å¤„ç†å™¨è®¾ç½® æ—¥å¿—ç­‰çº§ console_handler = logging.StreamHandler() # å®šä¹‰æµå¤„ç†å™¨ï¼Œç”¨äºè¾“å‡ºåˆ°ç»ˆç«¯ # StreamHandleræœªè®¾ç½®æ ¼å¼å™¨ï¼Œå®ƒä¼šé»˜è®¤ç»™ä½ è®¾ç½®ä¸€ä¸ª %(message)sï¼Œå³åªæœ‰æ—¥å¿—å†…å®¹ï¼Œæ²¡æœ‰æ—¥æœŸæ–‡ä»¶åç­‰ console_handler.setLevel('DEBUG') # ç»™æµå¤„ç†å™¨è®¾ç½® æ—¥å¿—ç­‰çº§ log = logging.getLogger(name='file_log') # logæ± ä¸­å–å‡ºä¸€ä¸ªlog(è‹¥æ²¡æœ‰åˆ™æ–°å»º) log.addHandler(file_handler) # æ·»åŠ ä¸€ä¸ªæ–‡ä»¶å¤„ç†å™¨ï¼ˆæ ¼å¼åŒ– è¾“å‡ºåˆ° æ–‡ä»¶ï¼‰ log.addHandler(console_handler) # å†æ·»åŠ ä¸€ä¸ªæµå¤„ç†å™¨ï¼ˆæ— æ ¼å¼ è¾“å‡ºåˆ° ç»ˆç«¯ï¼‰ log.info('æˆ‘åªä¼šè¾“å‡ºåˆ°ç»ˆç«¯') # å› ä¸º infoåªæ¯” console_handler è®¾ç½®çš„ DEBUGå¼º log.error('æˆ‘æ—¢ä¼šè¾“å‡ºåˆ°ç»ˆç«¯ï¼Œ åˆä¼šè¾“å‡ºåˆ°æ–‡ä»¶') # å› ä¸ºerror æ¯” console_handler è®¾ç½®çš„ DEBUG å¼ºï¼Œ åŒæ—¶ error ä¹Ÿæ¯” file_handler è®¾ç½®çš„ WARNING å¼º è¿è¡Œç»“æœï¼š ç»ˆç«¯è¾“å‡ºï¼š &gt;&gt; æˆ‘åªä¼šè¾“å‡ºåˆ°ç»ˆç«¯ æˆ‘æ—¢ä¼šè¾“å‡ºåˆ°ç»ˆç«¯ï¼Œ åˆä¼šè¾“å‡ºåˆ°æ–‡ä»¶ mylog.log æ–‡ä»¶ä¸­ï¼š [2019-09-10 23:54:59,055] [logging11.py: 20] [ERROR] =&gt; æˆ‘æ—¢ä¼šè¾“å‡ºåˆ°ç»ˆç«¯ï¼Œ åˆä¼šè¾“å‡ºåˆ°æ–‡ä»¶ ----------------------åä¸½åˆ†å‰²çº¿---------------- æŠ•æœºå–å·§æ–¹å¼ ï¼ˆä¸æ¨èï¼Œè¿™é‡Œå¼€å§‹å¾€åï¼Œå¯ä¸çœ‹ï¼‰ è¿™ç§æ–¹å¼åªæ–¹ä¾¿äº†ä¸€ç‚¹ç‚¹ï¼Œä½†ä¸çµæ´»ã€‚ å‰é¢æˆ‘ä»¬èŠ±äº†å¥½å¤§åŠ›æ°”ï¼Œ å…ˆæ˜¯å®šä¹‰äº†ä¸€ä¸ª æ ¼å¼å™¨ åˆæ˜¯å®šä¹‰äº†ä¸€ä¸ª æµå¤„ç†å™¨ å’Œ æ–‡ä»¶å¤„ç†å™¨ Loggeræ± ä¸­ï¼Œå®ä¾‹åŒ–ä¸€ä¸ª Logger å¹¶ä¸”æŠŠä»–ä»¬å„ç§æ‹¼è£…ï¼Œ è®¾ç½®æ—¥å¿—ç­‰çº§ã€‚ç­‰æ“ä½œ ï¼ˆè™½ç„¶çœ‹èµ·æ¥å¾ˆå¤šã€‚å…¶å®ä½ æ‹é€šäº†ã€‚çœŸçš„ä¸å¤æ‚ï¼‰ å…¶å® loggingä½“ç³»ä¸­ï¼Œ æœ‰ä¸€ä¸ªé»˜è®¤åˆå§‹çš„ Loggerï¼Œ å«åš root Logger. æˆ‘ä»¬ä¸éœ€è¦å®ä¾‹åŒ–å®ƒï¼Œä¹Ÿä¸éœ€è¦å®ä¾‹åŒ–&quot;æ ¼å¼å™¨&quot;ï¼Œ ä¹Ÿä¸éœ€è¦å®ä¾‹åŒ–æ§åˆ¶å™¨ã€‚ ä¸€è¡ŒAPIå°±å¯ä»¥ä½¿ç”¨å®ƒ (é»˜è®¤æ˜¯è¾“å‡ºåˆ°ç»ˆç«¯çš„)ï¼š import logging fmt = '[%(asctime)s] [%(filename)s: %(lineno)d] [%(levelname)s] =&gt; %(message)s' # æ ¼å¼ logging.basicConfig( # é»˜è®¤ä½¿ç”¨çš„å°±æ˜¯ root Logger level='DEBUG', # è®¾ç½®æ—¥å¿—ç­‰çº§ä¸ºDEBUG format=fmt, # è®¾ç½®æ ¼å¼ ) logging.info('æˆ‘åªä¼šè¾“å‡ºåˆ°ç»ˆç«¯') è¿è¡Œç»“æœï¼š &gt;&gt; [2019-09-11 00:15:55,219] [logging11.py: 30] [INFO] =&gt; æˆ‘åªä¼šè¾“å‡ºåˆ°ç»ˆç«¯ å¦‚æœæƒ³è¾“å‡ºåˆ°æ–‡ä»¶ï¼Œé‚£ä¹ˆåªéœ€åŠ  filename å’Œ filemode ä¸¤ä¸ªå‚æ•°å³å¯ï¼š import logging fmt = '[%(asctime)s] [%(filename)s: %(lineno)d] [%(levelname)s] =&gt; %(message)s' # æ ¼å¼ logging.basicConfig( level='DEBUG', format=fmt, filename='mylog.log', # æ–‡ä»¶å filemode='a' # æ–‡ä»¶æ“ä½œç¬¦ ) è¿è¡Œç»“æœï¼š mylog.logæ–‡ä»¶: [2019-09-11 00:20:22,396] [logging11.py: 32] [INFO] =&gt; ï¿½ï¿½Ö»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Õ¶ï¿½ ä½†ä½ å‘ç°æ²¡ï¼Œå¾€æ–‡ä»¶é‡Œé¢è¾“å‡ºä¹±ç äº†ï¼Œ ç”¨è€³æœµéƒ½èƒ½æƒ³å‡ºæ¥ï¼Œæˆ‘ä»¬æ²¡æœ‰é…ç½® encodingã€‚ã€‚ã€‚ ä½†æ˜¯ï¼Œæˆ‘å‘Šè¯‰ä½ ï¼Œ basicConfig() æ˜¯æ²¡æœ‰ encodingå‚æ•°çš„ã€‚ é‚£å’‹æ•´ ï¼Ÿï¼Ÿ ä½†å®ƒæœ‰ä¸ªå‚æ•°å«åš handlersï¼Œhandlersç†Ÿæ‚‰å§ï¼Œæ²¡é”™å°±æ˜¯æˆ‘ä»¬ä¸Šé¢è®²çš„ &quot;å¤„ç†å™¨&quot;, å¤æ•°è¯´æ˜å¯ä»¥ä¼ å¤šä¸ª logging.basicConfig( level='DEBUG', format=fmt, handlers=[ logging.FileHandler(filename='mylog.log',mode='a',encoding='utf-8') ] # çœ‹è¿™é‡Œè¿™ä¸ªå¤„ç†å™¨çš„å®šä¹‰æ–¹æ³•ï¼Œå’Œä¹‹å‰è®²è¿‡çš„ä¸€æ¨¡ä¸€æ ·ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥é… encoding ) # è¿™æ ·å°±ä¸ä¼šä¹±ç äº† Note: ä»¥ä¸Šå°±æ˜¯ç”¨ logging.baseConfig() ç®€å•æ—¥å¿—å®ç° è¯´äº†å®ƒæ˜¯æŠ•æœºå–å·§ï¼Œå› ä¸ºé™¤äº†æ–‡ä»¶ä¹±ç æœ‰é—®é¢˜ä¹‹å¤–ï¼Œ å®ƒè¿˜æ¬ ç¼ºçµæ´»æ€§ã€‚ æ¯”å¦‚ä½ æƒ³æƒ³å¯¹ä¸åŒçº§åˆ«çš„æ—¥å¿—ï¼Œç”¨ä¸åŒæ ¼å¼è¾“å‡ºå‡ºæ¥ã€‚è¿™æ—¶ä½ å•ç”¨basicConfigä¸€è¡Œæ˜¯æä¸å®šçš„ã€‚ æ‰€ä»¥è¿˜æ˜¯æ¨èç”¨ getLogger()é‚£å¥—ç»„åˆã€‚ ç»“æŸè¯­ loggingæ¨¡å—å…¶å®è¿˜æœ‰å¾ˆå¤šå¾ˆå¤šåŠŸèƒ½ï¼š è¿‡æ»¤å™¨ï¼šï¼ˆå…¶å®è¿˜æœ‰ä¸ªè¿™ä¸ªç»„ä»¶ï¼Œä½†æˆ‘æ²¡ç”¨è¿‡ï¼Œå°±æ²¡è¯´ï¼‰ æ ¼å¼å™¨ï¼šï¼ˆå‰é¢ç»™äº†å®˜æ¡£å¤§å…¨ï¼Œé‡Œé¢è¿˜æœ‰æ ¹æ®è¿›ç¨‹ã€çº¿ç¨‹çš„(PIDï¼ŒTID, tName,pName)ç­‰æ ¼å¼æ¥è¾“å‡ºæ—¥å¿—ã€‚ï¼‰ æ§åˆ¶å™¨ï¼šï¼ˆæˆ‘åªè¯´äº† stream å’Œ fileï¼‰,å…¶å®è¿˜æœ‰å¾ˆå¤šï¼Œå®ƒä»¬éƒ½åœ¨logging.handlersæ¨¡å—ä¸‹ï¼š from logging.handlers import ( RotatingFileHandler, # é€šè¿‡è®¾ç½®æ–‡ä»¶å¤§å°é˜ˆå€¼ï¼Œè¶…å‡ºè¿™ä¸ªé˜ˆå€¼ï¼Œå°±ä¼šå°†æ—¥å¿—è½¬å­˜æ–°æ–‡ä»¶ TimedRotatingFileHandler, # è®¾ç½®æ—¶é—´é—´éš”ï¼Œæ¯è¿‡è¿™ä¸ªé—´éš”ï¼Œå°±ä¼šå°†æ—¥å¿—è½¬å­˜æ–°æ–‡ä»¶ HTTPHandler, # é€šè¿‡HTTPåè®®å°†æ—¥å¿—è¾“å‡ºåˆ°è¿œç¨‹æœåŠ¡å™¨ï¼Œï¼ˆåªæ”¯æŒ GET å’Œ POSTï¼‰ SMTPHandler, # é€šè¿‡SMTPåè®®ï¼Œå°†æ—¥å¿—è¾“å‡ºåˆ°è¿œç¨‹é‚®ç®±äº† SocketHandler, # é€šè¿‡TCPåè®®å‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨ã€‚ã€‚ã€‚ DatagramHandler, # é€šè¿‡UDPåè®®å‘é€åˆ°è¿œç¨‹æœåŠ¡å™¨ã€‚ã€‚ã€‚ QueueHandler, # å‘åˆ°é˜Ÿåˆ—ä¸­ï¼ˆå¦‚æœæƒ³å‘RabbitMQä¹‹ç±»çš„ï¼Œå¯ä»¥å»githubæ‰¾åˆ«äººå†™çš„æˆå“ï¼‰ ) # è¿™äº›ç”¨æ³•ä¹Ÿå¾ˆç®€å•ï¼Œçœ‹å®˜æ¡£ï¼Œæˆ–è€…ç”¨Pycharm ctrl+å·¦é”®ç‚¹è¿›æºç ï¼Œçœ‹ä¸€ä¸‹__init__()å‚æ•°å®ä¾‹åŒ–å³å¯ # å®ä¾‹åŒ–åï¼Œç”¨ xxx.addHandler() æ·»åŠ åˆ° loggerå³å¯ä½¿ç”¨ ï¼ˆå’Œå‰é¢è®²çš„ fileå’Œstreamç”¨æ³•ä¸€æ ·ï¼‰ è¿˜å¯åšæˆå„ç±»å‹é…ç½®æ–‡ä»¶ä½¿ç”¨ï¼šhttps://docs.python.org/3/library/logging.config.html#logging.config.fileConfig å®˜æ¡£æ¡ˆä¾‹å¤§å…¨ï¼šhttps://docs.python.org/3/howto/logging-cookbook.html#logging-cookbook ","link":"https://cythonlin.github.io/post/py-greater-python-logging-mo-kuai-ri-zhi-yuan-li-jie-xi-ji-shi-yong/"},{"title":"PY => Python-ORMä¹‹peeweeï¼šæ’ä»¶æ‹“å±•ï¼ˆä¸‰ï¼‰","content":"å£°æ˜ æœ¬ç¯‡ä¸»è¦è®²ï¼Œå…³äºpeeweeçš„ä¸€äº›æ‹“å±•ï¼š åŒ…æ‹¬æ–°å¼CRUD-æ•°æ®å¯¼å…¥å¯¼å‡º-ä¿¡å·-æ•°æ®åº“åå‘ç”Ÿæˆæ¨¡å‹ã€‚ æ‰©å±•å®˜æ¡£ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/playhouse.html ä½œè€…å‹å¥½ ä¸ peeweeæé—®æ–¹å¼ å½“æˆ‘ç”¨åˆ°æ‹“å±•æ¨¡å—çš„ æ–°CRUDæ—¶ï¼Œæ–‡æ¡£ç»™çš„å†…å®¹å°‘ä¹‹åˆå°‘ã€‚ å› ä¸ºæ‹“å±•çš„æ–°CRUDæ˜¯çœŸçš„æ–¹ä¾¿å¥½ç”¨ï¼Œå’Œï¼ˆPyMongoçš„ç”¨æ³•å·®ä¸å¤šï¼‰ ä½†æ˜¯åŠŸèƒ½å´ä¸å…¨ã€‚å¹¶ä¸”ä¸æˆ‘ä»¬ç¬¬äºŒç¯‡ï¼Œè®²çš„CRUDåˆä¸å…¼å®¹ã€‚ æ‰€ä»¥åœ¨éš¾ä»¥å–èˆä¹‹é™…ï¼Œ æˆ‘é€‰æ‹©äº†æé—®ã€‚ peeweeä½œè€…åœ¨å®˜æ¡£ä¸­è¯¦ç»†è¯´åˆ°ã€‚ å¦‚æœä½ æœ‰é—®é¢˜æˆ–ç–‘æƒ‘å¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ç§æ–¹å¼ï¼š å»stack overflow æé—®é¢˜ï¼Œæ ‡ç­¾æ‰“ä¸Špython å’Œ peeweeã€‚ peeweeä½œè€…ä¼šä¸å®šæœŸæµè§ˆå¹¶å›ç­”ä½ ç»™ä½ å¸®åŠ©ã€‚ å»https://groups.google.com/group/peewee-ormï¼Œè¿™ä¸ªgoogleç¾¤ç»„æé—®ã€‚ï¼ˆéœ€è¦kexue ä¸Š ç½‘ï¼‰ æ‰€ä»¥æˆ‘é€‰æ‹©äº†å» stack overflowæé—®ã€‚ æˆ‘é—®é¢˜å‘å‡ºå»ï¼Œåº”è¯¥æ˜¯ä¸åˆ°ä¸€å°æ—¶ï¼Œä½œè€…å°±ç»™å›å¤äº†ï¼Œæˆ‘æƒŠäº†ã€‚ã€‚ï¼ˆå‘å®Œæˆ‘å°±ç¡è§‰äº†ï¼Œç¬¬äºŒå¤©èµ·æ¥æ‰çœ‹åˆ°ï¼‰ æé—®å†…å®¹ä¼ é€é—¨å¦‚ä¸‹ï¼šhttps://stackoverflow.com/questions/57774747/is-there-liking-query-operator-join-query-in-playhouse-extensions-to-peewee/57776856#57776856 ä½œè€…å›å¤çš„æ„æ€æ˜¯ï¼š æ‹“å±•çš„playhouse.dataseté‡Œé¢çš„DataSet çš„ æ–°å¼CRUD API çš„æ¶‰åŠåˆè¡·å°±æ˜¯ä¸ºäº†ç®€å•ä½¿ç”¨ã€‚ ä½†å®ƒå¹¶ä¸ä¼šä»£æ›¿ æ ¸å¿ƒCRUD (å°±æ˜¯æˆ‘ä»¬ç¬¬äºŒç¯‡è®²çš„CRUD) å¹¶ä¸”ï¼Œå®ƒè®¾è®¡çš„åˆè¡·å°±æ˜¯è®©æˆ‘ä»¬å¯ä»¥æ–¹ä¾¿ ï¼ˆjson/csvæ ¼å¼çš„æ•°æ® ä¸ æ•°æ®åº“çš„æ•°æ® ç›¸äº’å¯¼å…¥æˆ–å¯¼å‡ºï¼‰ æˆ‘è¯´çš„è¿™äº›æ“ä½œï¼Œä¸‹é¢éƒ½ä¼šå†™åˆ°ã€‚ æ‰€ä»¥è¯´ï¼Œè¯¥æé—®å°±æé—®ï¼Œä½ æ”¶è·äº†peeweeçŸ¥è¯†çš„åŒæ—¶ï¼Œåˆèƒ½å¢åŠ peeweeçš„ç¤¾åŒºæ´»è·ƒåº¦ã€‚ playhouseæ‰©å±•æ¨¡å—çš„DataSet æˆ‘ä»¬å‰2ç¯‡æ–‡ç« å°±ç”¨äº†è¿™ä¸€è¡Œä»£ç å°±å¯ä»¥å¯¼å…¥æ‰€æœ‰ï¼Œå› ä¸ºæ‰€æœ‰åŸºæœ¬åŠŸèƒ½éƒ½é›†æˆåœ¨ peeweeä¸‹ from peewee import * ä½†æ¥ä¸‹æ¥è®²çš„æ˜¯æ‰©å±•ï¼Œè€Œæ‰©å±•å°±æ˜¯æ–°åˆ†æ”¯äº†ï¼Œä¸peeweeæ²¡å…³ç³»äº† from playhouse.dataset import DataSet æ•°æ®åº“è¿æ¥ è¿›å…¥æ­£é¢˜ï¼Œè¿æ¥MySQL,ä½ å¯ä»¥æœ‰ä¸¤ç§è¿æ¥æ–¹å¼ï¼š # å¼ºè°ƒä¸€ä¸‹ï¼Œå®˜æ¡£ä¸­ç»™å‡º DataSet æ˜¯åœ¨ playhouse.dataset ä¸‹ # æˆ‘å†å¼ºè°ƒä¸€ä¸‹ï¼Œ æ˜¯ DataSet ï¼Œ è€Œä¸æ˜¯ DataBase !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! from playhouse.dataset import DataSet db = DataSet('mysql://root:Jilin963389970@39.107.86.223:3306/test') å®˜æ¡£-æ‰€æœ‰æ•°æ®åº“çš„è¿æ¥ç¤ºä¾‹ï¼š http://docs.peewee-orm.com/en/latest/peewee/playhouse.html#db-url æ•°æ®åº“ä¸è¡¨çš„åŸºæœ¬æ“ä½œ åˆ›å»ºè¡¨ owner = db['owner'] # åé¢è¿™ä¸ª&quot;owner&quot; æ˜¯ä½ è‡ªå·±æŒ‡å®šçš„key, ä¹Ÿå°±æ˜¯ä½ æŒ‡å®šçš„ &quot;è¡¨å&quot; # å‰é¢è¿™ä¸ª owner å˜é‡ç”¨æ¥æ¥å—è¿”å›ç»“æœï¼Œå®ƒå°±æ˜¯ä¸€ä¸ªå®ä¾‹åŒ–çš„è¡¨å¯¹è±¡ã€‚ ä¸€ä¼šæˆ‘ä»¬ç”¨å®ƒåšä¸€ç³»åˆ—æ“ä½œ æˆ‘è®²å®Œäº†ï¼Œè¡¨å·²ç»åˆ›å»ºå¥½äº†, (ä½ è„¸ä¸Šæœ‰æ²¡æœ‰å‡ºç°é—®å·ã€‚ã€‚) æƒŠä¸æƒŠå–œï¼Œæ„ä¸æ„å¤–ï¼Ÿï¼Ÿ é¢˜å¤–è¯ï¼š å¦‚æœä½ ç”¨è¿‡ï¼Œpymongoæ¥ä½¿ç”¨MongoDB, é‚£è¿™ç§åŸç†åº”è¯¥ä¸é™Œç”Ÿçš„ã€‚ é‚£ owner = db['owner'] è¿™ä¸€è¡Œä»£ç ç©¶ç«Ÿåšäº†ä»€ä¹ˆï¼Ÿ 1. å®ƒä¼šå»æ•°æ®åº“ï¼Œåˆ›å»ºä¸€ä¸ª åä¸º ownerçš„è¡¨ ï¼ˆæœ‰åˆ™è¿”å›ï¼Œæ— åˆ™åˆ›å»ºï¼‰ 2. ä¸ä½†åˆ›å»ºäº†è¡¨ï¼Œ è€Œä¸”å®ƒè¿˜åœ¨è¡¨ä¸­ è‡ªåŠ¨åˆ›å»ºäº†ä¸€ä¸ª id (intå‹ï¼Œä¸»é”®ï¼Œè‡ªå¢) åˆ—å‡ºè¡¨ &amp; åˆ—å‡ºå­—æ®µ åˆ—å‡ºè¡¨ï¼ˆç­‰ä»·äºMySQLä¸­çš„å‘½ä»¤ï¼š show tablesï¼‰ print(db.tables) &gt;&gt; ['new_owner', 'owner'] åˆ—å‡ºè¡¨ä¸­çš„å­—æ®µï¼ˆç­‰ä»·äºMySQLä¸­çš„å‘½ä»¤ï¼š show columnsï¼‰ï¼š table = db['owner'] # å…ˆé€‰æ‹©ä¸€ä¸ªè¡¨ã€‚ print(table.columns) &gt;&gt; ['id', 'name', 'age', 'gender', 'hobby', 'nickname'] ç»Ÿè®¡è¡¨ä¸­è®°å½•æ•°ï¼ˆå°±æ˜¯è¡Œæ•°ï¼‰ print(len(table)) &gt;&gt; 10 äº‹åŠ¡(transaction) å…¶å®æˆ‘åœ¨ç¬¬ä¸€ç¯‡ï¼Œå·²ç»è®²è¿‡äº‹åŠ¡äº† äº‹åŠ¡-ä¼ é€é—¨ï¼š https://segmentfault.com/a/1190000020265149#articleHeader11 å½“æ—¶æˆ‘æ˜¯ç”¨çš„ MySQLDatabase è¿æ¥å·¥å…·ã€‚ æˆ‘åªè®²äº†ä¸€ç§ä½¿ç”¨æ–¹æ³•ï¼š db.atomic() å…¶å®è¿˜æœ‰å¦å¤–ä¸€ç§ä½¿ç”¨æ–¹æ³•ï¼Œå°±æ˜¯ db.transaction() è¿™ä¸¤ç§æ–¹æ³•å·®ä¸å¤šï¼Œ ä½ å¯ä»¥è¿™ä¹ˆè®¤ä¸ºï¼Œå°±æ˜¯æŠŠ atomic å’Œ transaction å•è¯æ¢ä¸€ä¸‹ï¼Œç”¨æ³•ä¸€æ¨¡ä¸€æ · è€Œç°åœ¨æˆ‘ä»¬æ˜¯ä½¿ç”¨çš„ DataSet è¿æ¥å·¥å…· ï¼ˆå¼€ç¯‡æˆ‘å¼ºè°ƒè¿‡ï¼‰ï¼š db = DataSet(....) DataSet åªæä¾›ç»™æˆ‘ä»¬ transaction()è¿™ç§ç”¨æ³•ï¼Œ è€Œæ²¡æœ‰æä¾› atomic() ä½†æˆ‘è¯´äº†ï¼Œè¿™ä¸¤ç§ç”¨æ³•ä½ å¯ä»¥è®¤ä¸ºåªæ˜¯å•è¯æ¢äº†ä¸€ä¸‹ã€‚ç”¨æ³•ä¸€æ ·çš„ã€‚ å› æ­¤ä½ å®Œå…¨å¯ä»¥ç›´æ¥çœ‹æˆ‘å‰é¢ç»™çš„ &quot;äº‹åŠ¡-ä¼ é€é—¨&quot; è¿™ç¯‡ä¹‹å‰å†™çš„æ–‡ç« ã€‚ CRUD (è¿™ç§CRUDæ–¹å¼æˆ‘ä¸å¤ªæ¨è) æˆ‘ä»¬ç¬¬äºŒç« è¯¦ç»†è®²è¿‡å…¨å¥—çš„CRUDï¼Œå…¶å®é‚£å°±å¤Ÿäº†ã€‚ è€Œæœ¬ç« è¿™ä¸ªæ‹“å±•çš„CRUDï¼Œå®Œå…¨æ˜¯å¦ä¸€ç§æ¨¡å¼ã€‚å¦ä¸€ä¸ªæ¨¡å—çš„ä¸œè¥¿ã€‚ ä½†æˆ‘ä¸æ¨èç”¨ï¼Œå› ä¸ºæ„Ÿè§‰è¿˜æ²¡æˆç†Ÿï¼Œä¸å®Œå–„ï¼ˆå¾ˆå¤šCRUDç»†èŠ‚åŠŸèƒ½æ²¡æœ‰ï¼‰ï¼Œ å®˜æ¡£ç»™çš„ä¹Ÿç²—ç•¥ã€‚ æ­¤å¤–ï¼Œä¸‹é¢æ¶‰åŠåˆ°ä¸ æœ¬å¥—CRUDæœ‰å…³è”çš„æ“ä½œï¼Œ æˆ‘ä¸‹é¢ç»Ÿç§°ä¸º &quot;æ‹“å±•çš„CRUD&quot; å¢åŠ æ•°æ® owner.insert(name='Alice', age=20) owner.insert(name='Zhang', age=18) è¿™çœ‹èµ·æ¥æ²¡ä»€ä¹ˆé—®é¢˜ï¼Œæˆ‘ä»¬ä¹‹å‰è®²çš„å·®ä¸å¤šã€‚ä½†ä½ æœ‰æ²¡æœ‰æ„è¯†åˆ°å‡ ä¸ªé—®é¢˜ï¼š 1. ownerè¡¨ æ˜¯è‡ªåŠ¨åˆ›å»ºå‡ºæ¥çš„ï¼Œå®ƒåªæœ‰ä¸€ä¸ªä¸»é”®ã€‚ 2. æˆ‘ä»¬æ²¡æœ‰åˆ›å»º name å’Œ age å­—æ®µ 3. æ—¢ç„¶æ²¡æœ‰åˆ›å»ºå­—æ®µï¼Œä¸ºä»€ä¹ˆå¯ä»¥æ’å…¥æ•°æ®ï¼Ÿï¼Ÿï¼Ÿ è§£æƒ‘ï¼š 1. æˆ‘ä»¬è°ƒç”¨ç¬¬ä¸€ä¸ª insert()çš„æ—¶å€™, å®ƒå°±ä¼šè‡ªåŠ¨å¸®æˆ‘ä»¬ å»æ•°æ®åº“åˆ›å»ºå¯¹åº”å‚æ•°çš„å­—æ®µï¼ˆå›ºå®šäº†ï¼‰: æ•°æ®ç±»å‹å…³ç³»å¯¹ç…§å¦‚ä¸‹ï¼š pythonæ•°æ®ç±»å‹ MySQLæ•°æ®ç±»å‹ int int(11) å…è®¸ä¸ºç©º é»˜è®¤å€¼æœªç©º str text å…è®¸ä¸ºç©º é»˜è®¤å€¼æœªç©º é‚£peeweeä¸ºæˆ‘ä»¬è‡ªåŠ¨åˆ›å»ºçš„å­—æ®µå¦‚ä¸‹ï¼š +-------+---------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+---------+------+-----+---------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | name | text | YES | | NULL | | | age | int(11) | YES | | NULL | | +-------+---------+------+-----+---------+----------------+ 2. åˆ›å»ºåï¼Œå®ƒè¿˜ä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬æ ¹æ®æˆ‘ä»¬ä¼ çš„å‚æ•°ï¼Œ å¯¹åº”çš„æ’å…¥ å€¼ 3. ç‰¹åˆ«æ³¨æ„ï¼Œç‰¹åˆ«æ³¨æ„ï¼š å‡å¦‚æˆ‘ä»¬æ’å…¥è¿™æ ·ä¸€æ¡é”™è¯¯&quot;ç±»å‹&quot;çš„æ•°æ®: owner.insert(name=18, age=18) # æŒ‰ç†è¯´nameåº”è¯¥ä¸º textå‹ï¼Œageåº”è¯¥ä¸ºæ•´å½¢ è™½ç„¶æˆ‘ä»¬nameç»™çš„æ•´å½¢ï¼Œä½†ï¼Œpeeweeå†…éƒ¨ä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬è½¬ä¸ºå°† nameè½¬ä¸ºå­—ç¬¦ä¸²ç±»å‹ åŒç† å­—ç¬¦ä¸²ä¹Ÿä¼šè‡ªåŠ¨å¸®æˆ‘ä»¬è½¬ä¸ºæ•´å½¢ï¼ˆå¯¹åº”æ•°æ®åº“ä¸­çš„ç±»å‹ï¼‰ã€‚ ä½†'abc'è¿™æ ·çš„è½¬ä¸äº†å“¦ ä¿®æ”¹æ•°æ® owner.update(name='Alice', age='50') è¿™è¡Œä»£ç ä¸ºæˆ‘ä»¬åšäº†å¦‚ä¸‹äº‹æƒ…ï¼š å°†&quot;æ‰€æœ‰&quot;è¡Œæ•°æ®ï¼Œ nameæ”¹ä¸º Alice, ageæ”¹ä¸º 50 owner.update(name='Alice', age='50',columns=['name']) å¤šåŠ äº†ä¸€ä¸ª columnså‚æ•°ï¼Œä¸ºæˆ‘ä»¬åšäº†å¦‚ä¸‹äº‹æƒ…ï¼š å…ˆçœ‹æœ€åçš„ columns=['name'] ï¼š å…¶å®ä»–å°±ç­‰ä»·äº where name = xxx å…¶å®æ„æ€å°±æ˜¯ä»¥ &quot;nameå­—æ®µä¸ºæ¡ä»¶&quot; ä¿®æ”¹æ•°æ®ï¼š(è€Œnameæˆ‘ä»¬å·²ç»ç»™äº† = 'Alice') å…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼š 1. æ‰¾åˆ° name = Aliceï¼Œ çš„æ‰€æœ‰è®°å½• 2. å°† name= Alice çš„è®°å½• nameæ”¹ä¸ºAliceï¼ˆç›¸å½“äºæ²¡å˜ï¼‰, age æ”¹ä¸º 50 owner.update(gender='man') ä½ ä»”ç»†çœ‹çœ‹ï¼Œæˆ‘ä»¬ä¹‹å‰æ˜¯æ²¡æœ‰ genderè¿™ä¸ªå­—æ®µçš„ã€‚ å¦‚æœæ›´æ–°æœªåˆ›å»ºå­—æ®µï¼Œå®ƒä¼šä¸ºæˆ‘ä»¬åšå¦‚ä¸‹äº‹æƒ…ï¼š 1. å®ƒä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬åœ¨è¿™ä¸ªè¡¨ä¸­åˆ›å»ºä¸€ä¸ª è¿™ä¸ª &quot;genderæ–°å­—æ®µ&quot; 2. å¹¶ä¸”ï¼Œ&quot;æ‰€æœ‰è¡Œè®°å½•&quot; éƒ½ä¼šè¢«èµ‹äºˆæˆ &quot;man&quot; å€¼ã€‚ æ³¨æ„æ˜¯ æ‰€æœ‰è¡Œï¼Œæ‰€æœ‰è¡Œï¼Œæ‰€æœ‰è¡Œ 3. å¦‚æœä½ åªæƒ³&quot;ç»™æŒ‡å®šè®°å½•éƒ¨åˆ†&quot;èµ‹äºˆ &quot;man&quot;å€¼ï¼Œ é‚£ä½ å¯ä»¥åŠ ä¸€ä¸ªæˆ‘ä»¬ä¹‹å‰è¯´çš„ &quot;columnså‚æ•°&quot; è‡ªç„¶è€Œç„¶åœ°ï¼Œå…¶ä»– &quot;æœªé€šè¿‡ columnsæŒ‡å®šçš„è®°å½•&quot; å°±ä¼šè¢«èµ‹äºˆ NULL å€¼ã€‚ æŸ¥è¯¢æ•°æ® é¦–å…ˆè¯´ä¸€ä¸‹å®ƒè¿™ä¸ªæŸ¥è¯¢çš„ç‰¹è‰²ã€‚ å¯ä»¥å¯¹æŸ¥è¯¢ç»“æœè¿›è¡Œ åˆ‡ç‰‡ï¼Œç´¢å¼•æ“ä½œï¼ˆå’Œpythonçš„åˆ‡ç‰‡å’Œç´¢å¼•æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼‰ ç´¢å¼•ä¹‹åè‡ªåŠ¨è½¬ä¸º åˆ—è¡¨åµŒå­—å…¸ [{}, {}] ä¸‹é¢3ç§æ–¹å¼ï¼Œä¹Ÿéƒ½æ”¯æŒ åˆ‡ç‰‡å’Œç´¢å¼•ï¼ˆæˆ‘å°±ä¸ä¸¾ä¾‹äº†ï¼Œå¾ˆç®€å•ï¼‰ æ–¹å¼1ï¼šall() è·å–å…¨éƒ¨æ•°æ® owner = db1['owner'] query = owner.all() for obj in query: print(obj) # éå†æ¯æ¡è®°å½•ï¼Œ ç»“æœæ˜¯ å­—å…¸ ç±»å‹ æ–¹å¼2ï¼šfind() æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„æ‰€æœ‰æ•°æ® query = owner.find(name='Tom') # æŸ¥è¯¢åä¸º Tomçš„æ•°æ® for obj in query: print(obj) # éå†æ¯æ¡è®°å½•ï¼Œ ç»“æœæ˜¯ å­—å…¸ ç±»å‹ æ–¹å¼3ï¼šfind_one() æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„ ç¬¬ä¸€æ¡ æ•°æ® print(owner.find_one(name='Tom')) æ³¨æ„ä¸€ä¸‹ï¼Œfind_one æŸ¥å‡ºæ¥ç»“æœå°±æ˜¯ä¸€æ¡å­—å…¸ã€‚ ä¸è¦å†éå†äº†ï¼Œéå†å°±å‡ºäº‹äº†ã€‚ã€‚ã€‚ åˆ é™¤æ•°æ® result = owner.delete(name='Tom') è¯´æ˜ï¼š 1. è‹¥ delete() ä¸æŒ‡å®šå‚æ•°ï¼Œé‚£ä¹ˆå³ä¸ºå…¨éƒ¨åˆ é™¤ã€‚ã€‚æ…ç”¨ 2. è¿”å›å€¼resultçš„å€¼ï¼Œ ä»£è¡¨åˆ é™¤æ•°æ®çš„æ¡æ•° Json/CSVæ•°æ® å¯¼å…¥åˆ°æ•°æ®åº“ï¼ˆåªèƒ½è”ç”¨æ‹“å±•çš„CRUDï¼‰ Jsonå®ä¾‹ æˆ‘åœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª new_owner.jsonï¼Œ å†…å®¹å¦‚ä¸‹ï¼š [ {&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 18}, {&quot;name&quot;: &quot;Zhang&quot;, &quot;age&quot;: 30} ] ä¸»æ–‡ä»¶ä»£ç å¦‚ä¸‹ï¼š new_owner = db['new_owner'] # æ–°å»ºä¸€å¼ è¡¨ï¼Œåä¸º new_owner new_owner.thaw( filename='new_owner.json', # å°±æ˜¯ä¸Šé¢çš„é‚£ä¸ª jsonæ–‡ä»¶ format='json' # æŒ‡å®šæ ¼å¼ä¸ºjson, é»˜è®¤å€¼æ˜¯ csv ) è¿™æ ·å°±å¯¼å…¥å¥½äº†ï¼Œæ•°æ®åº“å†…å®¹å¦‚ä¸‹ï¼š +----+------+-------+ | id | age | name | +----+------+-------+ | 1 | 18 | Alice | | 2 | 30 | Zhang | +----+------+-------+ ç‰¹æ®Šæƒ…å†µåˆ†æï¼š å‡å¦‚åŸºäºä¸Šé¢åˆ›å»ºå¥½çš„æ•°æ®åº“ä¸æ•°æ®ï¼Œ å°†åˆšåˆšçš„jsonæ–‡ä»¶ç¨åŠ æ”¹åŠ¨ï¼ŒåŠ ä¸ª &quot;gender&quot; [ {&quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 18, &quot;gender&quot;: &quot;man&quot;}, {&quot;name&quot;: &quot;Zhang&quot;, &quot;age&quot;: 30} ] å‡å¦‚æˆ‘ä»¬è¿˜æ˜¯ç”¨ä¸Šé¢çš„ä¸€æ¨¡ä¸€æ ·çš„ä¸»æ–‡ä»¶ä»£ç ï¼ˆæˆ‘è¿™é‡Œå°±ä¸é‡å¤å†™äº†ï¼‰ï¼Œå¯¼å…¥åˆšä¿®æ”¹çš„ æ–°jsonæ•°æ®ã€‚ æˆ‘ä»¬åˆ†æä¸€ä¸‹ï¼š æˆ‘è¯´äº†ï¼Œæ˜¯åœ¨åŸæœ‰è¡¨ å’Œ å­—æ®µçš„ åŸºç¡€ä¸Šå»å¯¼å…¥æ–°æ•°æ®ã€‚ ï¼ˆåŸæœ‰æ•°æ®åº“å­—æ®µä¸º name å’Œ ageï¼‰ ä½†æ˜¯ä»Šæ—¶ä¸åŒå¾€æ—¥ã€‚ã€‚ã€‚ æˆ‘ä»¬åˆšåˆšçš„jsonæ–°æ·»åŠ äº†ä¸€ä¸ªï¼Œ genderã€‚ è€ŒåŸæœ‰çš„æ•°æ®åº“ä¸­ï¼Œå¹¶æ²¡æœ‰è¿™ä¸ªå­—æ®µã€‚ å¦‚æœæˆ‘ä»¬è¿˜æ˜¯ç”¨ä¹‹å‰çš„è¿™ä¸ªä»£ç ï¼š new_owner.thaw( filename='new_owner.json', # å°±æ˜¯ä¸Šé¢çš„é‚£ä¸ª jsonæ–‡ä»¶ format='json' # æŒ‡å®šæ ¼å¼ä¸ºjson, é»˜è®¤å€¼æ˜¯ csv ) é‚£ä¹ˆï¼Œpeeweeä¼šè‡ªåŠ¨æŠŠè¿™ä¸ª æ–° gender é”®ï¼ŒåŒæ­¥åˆ°æ•°æ®åº“ï¼Œå¹¶ç”Ÿæˆ æ–°å­—æ®µ gender +----+------+-------+--------+ | id | age | name | gender | +----+------+-------+--------+ | 1 | 18 | Alice | NULL | | 2 | 30 | Zhang | NULL | | 3 | 18 | Alice | man | | 4 | 30 | Zhang | NULL | +----+------+-------+--------+ çœ‹è§äº†æŠŠï¼Œgenderå­—æ®µï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆã€‚ ä½†æ˜¯åœ¨æŸç§æƒ…å†µä¸‹ï¼Œ ä½ å¹¶ä¸æƒ³è®©æ•°æ®åº“ åˆ›å»ºè¿™ä¸ª æ–°å­—æ®µ å‡å¦‚jsonä¸­ &quot;gender&quot; ï¼Œ å®ƒå±äºä¸€ä¸ªè„æ•°æ®ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä»–ï¼Œè€Œæ˜¯å•çº¯çš„æƒ³æ’å…¥ nameå’Œageæ•°æ®ã€‚ é‚£ä¹ˆä½ å¯ä»¥ï¼Œæ·»åŠ ä¸€ä¸ª strict=True å‚æ•°ï¼š new_owner.thaw( filename='new_owner.json', format='json', strict=True # çœ‹è¿™é‡Œï¼Œæ·»åŠ ä¸€ä¸ªè¿™ä¸ª strict=Trueå°±å¥½äº† ) strict=Trueæ„å‘³ç€ï¼Œå®ƒä¼šå¯¹ç…§jsonçš„key ä¸ æ•°æ®åº“çš„å­—æ®µï¼Œ å¹¶ä»¥æ•°æ®åº“çš„å­—æ®µä¸ºä¸»ï¼Œä¸¥æ ¼åŒ¹é…æ’å…¥ã€‚ CSVç¤ºä¾‹ å…¶å®å’Œjsonçš„å‡ ä¹å·®ä¸å¤šï¼Œæ³¨æ„csvæ ¼å¼ï¼Œé€—å·åˆ†éš”ï¼Œè®¾ç½®è¡¨å¤´ã€‚ new_owner.csv å†…å®¹å¦‚ä¸‹: name,age Alice,18 Zhang,30 ä¸»æ–‡ä»¶ä»£ç å¦‚ä¸‹ new_owner.thaw( filename='owner.csv', # format='csv' # æˆ‘è¯´è¿‡ï¼Œformaté»˜è®¤å‚æ•°å°±æ˜¯csvï¼Œæ‰€ä»¥ç»™ä¸ç»™formatå‚æ•°éƒ½è¡Œã€‚ # strict=True # ä¸¥æ ¼åŒ¹é…å­—æ®µæ’å…¥ï¼Œ å’Œä¸Šé¢è®²çš„jsonæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ä½œç”¨ã€‚ ) æœ€åè¯´ä¸ªå°ç»†èŠ‚ï¼Œä¸çŸ¥é“ä½ æœ‰æ²¡æœ‰æ³¨æ„ï¼Œæˆ‘ä»¬jsonå’Œcsvæ–‡ä»¶ï¼Œ éƒ½æ²¡æœ‰æŒ‡å®šidã€‚ è™½ç„¶æ²¡æœ‰æŒ‡å®šï¼Œä½†æ˜¯ peewee åŒæ ·ä¼šä¸ºæˆ‘ä»¬è‡ªåŠ¨åˆ›å»º id (åŒæ ·ä¹Ÿæ˜¯ int(11), ä¸»é”®ï¼Œ è‡ªå¢) æ•°æ®åº“æ•°æ®å¯¼å…¥åˆ°Json/CSVï¼ˆåªèƒ½è”ç”¨æ‹“å±•çš„CRUDï¼‰ å¯¼å…¥éƒ½è¯´å®Œäº†ï¼Œå¯¼å‡ºå°±æ›´ç®€å•äº†ã€‚ã€‚å°±APIå˜ä¸ªåçš„äº‹ï¼š å¯¼å‡ºå•ä¸ªè¡¨çš„å…¨éƒ¨æ•°æ®ï¼š owner = db['owner'] owner.freeze( filename='new_owner.json', format='json', # æŒ‡å®šæ ¼å¼ä¸ºjson, ä½ è¦æ˜¯ä¸æŒ‡å®šï¼Œé»˜è®¤å€¼æ˜¯ csv ) å½“ç„¶ï¼Œè¿™é‡Œæœ‰ä¸ªç‰¹è‰²ï¼Œå¯¼å‡ºæ–¹å¼è¿˜å¯ä»¥ å¯¼å‡ºæŸä¸ªæŸ¥è¯¢ç»“æœï¼ï¼ query = owner.find(name='Tom') db.freeze( query, # æŸ¥è¯¢ç»“æœï¼Œæ³¨æ„è¿™ä¸ªæŸ¥è¯¢ç»“æœï¼Œå¿…é¡»æ˜¯ä¸ªæŸ¥è¯¢é›†ç±»å‹ã€‚ filename='new_owner.json', format='json', # æŒ‡å®šæ ¼å¼ä¸ºjson, ä½ è¦æ˜¯ä¸æŒ‡å®šï¼Œé»˜è®¤å€¼æ˜¯ csv ) ä¸­åœºæš‚åœã€‚ã€‚ã€‚ è‡³æ­¤ï¼Œplayhouse.datasetçš„DataSeté‡Œé¢çš„ æ–°ç‰ˆCRUDï¼ŒåŠå…¶é™„å±åŠŸèƒ½ï¼ˆjsonå¯¼å…¥å¯¼å‡ºç­‰ï¼‰è®²å®Œã€‚ ä¹Ÿè®¸ä½ ä¼šå¾ˆä¸é€‚åº”ã€‚ ï¼ˆè¿™æ–°ç‰ˆçš„CRUDï¼Œå¦‚æœå®åœ¨ä¸èƒ½æŒæ¡ï¼Œå°±å½“äº†è§£å³å¯ï¼‰ æœ€é‡è¦çš„è¿˜æ˜¯ç¬¬äºŒç¯‡æ–‡ç« çš„CRUDï¼šhttps://segmentfault.com/a/1190000020265522 ä»¥ä¸‹è¦è®²çš„ï¼Œå°±æ˜¯ ç¬¬äºŒç¯‡æ–‡ç« è®²çš„ï¼Œæ­£å¸¸çš„ ï¼ˆfrom peewee import * ï¼‰é‡Œé¢çš„ CRUD ç›¸å…³çš„æ“ä½œäº†ã€‚ ä¿¡å·(Signal) å®˜æ–¹åªè®¾å®šäº†å¦‚ä¸‹ 4 ç§ä¿¡å·ï¼š ä¸€ã€pre_saveï¼š ä¿å­˜ä¹‹å‰è°ƒç”¨ äºŒã€post_saveï¼šä¿å­˜ä¹‹åè°ƒç”¨ pre_save å’Œ post_saveåªæ”¯æŒä¸‹é¢ä¸¤ç§APIï¼š 1. create() # åˆ›å»ºæ•°æ® è§¦å‘ï¼š Owner.create(name='Tom') # createåŒ…å«äº† save() ï¼Œæ‰€ä»¥ä¼šè‡ªåŠ¨è§¦å‘ 2. save() # æ›´æ–°æ•°æ® è§¦å‘ï¼š obj = Owner.get(name='Butch') obj.name = 'Alice' obj.save() æ³¨æ„ï¼š ä½ æƒ³ç”¨ä¿å­˜ä¿¡å·ï¼Œå°±å¿…é¡»ç”¨è¿™ä¸¤ç§APIï¼Œ ç”¨ update()æ˜¯ä¸å¥½ä½¿çš„å“¦ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ ä¸‰ã€pre_deleteï¼š åˆ é™¤æ•°æ®ä¹‹å‰è°ƒç”¨ å››ã€post_deleteï¼šåˆ é™¤æ•°æ®ä¹‹åè°ƒç”¨ pre_delete å’Œ post_delete åªæ”¯æŒä¸€ç§ API ï¼Œé‚£å°±æ˜¯ delete_instance() è§¦å‘ï¼š objs = Owner.select().where(Owner.name=='lin') for obj in objs: obj.delete_instance() æ¥ä¸‹æ¥æˆ‘ä»¬å¼€å§‹çœ‹ä»£ç å¦‚ä½•å†™ï¼š å…ˆæŠŠè¡¨å’Œæ•°æ®æ„é€ å‡ºæ¥ï¼Œè¿˜æ˜¯è€æ–¹å¼ï¼š from peewee import * # æ³¨æ„æ˜¯ playhouseé‡Œçš„Modelï¼Œ ä»¥åŠå‰é¢æåˆ°çš„ 4 ç§ ä¿¡å· from playhouse.signals import Model, post_save, pre_save, pre_delete, post_delete db = MySQLDatabase('test', user='root', password='123', host='IP', port=3306, charset='utf8mb4') class Owner(Model): &quot;&quot;&quot; ç‰¹åˆ«æ³¨æ„ï¼Œè¿™ä¸ªModel, ä½¿ç”¨æ˜¯playhouse.signalsä¸‹çš„ Model è€Œä¸æ˜¯ peewee ä¸‹çš„ Model, è¿™éœ€è¦ç‰¹åˆ«æ³¨æ„ ä¸¤ä¸ªæ¨¡å—éƒ½æœ‰Model, æ‰€ä»¥æŠŠç”¨çš„Modelæ”¾åœ¨ ç›¸å¯¹åä¸‹é¢å¯¼å…¥ &quot;&quot;&quot; data = IntegerField() # è€Œå­—æ®µä¾ç„¶æ˜¯ from peewee import * å¯¼å…¥çš„ class Meta: database=db db.create_tables([Owner]) è¿›å…¥æ­£é¢˜ï¼šä¿¡å·ä½¿ç”¨æœ‰ä¸¤ç§æ–¹å¼ï¼š æ–¹å¼1ï¼ˆè£…é¥°å™¨æ–¹å¼ï¼‰ï¼š # å‰é¢çš„4ç§ä¿¡å·çš„ç”¨æ³•å°±æ˜¯ç”¨æ¥ï¼Œè£…é¥°ä¸€ä¸ªè‡ªå®šä¹‰å‡½æ•°ã€‚ # è¿™ä¸ªè‡ªå®šä¹‰å‡½æ•°å°±æ˜¯ä¿¡å·å‡ºå‘ä¹‹åï¼Œä¸ºæˆ‘ä»¬åšäº‹çš„ã€‚ # æ¥ä¸‹æ¥æˆ‘ä»¥ post_save ä¸ºä¾‹ ï¼ˆå½“ç„¶æˆ‘è¿™ä¸ªä¾‹å­åªæ˜¯å¼ºè°ƒä¸€ä¸‹è¯­æ³•ï¼Œå¹¶æ²¡æœ‰å®ç”¨ä»·å€¼ï¼‰ @pre_save(sender=Owner) # senderæŒ‡å®š æˆ‘ä»¬çš„æ¨¡å‹ç±» def aaa(model_class, instance, created=True): # è¿™ä¸ªåå­—éšä¾¿èµ· &quot;&quot;&quot; model_class: å°±æ˜¯ Ownerè¿™ä¸ªç±»ï¼Œé»˜è®¤ä¼ è¿›æ¥æ–¹ä¾¿ä½ ä½¿ç”¨ instance å’Œ create=True ç…§ç€å†™ä¸Šå°±è¡Œä¸ç”¨ç®¡å®ƒ &quot;&quot;&quot; print(f&quot;æ•°æ®å…¥åº“ä¹‹å‰æˆ‘ä»¬æ•è·äº†æ­¤è¡¨å=&gt;{model_class}&quot;) for obj in model_class.select().dicts(): # model_classå°±æ˜¯Ownerç±»ï¼Œå®ƒå¯ä»¥ä»»æ„CRUD print(f&quot;å†æ¬¡æŸ¥çœ‹æ­¤è¡¨ä¿¡æ¯{obj}&quot;) è§¦å‘ä¿¡å·ï¼š obj = Owner.get(name='Tom') obj.name = 'Rose' obj.save() æ–¹å¼2 (å‡½æ•°è¿æ¥)ï¼š ä¿¡å·-å®˜æ¡£ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/playhouse.html#connecting-handlers å…¶å®ä½ ç”¨ æ–¹å¼1 å°±è¡Œäº†ã€‚ æ•°æ®åº“åå‘ç”Ÿæˆ Pythonæ¨¡å‹ç±» å‚æ•°å®˜æ¡£ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/playhouse.html#command-line-options çœ‹å¥½å‚æ•°å¤§å°å†™å°±è¡Œï¼ˆtestæ˜¯æˆ‘çš„æ•°æ®åº“åï¼‰ï¼š python -m pwiz -e mysql -H 192.6.6.6 -p 3306 -u root -P test &gt; mymodel.py # æŒ‡å®šäº† -P ï¼Œå¯†ç æ˜¯åç»­å‘½ä»¤è¡Œ è¿½å…¥çš„ã€‚ æ¨¡å‹è¿ç§» migration æˆ‘æ²¡æ€ä¹ˆçœ‹ï¼Œéœ€è¦çš„è‡ªå·±ç…ç…ã€‚ã€‚ æ¨¡å‹è¿ç§»-å®˜æ¡£ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/playhouse.html#schema-migrations ç»“æŸè¯­ å…¶å®ORMéƒ½å·®ä¸å¤šã€‚ Djangoï¼šçš„ORMè¿˜ç®—å¯ä»¥ã€‚ä½†æ˜¯ä¸å¤ªå¥½è„±ç¦»æ¡†æ¶å•ç‹¬ä½¿ç”¨ (ç›¸å½“äºä¸Djangoå¹³çº§)ã€‚ sqlalchemyï¼šæ²¡æ€ä¹ˆç”¨è¿‡ã€‚ä¹‹å‰çœ‹è¿‡å‡ çœ¼ã€‚æ„Ÿè§‰æåº¦ä¸é€‚ã€‚æ„Ÿè§‰å­¦ä¹ æˆæœ¬æœ‰ç‚¹é«˜ï¼ˆç›¸å½“äºä¸Pythonå¹³çº§ï¼‰ peeweeï¼šæ˜¯ä¸€ä¸ªå¯å•ç‹¬ä½¿ç”¨çš„ç®€ä¾¿çš„ORMæ¡†æ¶ï¼ˆå†™webçˆ¬è™«ä¹‹ç±»çš„éƒ½èƒ½ç”¨å¾—ä¸Šï¼Œç›¸å½“äºä¸Pythonå¹³çº§ï¼‰ æˆ‘æ„Ÿè§‰ï¼šå¦‚æœORMçš„å­¦ä¹ æˆæœ¬å¤§äºSQLçš„å­¦ä¹ æˆæœ¬ï¼Œ é‚£å€’ä¸å¦‚ç²¾ä¿®ä¸€ä¸‹SQLï¼Œå³ä½¿æ¢äº†ç¯å¢ƒä¹Ÿèƒ½ç”¨å¾—ä¸Šã€‚ æœ‰æ—¶å€™é«˜é˜¶ORMç”¨å¤šäº†ï¼Œå¯èƒ½è¿SQLéƒ½ä¸ä¼šå†™äº†ã€‚ã€‚ã€‚ ï¼ˆIt's just for me......ï¼‰ ç¬¬ä¸€ç¯‡ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020265149 ç¬¬äºŒç¯‡ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020265522 ","link":"https://cythonlin.github.io/post/py-greater-python-orm-zhi-peeweecha-jian-tuo-zhan-san/"},{"title":"PY => Python-ORMä¹‹peeweeï¼šCRUDå®Œæ•´è§£æï¼ˆäºŒï¼‰","content":"å£°æ˜ ä¸Šç¯‡åœ°å€ï¼šhttps://segmentfault.com/a/1190000020265149 è™½ç„¶ä¸Šä¸€ç¯‡ï¼Œå·²ç»è¯´æ˜ï¼Œä½†è¿˜æ˜¯å¼ºè°ƒä¸€ä¸‹ï¼Œpeeweeæ˜¯ python-ORMï¼ˆåªæ”¯æŒ MySQL,Sqlite,postgresql ï¼‰ è™½ç„¶ORMå¯ä»¥ä¸å¤šç§æ•°æ®åº“æ— ç¼ç›¸æ¥ï¼Œå¹¶ä¸”å…¼å®¹æ€§å¥½ï¼Œ ä½†æ˜¯æŸäº›ç»†å¾®çš„è¯­æ³•å¹¶ä¸æ˜¯æ•°æ®åº“å…±æœ‰çš„ã€‚ æˆ‘ç”¨MySQL, æ‰€ä»¥ä¸‹é¢è¯´çš„éƒ½æ˜¯åŸºäºMySQLï¼ˆå…¶ä»–2ç§æ•°æ®åº“ä¹Ÿå·®ä¸äº†å¤šå°‘ï¼Œ 99%æ˜¯ä¸€æ ·çš„ï¼‰ æ€»å®˜æ¡£åœ°å€ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/quickstart.html å®˜æ–¹Githubåœ°å€ï¼šhttps://github.com/coleifer/peewee å¢åŠ æ•°æ® æ–¹å¼1ï¼šï¼ˆæ¨èï¼‰ zhang = Owner.create(name='Zhang', age=20) æ–¹å¼2ï¼š zhang = Owner(name='Zhang1', age=18) zhang.save() # ä½ å¯ä»¥çœ‹è§ï¼Œå®ƒéœ€è¦ç”¨save()ï¼Œæ‰€ä»¥æ¨èç”¨ä¸Šä¸€ç§æ–¹å¼ã€‚ æ–¹å¼3ï¼šï¼ˆæ¨èï¼‰ cython = Owner.insert(name='Cython', age=15).execute() # æ–¹å¼1 å’Œ æ–¹å¼2, è¿”å›ç»“æœéƒ½æ˜¯æ¨¡å‹å®ä¾‹&quot;ï¼ˆä¹Ÿå°±æ„å‘³ç€åˆ›å»ºäº†ä¸€ä¸ªå®ä¾‹ï¼‰&quot; # è€Œæœ¬æ–¹å¼ï¼Œè¿”å›ç»“æœæ˜¯ æœ€æ–°æ’å…¥çš„ä¸»é”®å€¼&quot;ï¼ˆä¹Ÿå°±æ„å‘³ç€ä¸ä¼šåˆ›å»ºå®ä¾‹ï¼‰&quot; å¦‚æœå­˜åœ¨å¤–é”®å…³è”ï¼Œå‡å¦‚å­˜åœ¨ Petç±» å¼•ç”¨çš„ Ownerçš„ä¸»é”®ï¼Œæ’å…¥æ•°æ®æ–¹å¼æœ‰2ç§ï¼š æ–¹å¼1ï¼š ç”¨æ–°å»ºå¯¹è±¡å˜é‡ä¼ å€¼ï¼š lin = Owner.create(name='lin', age=20) tom1 = Pet.create(name='Tom', age=1, owner=lin) # æ³¨æ„ owner = lin æ–¹å¼2ï¼š æ‰‹åŠ¨ç»´æŠ¤ä¸»é”® idï¼Œé€šè¿‡ä¸»é”®ä¼ å€¼ï¼ˆæˆ–è€…é€šè¿‡æŸ¥è¯¢idï¼‰ï¼š lin = Owner.create(id=100, name='lin', age=20) # idè‡ªå·±ç»™çš„å€¼ä¸º 100 tom1 = Pet.create(name='Tom', age=1, owner=100) # æ³¨æ„ owner=100 æ’å…¥å¤šæ¡æ•°æ®ï¼šï¼ˆå®˜æ¡£æœ‰å¥½å‡ ç§æ–¹æ³•ï¼Œæˆ‘åªè¯´æœ€æå€¡ï¼Œæœ€å¿«é€Ÿçš„æ–¹æ³•ï¼ˆå¥½å¤„å°±æ˜¯ä¸€æ¬¡æ€§æäº¤ï¼Œä¸ç”¨å¾ªç¯ï¼‰ï¼‰ æ–¹å¼1ï¼š &quot;&quot;&quot; æ³¨æ„æ ¼å¼ [ {},{},{} ] æ¯ä¸ªå­—å…¸ï¼Œå¯¹åº”ä¸€æ¡è®°å½•ã€‚ &quot;&quot;&quot; data = [ {'name': 'Alice', 'age': 18}, {'name': 'Jack', 'age': 17}, ] Owner.insert_many(data).execute() æ–¹å¼2ï¼š (å°±æ˜¯ä¸ç”¨åœ¨æ•°æ®ä¸­éƒ½æŒ‡å®šé”®äº†ï¼Œæ–¹ä¾¿ä¸€ç‚¹) &quot;&quot;&quot; æ³¨æ„æ ¼å¼ [ (),(),() ] æ¯ä¸ªå…ƒç»„ï¼Œå¯¹åº”ä¸€æ¡è®°å½•ã€‚ &quot;&quot;&quot; data = [ ('Alice', 18), ('Jack', 17), ] User.insert_many(data, fields=[Owner.name, Owner.age]).execute() æ³¨æ„ä¸€ä¸‹ï¼šå°¾éƒ¨éƒ½å¿…é¡»è¦å¸¦ä¸€ä¸ªexecute() å¦‚æœæ•°æ®é‡è¿‡å¤§ï¼Œå¯èƒ½ä¼šå‡ºç°OOMç­‰é—®é¢˜ã€‚ä½ å¯ä»¥æ‰‹åŠ¨åˆ†æ‰¹ï¼Œä½†æ˜¯ peewee ç»™æˆ‘ä»¬æä¾›äº†æˆå“çš„ api from peewee import chunked with mysql_db.atomic(): # å®˜æ¡£å»ºè®®ç”¨äº‹åŠ¡åŒ…è£¹ for batch in chunked(data, 100): # ä¸€æ¬¡100æ¡ï¼Œ chunked() è¿”å›çš„æ˜¯å¯è¿­ä»£å¯¹è±¡ Owner.insert_many(batch).execute() é˜²æ­¢æ•°æ®é‡å¤æ’å…¥çš„2ç§åŠæ³•ï¼ˆæˆ–è€…é˜²æ­¢è®¾ç½®äº†ä¸»é”®ï¼Œé‡å¤æ’å…¥æŠ›å‡ºå¼‚å¸¸ï¼Œå¯¼è‡´ç¨‹åºæ— æ³•è¿è¡Œï¼‰ï¼š æ–¹æ³•1ï¼š INGOREå…³é”®å­— ï¼ˆè¿™ç§æ–¹å¼æ˜¯å¦‚æœå†²çªäº†ï¼Œå°±è‡ªåŠ¨å¿½ç•¥ï¼‰ SQL: insert ignore into owner (name,age) values ('lin',30); peewee: Owner.insert(name='lin', age=30).on_conflict_ignore() æ–¹æ³•2ï¼šç”¨ ON DUPLICATE KEY UPDATE ï¼ˆè¿™ç§æ–¹å¼ï¼Œæ˜¯å¦‚æœå†²çªäº†ï¼Œä½ è¿˜å¯ä»¥åšä¸€äº›æ“ä½œï¼‰ SQLï¼š insert into owner (name,age) values ('lin',30) ON DUPLICATE KEY UPDATE name='lin', age=30; # å¦‚æœå†²çªäº†ï¼Œå¯ä»¥é‡æ–°è®¾ç½®å€¼ peewee: Owner.insert(name='lin', age=30).on_conflict( preserve=[Owner.name, Owner.age], # è‹¥å†²çªï¼Œä½ æƒ³ä¿ç•™ä¸å˜çš„å­—æ®µ update={Owner.name: 'lin', Owner.age: 30} # è‹¥å†²çªï¼Œä½ æƒ³æ›´æ–°ä»€ä¹ˆ ).execute() # æ³¨ï¼š preserve å’Œ update æŒ‰æƒ…å†µç”¨ï¼Œä¸€èˆ¬è®¾ç½®ä¸€ä¸ªç”¨å°±è¡Œäº†ã€‚ åˆ é™¤æ•°æ® æ–¹æ³•1ï¼š php = Owner.get(name='PHP') # è·å–å•æ¡å¯¹è±¡ php.delete_instance() # æ³¨æ„ï¼š delete_instance() åªèƒ½åˆ é™¤å•æ¡å¯¹è±¡ï¼Œ å¦‚æœç”¨select()æŸ¥å‡ºæ¥çš„ï¼Œéœ€è¦éå†æ‰èƒ½åˆ  æ–¹æ³•2ï¼š Owner.delete().where(Owner.name == 'lin').execute() # æ³¨æ„è¿™ç§æ–¹æ³•å’Œæ·»åŠ ç±»ä¼¼ï¼Œ æœ€åä¹Ÿå¿…é¡»æœ‰ä¸ª execute() ä¿®æ”¹æ•°æ® æ–¹å¼1ï¼š(ä¸æ¨è) owner= æŸ¥è¯¢å•ä¸ªå¯¹è±¡ç»“æœ owner.name = 'Pack' owner.name = 50 owner.save() # ä½ å¯ä»¥çœ‹è§ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ‰‹åŠ¨è°ƒç”¨ä¸€ä¸‹save() æ–¹å¼2ï¼šï¼ˆæ¨èï¼‰ query = Owner.update(name='Pack', age=50).where(Owner.name == 'Zhang') query.execute() æŸ¥è¯¢æ•°æ® æŸ¥è¯¢å•æ¡æ•°æ® (ç‰¹åˆ«æ³¨æ„ï¼Œå¦‚æœä½ æœ‰å¤šæ¡ï¼Œå®ƒåªä¼šç»™ä½ è¿”å›ç¬¬ä¸€æ¡) &quot;&quot;&quot;å­˜åœ¨åˆ™è¿”å›åŸæœ‰å¯¹è±¡ï¼Œ ä¸å­˜åœ¨åˆ™æŠ›error&quot;&quot;&quot; one_owner = Owner.get(name='Zhang2') print(one_woner.age) æ‰©å±•ç‰ˆ1ï¼š get_or_create &quot;&quot;&quot;å­˜åœ¨åˆ™è¿”å›åŸæœ‰å¯¹è±¡ã€‚ä¸å­˜åœ¨åˆ™æ’å…¥æ•°æ®ï¼Œå¹¶è¿”å›æ–°å¯¹è±¡&quot;&quot;&quot; obj, status = Owner.get_or_create(name='Zhang23213',age=3123) print(obj.name, status) # objå°±æ˜¯è¿”å›çš„æ–°å¯¹è±¡ # statusè¡¨ç¤ºæ’å…¥æ˜¯å¦æˆåŠŸ True æˆ–è€… False æ‰©å±•ç‰ˆ2ï¼š get_or_none &quot;&quot;&quot;å­˜åœ¨åˆ™è¿”å›åŸæœ‰å¯¹è±¡ï¼Œ ä¸å­˜åœ¨åˆ™è¿”å› None (ä¸ä¼šæŠ›error)&quot;&quot;&quot; Owner.get_or_none(name='abc') æŸ¥è¯¢å¤šæ¡æ•°æ® æ­£å¸¸æŸ¥è¯¢æ‰€æœ‰æ•°æ® owners = Owner.select() # è¿”å›ç»“æœ owners æ˜¯å¯¹è±¡é›†åˆï¼Œéœ€è¦éå† for owner in owners: # owner æ˜¯æ¯ä¸ªå¯¹è±¡ï¼ˆå¯¹åº”æ¯æ¡è®°å½•ï¼‰ print(woner.name) å½“ç„¶ä½ å¯ä»¥åœ¨æŸ¥è¯¢åè½¬ä¸º python ç±»dictæ ¼å¼: owners = Owner.select().dicts() # è¿”å›ç»“æœ owners æ˜¯ &quot;ç±»å­—å…¸å¯¹è±¡é›†åˆ&quot; for owner in owners: # owneræ˜¯æ¯ä¸ªå­—å…¸å¯¹è±¡ï¼Œ ï¼ˆå®ƒ å¯¹åº”æ¯æ¡è®°å½•ï¼‰ print(owner['name']) # å­—å…¸è¯­æ³•å–å€¼ï¼Œæ‡‚äº†å§ï¼Œä¸å¤šè¯´äº†ã€‚ ä¸Šé¢çš„æŸ¥è¯¢å¦‚æœåœ¨æ•°æ®å¤§é‡çš„æƒ…å†µä¸‹å¯èƒ½ä¼šå¯¼è‡´OOMï¼Œå› æ­¤å¯è½¬ä¸ºè¿­ä»£ï¼š &quot;&quot;&quot;å†æ¯ä¸ªæŸ¥è¯¢çš„æœ€ååŠ ä¸Š .iterator() å³å¯&quot;&quot;&quot; eg: owners = Owner.select().iterator() owners = Owner.select().dicts().iterator() æ¡ä»¶æŸ¥è¯¢ï¼š é¦–å…ˆæˆ‘å…ˆå¼ºè°ƒä¸ªï¼Œ&quot;MySQLæ˜¯å¦åŒºåˆ†å¤§å°å†™&quot; çš„äº‹ï¼š MySQL5.7+ï¼Œæ˜¯åŒºåˆ†å¤§å°å†™çš„; (MySQL8ï¼Œå’Œ MariaDB æˆ‘æ²¡è¯•ï¼Œ åº”è¯¥å’Œ 5.7æ˜¯ä¸€æ ·çš„) ä½†è¿™ä¸ªåŒºåˆ†å¤§å°å†™ ä»…ä»…ä»…ä»…ä»…ä»… æ˜¯ é’ˆå¯¹äº SQLè¯­å¥çš„è¡¨å &quot;&quot; å¼•å·å¤–é¢çš„ï¼ˆå°±æ˜¯éå­—ç¬¦ä¸²è¯­æ³•ï¼‰ ä¸¾ä¸ªä¾‹å­ï¼š ç°æœ‰ä¸€è¡¨ï¼Œåå« owner desc owner # æ­£ç¡® desc OWNER # é”™è¯¯ï¼Œè¡¨ä¸å­˜åœ¨ è¿™ç§æƒ…å†µä¸‹ï¼Œå› ä¸ºä¸æ¶‰åŠå­—ç¬¦ä¸²çš„ &quot;&quot; å¼•å·æ“ä½œï¼Œæ‰€ä»¥æ˜¯ä¸¥æ ¼åŒºåˆ†å¤§å°å†™çš„ã€‚ &quot;è€Œå¼•å·é‡Œé¢&quot; ï¼ˆå…¶å®å°±æ˜¯æ¶‰åŠå­—ç¬¦ä¸²ï¼‰çš„æ•°æ®è¯­æ³•ï¼Œæ˜¯ ä¸åŒºåˆ† å¤§å°å†™çš„ã€‚ ä¸¾ä¸ªä¾‹å­ï¼ˆå› ä¸ºä¸‹é¢ä¾‹å­éƒ½æœ‰ &quot;&quot; å­—ç¬¦ä¸²æ“ä½œï¼Œæ‰€ä»¥éƒ½ ä¸åŒºåˆ† å¤§å°å†™ï¼‰ï¼š SQL: æŸ¥è¯¢ä¾‹å­ï¼š select * from owner where name='zHang' select * from owner where name='ZHANG' ä»–ä»¬ä¿©æŸ¥è¯¢çš„æ˜¯åŒä¸€ä¸ªæ•°æ®ã€‚ æ’å…¥ä¾‹å­ï¼š insert into owner values(&quot;zhaNg&quot;) insert into owner values(&quot;zhang&quot;) ä»–ä»¬ä¿© æ’å…¥çš„ ä¹Ÿæ˜¯åŒä¸€ä¸ªæ•°æ® peewee: æŸ¥è¯¢ä¾‹å­ï¼š ...where(name=&quot;zhang&quot;) ...where(name=&quot;ZHaNg&quot;) ä»–ä»¬ä¿©æŸ¥è¯¢çš„æ˜¯ åŒä¸€ä¸ªæ•°æ®ã€‚ æ’å…¥ä¾‹å­ï¼š ...insert({'name':'Zhang') ...insert({'name': 'zhANG') ä»–ä»¬ä¿© æ’å…¥çš„ ä¹Ÿæ˜¯åŒä¸€ä¸ªæ•°æ® å®˜æ¡£-æ¡ä»¶æ“ä½œç¬¦ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/query_operators.html#query-operators ä¸Šè¾¹çš„è¿æ¥æ˜¯å®˜æ¡£æ“ä½œç¬¦å¤§å…¨ï¼Œä¸‹é¢æˆ‘æŠŠéƒ¨åˆ†å¸¸ç”¨æ‘˜å‡ºæ¥è¯´ä¸€ä¸‹ã€‚ å¸¸ç”¨æ“ä½œç¬¦ ä¸æˆ–éï¼š ä¸ï¼š&amp; æ¨¡å‹ç±».where( (User.is_active == True) &amp; (User.is_admin == True) ) æˆ–ï¼š| æ¨¡å‹ç±».where( (User.is_admin) | (User.is_superuser) ) éï¼š~ æ¨¡å‹ç±».where( ~(User.username.contains('admin')) ) æˆ‘è¯´ä¸¤å¥ï¼Œæ–¹ä¾¿è®°å¿†ï¼š 1. SQLè¯­å¥ä¸­&quot;ä¸æˆ–é&quot; æ˜¯ &quot;and or not&quot; è¯­æ³•ï¼Œ ä¸ºå•¥peeweeä¸éµå¾ªï¼Ÿ ç­”ï¼š å› ä¸ºï¼Œ&quot;pythonåŸè¯­æ³•&quot;ä¹Ÿæ˜¯è¿™ä¸‰ä¸ªã€‚ã€‚ã€‚å†²çª, æ‰€ä»¥ peeweeæ”¹äº†ã€‚ 2. çœ‹ä¸Šé¢çš„ä¾‹å­ï¼Œ æ¯ä¸ªæ¡ä»¶æ“ä½œç¬¦ &quot;ä¸¤è¾¹&quot;çš„ä»£ç  éƒ½ç”¨ &quot;()&quot; æ‹¬èµ·æ¥äº† èŒƒå›´ï¼š # æŸ¥è¯¢å¹´é¾„18åˆ°20çš„æ•°æ® (å‰é—­åé—­) for owner in Owner.select().where(Owner.age.between(18,20)): print(owner.age) åŒ…å«&amp;ä¸åŒ…å«ï¼š ä¸åŒ…å«ï¼šnot_in ï¼ˆåŒä¸‹ï¼‰ ä¸åŒ…å«ï¼šin_ # å°†å§“ååŒ…å« Aliceå’ŒTomçš„è®°å½•æ‰¾å‡ºæ¥ for owner in Owner.select().where(Owner.name.in_(['Alice', 'Tom'])): print(owner.name) æ˜¯å¦ä¸ºnull: # True å°±ä»£è¡¨æŠŠæ‰€æœ‰ name ä¸º null çš„ è®°å½•éƒ½æŸ¥å‡ºæ¥ # False å°±ä»£è¡¨æŠŠæ‰€æœ‰ name ä¸º énull çš„ è®°å½•éƒ½æŸ¥å‡ºæ¥ for owner in Owner.select().where( Owner.name.is_null(True) ): print(owner.name) ä»¥..å¼€å¤´ &amp; ä»¥..ç»“å°¾ ä»¥..å¼€å¤´ï¼š startswith ä»¥..ç»“å°¾ï¼š endswith # æŠŠä»¥ ali å¼€å¤´çš„ éƒ½æŸ¥è¯¢å‡ºæ¥ for owner in Owner.select().where(Owner.name.startswith('ali')): print(owner.name) æ¨¡ç³ŠæŸ¥è¯¢ï¼š # å°†åŒ…å« li å­—ç¬¦ä¸²çš„æ•°æ®æŸ¥è¯¢å‡ºæ¥ for owner in Owner.select().where(Owner.name.contains('li')): print(owner.name) æ­£åˆ™æŸ¥è¯¢ï¼š è¿™ä¸ªå°±æœ‰æ„æ€äº†ã€‚å‰é¢æˆ‘ä»¬å¼ºè°ƒè¿‡ï¼ŒMySQLå¸¦å¼•å·å­—ç¬¦ä¸²æ˜¯ä¸åŒºåˆ†å¤§å°å†™çš„ã€‚ è€Œæ­£åˆ™åŠŸèƒ½æä¾›ç»™æˆ‘ä»¬åŒºåˆ†å¤§å°å†™çš„APIã€‚ï¼ˆè¿™æ˜¯ä¸ªç‰¹ä¾‹ï¼Œåªæœ‰æ­£åˆ™åŒºåˆ†å¤§å°å†™çš„åŠŸèƒ½ã€‚è®°ä½ï¼‰ ä¾‹å­æ¡ä»¶ï¼š å‡å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°æ® nameä¸º Alice regexpï¼š ä¸¥æ ¼åŒºåˆ†å¤§å°å†™çš„æ­£åˆ™ # ç”¨çš„æ˜¯ regexp,åŒºåˆ†å¤§å°å†™, æ¡ä»¶ç»™çš„æ˜¯ alå°å†™ï¼Œ æ‰€ä»¥å½“ç„¶ æŸ¥ä¸å‡ºæ¥ï¼Œè¿”å›ç©º for owner in Owner.select().where(Owner.name.regexp('al*')): print(owner.name) iregexpï¼šä¸åŒºåˆ†å¤§å°å†™çš„æ­£åˆ™ # ç”¨çš„æ˜¯ iregexp, ä¸åŒºåˆ†å¤§å°å†™ã€‚ å› æ­¤å³ä½¿ ä½ ç»™ alå°å†™ï¼Œ ä¹Ÿèƒ½å¤Ÿå°† AliceæŸ¥å‡ºæ¥ã€‚ for owner in Owner.select().where(Owner.name.iregexp('al*')): print(owner.name) ç»Ÿè®¡è®°å½•æ•° count print(MyModel.select().count()) offset &amp; limit &quot;&quot;&quot;è·³è¿‡å‰2è¡Œï¼Œä»ç¬¬2+1è¡Œå¼€å§‹ï¼Œå–1æ¡ï¼Œ å…¶å®å–å‡ºçš„å°±æ˜¯ç¬¬3è¡Œ&quot;&quot;&quot; for x in Owner.select().offset(2).limit(1).dicts(): print(x) åˆ†é¡µ paginate &quot;&quot;&quot; 1. paginate ç¬¬1ä¸ªå‚æ•°ä¸º ç¬¬å‡ é¡µ 2. paginate ç¬¬2ä¸ªå‚æ•°ä¸º ä¸€é¡µå‡ ä¸ªæ•°æ® 3. paginateä¼šè‡ªåŠ¨æ ¹æ®æŸ¥è¯¢çš„æ‰€æœ‰è®°å½•æ€»æ•° å’Œ ä½ ä¼ çš„ ä¸¤ä¸ª å‚æ•°æ¥ä¸ºä½ è‡ªåŠ¨åˆ†é¡µ &quot;&quot;&quot; for obj in MyModel.select().paginate(1,3).dicts(): # ç¬¬ä¸€é¡µï¼Œæ¯é¡µä¸‰ä¸ªæ•°æ® print(obj) # peeweeæä¾›ç»™æˆ‘ä»¬åˆ†é¡µå°±è¿™ä¹ˆå¤šï¼Œæƒ³è¦æ›´å¤šéœ€æ±‚ï¼Œéœ€è¦æˆ‘ä»¬è‡ªå·±å‘æ•£æ€ç»´ã€‚ # ä¸‹é¢æ˜¯æˆ‘è‡ªå·±ç²—ç•¥å†™çš„ä¸€ä¸ªç¬¨æ‹™çš„åˆ†é¡µã€‚ã€‚å¯ä»¥å‚è€ƒä¸‹ã€‚ã€‚ def page(document_count=None, per_page_size=None, start_page=1): page_count = (document_count // per_page_size) # æ•´é™¤çš„é¡µæ•°ï¼ˆå¯èƒ½æœ‰æ®‹é¡µï¼‰ is_rest = (document_count % per_page_size) # æ€»æ•°/æ¯é¡µæ•°ï¼šæ˜¯å¦èƒ½é™¤å°½ # é™¤å°½ä»£è¡¨æ•´é¡µç›´æ¥è¿”å›ï¼Œé™¤ä¸å°½æœ‰æ®‹é¡µ ï¼Œé¡µç +1 è¿”å› page_count = page_count if not is_rest else page_count + 1 for page in range(start_page, page_count + 1): for obj in MyModel.select().paginate(page, per_page_size).dicts().iterator(): yield obj document_count = MyModel.select().count() # å…ˆè·å–è®°å½•æ€»æ•° for obj in page(document_count=document_count, per_page_size=3, start_page=1): print(obj) # å¦‚æœä½ æœ‰éœ€æ±‚åˆ†é¡µåˆ‡ç‰‡æˆ–ç´¢å¼•ï¼Œ é‚£ä¹ˆä½ å¯ä»¥å°è£…æˆç±»ï¼Œç„¶åå®ç° __getitem__ æ–¹æ³• document_count = MyModel.select().count() for obj in page(document_count=document_count, per_page_size=3, start_page=1): print(obj) æ’åº order_by # é»˜è®¤å‡åº asc() for owner in Owner.select().order_by(Owner.age): print(owner.age) # é™åº desc() for owner in Owner.select().order_by(Owner.age.desc()): print(owner.age) åˆ†ç»„ group_by # ç”¨å§“ååˆ†ç»„ï¼Œç»Ÿè®¡äººå¤´æ•°å¤§äº1çš„æ‰€æœ‰è®°å½•ï¼Œé™åºæŸ¥è¯¢ query = Owner.select(Owner.name, fn.count(Owner.name).alias('total_num')) \\ .group_by(Owner.name) \\ .having(fn.count(Owner.name) &gt; 1) \\ .order_by(SQL('total_num').desc()) for owner in query: print(f'åå­—ä¸º{owner.name}çš„ äººæ•°ä¸º{owner.total_num}ä¸ª') åˆ†ç»„æ³¨æ„äº‹é¡¹ï¼Œè¯´å‡ ç‚¹ï¼š 1. åˆ†ç»„æ“ä½œï¼Œå’ŒSQLçš„group byä¸€æ ·ï¼Œ group byåé¢å†™äº†ä»€ä¹ˆå­—æ®µï¼Œ å‰é¢selectåŒæ—¶ä¹Ÿå¿…é¡»åŒ…å« 2. .alias('ç»Ÿè®¡ç»“æœå­—æ®µå')ï¼Œæ˜¯ç»™ç»Ÿè®¡åçš„ç»“æœèµ·ä¸€ä¸ªæ–°å­—æ®µåã€‚ 3. SQL('total_num') çš„ä½œç”¨æ˜¯ç»™ä¸´æ—¶å‘½åçš„æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œå½“ä½œä¸´æ—¶å­—æ®µä½¿ç”¨ï¼Œæ”¯æŒï¼Œdesc()ç­‰API 4. peeweeçš„APIæ˜¯é«˜ä»¿SQLå†™çš„ï¼Œæ–¹ä¾¿ä½¿ç”¨è€…ã€‚å› æ­¤æˆ‘ä»¬æœ€å¥½åŒæ­¥SQLçš„è¯­æ³•è§„èŒƒï¼ŒæŒ‰å¦‚ä¸‹é¡ºåºï¼š where &gt; group_by &gt; having &gt; order_by èšåˆåŸç† ä¸€ä¼šè®²peeweeçš„fnèšåˆåŸç†ä¼šæ¶‰åŠåˆ° getattr()ï¼Œå¦‚æœä½ ä¸äº†è§£ï¼Œå¯ä»¥çœ‹ä¸‹æˆ‘ä¹‹å‰å†™è¿‡çš„æ–‡ç« ã€‚ https://segmentfault.com/a/1190000019247293 èšåˆåŸç†å¦‚ä¸‹ï¼š ï¼ˆä»¥ä¸Šé¢åˆ†ç»„çš„ fn.count() ä¸ºä¾‹ï¼‰ fnæ˜¯æˆ‘äº‹å…ˆå¯¼å…¥è¿›æ¥çš„ï¼ˆå¼€ç¯‡æˆ‘å°±è¯´è¿‡ from peewee import * ï¼‰å°±å¯¼å…¥äº†ä¸€åˆ‡ï¼ˆå»ºè®®ç»ƒä¹ ä½¿ç”¨ï¼‰ fnå¯ä»¥ä½¿ç”¨èšåˆæ“ä½œï¼Œæˆ‘çœ‹äº†ä¸€ä¸‹æºç ï¼šè®²è§£ä¸‹æ€è·¯ï¼ˆä¸ä¸€å®šç‰¹åˆ«æ­£ç¡®ï¼‰ï¼š fnæ˜¯ Functionç±»å®ä¾‹çš„å‡ºçš„å¯¹è±¡ Function() å®šä¹‰äº† __getattr__æ–¹æ³•,ï¼ˆ__getattr__å¼€å¤´æˆ‘å·²ç»ç»™é“¾æ¥äº†ï¼Œä¸æ‡‚çš„å¯ä»¥ä¼ é€ï¼‰ å½“ä½ ä½¿ç”¨ fn.xx() : xx å°±ä¼šè¢«å½“ä½œå­—ç¬¦ä¸²ä¼ åˆ° __getattr__ ï¼Œ __getattr__é‡Œé¢ç”¨è£…é¥°å™¨æ¨¡å¼ï¼Œå°†ä½  xx è¿™ä¸ªå­—ç¬¦ä¸²ã€‚ ç»è¿‡ä¸€ç³»åˆ—æ“ä½œï¼Œæ˜ å°„ä¸ºåŒåçš„SQLè¯­å¥ ï¼ˆè¿™ç³»åˆ—æ“ä½œåŒ…æ‹¬å¤§å°å†™è½¬æ¢ç­‰ï¼‰ æ‰€ä»¥ä½ ç”¨ fn.count å’Œ fn.CoUNt æ˜¯ä¸€æ ·çš„ è¯´åˆ°åº• fn.xx() , çš„æ„æ€å°±æ˜¯ fn æŠŠ xx å½“ä½œå­—ç¬¦ä¸²æ˜ å°„åˆ°SQLè¯­å¥ï¼Œèƒ½æ˜ å°„åˆ°å°±èƒ½æ‰§è¡Œ å¸¸ç”¨fnèšåˆå‡½æ•° fn.count() ç»Ÿè®¡æ€»äººå¤´æ•°ï¼š for owner in Owner.select(fn.count(Owner.name).alias('total_num')): print(owner.total_num) fn.lower() / fn.upper() åå­—è½¬å°å†™/å¤§å†™ï¼ˆæ³¨æ„æ˜¯ä¸´æ—¶è½¬ï¼Œå¹¶æ²¡æœ‰çœŸçš„è½¬ï¼‰ï¼Œå¹¶æŸ¥è¯¢å‡ºæ¥ï¼š for owner in Owner.select(fn.Upper(Owner.name).alias('lower_name')): print(owner.lower_name) fn.sum() å¹´é¾„æ±‚å’Œï¼š for owner in Owner.select(fn.sum(Owner.age).alias('sum_age')): print(owner.sum_age) fn.avg() æ±‚å¹³å‡å¹´é¾„ï¼š for owner in Owner.select(fn.avg(Owner.age).alias('avg_age')): print(owner.avg_age) fn.min() / fn.max() æ‰¾å‡ºæœ€å°/æœ€å¤§å¹´é¾„: for owner in Owner.select(fn.max(Owner.age).alias('max_age')): print(owner.max_age) fn.rand() é€šå¸¸ç”¨äºä¹±åºæŸ¥è¯¢ (é»˜è®¤æ˜¯å‡åºçš„å“¦)ï¼š for owner in Owner.select().order_by() print(owner.name) å…³è”æŸ¥è¯¢å‰ææ•°æ®å‡†å¤‡ from peewee import * mysql_db = MySQLDatabase('ä½ çš„æ•°æ®åº“å', user='ä½ çš„ç”¨æˆ·å', password='ä½ çš„å¯†ç ', host='ä½ çš„IP', port=3306, charset='utf8mb4') class BaseModel(Model): class Meta: database = mysql_db class Teacher(BaseModel): teacher_name = CharField() class Student(BaseModel): student_name = CharField() teacher = ForeignKeyField(Teacher, backref='student') class Course(BaseModel): course_name = CharField() teacher = ForeignKeyField(Teacher, backref='course') student = ForeignKeyField(Student, backref='course') mysql_db.create_tables([Teacher, Student, Course]) data = ( ('Tom', ('stu1', 'stu2'), ('Chinese',)), ('Jerry', ('stu3', 'stu4'), ('English',)), ) for teacher_name, stu_obj, course_obj in data: teacher = Teacher.create(teacher_name=teacher_name) for student_name in stu_obj: student = Student.create(student_name=student_name, teacher=teacher) for course_name in course_obj: Course.create(teacher=teacher, student=student, course_name=course_name) å…³è”æŸ¥è¯¢ æ–¹å¼1ï¼šjoin (è¿æ¥é¡ºåº Teacer -&gt; Student ï¼Œ Student -&gt; Course) # æ³¨æ„ï¼š ä½ ä¸ç”¨å†™ on ï¼Œå› ä¸ºpeeweeä¼šè‡ªåŠ¨å¸®ä½ é…å¯¹ query = Teacher.select(Teacher.teacher_name, Student.student_name, Course.course_name) .join(Student, JOIN.LEFT_OUTER). \\ # Teacer -&gt; Student join(Course, JOIN.LEFT_OUTER) \\ # Student -&gt; Course .dicts() for obj in query: print(f&quot;æ•™å¸ˆ:{obj['teacher_name']}ï¼Œå­¦ç”Ÿ:{obj['student_name']},è¯¾ç¨‹:{obj['course_name']}&quot;) æ–¹å¼2ï¼šswitch ï¼ˆè¿æ¥é¡ºåº Teacer -&gt; Student ï¼Œ Teacher -&gt; Courseï¼‰ # è¯´æ˜ï¼Œæˆ‘ç»™çš„æ•°æ®ä¾‹å­ï¼Œå¯èƒ½å¹¶ä¸é€‚ç”¨è¿™ç§æ–¹å¼çš„è¯­ä¹‰ï¼Œåªæ˜¯å•çº¯æŠ›å‡ºè¯­æ³•ã€‚ query = Teacher.select(Teacher.teacher_name, Student.student_name, Course.course_name) .join(Student) \\ # Teacher -&gt; Student .switch(Student) \\ # æ³¨æ„è¿™é‡Œï¼ŒæŠŠjoinä¸Šä¸‹æ–‡æƒåŠ›è¿˜ç»™äº† Teacher .join(Course, JOIN.LEFT_OUTER) \\ # Teacher -&gt; Course .dicts() for obj in query: print(f&quot;æ•™å¸ˆ:{obj['teacher_name']}ï¼Œå­¦ç”Ÿ:{obj['student_name']},è¯¾ç¨‹:{obj['course_name']}&quot;) æ–¹å¼3ï¼šjoin_fromï¼ˆå’Œæ–¹å¼2æ˜¯ä¸€æ ·çš„æ•ˆæœï¼Œåªä¸è¿‡è¯­æ³•ä¹¦å†™æœ‰äº›å˜åŒ–ï¼‰ query = Teacher.select(Teacher.teacher_name, Student.student_name, Course.course_name) .join_from(Teacher, Student) \\ # æ³¨æ„è¿™é‡Œï¼Œç›´æ¥æŒ‡æ˜è¿æ¥é¦–å°¾å¯¹è±¡ .join_from(Teacher, Course, JOIN.LEFT_OUTER) \\ # æ³¨æ„è¿™é‡Œï¼Œç›´æ¥æŒ‡æ˜è¿æ¥é¦–å°¾å¯¹è±¡ .dicts() for obj in query: print(f&quot;æ•™å¸ˆ:{obj['teacher_name']}ï¼Œå­¦ç”Ÿ:{obj['student_name']},è¯¾ç¨‹:{obj['course_name']}&quot;) æ–¹å¼4ï¼šå…³è”å­æŸ¥è¯¢ ï¼ˆè¯´æ˜ï¼šå…³è”å­æŸ¥è¯¢çš„æ„æ€å°±æ˜¯:ä¹‹å‰æˆ‘ä»¬joinçš„æ˜¯ä¸ªè¡¨ï¼Œè€Œç°åœ¨joinåé¢ä¸æ˜¯è¡¨ï¼Œè€Œæ˜¯å­æŸ¥è¯¢ã€‚ï¼‰ SQLç‰ˆæœ¬å¦‚ä¸‹ï¼š SELECT t1.id, t1.student_name, t1.teacher_id, t2.stu_count FROM student AS t1 INNER JOIN ( SELECT t1.teacher_id AS new_teacher, count(t1.student_name) AS stu_count FROM student AS t1 GROUP BY t1.teacher_id ) AS t2 ON (t2.new_teacher = t1.teacher_id peeweeç‰ˆæœ¬å¦‚ä¸‹ï¼š # å­æŸ¥è¯¢ï¼ˆä»¥å­¦ç”Ÿçš„è€å¸ˆå¤–é”®åˆ†ç»„ï¼Œç»Ÿè®¡æ¯ä¸ªè€å¸ˆçš„å­¦ç”Ÿä¸ªæ•°ï¼‰ temp_query = Student.select( Student.teacher.alias('new_teacher'), # è®°ä½è¿™ä¸ªæ”¹å fn.count(Student.student_name).alias('stu_count') # ç»Ÿè®¡å­¦ç”Ÿï¼Œè®°ä½åˆ«åï¼Œç…§åº”ä¸‹é¢.cè¯­æ³• ).group_by(Student.teacher) # ä»¥å­¦ç”Ÿè¡¨ä¸­çš„è€å¸ˆå¤–é”®åˆ†ç»„ # ä¸»æŸ¥è¯¢ query = Student.select( Student, # select ä¼ æ•´ä¸ªç±»ä»£è¡¨ï¼ŒæŸ¥è¯¢ temp_query.c.stu_count # æŒ‡å®šæŸ¥è¯¢å­—æ®µä¸º å­æŸ¥è¯¢çš„å­—æ®µï¼Œ æ‰€ä»¥éœ€è¦ç”¨ .c è¯­æ³•æ¥æŒ‡å®š ).join( temp_query, # å…³è” å­æŸ¥è¯¢ on=(temp_query.c.new_teacher == Student.teacher) # å…³è”æ¡ä»¶ ).dicts() for obj in query: print(obj) æ–¹å¼5ï¼š æ— å¤–é”®å…³è”æŸ¥è¯¢ (æ— å¤–é”®ä¹Ÿå¯ä»¥joinå“¦ï¼Œè‡ªå·±æŒ‡å®šonå°±è¡Œäº†) é‡æ–°å»ºç«‹ä¸€ä¸ªæ— å¤–é”®çš„è¡¨ï¼Œå¹¶æ’å…¥æ•°æ® class Teacher1(BaseModel): teacher_name = CharField() class Student1(BaseModel): student_name = CharField() teacher_id = IntegerField() mysql_db.create_tables([Teacher1, Student1]) data = ( ('Tom', ('zhang1', 1)), ('Jerry', ('zhang2', 2)), ) for teacher_name, student_obj in data: Teacher1.create(teacher_name=teacher_name) student_name, teacher_id = student_obj Student1.create(student_name=student_name, teacher_id=teacher_id) ç°åœ¨æˆ‘ä»¬å®ç°æ— å¤–é”®å…³è”æŸ¥è¯¢ï¼š &quot;&quot;&quot;æŸ¥è¯¢å­¦ç”Ÿ å¯¹åº”è€å¸ˆ çš„å§“å&quot;&quot;&quot; query = Student1.select( Student1, # ä¸Šé¢å…¶å®å·²ç»è®²è¿‡äº†,selecté‡Œé¢ä¼ æŸå­—æ®µå°±æŸ¥æŸå­—æ®µï¼Œä¼ ç±»å°±æŸ¥æ‰€æœ‰å­—æ®µ Teacher1 # å› ä¸ºåé¢æ˜¯joinäº†,ä½†peeweeé»˜è®¤æ˜¯ä¸åˆ—å‡º Teacher1è¿™å¼ å¤–è¡¨çš„ã€‚ # æ‰€ä»¥éœ€è¦æ‰‹åŠ¨æŒ‡å®šTeacher1 ï¼ˆå¦‚æœæˆ‘ä»¬æƒ³æŸ¥Teacher1è¡¨ä¿¡æ¯,è¿™ä¸ªå¿…é¡»æŒ‡å®šï¼‰ ).join( Teacher1, # è™½ç„¶æ— å¤–é”®å…³è”ï¼Œä½†æ˜¯ä¾æ—§æ˜¯å¯ä»¥joinçš„ï¼ˆåŸç”ŸSQLä¹Ÿå¦‚æ­¤çš„ï¼‰ on=(Student1.teacher_id==Teacher1.id) # è¿™ä¸ª onå¿…é¡»æ‰‹åŠ¨æŒ‡å®šäº† # å¼ºè°ƒä¸€ä¸‹ï¼Œæœ‰å¤–é”®çš„æ—¶å€™ï¼Œpeeweeä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬åšonæ“ä½œï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦æŒ‡å®š # ä½†æ˜¯ï¼Œè¿™ä¸ªæ˜¯æ— å¤–é”®å…³è”çš„æƒ…å†µï¼Œæ‰€ä»¥å¿…é¡»æ‰‹åŠ¨æŒ‡å®šon, ä¸ç„¶æ‰¾ä¸ç€ ).dicts() for obj in query: print(obj) æ–¹å¼6ï¼š è‡ªå…³è”æŸ¥è¯¢ # æ–°å®šä¹‰ä¸ªè¡¨ class Category(Model): name = CharField() parent = ForeignKeyField('self', backref='children') # æ³¨æ„ä¸€ä¸‹ï¼Œå¤–é”®å¼•ç”¨è¿™é‡Œå†™çš„æ˜¯ &quot;self&quot; ï¼Œè¿™æ˜¯æ˜¯å›ºå®šå­—ç¬¦ä¸²å“¦ ï¼›backrefæ˜¯åå‘å¼•ç”¨ï¼Œè¯´è¿‡äº†ã€‚ # åˆ›å»ºè¡¨ mysql_db.create_tables([Category]) # æ’å…¥æ•°æ® data = (&quot;son&quot;, (&quot;father&quot;, (&quot;grandfather&quot;, None))) def insert_self(data): if data[1]: parent = insert_self(data[1]) return Category.create(name=data[0], parent=parent) return Category.create(name=data[0]) insert_self(data) # è¿™æ˜¯æˆ‘è‡ªå·±å®šä¹‰çš„ä¸€ä¸ªé€’å½’æ’å…¥çš„æ–¹å¼ã€‚ã€‚å¯èƒ½æœ‰ç‚¹low # å¯èƒ½æœ‰ç‚¹ç»•ï¼Œæˆ‘æŠŠæ’å…¥ç»“æœç›´æ¥è´´å‡ºæ¥å§ mysql&gt; select * from category; +----+-------------+-----------+ | id | name | parent_id | +----+-------------+-----------+ | 1 | grandfather | NULL | | 2 | father | 1 | | 3 | son | 2 | +----+-------------+-----------+ # å¼€å§‹æŸ¥è¯¢ Parent = Category.alias() # è¿™æ˜¯è¡¨çš„ï¼ˆä¸´æ—¶æŸ¥è¯¢ï¼‰æ”¹åæ“ä½œã€‚ æ¥å—å‚æ•° Parent å³ä¸ºè¡¨å # å› ä¸ºè‡ªå…³è”å˜›ï¼Œè‡ªå·±å’Œè‡ªå·±ï¼Œå¤åˆ¶ä¸€ä»½ï¼ˆæ”¹åå°±ç›¸å½“äºä¸´æ—¶è‡ªæˆ‘æ‹·è´ï¼‰ query = Category.select( Category, Parent ).join( Parent, join_type=JOIN.LEFT_OUTER, # å› ä¸ºé¡¶éƒ¨ç±»ä¸ºç©ºï¼Œå¹¶ä¸”é»˜è®¤è¿æ¥æ–¹å¼ä¸º inner # æ‰€ä»¥æœ€é¡¶ç«¯çš„æ•°æ®ï¼ˆgrandfatherï¼‰æ˜¯æŸ¥ä¸åˆ°çš„ # æ‰€ä»¥æŸ¥æ‰€æœ‰æ•°æ®éœ€è¦ç”¨ ==&gt; å·¦è¿æ¥ # on=(Parent.id == Category.parent) # å®˜æ¡£è¯´ on éœ€è¦æŒ‡å®šï¼Œä½†æˆ‘è¯•äº†,ä¸å†™ä¹Ÿèƒ½å…³è”ä¸Š ).dicts() è‡³æ­¤ï¼Œå…³è”æŸ¥è¯¢æ“ä½œä»‹ç»ç»“æŸï¼ æ¥ä¸‹æ¥å¯¹ä»¥ä¸Šå…­ç§å…¨éƒ¨æ–¹å¼çš„åšä¸€äº›å¼ºè°ƒå’Œè¯´æ˜ï¼š ä½ å¯ä»¥çœ‹è§æˆ‘ä¹‹å‰å…­ç§æ–¹å¼éƒ½æ˜¯ç”¨çš„dicts()ï¼Œè¿”å›çš„æ˜¯ç±»å­—å…¸æ ¼å¼ã€‚ï¼ˆæ­¤æ–¹å¼çš„å­—æ®µåç¬¦åˆSQLè§„èŒƒï¼‰ å½“ç„¶ä½ ä¹Ÿå¯ä»¥ä»¥ç±»å¯¹è±¡çš„æ ¼å¼è¿”å›ï¼Œï¼ˆè¿™ç§æ–¹å¼éº»çƒ¦ä¸€ç‚¹ï¼Œæˆ‘æ¨èè¿˜æ˜¯ç”¨ dicts() ï¼‰ å¦‚æœæƒ³è¿”å›ç±»å¯¹è±¡ï¼Œè§å¦‚ä¸‹ä»£ç ï¼ˆä¸‹é¢è¿™ç§æ–¹å¼å¤šäº†ç‚¹ä¸œè¥¿ï¼‰ï¼š query = Teacher.select(Teacher.teacher_name, Student.student_name, Course.course_name) \\ .join_from(Teacher, Student) \\ .join_from(Teacher, Course, JOIN.LEFT_OUTER) # æ³¨æ„ï¼Œæˆ‘æ²¡æœ‰ç”¨dicts() for obj in query: print(obj.teacher_name) # è¿™è¡Œåº”è¯¥æ²¡é—®é¢˜å§ã€‚æœ¬èº«Teacherå°±æœ‰teacher_nameå­—æ®µ # æ³¨æ„äº†ï¼ŒæŒ‰SQLåŸç†æ¥è¯´ï¼Œæ—¢ç„¶å·²ç»åšäº†joinæŸ¥è¯¢ï¼Œé‚£ä¹ˆæŸ¥è¯¢ç»“æœå°±åº”è¯¥ç›´æ¥å…·æœ‰æ‰€æœ‰è¡¨çš„å­—æ®µçš„ # æŒ‰ç†è¯´ çš„ç¡®æ˜¯è¿™æ ·ï¼Œä½†æ˜¯peeweeï¼Œéœ€è¦æˆ‘ä»¬å…ˆæŒ‡å®šå¤šè¡¨çš„è¡¨åï¼Œåœ¨è·Ÿå†™å¤šè¡¨çš„å­—æ®µ,æ­£ç¡®å†™æ³•å¦‚ä¸‹ print(obj.student.student_name) # è€Œä¸æ˜¯ obj.student_nameç›´æ¥è°ƒç”¨ print(obj.course.course_name) # è€Œä¸æ˜¯ obj.course_nameç›´æ¥è°ƒç”¨ # å…ˆåŸ‹ä¸ªç‚¹ï¼Œ å¦‚æœä½ çœ‹åˆ°ä¸‹é¢çš„ N+1æŸ¥è¯¢é—®é¢˜çš„å®ä¾‹ä»£ç å’Œè¿™ä¸ªæœ‰ç‚¹åƒã€‚ # ä½†æˆ‘ç›´æ¥è¯´äº†ï¼Œ è¿™ä¸ªæ˜¯ç”¨äº†é¢„å…ˆjoin()çš„ï¼Œ æ‰€ä»¥æ¶‰åŠåˆ°å¤–è¡¨æŸ¥è¯¢åï¼Œä¸ä¼šè§¦å‘é¢å¤–çš„å¤–è¡¨æŸ¥è¯¢ # è‡ªç„¶ä¹Ÿä¸ä¼šå‡ºç°N+1çš„æƒ…å†µã€‚ # ä½†å¦‚æœä½ æ²¡æœ‰ç”¨joinï¼Œä½†æŸ¥è¯¢ä¸­æ¶‰åŠäº†å¤–è¡¨ï¼Œé‚£ä¹ˆå°±ä¼šè§¦å‘é¢å¤–çš„å¤–è¡¨æŸ¥è¯¢ï¼Œå°±ä¼šå‡ºç°N+1çš„æƒ…å†µã€‚ å…³è”N+1æŸ¥è¯¢é—®é¢˜ï¼š ä»€ä¹ˆæ˜¯N+1 query? çœ‹ä¸‹é¢ä¾‹å­ï¼š # æ•°æ®æ²¡æœ‰ä»€ä¹ˆç‰¹æ®Šçš„ï¼Œå‡è®¾ï¼Œ è€å¸ˆ å’Œ å­¦ç”Ÿçš„å…³ç³»æ˜¯ä¸€å¯¹å¤šï¼ˆæ³¨æ„ï¼Œæˆ‘ä»¬ç”¨äº†å¤–é”®ï¼‰ã€‚ class Teacher(BaseModel): teacher_name = CharField() class Student(BaseModel): student_name = CharField() teacher_id = ForeignKeyField(Teacher, backref='student') # æŸ¥è¯¢ teachers = Teacher.select() # è¿™æ˜¯ 1 æ¬¡ï¼Œ æŸ¥å‡ºNä¸ªæ•°æ® for teacher_obj in teachers: for student in teacher_obj.student: # è¿™æ˜¯ N æ¬¡å¾ªç¯ï¼ˆNä»£è¡¨æŸ¥è¯¢çš„æ•°æ®ï¼‰ print(student.student_name) # æ¯æ¶‰åŠä¸€ä¸ªå¤–è¡¨å±æ€§ï¼Œéƒ½éœ€è¦å¯¹å¤–è¡¨è¿›è¡Œé¢å¤–çš„æŸ¥è¯¢, é¢å¤–Næ¬¡ # æ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°ï¼Œ æˆ‘ä»¬æ€»å…±æŸ¥è¯¢ 1+Næ¬¡ï¼Œ è¿™å°±æ˜¯ N+1 æŸ¥è¯¢ã€‚ # ï¼ˆå…¶å®æˆ‘ä»¬å…ˆåšä¸ª è¡¨è¿æ¥ï¼ŒæŸ¥è¯¢ä¸€æ¬¡å°±å¯è§£å†³é—®é¢˜äº†ã€‚ã€‚ è¿™ N+1è¿™ç§æ–¹å¼ å±å®å¼Ÿå¼Ÿï¼‰ # ä¸‹é¢æˆ‘ä»¬ä»‹ç»2ç§é¿å… N+1 çš„æ–¹å¼ peeweeè§£å†³N+1é—®é¢˜æœ‰ä¸¤ç§æ–¹å¼ï¼š æ–¹å¼1ï¼šï¼ˆjoinï¼‰ ç”¨ join å…ˆè¿æ¥å¥½ï¼Œå†æŸ¥è¯¢ï¼ˆå‰é¢è¯´äº†6ç§æ–¹å¼çš„joinï¼Œæ€»æœ‰ä¸€ç§ç¬¦åˆä½ éœ€æ±‚çš„ï¼‰ å› ä¸º peeweeæ˜¯æ”¯æŒç”¨æˆ·æ˜¾ç¤ºè°ƒç”¨joinè¯­æ³•çš„ï¼Œ æ‰€ä»¥ joinæ˜¯ä¸ª ç‰¹åˆ«å¥½çš„è§£å†³ N+1 çš„é—®é¢˜ æ–¹å¼2ï¼š ï¼ˆpeeweeçš„prefetchï¼‰ # å½“ç„¶ï¼Œé™¤äº† joinï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨peeweeæä¾›çš„ä¸‹é¢è¿™ç§æ–¹å¼ # ä¹çœ¼ä¸€çœ‹ï¼Œä½ ä¼šå‘ç°å’Œæˆ‘ä»¬ä¸Šé¢å†™çš„ n+1 æŸ¥è¯¢æ–¹å¼çš„ä¾‹å­å·®ä¸å¤šï¼Œä¸ä¸€æ ·ï¼Œä½ ä»”ç»†çœ‹çœ‹ teacher = Teacher.select() # å…ˆé¢„å…ˆæŠŠ ä¸»è¡¨ æŸ¥å‡ºæ¥ student = Student.select() # å…ˆé¢„å…ˆæŠŠ ä»è¡¨ æŸ¥å‡ºæ¥ teacher_and_student = prefetch(teacher, student) # ä½¿ç”¨ prefetchæ–¹æ³• ï¼ˆå…³é”®ï¼‰ for teacher in teacher_and_student: # ä¸‹é¢å°±å’ŒN+1ä¸€æ ·äº† print(teacher.teacher_name) for student in teacher.student: print(student.student_name) è¯´æ˜ï¼š 0. prefetchï¼Œ åŸç†æ˜¯ï¼Œå°†æœ‰å¤–é”®å…³ç³»çš„ä¸»ä»è¡¨ï¼Œéšå¼&quot;ä¸€æ¬¡æ€§&quot;å–å‡ºæ¥ã€‚&quot;éœ€è¦æ—¶&quot;æŒ‰éœ€åˆ†é…å³å¯ã€‚ 1. ä½¿ç”¨prefetchå…ˆè¦æŠŠï¼Œæœ‰å¤–é”®å…³è”çš„ä¸»ä»è¡¨æŸ¥å‡ºæ¥ï¼ˆæ³¨æ„ï¼Œ&quot;å¿…é¡»å¿…é¡»è¦æœ‰å¤–é”®ï¼Œä¸ç„¶ä¸å¥½ä½¿&quot;ï¼‰ 2. prefetch(ä¸»è¡¨,ä»è¡¨) # ä¼ è¿›å»å°±è¡Œï¼Œpeeweeä¼šè‡ªåŠ¨å¸®æˆ‘ä»¬æ ¹æ®å¤–é”®æ‰¾å…³ç³» 3. ç„¶åæ­£å¸¸ ä»¥å¤–é”®å­—æ®µ ä¸ºæ¡¥æ¢ æŸ¥å…¶ä»–è¡¨çš„ä¿¡æ¯å³å¯ 4. ï¼ˆ é¢˜å¤–è¯ï¼Œdjnagoä¹Ÿæœ‰ç±»ä¼¼çš„prefetchåŠŸèƒ½,ï¼ˆåæ­£éƒ½æ˜¯é¿å…n+1ï¼Œä¼˜åŒ–ORMæŸ¥è¯¢ï¼‰ è²Œä¼¼ç»™å¤–é”®å­—æ®µ è®¾ç½®select_related() å’Œ prefetch_related() å±æ€§ ï¼‰ æœªç»“æŸè¯­ æœ¬ç¯‡ä¸»è¦è®²äº†ï¼ŒCRUD, ç‰¹åˆ«æ˜¯é’ˆå¯¹æŸ¥è¯¢åšäº†å¤§ç¯‡å¹…è¯´æ˜ã€‚ æˆ‘è¿˜ä¼šæœ‰ä¸‹ä¸€ç¯‡æ¥ä»‹ç»peeweeçš„æ‰©å±•åŠŸèƒ½ã€‚ ä¸Šä¸€ç¯‡ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020265149 ä¸‹ä¸€ç¯‡ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020287565 ","link":"https://cythonlin.github.io/post/py-greater-python-orm-zhi-peeweecrud-wan-zheng-jie-xi-er/"},{"title":"PY => Python-ORMä¹‹peeweeï¼šæ¨¡å‹-å­—æ®µ-ç´¢å¼•-çº¦æŸ-äº‹åŠ¡ï¼ˆä¸€ï¼‰","content":"å‰è¨€ å»githubæœ &quot;python orm&quot;ï¼Œæœ€é«˜starå±…ç„¶ä¸æ˜¯sqlalchemyï¼Œè€Œæ˜¯peewee åæ¥å¾—çŸ¥peeweeï¼Œæ¯”sqlalchemyç®€å•å¥½ç”¨ã€‚å€¼å¾—ä¸€å­¦å“¦ï¼ï¼ æˆ‘æ€»ä½“æ„Ÿè§‰ï¼ˆpeeweeåƒ Django-ORMçš„åˆ†ç¦»ç‰ˆï¼Œï¼Œä½†æ¯”Django-ORMå’ŒSqlAlchemy å°å·§ï¼Œç®€å•ï¼Œæ–‡æ¡£ä¹Ÿå‹å¥½ï¼‰ è¿˜æœ‰ä¸€ä¸ªæ›´é‡è¦çš„æ„Ÿè§‰å°±æ˜¯ï¼Œ peewee çš„ APIæ–¹æ³•å å’Œ SQLè¯­å¥ çš„ å•è¯ åŸºæœ¬ç›¸ä¼¼ã€‚ ä¾‹å¦‚å¯¹æ¯”ä¸€ä¸‹(å…³é”®è¯è¯­æ³•éƒ½æ˜¯ update å’Œ where)ï¼š SQLè¯­å¥ï¼šupdate Lang set name='Python' where name='Java'; Peeweeï¼šLang.update(name='Python').where(Lang.name == 'Java') è¿™ç§è‰¯å¿ƒçš„APIï¼Œå¯ä»¥å¤§å¤§é™ä½æˆ‘ä»¬çš„å­¦ä¹ æˆæœ¬ï¼Œè¿˜å¯ä»¥å·©å›ºæˆ‘ä»¬å¯¹SQLçš„è®°å¿†ï¼ï¼ï¼ï¼ï¼ï¼ æ€»å®˜æ¡£åœ°å€ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/quickstart.html å®˜æ–¹Githubåœ°å€ï¼šhttps://github.com/coleifer/peewee å®‰è£…å’Œå¯¼å…¥ pip install peewee from peewee import * # peeweeçš„æ¨¡å—å¾ˆç»“æ„åŒ–ï¼Œéƒ½åœ¨peeweeä¸­ï¼Œå¦‚æœæ‡’å°±éƒ½å¯¼å…¥è¿›æ¥ã€‚ å½“ç„¶ä½ ä¹Ÿå¯ä»¥ç†Ÿäº†ï¼ŒæŒ‰éœ€å¯¼å…¥ # åé¢æ— ç‰¹æ®Šæƒ…å†µï¼Œå°±éƒ½æ˜¯è¿™æ ·å¯¼å…¥çš„ã€‚æˆ‘å°±ä¸æäº†ã€‚ æ•°æ®åº“ postgresql å’Œ sqlite peewee åªæ”¯æŒ sqlite, mysql å’Œ postgresql æ•°æ®åº“ï¼Œ å¦‚æœä½ æœ‰éœ€æ±‚ç”¨oracleç­‰ï¼Œè¯·ç»•è¡Œã€‚ã€‚ã€‚ å¦‚éœ€sqlite å’Œ postgresqlï¼Œé…ç½®è¯·å‚è€ƒ http://docs.peewee-orm.com/en/latest/peewee/database.html#database mysql å½“ç„¶æˆ‘ç»å¸¸ç”¨MySQLï¼Œä»¥åçš„æ‰€æœ‰éƒ½å›´ç»•mysqlæ¥è®²ï¼Œå¦‚ä¸‹æ˜¯åŸºæœ¬é…ç½® mysql_db = MySQLDatabase( 'lin', # æ•°æ®åº“ user='root', # ç”¨æˆ·å password='123', # å¯†ç  host='IP', # IP port=3306, # ç«¯å£ charset='utf8mb4' # å­—ç¬¦é›†ç±»å‹ï¼Œ utf8mb4 æ˜¯ utf8çš„å¤§å“¥ ) peeweeçš„mysqlå¼•æ“é»˜è®¤ä¼˜å…ˆä½¿ç”¨pymysqlã€‚ å¦‚æœä½ æ²¡å®‰è£…pymysqlï¼Œ ä»–å°±ä¼šå»å¯»æ‰¾ MySQLdbã€‚ éƒ½æ²¡æœ‰å°±ä¼šæŠ¥é”™ã€‚ å—¯ï¼Œéƒ½å•¥å¹´ä»£äº†ï¼Œpython3çš„æ—¶ä»£ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨ pymysqlæ¨¡å—å³å¯ï¼Œè‹¥æ²¡å®‰è£…ï¼Œè·³å‡ºæ¥å®‰è£…ä¸‹å³å¯ pip install pymysql æ—¢ç„¶ç”¨çš„pymysqlé©±åŠ¨ï¼ŒMySQLDatabase() é‡Œé¢çš„å†™æ³• å’Œ pymysqlå¯¹è±¡å®ä¾‹åŒ–çš„å‚æ•°é…ç½®æ˜¯ä¸€æ ·çš„ã€‚ å¦‚æœæˆ‘ç»™çš„ä¾‹å­çš„å‚æ•°ä¸å¤Ÿç”¨ï¼Œä½ å¯ä»¥æ¥ä¸‹é¢çš„é“¾æ¥è‡ªå·±é€‰å§ï¼šhttps://github.com/PyMySQL/PyMySQL/blob/f08f01fe8a59e8acfb5f5add4a8fe874bec2a196/pymysql/connections.py#L494-L513 å»ºç«‹æ•°æ®åº“è¿æ¥ print(mysql_db.connect()) å…³é—­æ•°æ®åº“è¿æ¥ print(mysql_db.close()) æµ‹è¯•æ•°æ®åº“è¿æ¥æ˜¯å¦å…³é—­ mysql_db.is_closed() åˆ—å‡ºæ•°æ®åº“çš„æ‰€æœ‰è¡¨ï¼š mysql_db.get_tables() åˆ—å‡ºæ‰€æœ‰å­—æ®µçš„è¯¦ç»†ä¿¡æ¯ï¼š print(db.get_columns('owner')) # å‡è®¾ owneræ˜¯è¡¨åï¼Œä¸‹é¢åŒç† åˆ—å‡ºæ‰€æœ‰ä¸»é”®çš„å­—æ®µï¼š print(db.get_primary_keys('owner')) åˆ—å‡ºæ‰€æœ‰ç´¢å¼•å­—æ®µçš„è¯¦ç»†ä¿¡æ¯ï¼š print(db.get_indexes('owner')) åˆ—å‡ºæ‰€æœ‰å¤–é”®çš„å­—æ®µï¼š print(db.get_foreign_keys('owner')) Python å„ç§ webæ¡†æ¶åµŒå…¥ä½¿ç”¨ peewee æ¡ˆä¾‹ä¼ é€é—¨ï¼š å®˜æ¡£-Webæ¡ˆä¾‹ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/database.html#framework-integration è¡¨-è®°å½•-å­—æ®µ ORMè¯­æ³• å’Œ æ•°æ®åº“çš„ ï¼ˆè¡¨-è®°å½•-å­—æ®µï¼‰å¯¹åº”å…³ç³»å¦‚ä¸‹ï¼š ORMç»“æ„æ•°æ®åº“ ç±»è¡¨ å®ä¾‹ï¼ˆå¯¹è±¡ï¼‰è®°å½• ç±»å±æ€§åˆ— ### é»˜è®¤è‡ªå¢ä¸»é”®ID å®šä¹‰ä¸€ä¸ªç±»ï¼Œç»§æ‰¿äº†peeweeæ¨¡å—çš„Modelç±»ï¼Œè¿™ä¸ªç±»å°±å¯ä»¥å½“ä½œModelæ¥ç”¨äº† é¦–å…ˆå»ºç«‹ä¸€å¼ \"ç©ºè¡¨\" mysql_db = MySQLDatabase('lin_test', user='root', password='123', host='ip', port=3306, charset='utf8mb4') class Owner(Model): class Meta: database=mysql_db # è¿™é‡Œæ˜¯\"å¿…é¡»\" è¦æŒ‡å®šçš„ï¼Œ æŒ‡å®šå“ªä¸€æ•°æ®åº“ mysql_db.create_tables([Owner]) # æ³¨æ„ï¼Œæºç æ˜¯å–å‡ºå‚æ•°éå†ï¼Œæ‰€ä»¥è¿™é‡Œå‚æ•°ç”¨åˆ—è¡¨ ä¸Šè¿°ä»£ç å°±å¯ä»¥å»ºç«‹ä¸€å¼ \"ç©ºè¡¨\"ã€‚ ä¸ºä»€ä¹ˆ\"ç©ºè¡¨\" ç”¨å¼•å·æ‹¬èµ·æ¥å‘¢ï¼Ÿï¼Ÿ è¿™æ˜¯å…³äºpeewee ormçš„æœºåˆ¶ï¼Œ\"ä½ è‹¥ä¸æŒ‡å®šï¼ˆprimary keyï¼‰\"ï¼Œå®ƒå°±ä¼š\"è‡ªåŠ¨\"ä¸ºä½ åˆ›å»ºä¸€ä¸ª \"åä¸º id\", \"ç±»å‹ä¸º int\", å¹¶è®¾ç½®ä¸º \"primary\" çš„ \"è‡ªå¢(auto_increment)\" çš„å­—æ®µ ä½† ä¸€æ—¦ä½ æŠŠä¸€ä¸ªè‡ªå®šä¹‰çš„å­—æ®µï¼Œè®¾ä¸ºä¸»é”®ï¼Œé»˜è®¤çš„idå­—æ®µå°±ä¼šè¢«è¦†ç›–ï¼š name = CharField(primary_key=True) # nameè®¾ä¸ºäº†ä¸»é”®ï¼Œ åŸæœ‰çš„é»˜è®¤idå°±æ²¡äº† å®˜æ¡£ä¹Ÿè¯´æ˜ï¼šå¦‚æœä½ æƒ³è‡ªå·±å»ºç«‹ä¸€ä¸ªè‡ªå¢ä¸»é”®ï¼Œå¹¶è¦†ç›–é»˜è®¤idã€‚ä½ å¯ä»¥ç”¨AutoFieldå­—æ®µï¼š new_id = AutoField() # è¿™å¥è¯ç›´æ¥å°±ä¸ºä½  è®¾ç½®ä¸º intå‹ å’Œ ä¸»é”® å’Œè‡ªå¢ã€‚ \"è¿™æ˜¯å®˜æ¡£æœ€æ¨èè¦†ç›–idçš„æ–¹æ³•ï¼Œ è€Œä¸æ˜¯è‡ªå·±å¼„ä¸€ä¸ª Integerï¼Œå†è®¾ä¸»é”®\" è‡ªå¢idå°±è®²å®Œäº†ï¼Œ ä¸è¿‡ä½ æ˜¯å¦å‘ç°æ¯ä¸ª ç±»ä¸‹éƒ½æœ‰ class Meta: database= xxx # è¿™æ˜¯ä¸ºæ¯å¼ è¡¨æŒ‡å®šæ•°æ®åº“ï¼Œå¿…é¡»è¦æŒ‡å®šçš„ã€‚ä¸ç„¶å®ƒä¸çŸ¥é“ä½ è¿™ä¸ªè¡¨åœ¨å“ªä¸ªæ•°æ®åº“ æ—¢ç„¶è¿™æ ·ï¼Œè‹¥æˆ‘ä»¬è¦åœ¨ä¸€ä¸ªæ•°æ®åº“ä¸­åˆ›å»ºå¾ˆå¤šå¾ˆå¤šè¡¨ï¼Œé‚£å²‚ä¸æ˜¯æ¯æ¬¡éƒ½éœ€è¦ç»™æ¯å¼ è¡¨æŒ‡å®šä¸€ä¸ªæ•°æ®åº“ï¼Ÿï¼Ÿ å°±åƒè¿™æ ·ï¼š class User(Model): class Meta: database = mysql_db class Owner(Model): class Meta: database = mysql_db è¿™æ ·æœ‰ç‚¹çƒ¦ï¼Œä½†æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªåŸºç±»æŒ‡å®šå¥½æ•°æ®åº“ï¼Œ ç„¶åå…¶ä»–å­ç±»æ¨¡å‹ç»§æ‰¿å®ƒå°±å¥½äº†ã€‚ class BaseModel(Model): name = CharField(max_length=10) # å®šä¹‰ä¸€ä¸ª name å­—æ®µ class Meta: database = mysql_db class User(BaseModel): # ç»§æ‰¿åŸºç±» pass class Owner(BaseModel): # ç»§æ‰¿åŸºç±» pass mysql_db.create_tables([User, Owner]) # æ­£å¼åˆ›å»ºè¡¨ï¼Œ åŸºç±»ä¸éœ€è¦ï¼Œå¯ä»¥ä¸æ”¾è¿›æ¥ åƒä¸Šè¿°ä»£ç CharField, æ›´å¤šç±»å‹å­—æ®µå®šä¹‰ï¼Œå®˜æ¡£ç»™çš„å¾ˆè¯¦ç»†äº†ï¼Œæˆ‘ä¸å†èµ˜è¿°äº†ã€‚ å®˜æ¡£-å­—æ®µ-å‚æ•°ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/models.html#field-types-table ä½†ä¸‹é¢æˆ‘è¿˜ä¼šæŒ‘ä¸€äº›ä¸»è¦å¸¸ç”¨ï¼ˆæœ‰ä¸€ç‚¹ç‚¹ç‚¹éš¾ç‰¹åˆ«ï¼‰çš„è¯´ä¸€ä¸‹ã€‚ã€‚ã€‚ å¤–é”®å­—æ®µï¼ˆForeignKeyFieldï¼‰ æ™®é€šå¤–é”® class BaseModel(Model): # åŸºç±» name = CharField(max_length=10) class Meta: database = mysql_db class Owner(BaseModel): # ä¸»äººç±» pass class Pet(BaseModel): # å® ç‰©ç±» owner = ForeignKeyField( Owner, backref='owner_conn', # é€šè¿‡å¼•ç”¨åè·å–å¯¹è±¡ã€‚&quot;ä¸»äººï¼Œä½ å¯ä»¥é€šè¿‡è¿™ä¸ªåå­—è°ƒç”¨æˆ‘&quot; on_delete='Cascade', # çº§è”åˆ é™¤ # é»˜è®¤ä¸ºNoneï¼Œ è¿™æ—¶ï¼Œä½ æƒ³åˆ ä¸»äººæ˜¯åˆ ä¸æ‰çš„ã€‚ä¼šæŠ¥é”™ã€‚ å¿…é¡»å…ˆåˆ å® ç‰©å†åˆ ä¸»äººã€‚ # è®¾ä¸º Cascadeåï¼Œ ä½ å¯ä»¥ç›´æ¥åˆ ä¸»äººã€‚ ä»–çš„å® ç‰©ä¹Ÿä¼šéšä¹‹è‡ªåŠ¨åˆ é™¤ã€‚ è¿™å°±æ˜¯çº§è”åˆ é™¤ on_update=Cascade, # çº§è”æ›´æ–°ï¼ŒåŸç†åŒ on_delete ) å±‚çº§å¤–é”®ï¼ˆé€šå¸¸ç”¨äºå±‚çº§åˆ†ç±»,è‡ªå…³è”æŸ¥è¯¢ï¼‰ï¼š class Category(BaseModel): name = CharField() parent = ForeignKeyField('self', null=True, backref='children') æ³¨ï¼š &quot;self&quot; å­—ç¬¦ä¸²æ˜¯å›ºå®šè¯­æ³•ï¼Œ ä¸‹ä¸€ç¯‡è¿˜ä¼šå°†ï¼Œè‡ªå…³è”æŸ¥è¯¢ æ—¥æœŸå­—æ®µï¼ˆDateTimeFieldï¼‰ import datetime ...... date_time= DateTimeField(default=datetime.datetime.now) è¡¨å±æ€§ï¼ˆMetaï¼‰ è¡¨å±æ€§å°±æ˜¯å¯ä»¥ æ”¹è¡¨åï¼Œè®¾ç½®ä¸»é”®ï¼Œè”åˆä¸»é”®ï¼Œè®¾ç½®ç´¢å¼•ï¼Œè”åˆç´¢å¼•ç­‰æ“ä½œã€‚ä¸å†èµ˜è¿°ï¼Œè§å®˜æ¡£ã€‚ å®˜æ¡£ Meta: http://docs.peewee-orm.com/en/latest/peewee/models.html#model-options-and-table-metadata ç´¢å¼• å’Œ çº¦æŸ è®¾ç½®ç´¢å¼•æœ‰3ç§æ–¹æ³•ï¼š é€šè¿‡å®šä¹‰å­—æ®µçš„å‚æ•°ï¼š æ™®é€šç´¢å¼• name = CharField(index=True) å”¯ä¸€ç´¢å¼• name = CharField(unique=True) é€šè¿‡å®šä¹‰è¡¨å±æ€§Metaï¼š è”åˆå”¯ä¸€ç´¢å¼• class Meta: indexes = ( (('å­—æ®µ1', 'å­—æ®µ2'), True), # å­—æ®µ1ä¸å­—æ®µ2æ•´ä½“ä½œä¸ºç´¢å¼•ï¼ŒTrue ä»£è¡¨å”¯ä¸€ç´¢å¼• (('å­—æ®µ1', 'å­—æ®µ2'), False), # å­—æ®µ1ä¸å­—æ®µ2æ•´ä½“ä½œä¸ºç´¢å¼•ï¼ŒFalse ä»£è¡¨æ™®é€šç´¢å¼• ) éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸Šé¢è¯­æ³•ï¼Œä¸‰å±‚å…ƒç»„åµŒå¥—ï¼Œ å…ƒç»„ä½ æ‡‚å¾—ï¼Œ ä¸€ä¸ªå…ƒç´ æ—¶éœ€è¦åŠ ä¸ª , é€—å·ã€‚ åˆ«å¿˜äº†ã€‚ ç´¢å¼•APIï¼š å®˜æ¡£ï¼šhttp://docs.peewee-orm.com/en/latest/peewee/models.html#advanced-index-creation è®¾ç½®çº¦æŸæœ‰2ç§æ–¹æ³•ï¼š é€šè¿‡å®šä¹‰å­—æ®µçš„å‚æ•°ï¼š -------é€šå¸¸ç”¨æ¥å•ä¸€å­—æ®µä¸»é”®ï¼š name = CharField(primary_key=True) é€šè¿‡å®šä¹‰è¡¨å±æ€§Meta -------é€šå¸¸ç”¨ä½œè”åˆä¸»é”®ï¼š class Meta: primary_key = CompositeKey('å­—æ®µ1', 'å­—æ®µ2') # primary_key = False # ä¹Ÿå¯ä»¥ä¸ä½¿ç”¨ä¸»é”®ï¼ˆä¸è¦†ç›–ï¼Œä¹Ÿ å–æ¶ˆ åˆ›å»ºé»˜è®¤idå­—æ®µï¼‰ äº‹åŠ¡ æ”¯æŒwithä¸Šä¸‹æ–‡è¯­æ³•ï¼Œæ”¯æŒäº‹åŠ¡åµŒå¥—ï¼Œæ³¨æ„åµŒå¥—äº‹åŠ¡ åªä¼šå›æ»š ç¦»å®ƒæœ€è¿‘ çš„ä¸€å±‚ä¹‹é—´çš„ä»£ç ã€‚ åŒ…è£¹åœ¨withè¯­å¥ä¸­çš„ä»£ç ï¼Œåªè¦å­˜åœ¨å¼‚å¸¸ï¼Œå°±ä¼šå›æ»šã€‚åµŒå¥—çš„äº‹åŠ¡ï¼Œä¹Ÿæ˜¯æœ‰ä¸€å¤„å¼‚å¸¸ï¼Œæ‰€æœ‰å±‚äº‹åŠ¡éƒ½ä¼šå›æ»šã€‚ å½“ç„¶ä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨ rollback()æ¥å›æ»šã€‚ åµŒå¥—äº‹åŠ¡ç¤ºä¾‹å¦‚ä¸‹ï¼š with mysql_db.atomic() as transaction1: # ç¬¬ä¸€å±‚äº‹åŠ¡ã€‚ atomic(), å›ºå®šè¯­æ³•å°±ä¸è¯´äº†ã€‚ User.create(username='Tom') with mysql_db.atomic() as transaction2: # ç¬¬äºŒå±‚äº‹åŠ¡ User.create(username='Jerry') User.create(username='Spike') transaction2.rollback() # å°±è¿‘åŸåˆ™ï¼Œ ç¬¬äºŒå±‚çš„rollback()å›æ»š User.create(username='Butch') # å¦‚æœçœŸçš„å‡ºç°å›æ»šï¼Œé‚£ä¹ˆ ä» ç¬¬äºŒå±‚çš„ with() å¼€å§‹ç®— äº‹åŠ¡å†…å®¹ï¼Œ åˆ° rollback() ç»“æŸ # å½¢è±¡ä¾‹å­ï¼š é¡¶éƒ¨ é¢åŒ…ç‰‡ä» ç¬¬äºŒå±‚çš„with()å¼€å§‹å¤¹ï¼Œ åº•éƒ¨ é¢åŒ…ç‰‡ å¤¹åˆ° rollback() # æ³¨æ„ä¸€ç‚¹ï¼Œè™½ç„¶æ˜¯åµŒå¥—äº‹åŠ¡ï¼Œä½†æ˜¯æ¯å±‚withäº‹åŠ¡éƒ½æœ‰å¯¹åº”çš„åå­—ï¼ˆå°±æ˜¯with as ä¹‹åå˜é‡ï¼‰ã€‚ # æ‰€ä»¥å›æ»šå†™åœ¨å“ªå±‚äº‹åŠ¡é‡Œé¢ï¼Œ å°±è¦ç”¨å“ªå±‚äº‹åŠ¡çš„åå­—ï¼ˆå°±è¿‘åŸåˆ™ï¼‰ã€‚ ä¸ç„¶ä¼šæŠ¥é”™çš„ã€‚ # é”™è¯¯å®ä¾‹ï¼š å€’æ•°ç¬¬äºŒè¡Œçš„ï¼š transaction2.rollback() å†™æˆ transaction1.rollback()ã€‚ é”™è¯¯ï¼ å¸¦æœ‰commit()çš„åµŒå¥—äº‹åŠ¡ç¤ºä¾‹å¦‚ä¸‹ï¼šï¼ˆç¼©å°äº‹åŠ¡çš„ä»£ç èŒƒå›´ï¼Œ å°±åƒ &quot;é¢åŒ…é‡Œå¤¹çš„ä¸œè¥¿å˜å°‘äº†&quot; çš„æ„æ€ï¼‰ with mysql_db.atomic() as transaction1: # ç¬¬ä¸€å±‚äº‹åŠ¡ User.create(username='Tom') with mysql_db.atomic() as transaction2: # ç¬¬äºŒå±‚äº‹åŠ¡ User.create(username='Jerry') transaction2.commit() # å°±è¿™é‡Œå˜äº†ï¼Œ æ’å…¥äº†ä¸€è¡Œ commit User.create(username='Spike') transaction2.rollback() # rollback()å›æ»š User.create(username='Butch') # commit()ï¼ŒåŠ å…¥äº†è¿™ä¸€è¡Œï¼Œå°±æ„å‘³ç€ ä» è¿™è¡Œå¼€å§‹ç®— å›æ»šå†…å®¹ï¼Œåˆ° rollback() ç»“æŸ # å½¢è±¡ä¾‹å­ï¼š ï¼ˆé¡¶éƒ¨ é¢åŒ…ç‰‡ ä»commit() è¿™é‡Œå¼€å§‹å¤¹, åº•éƒ¨ é¢åŒ…ç‰‡ å¤¹åˆ° rollback() ï¼‰ ä¸Šé¢æ— è®ºå“ªä¸ªäº‹åŠ¡ä¾‹å­ï¼Œ éƒ½å¿…é¡»æ³¨æ„ï¼š æ¯å±‚äº‹åŠ¡ï¼Œåªç®¡è‡ªå·±å±‚å†…çš„ rollback()ï¼Œæ‰æœ‰æ•ˆï¼Œ ä¸èƒ½ç®¡å…¶ä»–å±‚çš„ã€‚ å°±ç®—ä½ ç”¨ commit() å¤¹ï¼Œ å¦‚æœè‡ªå·±å±‚å†…æ²¡æœ‰ rollback()ï¼Œ é‚£ä¹ˆä½ çš„ commit()æ˜¯æ— æ•ˆçš„ï¼ˆå¤¹ä¸ä½ï¼‰ äº‹åŠ¡å°±å·®ä¸å¤šè¿™äº›ï¼Œå®˜æ¡£è¿˜æœ‰ä¸€äº›ç”¨æ³•å’Œè¯­æ³•ï¼Œä½†æœ€ç»ˆåŠŸèƒ½ç»“æœéƒ½æ˜¯ä¸€æ ·çš„ã€‚é€‰ä¸€ç§ï¼ˆæˆ‘çš„ä¾‹å­ï¼‰å°±è¡Œã€‚ å®˜æ¡£-äº‹åŠ¡: http://docs.peewee-orm.com/en/latest/peewee/database.html#managing-transactions é—²æ‚ç”¨æ³• æŸ¥çœ‹ORMå¯¹åº”çš„åŸç”ŸSQLè¯­å¥ï¼š .....ORMè¯­å¥.sql() # åç¼€ .sql() æ‰“å°å¯¹åº”åŸç”Ÿsql æ‰§è¡ŒåŸç”ŸSQLï¼š # æ³¨æ„ï¼Œä¼ æ•°æ®ç”¨å‚æ•°ï¼Œä¸è¦ç”¨å­—ç¬¦ä¸²æ‹¼æ¥ï¼ˆé˜²SQLæ³¨å…¥ï¼‰ for owner in Owner.raw('select * from owner where name=%s', 'Alice'): print(owner.name) æ›´åŸç”Ÿçš„æ‰§è¡ŒåŸç”ŸSQL: print(mysql_db.execute_sql('select * from user').fetchall()) # sqlï¼Œå¯ä»¥ä¼ ä½ç½®å‚æ•°ï¼ˆé˜²æ³¨å…¥ï¼‰ï¼Œå°±åƒä½¿ç”¨ pymysqlä¸€æ ·ã€‚ è¡¨æ”¹åï¼š æ³¨ï¼šæˆ‘è¯´çš„æ”¹ååªæ˜¯æŸ¥è¯¢æ—¶çš„ä¸´æ—¶å ä¸‹ä¸€ç¯‡æ–‡ç« æŸ¥è¯¢ï¼Œä¼šæåˆ° å­—æ®µæ”¹åï¼Œ æ ¼å¼ï¼š å­—æ®µ.alias('æ–°å­—æ®µå') é‚£è¡¨æ”¹åä¹Ÿå·®ä¸å¤šï¼Œæœ‰2ç§æ–¹å¼ï¼š æ–¹å¼1ï¼š æ ¼å¼ï¼š è¡¨ç±».alias('æ–°è¡¨å') æ–¹å¼2ï¼š æ ¼å¼ï¼š æ–°è¡¨å = è¡¨ç±».alias() æœªç»“æŸè¯­ æœ¬ç¯‡å†™äº†ä¸€äº›å…¥é—¨æ€§çš„æ¨¡å‹çš„å»ºç«‹ï¼Œæ•°æ®åº“ï¼Œäº‹åŠ¡ï¼Œç´¢å¼•ï¼Œç®—æ˜¯æ¯”è¾ƒåŸºæœ¬çš„ã€‚ å½“ç„¶è¿˜æœ‰æ›´å¸¸ç”¨ï¼Œæ›´é‡è¦çš„CRUDç­‰ï¼Œä¼šåœ¨ä¸‹ä¸€ç¯‡ä»‹ç»ã€‚ ä¸‹ä¸€ç¯‡ä¼ é€é—¨ï¼šhttps://segmentfault.com/a/1190000020265522 ","link":"https://cythonlin.github.io/post/py-greater-python-orm-zhi-peeweemo-xing-zi-duan-suo-yin-yue-shu-shi-wu-yi/"},{"title":"PY => Pythonç‰ˆ-Dockerä½¿ç”¨seleniumç®€å•ç¤ºä¾‹","content":"Dockerfileå†…å®¹å¦‚ä¸‹ FROM python RUN pip install -i http://pypi.douban.com/simple \\ requests selenium retrying --trusted-host pypi.douban.com docker-compose.yamlå†…å®¹å¦‚ä¸‹ version: &quot;3.7&quot; services: myspider: build: . volumes: # æ•°æ®å·æ˜ å°„ - /root/mycode:/root/mycode command: python /root/mycode/1.py # ä¾èµ–ä¸‹æ–¹ seleniumæœåŠ¡ï¼Œæ³¨æ„æ­¤ä¾èµ–ä»…ä»…èƒ½åšåˆ° # seleniumæœåŠ¡å…ˆå¯åŠ¨ï¼Œ myspideræœåŠ¡åå¯åŠ¨ï¼ˆæœ‰çš„æœåŠ¡å†…éƒ¨ç¨‹åºå¯åŠ¨çš„å¿«ï¼Œæœ‰çš„æ…¢ï¼‰ # æ ¹æœ¬ç¨‹åº¦ä¸Šè¿˜æ˜¯è§£å†³ä¸äº† å®Œå…¨ä¾èµ– çš„ é—®é¢˜ï¼Œ å› æ­¤å¯ä»¥ç”¨å»¶æ—¶å¤„ç†ç­‰æ–¹æ³• depends_on: - selenium selenium: image: selenium/standalone-chrome # æ‹‰å–é•œåƒå®Œæˆè‡ªåŠ¨åŒ–å…¨å¥—é…ç½® ports: - &quot;4444:4444&quot; shm_size: 2g # è®¾ç½®ä¸»æœºå…±äº«å†…å­˜2g hostname: selenium # å…¶ä»–å®¹å™¨å¯ä»¥ç”¨æ­¤åæ¥è®¿é—® eg: http://selenium:4444/ çˆ¬è™«è„šæœ¬ä»£ç 1.pyå¦‚ä¸‹ import requests from selenium import webdriver from selenium.webdriver.common.desired_capabilities import DesiredCapabilities from selenium.webdriver.chrome.options import Options from retrying import retry # æ³¨ï¼šdocker-compose.yamlä¸­çš„depends_oné‚£é‡Œæåˆ°è¿‡ï¼š # æœåŠ¡å¯ä»¥èµ·åˆ°å…ˆåä¾èµ–çš„æ•ˆæœã€‚ # è€ŒæœåŠ¡ä¸­çš„å¯åŠ¨ç¨‹åºï¼Œå¹¶ä¸èƒ½è¾¾åˆ°å®Œå…¨çš„ä¾èµ–ï¼ˆå¯åŠ¨é€Ÿåº¦ç›¸å½“çš„æƒ…å†µä¸‹ï¼Œè°å¿«è°æ…¢è¿æ°”æˆåˆ†ï¼‰ # å¯ä»¥é€šè¿‡åŠ å»¶æ—¶æ¥æ§åˆ¶å…ˆåé¡ºåº # import time # time.sleep(3) # è¿™ç§ç¡çœ å»¶æ—¶æ–¹å¼ï¼Œæˆ–å¤šæˆ–å°‘ä¸å¤ªç²¾ç¡®ï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„ retryingä»£æ›¿ä¹‹ # ä¹Ÿå¯ä»¥é€šè¿‡ retryingæ¨¡å—è£…é¥°å®ç° # retryingç”¨æ³•ï¼Œå¯å‚è€ƒ https://segmentfault.com/a/1190000019301761#articleHeader17 @retry( stop_max_attempt_number = 10000, stop_max_delay = 10*1000, ) def verify_request(): response = requests.get(&quot;http://selenium:4444&quot;, timeout=0.5) print(response) verify_request() # ä¸‹é¢åŸºæœ¬ä¸Šæ˜¯è¿æ¥Docker SeleniumæœåŠ¡çš„å›ºå®šå†™æ³•ï¼Œå¯å½“ä½œæ¨¡æ¿å¥— options = Options() options.add_argument('--headless') with webdriver.Remote( command_executor='http://selenium:4444/wd/hub', # seleniumä¸ºdocker-composeçš„hostå desired_capabilities=DesiredCapabilities.CHROME, options=options ) as driver: driver.get('http://www.baidu.com') # è¿™é‡Œä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œ å¦åˆ™æ•°æ®å·æ˜ å°„å¤±è´¥ # æ˜ å°„éƒ¨åˆ†åœ¨ä¸Šé¢ docker-compose.yaml çš„ volumeséƒ¨åˆ† with open('/root/mycode/test.html', 'w') as f: f.write(driver.page_source) print('å†™å…¥æˆåŠŸ') è¸©å‘ selenium å› ä¸ºæœ‰æœåŠ¡ç«¯ç¨‹åºï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨è¿œç¨‹&quot;äº‘æœåŠ¡å™¨ç”¨Dockerå®¹å™¨éƒ¨ç½²&quot; å®¹å™¨éƒ¨ç½²åã€‚ã€‚ã€‚ã€‚ &quot;åªèƒ½äº‘æœåŠ¡å™¨ä¸­è®¿é—®ï¼Œ ä¸èƒ½åœ¨è¿œç¨‹æœåŠ¡å™¨è®¿é—®ã€‚ ï¼ˆ å…¶å®æ ¹æœ¬ä¸éœ€è¦åœ¨è¿œç¨‹æœåŠ¡å™¨è®¿é—®çš„ï¼ŒæŸç§é‚ªæ¶çš„å¿µå¤´ï¼Œè®©æˆ‘èµ°äº†å¼¯è·¯ã€‚ã€‚ã€‚ä¸€æ ¹ç­‹æƒ³è¦è¿œç¨‹è®¿é—® å…¶å®ä»£ç åŒæ˜¯éƒ¨ç½²åœ¨å®¹å™¨ä¸­çš„ï¼Œå®¹å™¨äº’é€šæ˜¯å®Œå…¨OKçš„ã€‚ ä½†å¦‚æœä½ ä¹Ÿæƒ³è¯•è¯•è¿œç¨‹è®¿é—®ï¼Œ å®ƒå´çœŸçš„æ— æ³•è®¿é—®ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ ï¼‰&quot; ï¼ˆ æˆ‘çš„è®¤çŸ¥é‡Œï¼Œæ—¢ç„¶äº‘æœåŠ¡å™¨å®¿ä¸»æœºå¯ä»¥è®¿é—®å®¹å™¨å†…éƒ¨ å¯åŠ¨çš„æœåŠ¡ç«¯ç¨‹åº è€Œè¿œç¨‹æœåŠ¡å™¨ä¸èƒ½è®¿é—®å®¹å™¨å†…éƒ¨çš„ å¯åŠ¨çš„æœåŠ¡ç«¯ç¨‹åºã€‚ã€‚ã€‚ã€‚é‚£ä¸€å®šæ˜¯å®¹å™¨å’Œå®¿ä¸»æœºè¿é€šé…ç½®é—®é¢˜é˜¿ã€‚ å¸¦ç€è¿™ä¸ªæ€è·¯ï¼Œæ‰¾äº†å¾ˆä¹…å¾ˆä¹…ï¼Œ ç„¶å¹¶åµã€‚ã€‚ã€‚ ï¼‰ å®åœ¨æ²¡åŠæ³•äº†ã€‚ã€‚kexueä¸Š ç½‘ï¼Œæœä¸€ä¸‹è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆå§ã€‚ åæ¥æ— æ„ä¸­å‘ç°ï¼Œå®¢æˆ·ç«¯ç°åœ¨å±…ç„¶å¯ä»¥è¿ä¸Šäº†ã€‚ã€‚ åæ¥æµ‹è¯•ï¼Œå“‡ï¼Œ æœç„¶æ˜¯ éœ€è¦kexue ä¸Š ç½‘æ‰èƒ½ è¿œç¨‹è®¿é—®åˆ°ï¼Œæ­¤æœåŠ¡ç«¯ã€‚ã€‚ã€‚ ä½†æˆ‘ç°åœ¨è¿˜æ²¡æœ‰æ˜ç™½ï¼Œä¸ºä»€ä¹ˆæˆ‘äº‘æœåŠ¡å™¨å®¿ä¸»æœºï¼Œ ä¸éœ€è¦kexue ä¸Š ç½‘ï¼Œä¹Ÿèƒ½æˆåŠŸè®¿é—®å†…éƒ¨å®¹å™¨çš„æœåŠ¡ç«¯ï¼Ÿï¼Ÿ ï¼ˆè™½ç„¶è¿™ä¸ªç–‘æƒ‘æ²¡æœ‰å¿…è¦ï¼‰ ","link":"https://cythonlin.github.io/post/py-greater-python-ban-docker-shi-yong-selenium-jian-dan-shi-li/"},{"title":"PY => Flaskæ¡†æ¶ä¸Sanicæ¡†æ¶åŸºæœ¬ä½¿ç”¨å¯¹æ¯”ä»‹ç»","content":"Sanic å’Œ Flask ç®€è¦æ¦‚è¿° &quot;&quot;&quot; Flaskå¸¸ç”¨ Sanicå’ŒFlaskå¾ˆåƒï¼Œäºæ˜¯æŒ‰ç€Sanicå®˜æ–¹æ–‡æ¡£å­¦äº†ä¸€ä¸‹ï¼Œå¯¹æ¯”Flaskå­¦ä¹ å¹¶åšä¸‹ç¬”è®°,å›é¡¾ä¸€ä¸‹ &quot;&quot;&quot; Flaskï¼šè½»é‡çº§Webæ¡†æ¶ï¼Œä¸‰æ–¹ç»„ä»¶é½å…¨ï¼Œç”¨æ—¶å®‰è£…ï¼Œæ‰©å±•çµæ´»åº¦é«˜ã€‚ Sanic: å’ŒFlaskç‰¹åˆ«åƒï¼ŒåŸºç¡€è¯­æ³•ï¼ŒåŸºç¡€å‘½åç‰¹åˆ«ç›¸ä¼¼ï¼ˆä½¿ç”¨å‡ ä¹å·®ä¸å¤šï¼‰ã€‚ Sanicæ˜¯åŸºäºUvloop(æ²¡ç”¨è¿‡ï¼Œäº†è§£å³å¯ï¼Œwindowsä¸æ”¯æŒ)å®ç°ï¼Œ å…·æœ‰ å¼‚æ­¥-éé˜»å¡çš„ç‰¹æ€§ ï¼ˆç½‘ä¸Šä¹Ÿæœ‰è¯´Sanicå¯ä»¥é€šè¿‡ä¸€äº›æ“ä½œåï¼Œå¯ä»¥åœ¨Windowsç¯å¢ƒä¸‹ä½¿ç”¨ï¼Œæˆ‘è¯•äº†è²Œä¼¼ä¸è¡Œï¼‰ ï¼ˆLinuxä¸‹è¿è¡Œæ‰ä¼šå…·æœ‰æœ€å¥½çš„æ€§èƒ½è¡¨ç°ï¼‰ python3.5+ åŸç”Ÿæ”¯æŒåŸç”Ÿåç¨‹ async+awaitï¼Œ è¿™ä¹Ÿå¯ä»¥åœ¨sanicçš„è§†å›¾ä¸­ç”¨åˆ°ï¼Œä¸‹é¢ä¼šä»‹ç» å®‰è£… pip install flask pip install sanic å…¥é—¨ç¨‹åº ï¼ˆFlask vs Sanicï¼‰ Flask: from flask import Flask app = Flask(__name__) @app.route('/') def index(): # æ³¨æ„è¿™è¡Œ return 'hello' # æ³¨æ„è¿™è¡Œ if __name__=='__main__': app.run('0.0.0.0', 1119, debug=True) Sanicï¼š from sanic import Sanic,response app = Sanic(__name__) @app.route('/') def index(request): # æ³¨æ„è¿™è¡Œ return response.text('hello') # æ³¨æ„è¿™è¡Œ if __name__=='__main__': app.run('0.0.0.0', 1119, debug=True) ä½¿ç”¨Sanicçš„æ­£ç¡®å§¿åŠ¿ ä¹‹ è§†å›¾å¼‚æ­¥éé˜»å¡ ä¸Šé¢å…¥é—¨ç¨‹åºå¯ä»¥çœ‹åˆ° flask å’Œ sanic çš„è·¯ç”±å¯¹åº”çš„è§†å›¾å‡½æ•°ï¼Œæ˜¯ä¸€æ ·çš„ ç‰¹æ®Šçš„æ˜¯ï¼šsanicæ”¯æŒå¼‚æ­¥é«˜æ€§èƒ½ï¼Œæ¯ä¸ª def å‰é¢ éœ€è¦åŠ ä¸Š async å³å¯ eg: @app.route('/') async def index(): # ä»¥åå†™æ¯ä¸ªè§†å›¾å‡½æ•°å‰é¢éƒ½è¦åŠ ä¸Š async return 'hello' æ¨¡æ¿å¼•æ“(Flask VS Sanic) Flask: from flask import render_template app = Flask(__name__) @app.route('/') def home(): return render_template('index.html', data=[dict(name='Tom', age=18), dict(name='Jerry', age=20)] ) # è¿™ä¸ªæ¨¡æ¿æ¸²æŸ“å™¨æ˜¯flaskåº“ä¸­è‡ªå¸¦çš„ï¼Œä¸éœ€é¢å¤–å®‰è£… Sanicï¼š pip install sanic-jinja2 # è¿˜éœ€å®‰è£…è¿™ä¸ªä¸‰æ–¹æ’ä»¶ from sanic import Sanic,response from sanic_jinja2 import SanicJinja2 as sj # å¯¼å…¥å°±ä¸è¯´äº†ï¼Œsjåªæ˜¯å‘½åæ¥æ–¹ä¾¿è°ƒç”¨ app = Sanic(__name__) tp = sj(app) # æ³¨æ„è¿™é‡Œï¼Œè¿™ä¸ªå’Œ flaskä¸‰æ–¹åº”ç”¨æ³¨å†Œæ˜¯ä¸€ä¸ªé“ç† ä½¿ç”¨æ–¹å¼1ï¼šï¼ˆSanicç‰¹æœ‰çš„è£…é¥°å™¨æ–¹å¼ï¼‰ @app.route('/') @tp.template('index.html') # æ³¨æ„è¿™è¡Œï¼Œä»¥è£…é¥°å™¨çš„æ–¹å¼æ¸²æŸ“æ¨¡æ¿ async def index(request): return { # æ³¨æ„è¿™é‡Œï¼Œè¿”å›å€¼å°±æ˜¯å‘æ¨¡æ¿å¡«å……çš„æ•°æ® 'data': [ dict(name='Tom', age=18), dict(name='Jerry', age=8) ] } ä½¿ç”¨æ–¹å¼2ï¼š ï¼ˆå’ŒFlaskæ¨¡æ¿ä½¿ç”¨æ–¹æ³•å¾ˆåƒï¼Œå¾ˆåƒï¼‰ @app.route('/') async def index(request): return tp.render( # è¿™ä¸ªæ–¹æ³•ä»£æ›¿äº† ä¸Šä¸€ç§æ–¹æ³•çš„è£…é¥°å™¨ 'index.html', request, # è¿™ä¸ªrequestå‚æ•°ï¼Œå¿…é¡»æœ‰ data = [ # æ¨¡æ¿æ¸²æŸ“æ•°æ®ä½œä¸º redner()çš„ **kwargså‚æ•°æ¥ä¼ é€’ dict(name='Tom', age=18), dict(name='Jerry', age=8) ] ) if __name__=='__main__': app.run('0.0.0.0', 1119, debug=True) å°ç»“ï¼š Flaskçš„æ¨¡æ¿æ¸²æŸ“æœºåˆ¶æ˜¯é›†æˆåœ¨ flaskåº“ä¸­ï¼Œç”¨ render_templateæ–¹æ³•æ¥ç›´æ¥æ¸²æŸ“æ¨¡æ¿ å¹¶ä¸”ï¼Œä»¥æ–¹æ³•å‚æ•°çš„å½¢å¼å‘æ¨¡æ¿ä¼ é€’æ•°æ® Sanicçš„æ¨¡æ¿æ¸²æŸ“æœºåˆ¶æ˜¯ä»¥ç¬¬ä¸‰æ–¹æ’ä»¶ sanic-jinja2 ä¸­çš„ SanicJinja2ç»„ä»¶æ¥å®ç°ã€‚ ä½¿ç”¨æ—¶ï¼Œéœ€è¦å…ˆæ³¨å†Œåˆ°appä¸­ï¼Œ æ‰€æ¥å—çš„è¿”å›å€¼ï¼Œä»¥è£…é¥°å™¨çš„æ–¹å¼æ¥æ¸²æŸ“æ¨¡æ¿ ä¸ªäººçœ‹æ³•ï¼š æŸç§ç¨‹åº¦ä¸Šæ¥è¯´ï¼Œ Sanic æ›´åŠ ç»†ç²’åº¦çš„å°† åŠŸèƒ½ ä»¥ç¬¬ä¸‰æ–¹åº”ç”¨çš„æ–¹å¼åˆ’åˆ†å‡ºæ¥ã€‚ å³ä¾¿å¦‚æ­¤ï¼Œä½†æˆ‘è¿˜æ˜¯å–œæ¬¢ flask ä¸­ render_templateæœºåˆ¶ã€‚ responseçš„å„ç§è¿”å›æ–¹å¼å¯¹æ¯”åˆ†æ(Flask VS Sanic) Flask: from flask import Markup, jsonify, send_file @app.route('/') def index(): # return 'hello' # Content-Type='text/plain' # return Markup('&lt;h1&gt;hello&lt;/h1&gt;') # åè½¬ä¹‰ # return jsonify(dict(name='Tom')) # Content-Type-'application/json' # return send_file('static/1.png') # è¿”å›å„ç§ç±»å‹æ–‡ä»¶ # return 'Tom'.encode('utf-8') # è¿”å›å­—èŠ‚å½¢å¼ ä¸‹é¢æ˜¯ä¿®æ”¹ çŠ¶æ€ç  å’Œ headers çš„æ–¹å¼: # return render_template('home.html'), 220, {'a': 1} æ ¼å¼ï¼š retrun è¯·æ±‚ä½“,çŠ¶æ€ç ,å“åº”å¤´ Sanic: @app.route('/') async def index(request): # return response.text('hello') # Content-Type='text/plain' # return response.html('&lt;h1&gt;hello&lt;h1/&gt;') # ä»£æ›¿åè½¬ä¹‰ # return response.json(dict(name='Tom')) # return response.redirect('/xxx') # return await response.file('static/1.png') # è¿”å›å„ç§ç±»å‹æ–‡ä»¶ï¼Œæ³¨æ„æœ‰ä¸ª await # return response.raw(b'Tom') # è¿”å›åŸç”Ÿå­—èŠ‚ç±»å‹æ•°æ® ä¸‹é¢æ˜¯ä¿®æ”¹ çŠ¶æ€ç  å’Œ headers çš„æ–¹å¼: 1. å¦‚æœè¿”å›çš„å“åº”ä½“ ä¸º æ¨¡æ¿ï¼Œå°±ç”¨ä¸‹é¢çš„æ–¹å¼ @tp.template('index.html',status=220,headers={'name':'Tom'}) # åœ¨è£…é¥°å™¨å‚æ•°é‡Œ 2. å¦‚æœè¿”å›çš„å“åº”ä½“ ä¸º éæ¨¡æ¿å†…å®¹ï¼Œå°±ç”¨å¦‚ä¸‹æ–¹å¼ return response.text('hello',300,{'name':'Tom'}) æ ¼å¼: response.text(è¯·æ±‚ä½“ï¼ŒçŠ¶æ€ç ï¼Œå“åº”å¤´) å°ç»“ï¼š ä¸Šé¢æ˜¯é’ˆå¯¹responseè¿”å›æ—¶ï¼Œå¯¹å„ç§æ•°æ®ç±»å‹çš„è¿”å›æ—¶å¯èƒ½ç”¨åˆ°çš„æ–¹å¼è¿›è¡Œå¯¹æ¯”ä»‹ç»ã€‚ åŒæ—¶è¿˜å¯¹æ¯”è®²è¿°äº† å¦‚ä½• ä¿®æ”¹ å“åº”å¤´ å’Œ çŠ¶æ€ç  ä¸ªäººçœ‹æ³•ï¼š Flaskï¼š 1. responseå„ç§å˜å½¢è¿”å›æ–¹å¼ éƒ½å°è£…äº† flaskè¿™ä¸ªæ¨¡å—ä¹‹ä¸­ 2. responseçš„å“åº”ä¿¡æ¯ï¼ˆçŠ¶æ€ç ï¼Œå“åº”å¤´ï¼‰ç­‰ï¼Œ é€šè¿‡ return ä»¥ é€—å·æˆ–å…ƒç»„ æ–¹å¼æ„é€ è¿”å›. eg: return å“åº”ä½“ï¼ŒçŠ¶æ€ç ï¼Œå“åº”å¤´ Sanic: 1. responseçš„å„ç§å˜å½¢è¿”å›æ–¹å¼ éƒ½å°è£…äº† sanic æ¨¡å—çš„ response ä¸­ ï¼ˆåˆ†ç±»æ›´åŠ æ˜ç¡®ï¼‰ 2. responseçš„å“åº”ä¿¡æ¯ï¼ˆçŠ¶æ€ç ï¼Œå“åº”å¤´ï¼‰ç­‰ï¼Œ éƒ½æ”¾åœ¨å‡½æ•°ä¸­ä½œä¸ºå‚æ•°. eg: response.xx(å“åº”ä½“ï¼ŒçŠ¶æ€ç ï¼Œå“åº”å¤´) requestçš„å„ç§è¯·æ±‚æ–¹å¼å¯¹æ¯”åˆ†æ ï¼ˆFlask vs Sanicï¼‰ Flask: from flask import request request.method # è·å–ç”¨æˆ·çš„è¯·æ±‚æ–¹å¼: GET æˆ– POST request.args # æ¥å—getçš„urlå‚æ•° request.form # æ¥å—postçš„formè¡¨å• Content-Type='x-www-form-urlencoded' request.json # å¿…é¡»æ¥å— Content-Type='application/json' æ ¼å¼è¯·æ±‚çš„æ•°æ® request.data # è¯·æ±‚æ•°æ®å¯¹åº”çš„Content-Typeé™¤äº†è¡¨å•ï¼ˆxxx-formï¼‰æ ¼å¼å¤–ï¼Œéƒ½å¯ç”¨æ­¤æ¥å— request.values # å¦‚æœ‰form å’Œ url è”åˆå‚æ•°ï¼Œç”¨è¿™ä¸ªæ¥å— æ³¨ï¼šä»¥ä¸Šè·å–çš„å¯¹è±¡éƒ½æ˜¯ ç±»å­—å…¸å¯¹è±¡ï¼Œ å¯ä»¥ä½¿ç”¨å­—å…¸çš„ get('å‰ç«¯name') è·å– value æ­¤å¤–ï¼š ä½ è¿˜å¯ä»¥ä½¿ç”¨ to_dict()æ–¹æ³•ï¼Œå°±å˜æˆäº†çº¯ç§çš„å­—å…¸ {k: v} img = request.files.get() # æ¥å—æ–‡ä»¶ç±»å‹ img.save(img.filename) # filenameè·å–æ–‡ä»¶åŸå§‹åï¼Œ saveç›´æ¥ä¿å­˜ï¼Œ é»˜è®¤å½“å‰è·¯å¾„ã€‚ request.url # http://localhost:5000/login request.path # /login request.host # localhost:5000 request.host_url # http://localhost:5000/ request.remote_addr # å•çº¯è·å–IPåœ°å€ Sanic: flaskä¸­çš„requestæ˜¯å¯¼å…¥è¿›æ¥çš„ è€Œsanicä¸­çš„requestæ˜¯åœ¨è§†å›¾å‚æ•°ä¹‹ä¸­ï¼ˆå‚è€ƒdjangoï¼‰ eg: def f(request) å°±æ˜¯è¿™ä¸ªæ„æ€ request.method # åŒFlask rqeust.args # åŒFlask request.form # åŒFlask request.json # è¯·æ±‚è‹¥ä¸ºè¡¨å•(xxx-form)æ ¼å¼ä¼šæŠ¥é”™ï¼Œ é™¤äº†è¡¨å•éƒ½å¯æ¥å— request.body # äº²æ±‚è‹¥ä¸ºè¡¨å•(xxx-form)æ ¼å¼ï¼Œåˆ™ä¼šå‡ºç°ä¸€å¤§å † äºŒè¿›åˆ¶ä¿¡æ¯ï¼Œéè¡¨å•éƒ½å¯æ¥å— request.url # åŒFlask request.path # åŒFlask request.host # åŒFlask request.ip # åŒæ ·å•çº¯è·å–IPï¼Œ å±æ€§åå’Œä¸Šé¢ flaskç¨å¾®æœ‰ç‚¹ä¸åŒ è·¯ç”±è®²è§£ ï¼ˆFlask vs Sanicï¼‰ Flask: @app.route( 'login/&lt;int:id&gt;', # è·¯ç”±å‚æ•°è§£æå¹¶ è‡ªåŠ¨è½¬æ¢intç±»å‹ï¼Œ å†’å·åä¸ºæ¥å—å‚æ•° methods=['GET,'POST'], # å»ºè®®å…¨éƒ¨å¤§å†™ endpoint='sign', # é»˜è®¤ä¸ºä¸‹é¢çš„è§†å›¾å‡½æ•°åï¼Œå³loginï¼Œç”¨äºurl_foråå‘è§£æ redirect_to='/xxx' # é‡å®šå‘è·³è½¬ï¼Œæ³¨æ„è¯·æ±‚è¿‡æ¥ç›´æ¥è·³è½¬ï¼Œä¸è¿›å…¥ä¸‹é¢è§†å›¾å‡½æ•° ) def login(id): # requestæ˜¯é»˜è®¤å¿…é¡»ä¼ é€’çš„å‚æ•°ï¼Œ idæ˜¯ä¸Šé¢è·¯ç”±è§£ææ¥æ”¶çš„ return f'{id+1}' # è·¯ç”±å‚æ•° + python3.6æ–°å¢è¯­æ³•å®ç° f-string æ¥å—å‚æ•°è‡ªå¢ Sanic: @app.route( 'login/&lt;int:id&gt;', # è·¯ç”±å‚æ•°è§£æå¹¶ è‡ªåŠ¨è½¬æ¢intç±»å‹ï¼Œ å†’å·åä¸ºæ¥å—å‚æ•° methods=['GET,'POST'], # å»ºè®®å…¨éƒ¨å¤§å†™ name='sign' # åŒ flask çš„ endpointï¼Œ ç”¨äº url_foråå‘è§£æ ) def login(request, id): # requestæ˜¯é»˜è®¤å¿…é¡»ä¼ é€’çš„å‚æ•°ï¼Œ idæ˜¯ä¸Šé¢è·¯ç”±è§£ææ¥æ”¶çš„ return f'{id+1}' # è·¯ç”±å‚æ•° + python3.6æ–°å¢è¯­æ³•å®ç° f-string æ¥å—å‚æ•°è‡ªå¢ Flask æ¨¡æ¿ ç›¸å…³æ“ä½œ (Flask) æ³¨ï¼šç”±äº sanic çš„ templateè¿˜ä¸æˆç†Ÿï¼Œ èŠ±å¼æ“ä½œæˆ‘ä¹Ÿå°±æ²¡æ‰¾ï¼Œä¸‹é¢å°±åªè®²ä¸€ä¸‹ flaskçš„å¸¸ç”¨æ¨¡æ¿æ“ä½œ æ¨¡æ¿å®(macro)ï¼š ä¸»è¦ç›®çš„æ˜¯ä¸ºäº†å‰ç«¯ä»£ç çš„å¤ç”¨ å®šä¹‰ æ¨¡æ¿å® å°±å’Œ å®šä¹‰ pythonçš„å‡½æ•°ç±»ä¼¼ï¼Œ æˆ–è€…ä½ å¯ä»¥æŠŠ macro çœ‹ä½œ pythonçš„ def eg: å®šä¹‰éƒ¨åˆ†ï¼šå¯ç†è§£ä¸ºå‡½æ•°å®šä¹‰ {% macro user(type, value) %} &lt;input type=&quot;{{ type }}&quot; value=&quot;{{ value }}&quot;&gt; {% endmacro %} è°ƒç”¨éƒ¨åˆ†ï¼šå¯ç†è§£ä¸ºå‡½æ•°è°ƒç”¨ {{ user('text', 'ç”¨æˆ·å') }} {{ user('password','å¯†ç ') }} å…¨å±€æ¨¡æ¿è‡ªå®šä¹‰å‡½æ•°ï¼š è§†å›¾æ–‡ä»¶.pyä¸­å®šä¹‰: @app.template_global() def f(x): return x**2 æ¨¡æ¿ä¸­è°ƒç”¨: {{ f(5) }} æ¨¡æ¿è¿‡æ»¤å™¨è‡ªå®šä¹‰å‡½æ•°ï¼š è§†å›¾æ–‡ä»¶.pyä¸­å®šä¹‰: @app.template_filter() def add(a, b): return a+b æ¨¡æ¿ä¸­è°ƒç”¨ï¼š {{ 1 | add(2) }} æ¨¡æ¿ç»§æ‰¿ï¼š ï¼ˆå¯ç†è§£ä¸ºæŒ–å‘ ä¸ å¡«å‘ï¼‰ çˆ¶çº§æ¨¡æ¿: header.html xxxxxxxå‰é¢è‹¥å¹²å†…å®¹ {% block header %} # è¿™ä¸ª headerï¼Œå°±æ˜¯æŒ–å‘èµ·çš„åï¼Œè®°ä½äº† è¿™é‡Œé¢å°±æ˜¯ä½ æŒ–çš„å‘ï¼Œå•¥ä¹Ÿä¸ç”¨å†™ {% endblock %} xxxxxxxåé¢è‹¥å¹²å†…å®¹ å­çº§æ¨¡æ¿ï¼šcontent.html {% extends 'header.html' %} # å¿…é¡»å†™ä¸Šè¿™å¥ï¼Œè¿™æ˜¯å¡«å‘çš„æš—å·ã€‚ã€‚ {% block header %} # è¿™ä¸ªåheaderæ˜¯å’Œä¸Šé¢æŒ–å‘çš„åä¸€æ · è¿™é‡Œé¢å°±æ˜¯ä½ è¦å¡«å‘çš„æ•°æ® {% endblock %} å¡«å®Œå‘ä¹‹åï¼Œè¿™ä¸ª content.htmlå­çº§æ¨¡æ¿çš„å†…å®¹ = çˆ¶çº§æ¨¡æ¿å†…å®¹ + å¡«å‘å†…å®¹ æ¨¡æ¿ä»£ç å—çš„å¯¼å…¥ï¼ˆæ’å…¥ï¼‰ï¼š ä½œç”¨è¿˜æ˜¯ html ä»£ç çš„å¤ç”¨ å†™å¥½ä¸€ä¸ª html ä»£ç å—ï¼Œæ”¾åœ¨ header.htmlä¸­ eg: &lt;h1&gt; Tom &lt;h1/&gt; # æ³¨æ„ï¼Œä¸€ä¸ªhtmlæ–‡ä»¶ä¸­å°±å†™è¿™ä¸€å¥å°±è¡Œ å¦ä¸€ä¸ªæ–‡ä»¶ï¼š index.html å†™å…¥ å¦‚ä¸‹ä»£ç : xxxxå‰é¢è‹¥å¹²å†…å®¹ {% include 'header.html' %} # è¿™ä¸€å¥å°±å¯æŠŠ é‚£ä¸€ä¸ªhtmlå†…å®¹å…¨éƒ¨æ’å…¥è¿›æ¥ xxxxåé¢è‹¥å¹²å†…å®¹ ï¼ˆä¸­é—´ä»¶ï¼‰é’©å­å‡½æ•° ï¼ˆFlask vs Sanicï¼‰ Flask: @app.errorhandler(404) # é”™è¯¯å¤„ç†çš„é’©å­å‡½æ•° def f(err): return 'å‡ºé”™äº†' æ³¨ï¼š å‡ºç°äº†å¼‚å¸¸ï¼Œ before_requestè£…é¥°çš„å‡½æ•°ä¼šç«‹åˆ»æ–­æ‰ï¼Œè€Œ after_requestçš„ä¼šä¾ç„¶å€’åºæ‰§è¡Œ @app.before_request # è§†å›¾å‡½æ•°æ‰§è¡Œä¹‹å‰ def f(): return Noneä»£è¡¨æ­£å¸¸æŒ‰é¡ºåºæ‰§è¡Œï¼Œ xxx retrunå…¶ä»–å€¼ï¼Œå°±ä¸ä¼šè¿›å…¥è§†å›¾å‡½æ•°ï¼Œç›´æ¥responseè¿”å› æ³¨ï¼š å¦‚æœæœ‰å¤šä¸ªbefore_requestï¼Œé‚£ä¹ˆå°± æ­£åº è£…é¥°æ‰§è¡Œ @app.after_request # è§†å›¾æ‰§è¡Œä¹‹åï¼Œè¿”å›ç»™ å®¢æˆ·ç«¯ä¹‹å‰ def f(res): å¿…é¡»æœ‰ä¸ªå‚æ•°æ¥å— responseå¯¹è±¡ï¼Œå¹¶ä¸”return å›å» xxx return res æ³¨ï¼š å¦‚æœæœ‰å¤šä¸ªbefore_requestï¼Œé‚£ä¹ˆå°± å€’åº è£…é¥°æ‰§è¡Œ å¦‚æœä»ç„¶ä¸æ˜ç™½æ‰§è¡Œé¡ºåºï¼Œçœ‹è¥¿é¢ä¾‹å­ï¼š eg: @app.before_request def req1(): print('è¯·æ±‚æ¥äº†-1') @app.before_request def req2(): print('è¯·æ±‚æ¥äº†-2') @app.after_request def res1(response): print('è¯·æ±‚èµ°äº†-1') @app.after_request def res1(response): print('è¯·æ±‚èµ°äº†-2') @app.route('/lin') def lin(): print('è¿›å…¥è§†å›¾') return '11' ç»“æœ&gt;&gt;&gt; è¯·æ±‚æ¥äº†-1 è¯·æ±‚æ¥äº†-2 è¿›å…¥è§†å›¾ è¯·æ±‚èµ°äº†-2 è¯·æ±‚èµ°äº†-1 # è¿™ä¸¤ä¸ªresponseæ˜¯é€†åºçš„ Sanic: from sanic.exceptions import NotFound @app.exception(NotFound) # é”™è¯¯å¤„ç†çš„é’©å­å‡½æ•° def f(request, err): return response.text('å‡ºé”™äº†') è¯·æ±‚ï¼Œè¿”å›ä¸­é—´ä»¶å’Œ flaskå¤§åŒå°å¼‚ï¼Œé¡ºåºæœ‰äº›åŒºåˆ«ï¼Œæˆ‘ç›´æ¥ä¸Šä¾‹å­äº† eg: @app.middleware('request') async def req(request): print('è¯·æ±‚æ¥äº†-1') @app.middleware('request') async def req(request): print('è¯·æ±‚æ¥äº†-2') @app.middleware('response') async def res(request, response1): print('è¯·æ±‚èµ°äº†-1') return response1 @app.middleware('response') async def res(request, response1): print('è¯·æ±‚èµ°äº†-2') return response1 @app.route(xxx) async def f(request): print('è¿›å…¥è§†å›¾') return response.text('xx') ç»“æœ&gt;&gt;&gt; è¯·æ±‚æ¥äº†-1 è¯·æ±‚æ¥äº†-2 è¿›å…¥è§†å›¾ è¯·æ±‚èµ°äº†-2 # æ³¨æ„è¿™é‡Œå³å¯ï¼Œåªè¿”å›ä¸€ä¸ªã€‚ä¸‹é¢ä¸åŒç‚¹ä¼šè¯¦è®² æ€»ç»“ï¼šFlask ä¸ Sanic ä¸­é—´ä»¶è¿”å›é¡ºåºå¯¹æ¯” ç›¸åŒç‚¹ï¼š requestå¤„ç†éƒ¨åˆ† : è£…é¥°å™¨ä»£ç vsæ‰§è¡Œæµç¨‹ =&gt; æ­£åº responseå¤„ç†éƒ¨åˆ†: è£…é¥°å™¨ä»£ç vsæ‰§è¡Œæµç¨‹ =&gt; é€†åº ä¸åŒç‚¹ï¼š Sanic åªæ‰§è¡Œ æœ€åä¸€ä¸ª ç”¨è£…é¥°å™¨æ³¨å†Œçš„ response Flask æ‰§è¡Œé¡ºåºæ˜¯ å…¨éƒ¨ ç”¨è£…é¥°å™¨æ³¨å†Œçš„ é€†åºè¿”å›çš„ response è“å›¾ ï¼ˆFlask vs Sanicï¼‰ è“å›¾ä½¿ç”¨ä¸‰éƒ¨æ›²ï¼š 1. æ–°å»ºç›®å½•å’Œæ–‡ä»¶ï¼Œåˆ›å»ºè“å›¾å¯¹è±¡ 2. åœ¨ä¸»appæ–‡ä»¶ä¸­, å¯¼å…¥è“å›¾å¯¹è±¡ 3. æ³¨å†Œè“å›¾å¯¹è±¡ Flask: 1. æ–°å»º /Admin/user.pyï¼Œå†™å…¥å¦‚ä¸‹ä»£ç  from flask import Blueprint user_bp = Blueprint('user_bp', __name__, url_prefix='/admin') # å¢åŠ urlå‰ç¼€ @user_bp.route('/user') def f(): return 'admin-user' 2. åœ¨appä¸­å¯¼å…¥ è“å›¾å¯¹è±¡ from Admin.user import user_bp 3. æ³¨å†Œè“å›¾ app.register_blueprint(user_bp) # è¿™é‡Œä¹Ÿå¯ä»¥å†™urlå‰ç¼€, å¦‚æœå†™äº†å°±ä¼šè¦†ç›–ä¸Šé¢å†™çš„ Sanic: 1. æ–°å»º /Admin/user.pyï¼Œå†™å…¥å¦‚ä¸‹ä»£ç  from sanic import Blueprint, response user_bp = Blueprint( __name__, url_prefix='/admin') @user_bp.route('/user') async def f(request): return response.text('admin-user') 2. åœ¨appä¸­å¯¼å…¥ è“å›¾å¯¹è±¡ï¼ˆåŒFlaskï¼‰ from Admin.user import user_bp 3. æ³¨å†Œè“å›¾ (æœ¬æ¥æ˜¯å’Œflaskä¸€æ ·ç”¨register_blueprintï¼Œåæ¥ç‰ˆæœ¬æ›´æ–°æ”¹ç”¨ blueprintæ³¨å†Œ) app.blueprint(user_bp) # è¿™é‡Œä¹Ÿå¯ä»¥å†™urlå‰ç¼€, å¦‚æœå†™äº†å°±ä¼šè¦†ç›–ä¸Šé¢å†™çš„ æ³¨ï¼šFlaskçš„è“å›¾å¯¹è±¡ï¼ŒåŒ Flaskç±»ä¼¼ï¼Œéƒ½å…·æœ‰æ¨¡æ¿è·¯å¾„ã€é™æ€æ–‡ä»¶è·¯ç”± ä¸ é™æ€æ–‡ä»¶æœ¬åœ°è·¯å¾„çš„é…ç½® å› æ­¤ï¼Œè“å›¾å®ä¾‹åŒ–çš„æ—¶å€™ï¼Œé…ç½®å“åº”å‚æ•°å³å¯ï¼š template_folder = 'xxx' # å¯¹åº”æœ¬åœ°æ¨¡æ¿è·¯å¾„ ï¼Œé»˜è®¤ templates static_folder = 'xxx' # å¯¹åº”æœ¬åœ°æ–‡ä»¶è·¯å¾„ ï¼Œé»˜è®¤ static static_url_path = '/xxx' # å¯¹åº”urlè·¯å¾„ ï¼Œé»˜è®¤ /static æ³¨2ï¼š å¦‚æœè“å›¾ å’Œ app çš„ æ¨¡æ¿æˆ–é™æ€æ–‡ä»¶å‘½åé‡å¤ï¼Œé‚£ä¹ˆä¼šä¼˜å…ˆé€‰æ‹© appä¸‹çš„æ¨¡æ¿æˆ–é™æ€æ–‡ä»¶ CBV ï¼ˆFlask vs Sanicï¼‰ CBV(Class-Based-View)ï¼š å°±æ˜¯æ‹¿ç±»å½“ä½œè§†å›¾ ï¼ˆæˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„å‡½æ•°ä½œä¸ºè§†å›¾ï¼‰ Flask çš„ CBVæ„Ÿè§‰æ²¡ FVBå¥½ç”¨ï¼Œ CBVæ˜¯Djangoçš„é‡ç‚¹ Flask: from flask import views class UserView(views.MethodView): methods = ['GET'] # è¿™é‡Œå†™ çš„æ˜¯ å…è®¸çš„è¯·æ±‚æ–¹å¼ decorators = [è£…é¥°å™¨å,] # å…¨å±€è£…é¥°å™¨é¡ºåºè£…é¥°ï¼Œ å•ç‹¬ç»™å‡½æ•°åŠ @è£…é¥°å™¨ä¹Ÿå¯ä»¥ def get(self,*args, **kwargs): return xx def post(self, *args, **kwargs): return xx app.add_url_rule( '/user',None,UserView.as_view('endpointå') ) Sanic: from sanic.views import HTTPMethodView class UserView(HTTPMethodView): async def get(self, request): return text('get') async def post(self, request): return text('post') app.add_route(UserView.as_view(), '/') # Sanic è§†å›¾åœ¨å‰ï¼Œè·¯ç”±åœ¨åã€‚ æ€»ç»“ï¼š è®²é“ç†ï¼ŒCBVåœ¨è¿™ä¸¤ä¸ªè½»å‹æ¡†æ¶æ„Ÿè§‰ç”¨çš„å¾ˆç¬¨æ‹™ã€‚ã€‚ è¿˜æ˜¯å¾ˆç”¨CBVè¾ƒå¥½ Flaskçš„flash ï¼ˆFlaskï¼‰ flashåŸç†ï¼š æœåŠ¡å™¨ç»™flashè®¾ç½®äº†å€¼ï¼Œé‚£ä¹ˆç”¨æˆ·æ¯è¯·æ±‚ä¸€æ¬¡ï¼Œå°±ä¼šæŠŠsessionæ”¾åˆ°ç”¨æˆ·cookieä¸­ (åé¢ä¼šæåˆ°sessionæ’ä»¶æ–¹æ³•) ä¸æ­¤åŒæ—¶ä¹ŸæŠŠ flashå€¼è®°å½•åœ¨é‡Œé¢ã€‚ flashå°±ç›¸å½“äºä¸€è·Ÿç®¡é“ flash(): # æŠŠå€¼å¡è¿›ç®¡é“ get_flashed_messages(): # æŠŠå€¼ä»ç®¡é“å–å‡ºæ¥ from flask import flash, get_flashed_messages # flashæ˜¯åŸºäº sessionæ¥å®ç°çš„ï¼Œæ‰€ä»¥éœ€è¦å†™ä¸€å¥ï¼š app.secret_key = '111' @app.route('/lin') def lin(): flash('666') return redirect('/user') @app.route('/user') def user(): msg = get_flashed_messages() print(msg) # æ³¨æ„ä» flashå–å‡ºæ¥çš„æ˜¯åˆ—è¡¨ï¼Œå› ä¸ºä½ å¯ä»¥æŠŠä¸åŒæ•°æ®å¤šæ¬¡ å¡«å…¥ flash return '' &gt;&gt;&gt; [666] ","link":"https://cythonlin.github.io/post/py-greater-flask-kuang-jia-yu-sanic-kuang-jia-ji-ben-shi-yong-dui-bi-jie-shao/"},{"title":"PY => Pythonç‰ˆ-Redisåˆ†å¸ƒå¼é”ç®€å•å®ç°","content":"å®šä¹‰ä»£ç å¦‚ä¸‹ import redis import contextlib import pickle import os, socket, threading class RedisLock: def __init__(self, lock_name, host='', port=6379, db=0): self.lock_name = lock_name self.redis = redis.Redis(connection_pool=redis.ConnectionPool(host=host, port=port, db=db)) def acquire_lock(self, lock_id, expire=None): lock_id = lock_id if lock_id else self.get_lock_id() return True if self.redis.set(self.lock_name, pickle.dumps(lock_id), nx=True, ex=expire) else False # Above 1 line code can replace with follow codes to debug # if self.redis.set(self.lock_name, pickle.dumps(lock_id), nx=True, ex=expire): # print('Lock Succeed') # return True # else: # print('Lock Failed') # return False def release_lock(self, lock_id=None): lock_id = lock_id if lock_id else self.get_lock_id() if lock_id == pickle.loads(self.redis.get(self.lock_name)): self.redis.delete(self.lock_name) # print('Unlock Succeed') return True else: # print('Unlock Failed') return False @contextlib.contextmanager def lock(self, lock_id=None, expire=None): if not self.acquire_lock(lock_id, expire): exit(0) yield self self.release_lock(lock_id) def get_lock_id(self): &quot;&quot;&quot; hostname+processID+threadName&quot;&quot;&quot; return f'{socket.gethostname()}{os.getpid()}{threading.current_thread().name}' è°ƒç”¨ä»£ç å¦‚ä¸‹ redis_lock = RedisLock('lockname', host='Your IP') # ç¬¬ä¸€ä¸ªåŒ¿åå‚æ•°å¿…ä¼ ï¼Œä½œä¸º redisçš„key with redis_lock.lock() as lock: print('You Can Do Something Here') æ³¨æ„è¯´æ˜ 1. æ³¨é‡Šéƒ¨åˆ†æ˜¯æˆ‘å†™çš„æ—¶å€™ï¼Œè°ƒè¯•ç”¨çš„ä»£ç ï¼Œæœ€åå†™å®Œçš„æ—¶å€™éƒ½æ›¿æ¢ä¸ºç®€æ´çš„è¯­æ³•. 2. å› ä¸ºé”å…·æœ‰äº’æ–¥ç‰¹æ€§ï¼Œ æ‰€ä»¥é€‰æ‹© set() çš„ nx å‚æ•°æ¥å®ç°ï¼Œ nxå‚æ•°ï¼šæˆ‘ä¸ªäººä¸€ç›´è¿™æ ·è®°ï¼ˆè¯»ä½œ not existï¼‰ ====&gt; ä¸å­˜åœ¨ ç†è§£ï¼š ä¸å­˜åœ¨åˆ™æ·»åŠ ï¼Œå­˜åœ¨å°±ä¸æ·»åŠ äº†ã€‚ ä¸¾ä¸€åä¸‰ï¼Œæ²¡æœ‰é”å°±åŠ ä¸ªé”ã€‚æœ‰é”å°±ä¸åŠ é”äº†ã€‚ 3. setæ–¹æ³• çš„ ex å‚æ•°ï¼Œ å¯ä»£æ›¿expireæ–¹æ³•çš„æ¥è®¾ç½®è¿‡æœŸæ—¶é—´ 4. redis æœ‰ å¾ˆå¤šæŒ‡ä»¤å˜å½¢ã€‚ æ¯”å¦‚ set(nx=, ex=) å¯æ‹†åˆ†ä¸º setnx setex ä½† &quot;set() è¿™ç§æŒ‡ä»¤æ›´ä¼˜&quot;ï¼Œ èƒ½ç”¨å°±å°½é‡ç”¨ï¼Œ ç†ç”±å¦‚ä¸‹ï¼š &quot;setæŒ‡ä»¤ å¥½å¤„æ˜¯ setå…·æœ‰åŸå­æ€§&quot;, é¿å…äº†è§£å†³èµ„æºç«äº‰çš„åŒæ—¶å¼•å‘è‡ªèº«å¯èƒ½å‡ºç°çš„èµ„æºç«äº‰ 5. æˆ‘ä½¿ç”¨è£…é¥°å™¨ç‰ˆ çš„ ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¯¹ä»£ç åšäº†å°è£…ï¼Œ æ‰€ä»¥è°ƒç”¨æ—¶ï¼Œç”¨&quot;withè¯­å¥&quot;å³å¯ 6. with redis_lock.lock() as lock ï¼Œ&quot;lock() è¿™é‡Œå¯ä»¥è‡ªå·±æŒ‡å®š2ä¸ªå‚æ•°&quot;ï¼š lock_id=None # è¿™æ˜¯åŒºåˆ†ä¸åŒçº¿ç¨‹çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œé»˜è®¤ä¸ºï¼ˆä¸»æœºå+è¿›ç¨‹ID+çº¿ç¨‹åï¼‰ï¼Œå¯è‡ªä¼  expire=None # è¿‡æœŸæ—¶é—´ï¼Œç§’ä¸ºå•ä½ 7. éœ€è¦æ³¨æ„ä¸€ä¸ªç‚¹ï¼Œä¸redisé€šä¿¡æ˜¯ä»¥äºŒè¿›åˆ¶å½¢å¼ã€‚ æ‰€ä»¥æˆ‘åœ¨ä»£ç å†…éƒ¨å¯¹ lock_id åšäº†&quot;pickleåºåˆ—åŒ–&quot; å½“ç„¶å¦‚æœæ˜¯å­—ç¬¦ä¸²ç”¨ encode() ä¸ decode() æ¥å®ç°ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚ ","link":"https://cythonlin.github.io/post/py-greater-python-ban-redis-fen-bu-shi-suo-jian-dan-shi-xian/"},{"title":"PY => Pythonç‰ˆ-Dockerä½¿ç”¨Appiumç®€å•å®éªŒ","content":"Docker-Appiumå®‰è£… Github docker-appiumåœ°å€ ï¼š https://github.com/appium/appium-docker-android åˆ›å»ºä¸´æ—¶å®¹å™¨ï¼ˆç”¨äºç®€å•å‘½ä»¤æµ‹è¯•ï¼‰ docker run --privileged -d -p 4723:4723 -v ~/.android:/root/.android -v /dev/bus/usb:/dev/bus/usb --name container-appium appium/appium è‹¥ä½¿ç”¨æ¨¡æ‹Ÿå™¨ç­‰ï¼ˆéUSBè¿æ¥ï¼‰ æ¨¡æ‹Ÿå™¨çš„adbå°†USBæ¨¡å¼è½¬ä¸ºTCPè¿æ¥æ–¹å¼ï¼š adb -s 127.0.0.1:62001 tcpip 1119 è¿œç¨‹Dockerè¿æ¥æ­¤æ¨¡æ‹Ÿå™¨ï¼š docker exec -it container-appium adb connect 192.168.0.103:1119 æŸ¥çœ‹è™šæ‹Ÿè®¾å¤‡æ˜¯å¦è¿æ¥æˆåŠŸ docker exec -it container-appium adb devices è‹¥ä½¿ç”¨çœŸæœºï¼ˆUSBè¿æ¥ï¼‰å¯ç›´æ¥ä½¿ç”¨å¦‚ä¸‹é…ç½® Dockerfileå†…å®¹å¦‚ä¸‹ FROM python RUN pip install -i http://pypi.douban.com/simple \\ requests retrying appium-python-client --trusted-host pypi.douban.com docker-compose.yamlå†…å®¹å¦‚ä¸‹ version: &quot;3.7&quot; services: myspider: build: . volumes: - /root/mycode:/root/mycode command: python /root/mycode/1.py depends_on: - appium appium: image: appium/appium # æ‹‰å–é•œåƒå®Œæˆè‡ªåŠ¨åŒ–å…¨å¥—é…ç½® ports: - &quot;4723:4723&quot; privileged: true hostname: appium # command: adb connect 192.168.0.103:1119 # command: # - /bin/sh # - -c # - | # adb connect 192.168.0.103:1119 # adb devices # entrypoint: adb connect 192.168.0.103:1119 volumes: - ~/.android:/root/.android - /dev/bus/usb:/dev/bus/usb çˆ¬è™«è„šæœ¬ä»£ç 1.pyå¦‚ä¸‹ from appium import webdriver from retrying import retry import requests import time config = {} config['platformName'] ='Android' config['platformVersion'] = '7.1.1' config['deviceName'] = 'åšæœ Pro 2' config['noReset'] = True config['appPackage'] = 'org.mozilla.firefox' config['appActivity'] = 'org.mozilla.gecko.BrowserApp' ################### æŸ¥çœ‹ appPackage å’Œ appActivity ################# ## æ³¨æ„ï¼š ## è¿™ä¸¤ä¸ªå€¼æ˜¯é’ˆå¯¹æŸä¸€è½¯ä»¶çš„é…ç½®ï¼Œä½ éœ€è¦åœ¨æ‰‹æœºä¸Šæ‰“å¼€ä½ è¿™ä¸ªè½¯ä»¶ï¼Œç„¶åå†æ‰§è¡Œæ­¤å‘½ä»¤ï¼š ## æˆ‘æ­¤ä¾‹å°±æ˜¯ç”¨çš„ æ‰‹æœºé‡Œé¢çš„ç«ç‹æµè§ˆå™¨ã€‚ ## é‚£ä¹ˆæˆ‘é¦–å…ˆéœ€è¦ï¼Œå°†ç«ç‹æ‰“å¼€ã€‚ ## ç„¶åå†æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æ‰èƒ½æŸ¥åˆ°æƒ³å¯¹åº”çš„é…ç½®ã€‚ ## å¦åˆ™ï¼ŒæŸ¥çš„æ˜¯ä½ æ‰‹æœºè¿è¡ŒçŠ¶æ€çš„ä¸»ç•Œé¢åº”ç”¨ç¨‹åºçš„é…ç½®ä¿¡æ¯ ## å‘½ä»¤å¦‚ä¸‹ï¼š ## docker exec -it container-appium adb shell # è¿›å…¥ adb shell ## dumpsys activity | grep mFocusedActivity ## è¿”å›ç»“æœ / å‰é¢çš„æ˜¯ appPackage çš„å€¼ ## è¿”å›ç»“æœ / åé¢çš„æ˜¯ appActivity çš„å€¼ @retry( stop_max_attempt_number = 1000000, stop_max_delay = 10*1000, ) def verify_request(): response = requests.get(&quot;http://appium:4723/wd/hub&quot;,timeout=0.5) print(response) verify_request() with webdriver.Remote( command_executor='http://appium:4723/wd/hub', desired_capabilities=config ) as driver: driver.get('https://tieba.baidu.com/index.html') time.sleep(5) with open('/root/mycode/test.html', 'w') as f: f.write(driver.page_source) print('å†™å…¥æˆåŠŸ') time.sleep(3) å‰æƒ…é“¾æ¥ Pycharm ä¸ Docker ç›¸å…³æ“ä½œï¼šhttps://segmentfault.com/a/1190000020050218 Docker ä¸­ Seleniumçš„ä½¿ç”¨ï¼š https://segmentfault.com/a/1190000020067591 ","link":"https://cythonlin.github.io/post/py-greater-python-ban-docker-shi-yong-appium-jian-dan-shi-yan/"},{"title":"PY => Pycharmè¿æ¥DockeråŠä»£ç è‡ªåŠ¨ä¸Šä¼ ä¸è¿è¡Œ","content":"ä¸€ã€Pycharmåˆ›å»ºDockerå®¢æˆ·ç«¯ äºŒã€ä¿®æ”¹Dockerå®¢æˆ·ç«¯é…ç½® åœ¨pycharmåº•éƒ¨ç‚¹è¿™ä¸ªæ‰“å¼€é…ç½® å¡«å†™DockeræœåŠ¡ç«¯ï¼Œçš„IPåœ°å€åŠç«¯å£ï¼ˆtcp:// ä¸èƒ½å°‘ï¼‰ ä¸Šé¢è¿™ä¸ªé…ç½®å®Œåï¼Œä¸‹é¢ä¼šå‡ºç° connected successfullyï¼Œè¯´æ˜é…ç½®æˆåŠŸã€‚ å¦‚æœé…ç½®å¤±è´¥ï¼Œæœ‰å‡ ç§æƒ…å†µï¼š ä¸€ã€ ä½ å½“å‰ä¸»æœºç¯å¢ƒ æ— æ³• ping é€š Dockeræ‰€åœ¨æœåŠ¡å™¨ï¼ˆäº‘æœåŠ¡å™¨ã€é˜²ç«å¢™ã€çš„ç«¯å£æ²¡æ”¾é€šï¼‰ äºŒã€ Dockeræœªåš IPé…ç½® å¦‚ä½•é…ç½®å‚è€ƒä¸‹é¢é“¾æ¥çš„è§£å†³æ–¹æ¡ˆå³å¯é…ç½®æˆåŠŸã€‚ https://segmentfault.com/q/1010000020042977 é…ç½®å®Œæˆåï¼Œè®°å¾—é‡å¯ DockeræœåŠ¡ ä¸‰ã€Pycharm sftpå‘Dockeræ‰€åœ¨ä¸»æœºä¸Šä¼ ä»£ç  è¿æ¥æµ‹è¯•æˆåŠŸåï¼Œ ä¸è¦ç‚¹OKï¼Œ é€‰æœ€ä¸Šé¢çš„ Mappingsé¡¹,ç»§ç»­é…ç½® ä¸Šé¢é…ç½®å®Œåï¼Œç‚¹OKï¼Œç„¶åå¼€å§‹ä¸Šä¼  å››ã€åˆ›å»ºDockeré‡Œçš„Pythonè§£é‡Šå™¨ ctrl+alt+sæ‰“å¼€é…ç½®ï¼Œ ç„¶åæŒ‰ä¸‹å›¾æ“ä½œæ·»åŠ è§£é‡Šå™¨ äº”ã€ç»™è„šæœ¬æŒ‡å®šè§£é‡Šå™¨ åŠ ç›¸å…³é…ç½® ä¸‹é¢å…¶ä»–éƒ½æ˜¯é»˜è®¤é…å¥½çš„ï¼Œ ä¸»è¦é…ç½®ä¸‹é¢çº¢æ¡†éƒ¨åˆ†çš„ 2 å¤„å†…å®¹ åˆ‡è®°ï¼š ä¸Šé¢çš„ç¬¬ä¸€ä¸ªçº¢æ¡†ï¼š Path mappingsé¡¹ å¿…é¡»é…ï¼Œä¸ç„¶å°±ä¼šå‡ºç°ä¸‹å›¾çš„é”™è¯¯ è¿™ä¸ªé”™è¯¯ï¼Œstack, githubéƒ½æ²¡æ‰¾åˆ°è§£å†³åŠæ³•ã€‚ ï¼ˆæ˜æ˜å·²ç»æ˜¯ç»å¯¹è·¯å¾„äº†ï¼Œè¿˜æ˜¯è®©ä½ æä¾›ç»å¯¹è·¯å¾„ï¼‰ åæ¥æ— å¥ˆä¹‹ä¸‹ï¼Œéšæ‰‹æŠŠ Path mappings è¿™é¡¹æ˜ å°„é…äº†ã€‚ å±…ç„¶å°±æˆåŠŸäº†ã€‚ã€‚ã€‚ã€‚ã€‚ï¼ï¼ å…­ã€æœ€åç›´æ¥æ‰§è¡Œæœ¬åœ°pythonæ–‡ä»¶å³å¯ å°±æ˜¯æˆ‘ä»¬å¹³æ—¶åœ¨pycharmæ­£å¸¸å†™ä»£ç çš„æ‰§è¡Œæ“ä½œã€‚ã€‚ã€‚ æ€»ç»“ + è§£æƒ‘ æ€»ç»“ æˆ‘ä»¬åˆ›å»ºäº†Dockerå®¢æˆ·ç«¯,å¹¶ä¿®æ”¹äº†ç›¸å…³é…ç½® sftpä¸Šä¼ ä»£ç ï¼ˆæˆ‘ä»¬æ˜ å°„éƒ¨åˆ†ï¼Œå¡«çš„æ˜¯è·¯å¾„ï¼Œ å®ƒä¼šè‡ªåŠ¨æŠŠè¯¥è·¯å¾„ä¸‹çš„æ–‡ä»¶ä¸Šä¼ åˆ°äº‘æœåŠ¡å™¨ï¼‰ åˆ›å»ºpythonè§£é‡Šå™¨ï¼Œå¹¶åšå‡ºè¯¦ç»†é…ç½®ï¼ˆå„ç§æ˜ å°„ï¼‰ ç–‘æƒ‘è§£æï¼š ä¸ºå•¥ä¿®æ”¹ä»£ç ä¿å­˜ä¸€æ¬¡ï¼Œè¿œç¨‹æœåŠ¡å™¨ä¹Ÿä¼šåŒæ­¥è‡ªåŠ¨ä¿®æ”¹ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ å› ä¸ºæˆ‘ä»¬åœ¨sftpçš„æ—¶å€™ï¼Œmapppingsé€‰é¡¹ä¸­ é…ç½®äº†å®¢æˆ·ç«¯å’Œäº‘æœåŠ¡å™¨çš„ä»£ç ç›®å½• æ˜ å°„ã€‚ å¹¶ä¸”ï¼Œæˆ‘ä»¬åœ¨ç¬¬ä¸€æ¬¡åŒæ­¥ä»£ç çš„æ—¶å€™å‹¾é€‰äº†ï¼Œè‡ªåŠ¨åŒæ­¥é€‰é¡¹ ï¼ˆAutomatic uploadï¼‰ ä¸ºå•¥å¯ä»¥æ“ä½œè¿œç¨‹çš„Dockeré‡Œé¢çš„pythonè§£é‡Šå™¨ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ é¦–å…ˆæˆ‘ä»¬åˆ›å»ºäº† docker çš„å®¢æˆ·ç«¯ã€‚å¹¶åšå‡ºäº† è¿æ¥è¿œç¨‹æœåŠ¡å™¨çš„é…ç½®ã€‚ åŸºäºä¸Šè¿°æ¡ä»¶ï¼Œæˆ‘ä»¬åœ¨å»ºè§£é‡Šå™¨æ—¶åšäº†å¦‚ä¸‹æ“ä½œ: é€‰å®šäº‘æœåŠ¡å™¨çš„Docker, é€‰å®šDockerä¸­çš„é•œåƒ é€‰å®šDockerä¸­çš„é•œåƒä¸­çš„pythonè§£é‡Šå™¨ pythoné•œåƒæ˜¯Dockerï¼ˆå†…éƒ¨ï¼‰ï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬å¯ä»¥ç›´æ¥è®¿é—®äº‘æœåŠ¡å™¨ï¼ˆå¤–éƒ¨ï¼‰æ¥è¾¾åˆ°éœ€æ±‚ ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ å› ä¸ºæˆ‘ä»¬åœ¨é…ç½®è§£é‡Šå™¨çš„æ—¶å€™ï¼Œ é…ç½®äº†æ•°æ®å·æ˜ å°„ï¼ˆç¬¬ äº” ç« æˆªå›¾å†…Docker Container settingsé¡¹ï¼‰ å½“ç„¶è¿™å±äºDockeræ•°æ®å·ï¼ˆvolumeï¼‰çŸ¥è¯†ç‚¹èŒƒç•´ã€‚ Dockeræ•°æ®å·æ•™ç¨‹å‚è€ƒé“¾æ¥ï¼šhttps://segmentfault.com/a/1190000020039341#articleHeader37 END ","link":"https://cythonlin.github.io/post/py-greater-pycharm-lian-jie-docker-ji-dai-ma-zi-dong-shang-chuan-yu-yun-xing/"},{"title":"PY => Dockerè¯­æ³•å…¨é¢å›å¿†","content":"Hello Docker å®˜æ–¹å®‰è£…æ•™ç¨‹ï¼šhttps://docs.docker.com/install/linux/docker-ce/ubuntu/ è¿›å»é€‰å¥½å¯¹åº”ç³»ç»Ÿ/å‘è¡Œç‰ˆï¼Œ ç…§ç€å‘½ä»¤å¤åˆ¶-ç²˜è´´-è¿è¡Œã€‚ å°±å¯ä»¥å®‰è£…æˆåŠŸï¼ˆæ ¹æœ¬ä¸éœ€è¦å¤šä½™æ“ä½œï¼‰ Imageï¼ˆé•œåƒï¼‰ docker search docker search python # åˆ—å‡ºdockerhub æä¾›çš„ image docker pullï¼ˆä¸‹è½½ï¼‰ docker pull python:3.7 # ä» dockerhubä¸‹è½½ image å†’å·:æ•°å­— ç”¨æ¥æŒ‡å®šç‰ˆæœ¬ï¼ˆä¸æŒ‡å®šå°±æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼‰ docker imagesï¼ˆåˆ—å‡ºï¼‰ docker images # åˆ—å‡ºæœ¬åœ°é•œåƒ ï¼ˆæˆ– docker image lsï¼‰ docker images py* # ä¹Ÿå¯ä»¥é€šè¿‡åç§°æ¥ç­›é€‰æŸ¥çœ‹ imageï¼Œ ä¹Ÿå¯ä½¿ç”¨é€šé…ç¬¦ docker rmiï¼ˆåˆ é™¤ï¼‰ docker rmi &quot;imageå&quot; æˆ– &quot;imageID&quot; # åˆ é™¤ image docker rmi python -f # å¼ºåˆ¶åˆ é™¤ï¼ˆå½“imageå†…æœ‰å®¹å™¨è¿è¡Œæ— æ³•åˆ é™¤æ—¶ï¼Œå¯é€šè¿‡-få¼ºåˆ¶åˆ é™¤ï¼‰ å¦‚æœä¸¤ä¸ªimageæœ‰ç›¸åŒ &quot;imageID&quot;ï¼Œä¼šåˆ é™¤å¤±è´¥ï¼Œ è¿™æ—¶å¯ä»¥è€ƒè™‘ç”¨ &quot;imageå&quot; æ¥åˆ é™¤ å¦‚æœä¸¤ä¸ªimageæœ‰ç›¸åŒçš„ &quot;imageå&quot;ï¼Œ é‚£ä¹ˆå¯ä»¥è€ƒè™‘ç”¨ &quot;imageå:Tag&quot; æ¥åˆ é™¤ docker saveï¼ˆä¿å­˜å¤‡ä»½ï¼‰ æ–¹å¼1ï¼šdocker save python &gt; python.tar # å¯è¿½åŠ å¤šä¸ªimageæ¥ æŠŠå¤šä¸ªimageæ‰“åŒ…ä¿å­˜ æ–¹å¼2: docker save python -o python.tar python.taræ–‡ä»¶ å¯åˆ†äº«ä¼ è¾“ï¼Œç»™åˆ«äººè¿˜åŸåŠ è½½ä½¿ç”¨ æ³¨ï¼š ä¸Šä»¤ä¸ºä¾‹ï¼Œå¦‚æœæœ‰å¤šä¸ªpythonç‰ˆæœ¬ï¼Œ é‚£ä¹ˆä¼šå°†æ‰€æœ‰python images éƒ½ä¼šæ‰“åŒ…åœ¨ä¸€èµ·ä¿å­˜ å¦‚æœä½ æœ‰å¤šä¸ªé•œåƒï¼Œ ä¸ºäº†é¿å…æ··æ·†ï¼Œä¸€å®šè¦æŒ‡å®šä¸€ä¸‹ç‰ˆæœ¬å· docker save python:latest docker loadï¼ˆè¿˜åŸï¼‰ æ–¹å¼1ï¼š docker load -i python.tar æ–¹å¼2ï¼š docker load &lt; python.tar docker tagï¼ˆæ”¹åï¼Œæ”¹ç‰ˆæœ¬å·ï¼‰ docker tag python:latest py:3.7 # æŠŠ &quot;python:latest&quot; æ”¹ä¸º &quot;py:3.7 &quot; æ³¨1ï¼š è‹¥imageåä¸ä¸º&lt;none&gt;, é‚£ä¹ˆé¦–å…ˆä¼šå°† image å¤åˆ¶åˆ›å»ºä¸€ä»½ï¼Œç„¶åæ”¹å æ³¨2ï¼š è‹¥åŸimageåä¸º &lt;none&gt; ï¼Œé‚£ä¹ˆ æ”¹ååï¼Œä¼šç›´æ¥åœ¨åŸæœ‰imageä¸Šç›´æ¥æ”¹å docker inspectï¼ˆæŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼‰ docker inspect python docker historyï¼ˆæŸ¥çœ‹åˆ†å±‚å†å²ä¿¡æ¯ï¼‰ docker history mypython:3.7 Containerï¼ˆå®¹å™¨ï¼‰ docker createï¼ˆåˆ›å»ºï¼‰ docker create --name py-con python:latest # --nameåè‡ªå®šä¹‰åå­—ï¼Œ æœ€åæŒ‡å®šå“ªä¸€ä¸ªé•œåƒ docker create -it python:latest python # åˆ›å»ºå¸¦æœ‰æ ‡å‡†è¾“å…¥ç¯å¢ƒçš„å®¹å™¨ï¼Œå¹¶æ‰§è¡Œpythonå‘½ä»¤ -t ä¸ºäº†ç»™å®¹å™¨åˆ›å»ºä¸€ä¸ª terminal -i ä¸ºäº†ç»™å®¹å™¨æä¾›ä¸€ä¸ª æ ‡å‡†è¾“å…¥æµ ï¼ˆå¦åˆ™ï¼Œå®¹å™¨ç»ˆç«¯é‡Œæ— æ³•è¾“å…¥ï¼‰ æ³¨ï¼šåˆ›å»ºé»˜è®¤æ˜¯ createdçŠ¶æ€ï¼Œ éœ€è¦ä¸‹é¢ docker start å‘½ä»¤æ¥å¯åŠ¨ docker startï¼ˆå¼€å¯ï¼‰ docker start -ai å®¹å™¨ID # ä»¥æ ‡æ ‡å‡†ç¯å¢ƒå¼€å¯å®¹å™¨ -a ä»£è¡¨æä¾›æ ‡å‡†è¾“å‡º -i åŒcreate -i ï¼Œæä¾›æ ‡å‡†è¾“å…¥ docker runï¼ˆåˆ›å»º+å¯åŠ¨, æ¨èï¼‰ docker run -it python:latest python # ä¸€å¥—æå®š create+start çš„ç¹æ‚è¿‡ç¨‹ï¼Œ -itåŒä¸Šä¸è§£é‡Š # å‘½ä»¤é˜²æ··æ·†è§£é‡Šï¼š æ ¹æ®python:latesté•œåƒ ï¼Œåˆ›å»ºå¹¶æ‰§è¡Œå®¹å™¨ï¼ŒåŒæ—¶æ‰§è¡Œ pythonå‘½ä»¤ docker run -d -it python:latest python # å…¶ä»–ä¸å˜ï¼Œå¤šåŠ ä¸€ä¸ª -dï¼Œ å¯ä»¥åˆ›å»ºå¹¶æ”¾å…¥ &quot;åå°&quot; æ‰§è¡Œ ï¼ˆä¸åŠ -d , é»˜è®¤&quot;å‰å°&quot;ï¼‰ docker run -dit --rm python:latest python # --rm å‚æ•°ä»£è¡¨ å®¹å™¨åœæ­¢ï¼Œå³ï¼ˆexitedçŠ¶æ€ï¼‰ï¼Œ å°±ä¼šè‡ªåŠ¨åˆ é™¤ã€‚ docker run --network bridge -itd mypython:latest python # --network ä»£è¡¨æŒ‡å®šç½‘ç»œï¼ˆè‹¥ä¸æŒ‡å®šï¼Œé»˜è®¤ä¹Ÿæ˜¯bridgeï¼Œè§ä¸‹é¢ ç½‘ç»œç« èŠ‚ï¼‰ docker run -dit -p 6006:6379 redis # ç«¯å£æ˜ å°„ï¼Œ å®¿ä¸»æœºï¼ˆ6006ï¼‰ï¼šå®¹å™¨(6379) (-Pä»£è¡¨å®¹å™¨å†…éƒ¨æ‰€æœ‰ç«¯å£ ä¸å®¿ä¸»æœºéšå³æ˜ å°„) docker run --restart always # --restart always ä»£è¡¨ dockeræœåŠ¡é‡å¯æ—¶ï¼Œ é‡Œé¢çš„å®¹å™¨ä¹Ÿä¼šè·Ÿç€é‡å¯ docker run --name mysql -e MYSQL_ROOT_PASSWORD=123 -p 3306:3306 -itd mysql # mysqlç¤ºä¾‹ï¼Œå‰ææ˜¯å·²ç» docker pull mysql docker stopï¼ˆç»ˆæ­¢ï¼Œç»“æŸï¼‰ docker ps # æŸ¥çœ‹ä¸€ä¸‹ &quot;è¿è¡Œä¸­å®¹å™¨ID&quot; docker stop å®¹å™¨ID # åœæ­¢ &quot;è¿è¡Œä¸­&quot; çš„å®¹å™¨ ( é»˜è®¤ 10ç§’é’Ÿå æ‰åœæ­¢) docker stop -t 0 374 # -tæŒ‡å®šæ—¶é—´ 0ç§’åï¼Œ å³ç¬é—´å°±å¯ä»¥åœæ­¢ æ‰©å±•ï¼ˆåœæ­¢æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„å®¹å™¨ï¼‰ï¼š docker stop $(docker ps -q) # -qå‚æ•°ä»£è¡¨åªæ˜¾ç¤ºå®¹å™¨ID docker restartï¼ˆé‡å¯ï¼‰ docker restart -t 0 281 # 0ç§’é‡å¯ docker pauseï¼ˆæš‚åœï¼‰ docker pause 281 # æš‚åœå®¹å™¨å†…çš„æ‰€æœ‰è¿›ç¨‹ï¼Œ æ³¨æ„æ˜¯æš‚åœï¼Œ ä¸æ˜¯ç»ˆæ­¢ docker unpauseï¼ˆç»§ç»­ï¼‰ docker unpause 281 # æŠŠæš‚åœçš„å®¹å™¨ï¼Œç»§ç»­å¼€å¯ docker psï¼ˆæŸ¥çœ‹ï¼‰ docker ps # åˆ—å‡ºæ‰€æœ‰ &quot;è¿è¡Œä¸­&quot; çš„å®¹å™¨ docker ps -a # åˆ—å‡ºæ‰€æœ‰ å®¹å™¨ docker logsï¼ˆæŸ¥çœ‹è¾“å‡ºæ—¥å¿—ï¼‰ docker logs 281 # æŸ¥çœ‹å®¹å™¨å†…éƒ¨è¾“å‡ºæ—¥å¿— docker logs -f 281 # -f ä»£è¡¨é˜»å¡ç›‘æ§ï¼Œ (å’Œ tail -f ä¸€ä¸ªé“ç†) docker renameï¼ˆé‡å‘½åï¼‰ docker rename 281 python # æŠŠ 281çš„å®¹å™¨ æ”¹åä¸º python docker inspectï¼ˆæŸ¥çœ‹å®¹å™¨è¯¦ç»†ä¿¡æ¯ï¼‰ docker inspect 374 # æŸ¥çœ‹å®¹å™¨æ‰€æœ‰ä¿¡æ¯ docker rmï¼ˆåˆ é™¤ï¼‰ docker rm å®¹å™¨ID # åˆ é™¤å·²åœæ­¢çš„å®¹å™¨ docker rm å®¹å™¨ID -f # å¼ºåˆ¶åˆ é™¤ï¼ˆè¿è¡Œä¸­ï¼‰ç­‰ç‰¹æ®Šæƒ…å†µçš„å®¹å™¨ docker attachï¼ˆè¿›å…¥åˆ°å®¹å™¨å‘½ä»¤æ‰§è¡Œå¤„ï¼‰ docker run -itd python:latest python # æ–°åˆ›å»ºå®¹å™¨ï¼Œåæ‰§è¡Œ pythonå‘½ä»¤ docker attach 281 # ç›´æ¥è¿›å…¥281è¿™ä¸ªå®¹å™¨ï¼Œå¹¶ç›´æ¥è·³åˆ° pythonæ§åˆ¶å°å†…éƒ¨ &quot;æ³¨ï¼š è¿›å…¥pythonæ§åˆ¶å°åï¼Œå†é€€å‡ºå»ï¼Œå°±æ„å‘³ç€ï¼Œ å®¹å™¨çš„é€€å‡ºã€‚&quot; docker execï¼ˆæ‰§è¡Œå‘½ä»¤ï¼‰ docker exec -it 281 python # åœ¨&quot;å®¹å™¨å¤–éƒ¨&quot;, æ‰§è¡Œ&quot;å†…éƒ¨å®¹å™¨&quot;çš„ pythonå‘½ä»¤ &quot;æ³¨ï¼š ä¸ä¸Šä¸€æ¡attachä¸åŒçš„æ˜¯ï¼Œé€€å‡ºpythonæ§åˆ¶å°åï¼Œå®¹å™¨ä¾æ—§è¿è¡Œï¼ï¼ˆå› ä¸ºæ˜¯åœ¨å®¹å™¨å¤–é¢æ‰§è¡Œçš„pythonå‘½ä»¤ï¼‰&quot; Container and Imagesï¼ˆå®¹å™¨ä¸é•œåƒå…³è”ï¼‰ docker commit (æŠŠå®¹å™¨&quot;å°è£…&quot;æˆä¸€ä¸ªæ–°é•œåƒ) docker commit 4d mypython:3.7 # æŠŠ4dè¿™ä¸ªå®¹å™¨æ‰€æœ‰å†…å®¹,å°è£…ä¸ºä¸€ä¸ª&quot;åå­—:ç‰ˆæœ¬&quot;å«&quot;mypython:3.7&quot;çš„é•œåƒ docker export (å®¹å™¨å¯¼å‡ºä¸ºä¸€ä¸ªæ–‡ä»¶) docker export fc8 -o mypython.tar # æŠŠæ­¤å®¹å™¨å¯¼å‡ºä¸ºä¸€ä¸ª.taræ–‡ä»¶ ï¼Œå’Œå‰é¢è¯´è¿‡çš„ imageçš„ saveç±»ä¼¼ docker import (æŠŠexportå¯¼å‡ºçš„æ–‡ä»¶å¯¼å‡ºï¼Œå¹¶&quot;ç”Ÿæˆ&quot;ä¸€ä¸ªé•œåƒï¼‰ docker import mypython.tar mypython:latest æ³¨ï¼š æŠŠexportå¯¼å‡ºçš„ mypython.taræ–‡ä»¶å¯¼å…¥ å¹¶ ç›´æ¥åˆ›å»ºä¸€ä¸ª mypython:latest çš„ é•œåƒ docker commit &amp; docker importåŒºåˆ« å‰é¢è¯´è¿‡ï¼š docker commit æ˜¯ ç›´æ¥æŠŠä¸€ä¸ªcontainer å°è£…ä¸ºä¸€ä¸ªimage docker import æ˜¯ æŠŠexportå¯¼å‡ºçš„container.taræ–‡ä»¶ å† å¯¼å…¥è¿›æ¥ï¼Œå¹¶é‡æ–°ç”Ÿæˆä¸€ä¸ª æ–° image docker commit æ˜¯ç»§æ‰¿å°è£…çš„ï¼Œå¹¶åˆ›å»ºå…·æœ‰åˆ†å±‚å†å²è®°å½• ï¼ˆdocker history imageID å³å¯æŸ¥çœ‹ï¼‰ docker import æ˜¯ç›´æ¥ç”Ÿæˆçš„ï¼Œä¸å…·æœ‰åˆ†å±‚è®°å½• ï¼ˆdocker history imageID å³å¯æŸ¥çœ‹ï¼‰ ç½‘ç»œ docker network ls ï¼ˆæŸ¥çœ‹ï¼‰ docker network ls bridgeï¼ˆç½‘æ¡¥ï¼‰ï¼šå®¹å™¨é»˜è®¤ç½‘ç»œæ¨¡å¼ å®¹å™¨-å®¹å™¨ç½‘ç»œè¿æ¥ï¼š container1(etho0)--veth1--Docker(bridge)--veth2--container2(etho0) å®¹å™¨-å®¿ä¸»æœºç½‘ç»œè¿æ¥ï¼š container1(etho0)--veth1--Docker(bridge)--å®¿ä¸»æœº(etho0) æ³¨ï¼š vethæ˜¯åˆ›å»ºç½‘ç»œæ—¶ï¼Œè‡ªåŠ¨åˆ›å»ºçš„ï¼Œä¸éœ€è¦æ‰‹åŠ¨ç®¡ç† hostï¼ˆä¸»æœºï¼‰ï¼š å®¹å™¨ç½‘ç»œå’Œä¸»æœºä½¿ç”¨åŒä¸€ä¸ªç½‘ç»œ å®¹å™¨-å®¹å™¨ç½‘ç»œè¿æ¥ï¼š container1(etho0)--å®¿ä¸»æœº--container2(etho0) å®¹å™¨-å®¿ä¸»æœºç½‘ç»œè¿æ¥ï¼š container1(etho0)--å®¿ä¸»æœº å®¹å™¨ç½‘ç»œï¼ˆç‰¹æ®Šhostï¼‰ï¼š container1--container2 # å°±æ˜¯ â€˜æ¯ä¸ªå®¹å™¨äº’ç›¸æŠŠå¯¹æ–¹è®¤ä½œä¸º å®¿ä¸»æœºâ€™ è¿™ä¸ªæ„æ€ ä½¿ç”¨æ–¹æ³•ï¼š docker run -it --network container:24f1 mypython:latest ls # container:24f1 çš„containeræ˜¯è¯­æ³•å…³é”®è¯ 24f1æ˜¯è¿æ¥çš„å¯¹æ–¹å®¹å™¨ï¼ˆï¼‰ nullï¼ˆæ— ç½‘ç»œï¼‰ï¼šæ‰€æœ‰å®¹å™¨æ— ç½‘ç»œ docker network create ï¼ˆåˆ›å»ºï¼‰ docker network create -d bridge mybridge # å¯åˆ›å»ºå¤šä¸ªbridge docker network create -d host myhost # åªå¯åˆ›å»ºä¸€ä¸ªhostï¼ˆé»˜è®¤å°±æœ‰ä¸€ä¸ªï¼Œæ•…æ— æ³•åˆ›å»ºï¼‰ docker network create -d null mynull # åªå¯åˆ›å»ºä¸€ä¸ªnullï¼ˆé»˜è®¤å°±æœ‰ä¸€ä¸ªï¼Œæ•…æ— æ³•åˆ›å»ºï¼‰ docker network rm ï¼ˆåˆ é™¤ï¼‰ docker network rm ab5 æ³¨ï¼šé»˜è®¤è‡ªå¸¦çš„ç½‘ç»œä¸å¯ä»¥åˆ é™¤ï¼ˆnull host å’Œ è‡ªå¸¦çš„ä¸€ä¸ª bridgeï¼‰ docker network connect (ç»™å®¹å™¨ç»‘å®šç½‘ç»œ) docker network connect mybridge 4c4 # ç»™4c4è¿™ä¸ªå®¹å™¨ç»‘å®šä¸€ä¸ª mybridgeç½‘ç»œï¼ˆè‡ªå®šä¹‰çš„bridgeï¼‰ docker inspect 4c4 # æŸ¥çœ‹ä¸€ä¸‹å®¹å™¨ä¿¡æ¯ï¼Œæœ€ä¸‹é¢å°±æ˜¯ç½‘ç»œ æ³¨ï¼šä¸€ä¸ªcontainer å¯ä»¥ç»‘å®š å¤šä¸ªbridge ç½‘ç»œï¼Œ docker network disconnect (ç»™å®¹å™¨ è§£é™¤ç»‘å®šçš„ç½‘ç»œ) docker network disconnect mybridge 4c4 # ç»™å®¹å™¨è§£é™¤ç»‘å®šç½‘ç»œmybridge æ³¨ï¼š ä¸€ä¸ªcontainer ä¸­ bridge å’Œ none ç½‘ç»œä¸å¯ä»¥å…±å­˜ï¼Œ ï¼ˆè‹¥å†²çªï¼Œåˆ™å…ˆdisconnectå†connectï¼‰ æ³¨2ï¼šhost ç½‘ç»œä¸èƒ½ connect å’Œ disconnect æ•°æ®å· (volume) docker volume createï¼ˆåˆ›å»ºæ•°æ®å·ï¼‰ docker volume create myvolume æ³¨ï¼š myvolumeä¸ºæ•°æ®å·å docker volume lsï¼ˆåˆ—å‡ºæ•°æ®å·ï¼‰ docker volume ls æ³¨ï¼š è‹¥æ•°æ®å·æœªæŒ‡å®šåå­—ï¼Œå½“ ä½¿ç”¨docker run -v æ–¹å¼æ—¶ï¼Œåˆ™ä¼šæ–°å»ºæ•°æ®å·IDï¼Œå¹¶ä»¥æ­¤IDå‘½åã€‚ docker volume pruneï¼ˆåˆ é™¤æœªè¢«å®¹å™¨ä½¿ç”¨çš„ æ‰€æœ‰ æ•°æ®å·ï¼‰ docker volume prune æ³¨ï¼šå®¹å™¨å ç”¨çš„æ•°æ®å·ï¼Œåˆ ä¸äº† docker volume rm ï¼ˆåˆ é™¤ ä¸€ä¸ª æˆ– å¤šä¸ª æŒ‡å®šæ•°æ®å·ï¼‰ docker volume rm myvolume æ³¨ï¼š åˆ é™¤ myvolumeè¿™ä¸ªæ•°æ®å·ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥è¿ç»­å‚æ•°ï¼Œè¿½åŠ åˆ é™¤å¤šä¸ªæ•°æ®å· æŒ‚è½½æ•°æ®å· &quot;&quot;&quot;æ„ä¹‰ï¼š å¯ä»¥è®© å®¿ä¸»æœº ä¸ å®¹å™¨ æ•°æ®è”é€šå…±äº«&quot;&quot;&quot; æ–¹å¼1 ï¼ˆ-vå‚æ•°ï¼‰ -vä½¿ç”¨æ–¹å¼1ï¼šï¼ˆæŒ‡å®šè·¯å¾„æ˜ å°„æŒ‚è½½ï¼‰ docker run -itd -v /root:/root mypython:latest python # -v å®¿ä¸»æœºè·¯å¾„:å®¹å™¨è·¯å¾„ æµ‹è¯•ï¼š cd /root touch aaa.txt # å®¿ä¸»æœºåˆ›å»ºæ–‡ä»¶ aaa.txt docker exec -it cfb ls /root # ç»“æœå¯çœ‹è§å®¹å™¨é‡Œé¢ä¹Ÿæœ‰ aaa.txt æ–‡ä»¶ -vä½¿ç”¨æ–¹å¼2ï¼šï¼ˆæŒ‡å®šæ•°æ®å·å¯¹è±¡ æ˜ å°„æŒ‚è½½ï¼‰ docker run -itd -v myvolume:/root mypython:latest python # å†’å·å‰é¢ å˜æˆäº†myvolume æ³¨1ï¼š è¿™ä¸ªmyvolumeå°±æ˜¯ä¸€ä¸ªæ•°æ®å·å¯¹è±¡ï¼Œ æ‰§è¡Œä¸Šé¢è¿™æ¡å‘½ä»¤ï¼Œå°±ä¼šä¸ºæˆ‘ä»¬è‡ªåŠ¨åˆ›å»ºè¿™ä¸ªæ•°æ®å·å¯¹è±¡ æ³¨2ï¼š ç”±äºæ²¡æœ‰å®¿ä¸»æ˜ å°„è·¯å¾„ï¼Œé‚£ä¹ˆæ˜ å°„çš„å®¿ä¸»è·¯å¾„ æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿï¼Ÿ docker volume inspect myvolume # ç»“æœMountpointåé¢çš„å°±æ˜¯ï¼Œå®¿ä¸»æœºæ˜ å°„çš„ é»˜è®¤é’©å­è·¯å¾„ cd /var/lib/docker/volumes/myvolume11/_data # æ­¤è·¯å¾„å’Œvolumeåæœ‰å…³ touch bbb.txt # å®¿ä¸»æœºåˆ›å»ºæ–‡ä»¶ bbb.txt docker exec -it 916 ls /root # æ‰“å°ç»“æœå¯è§ï¼Œå®¹å™¨å†…éƒ¨ä¹Ÿæœ‰bbb.txtï¼Œè¯´æ˜æˆåŠŸå…±äº«ã€‚ æ–¹å¼2ï¼šï¼ˆ--mountå‚æ•°ï¼ŒåŒæ ·åŒ…æ‹¬ -vçš„ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼Œ å¦å¤–è¿˜æ–°å¢å¦ä¸€ç§ æ–‡ä»¶&quot;ç¼“å­˜&quot;æŒ‚è½½æ–¹å¼ï¼‰ docker run -itd --mount type=volume,src=myvolume11,dst=/root mypython:latest python æ³¨ï¼š type: æŒ‡å®šç±»å‹ï¼ˆè·¯å¾„æ˜ å°„: bindï¼‰æˆ– (æ•°æ®å·å¯¹è±¡æ˜ å°„: volume) æˆ–ï¼ˆå†…å­˜æ˜ å°„ï¼štmpfsï¼‰ src: å¯¹åº”ä¸Šé¢æ–¹å¼1ï¼ˆå®¿ä¸»æœºè·¯å¾„ï¼‰ æˆ– å¯¹åº”ä¸Šé¢æ–¹å¼2ï¼ˆæ•°æ®å·åï¼‰ æˆ– çœç•¥æ­¤é¡¹ï¼ˆå¯¹åº”æ–°å¢ï¼‰ dst: å®¹å™¨è·¯å¾„ é€—å·åˆ†éš”ï¼Œå…¶ä»–æ²¡å˜ docker run -itd --mount type=tmpfs,dst=/root mypython:latest python (tmpfs&quot;ç¼“å­˜&quot;æŒ‚è½½) &quot;ç»¼ä¸Š,å¯æ€»ç»“ä¸º3ç§æŒ‚è½½é€‰æ‹©ç”¨é€”&quot;ï¼š ä¸€. &quot;å®¿ä¸»è·¯å¾„ ä¸ å®¹å™¨è·¯å¾„&quot; æ˜ å°„æŒ‚è½½ äºŒ. &quot;æ•°æ®å· ä¸ å®¹å™¨è·¯å¾„&quot; æ˜ å°„æŒ‚è½½ ä¸‰. &quot;å®¿ä¸»å†…å­˜ ä¸ å®¹å™¨è·¯å¾„&quot; æ˜ å°„æŒ‚è½½ &quot;ç»¼ä¸Š,å¯æ€»ç»“ä¸º2ç§æŒ‚è½½å‚æ•°ä½¿ç”¨&quot;ï¼š ä¸€ã€ &quot;-v å‚æ•°&quot; 2ç§ç”¨é€” (è·¯å¾„æ˜ å°„ å’Œ æ•°æ®å·å¯¹è±¡æ˜ å°„) äºŒã€ &quot;--mount å‚æ•°&quot; 3ç§ç”¨é€” (è·¯å¾„æ˜ å°„ å’Œ æ•°æ®å·å¯¹è±¡æ˜ å°„ å’Œ å†…å­˜æ˜ å°„) å®¹å™¨ä¹‹é—´å…±äº«æ•°æ® &quot;&quot;&quot;å€ŸåŠ©å·²ç»æ‹¥æœ‰æ•°æ®å·çš„å®¹å™¨ æ¥ åˆ›å»ºä¸€ä¸ªæ–°å®¹å™¨&quot;&quot;&quot; docker run -itd --volumes-from 6252 python:latest # å€ŸåŠ©6252å®¹å™¨åˆ›å»ºæ–°å®¹å™¨ï¼Œæ¥å…±äº«æ•°æ®å· éªŒè¯ï¼š docker exec -it 97db touch /root/abc # æ–°å®¹å™¨ åˆ›å»ºä¸€ä¸ªæ–‡ä»¶abc docker exec -it 6252 ls /root # æ—§å®¹å™¨æŸ¥çœ‹ ï¼Œä¹Ÿæœ‰æ–°æ–‡ä»¶abcï¼Œå…±äº«æˆåŠŸ ç»†èŠ‚æ³¨æ„äº‹é¡¹ ä¸€ã€è‹¥å°† &quot;ç©ºæ•°æ®å·&quot; æŒ‚è½½åˆ° å®¹å™¨éç©ºç›®å½•ä¸­ï¼Œåˆ™&quot;æ­¤å®¹å™¨ç›®å½•ä¸‹çš„å†…å®¹ ä¼šcopyä¸€ä»½åˆ° æ•°æ®å·ä¸­&quot; äºŒã€è‹¥å°† &quot;éç©ºæ•°æ®å·&quot; æŒ‚è½½åˆ° å®¹å™¨ä»»æ„ç›®å½•ä¸­ï¼Œåˆ™&quot;æ•°æ®å·çš„æ•°æ® ä¼šcopyåˆ°è¿™ä¸ªç›®å½•ä¸­ï¼Œå¹¶å°†æ­¤ç›®å½•åŸæ•°æ®éšè—&quot; æ›´é€šä¿—ä¸€ç‚¹ç†è§£å°±æ˜¯ï¼š æ•°æ®å·å¤§å“¥è¯´ï¼š&quot;å¦‚æœæˆ‘è¿™é‡Œæœ‰æ•°æ®ï¼Œ ä½ çš„å®¹å™¨æ¥æŒ‚è½½ï¼Œä½ çš„æ•°æ®å°±ä¼šè¢«æˆ‘è¿™é‡Œé¢çš„æ•°æ®è¦†ç›–ã€‚ã€‚&quot; æ•°æ®å·å¤§å“¥åˆè¯´ï¼š&quot;å¦‚æœæˆ‘è¿™é‡Œæ˜¯ç©ºçš„ï¼ˆæ²¡æœ‰æ•°æ®ï¼‰ï¼Œé‚£ä¹ˆ ä½ çš„å®¹å™¨æ¥æŒ‚è½½ï¼Œ ä½ çš„æ•°æ®å°±è¦æä¾›ä¸€ä»½ç»™æˆ‘&quot; DockerHubï¼ˆä»“åº“ï¼‰ æ— è®¤è¯ ç§æœ‰ä»“åº“ æ­å»ºä»“åº“ docker pull registry # æ‹‰å– registryé•œåƒ docker run -itd \\ --restart always \\ # dockeré‡å¯æ—¶ï¼Œæ­¤å®¹å™¨ä¹Ÿè·Ÿç€é‡å¯ --name myregistry \\ # æŒ‡å®šå®¹å™¨å -p 6006:5000 \\ # ç«¯å£æ˜ å°„ ï¼ˆregistryæœåŠ¡é»˜è®¤ä¸º5000ç«¯å£ï¼Œæ˜ å°„ä¸º6006ï¼‰ -v /root:/var/lib/registry \\ # ç»‘å®šæ•°æ®å· ï¼ˆæŒä¹…åŒ–å­˜å‚¨ï¼‰ï¼Œ å†’å·åé¢çš„å®¹å™¨è·¯å¾„æ—¶é»˜è®¤çš„ registry # æ‹‰å–çš„ registryé•œåƒ éªŒè¯ï¼šï¼ˆä¸€ç§webæœåŠ¡ï¼Œæ‰€ä»¥é€šè¿‡å›ºå®šUrlè®¿é—®å³å¯ï¼‰ å¤–éƒ¨æµè§ˆå™¨éªŒè¯ï¼š æµè§ˆå™¨è¾“å…¥ æœåŠ¡å™¨å¤–ç½‘IP:6006/v2/_catalog å³å¯ æœåŠ¡å™¨å†…éƒ¨éªŒè¯ï¼š curl 127.0.0.1:6006/v2/_catalog ä¸Šä¼ é•œåƒ ä¸€ã€å…ˆæŠŠè¦ä¸Šä¼ çš„é•œåƒæ”¹å docker tag mypython:latest 127.0.0.1:6006/mython_hub æ³¨ï¼š ç›®æ ‡åå›ºå®šæ ¼å¼ï¼ˆéœ€æ³¨æ„ï¼Œå¿…é¡»æ­¤æ ¼å¼ï¼‰ï¼š IP:Port/æ–°é•œåƒå äºŒã€å¼€å§‹ä¸Šä¼  docker push 127.0.0.1:6006/mython_hub # docker push é•œåƒåï¼Œæ³¨æ„è¿™é‡Œç”¨IDä¸å¥½ä½¿ï¼Œå¿…é¡»ç”¨è¿™å ä¸‰ã€éªŒè¯ åŒä¸Šé¢æ­å»ºä»“åº“æ—¶çš„éªŒè¯æ–¹æ³•ï¼Œ å¯çœ‹è§ç»“æœ repositoriesåˆ—è¡¨ä¸­å¤šäº†ä¸€ä¸ª åˆšåˆšä¸Šä¼ çš„é•œåƒ curl 127.0.0.1:6006/v2/_catalog ä¸‹è½½é•œåƒ docker pull 127.0.0.1:6006/mython_hub æ³¨ï¼š è¿™ä¸ªåå°±æ˜¯ä¸Šä¼ æ—¶å€™çš„ é‚£ä¸ªåï¼Œ ä¸€æ ·çš„ Dockerfileï¼ˆé…ç½®æ–‡ä»¶å¼ï¼‰ Dockerfileè®¤çŸ¥ Docker ä¸ dockerå‘½ä»¤çš„å…³ç³»å°±ç›¸å½“äº shellç¼–ç¨‹ ä¸ å•æ¡å‘½ä»¤ ä¸»è¦å°±æ˜¯æŠŠä¸Šé¢è®²çš„æ‰€æœ‰å‘½ä»¤è¿èµ·æ¥ï¼Œè„šæœ¬å¼æ‰§è¡Œï¼Œ å½“ç„¶dockerfileä¹Ÿæœ‰è‡ªå·±çš„è¯­æ³•å…³é”®è¯ã€‚ Dockerfileæ˜¯åŸºäºç¼“å­˜ï¼Œæ‰€ä»¥é‡Œé¢çš„æ–‡ä»¶å†…å®¹(æŸæ¡å‘½ä»¤) &quot;å¦‚æœæœªå‘ç”Ÿæ”¹å˜ï¼Œåˆ™ä¸ä¼šé‡æ–°æ‰§è¡Œï¼ˆç”¨çš„æ˜¯ç¼“å­˜ï¼‰&quot; Dockerfileæœºåˆ¶ï¼š ä¸€ã€è‹¥åœ¨ç»“å°¾æ¯&quot;è¿½åŠ &quot;ä¸€æ¡æ–°å‘½ä»¤,é‡æ–°æ„å»ºDockerfileæ—¶ï¼Œ&quot;åªä¼šæ‰§è¡Œè¿™ä¸ªæ–°å‘½ä»¤ï¼Œå…¶ä»–æ—§å‘½ä»¤éƒ½ä¼šä½¿ç”¨ç¼“å­˜&quot; äºŒã€è‹¥æ–°å‘½ä»¤ æ˜¯åœ¨&quot;ä¸­é—´æ’å…¥ç¼–å†™çš„&quot;ï¼Œåˆ™æ­¤æ¡æ–°å‘½ä»¤&quot;ä¹‹å‰çš„å‘½ä»¤ç”¨ç¼“å­˜&quot;, &quot;ä¹‹å&quot;çš„å‘½ä»¤éƒ½ä¼šé‡æ–°æ‰§è¡Œä¸€éï¼Œ ä¸‰ã€FROM å…³é”®å­—æ˜¯ Dockerfileçš„å…¥å£ã€‚ æ–°å‘½ä»¤åªè¦ä¸æ˜¯ å†™åœ¨ &quot;FROMçš„ä¸‹ä¸€æ¡&quot;, é‚£ä¹ˆæ‰€æœ‰æ–°å‘½ä»¤åŠå…¶ä¹‹åçš„å‘½ä»¤éƒ½ä¼šåœ¨ æ„å»ºDockerfileæ—¶--&gt; è§¦å‘&quot;å±‚å±‚å°è£…&quot;æœºåˆ¶ ï¼Œå³æ¯æ¡&quot;éç¼“å­˜å‘½ä»¤&quot;è¿è¡Œä¸€éï¼Œéƒ½ä¼šcommitå°è£…ä¸€å±‚é•œåƒ Dockerfileæ„å»º docker build /Dockerfileæ‰€åœ¨è·¯å¾„ -t mypython:v2 æ³¨1ï¼š æŒ‡å®šDockerfileæ‰€åœ¨è·¯å¾„å³å¯ï¼Œbuildä¼šè‡ªåŠ¨å¸®æˆ‘ä»¬æ‰¾åˆ°dockerfileæ–‡ä»¶ æ³¨2ï¼š å¦‚æœDockerfileå°±åœ¨å½“å‰è·¯å¾„ä¸‹ï¼Œé‚£ä¹ˆå¯ä»¥ç”¨ . æ¥æ›¿ä»£ç»å¯¹è·¯å¾„ æ³¨3ï¼š -t ç»™é•œåƒæŒ‡å®šåå­— Dockerfileè¯­æ³• FROM &quot;ä¸‹è½½é•œåƒ,ç±»ä¼¼ docker pull&quot; FROM python:latest # åŒæ ·å¯ä»¥æŒ‡å®šç‰ˆæœ¬å· RUN | CMD | ENTRYPOINT è¿™ä¸‰ä¸ª å‘½ä»¤ éƒ½æœ‰å…±åŒçš„ 2ç§ä¹¦å†™æ–¹å¼ï¼š ä¸€ã€ï¼ˆexecï¼‰æ ¼å¼--å½“å‰è¿›ç¨‹æ‰§è¡Œ eg: python -V # å°±æ˜¯ç©linuxçš„å‘½ä»¤æ­£å¸¸å†™ äºŒã€ï¼ˆshellï¼‰ æ ¼å¼--å­è¿›ç¨‹æ‰§è¡Œ eg: [&quot;python&quot;, &quot;-V&quot;] # å‘½ä»¤ä¸ä½œä¸ºå­—ç¬¦ä¸²åˆ—è¡¨æ¥ä¹¦å†™ï¼Œ å’Œpyçš„scrapyçš„shellç±»ä¼¼ RUN: &quot;æ„å»ºé•œåƒè¿‡ç¨‹ä¸­&quot;æ‰§è¡Œçš„å‘½ä»¤ï¼Œ æ¯”å¦‚å®‰è£…ä¸œè¥¿ä¹‹ç±»çš„ã€‚ã€‚ï¼ˆå¯å†™å¤šä¸ªï¼‰ CMD: å¯åŠ¨å®¹å™¨æ—¶ æ‰§è¡Œçš„å‘½ä»¤ï¼Œ å°±å’Œ ä¹‹å‰è¯´è¿‡çš„ docker run è·Ÿçš„å‘½ä»¤æ˜¯ä¸€æ ·çš„ &quot;ä½†æ˜¯ docker run è¦æ˜¯æŒ‡å®šäº†ä¸€ä¸ªå‘½ä»¤ï¼Œé‚£ä¹ˆ è¿™ä¸ªCMDé…ç½®å°±ä¼šå¤±æ•ˆ&quot; ENRTYPOINT: å’ŒCMDç±»ä¼¼ï¼Œ ä¸è¿‡ åœ¨docker run æŒ‡å®šæ–°å‘½ä»¤æ˜¯ï¼Œ ENTRYPOINTçš„å‘½ä»¤æ˜¯ä¸ä¼šè¢«è¦†ç›–çš„ã€‚éƒ½ä¼šæ‰§è¡Œ ADD | COPY &quot;&quot;&quot;å°†å®¿ä¸»æœºæ–‡ä»¶ æ‹·è´ åˆ°é•œåƒçš„æŸä¸ªç›®å½•ä¸­&quot;&quot;&quot; COPY aaa.txt /root # å°†aaa.txt æ‹·è´åˆ° é•œåƒçš„/rootç›®å½•ä¸­ ADD aaa.txt /root # å’ŒCOPYä¸€æ ·ï¼Œä¸è¿‡ ADDå¯ä»¥å°†å‹ç¼©æ–‡ä»¶æ‹·è´è¿›å»åï¼Œ&quot;è‡ªåŠ¨è§£å‹&quot; ENV &quot;&quot;&quot;å°±ç›¸å½“äºç¼–ç¨‹è¯­è¨€çš„ å˜é‡èµ‹å€¼&quot;&quot;&quot; ENV name=python ENV nickname=$name # $name æ„ä¸ºå–å‡º nameå˜é‡çš„å€¼ WORKDIR &quot;&quot;&quot;åˆ‡æ¢ç›®å½• ç±»ä¼¼cdå‘½ä»¤&quot;&quot;&quot; WORKDIR /root VOLUME &quot;&quot;&quot;æ·»åŠ æ•°æ®å·&quot;&quot;&quot; VOLUME /root # å°±ç›¸å½“äºå‰é¢è¯´è¿‡çš„docker run -v /root, å³è‡ªåŠ¨åˆ›å»ºä¸€ä¸ªæ•°æ®å·æ˜ å°„åˆ° å®¹å™¨çš„/root EXPOSE &quot;&quot;&quot;æš´éœ²ç«¯å£&quot;&quot;&quot; EXPOSE 6379 EXPOSE 3306 # å¯ä»¥ç”¨å¤šä¸ª EXPOSE æš´éœ²å¤šä¸ªç«¯å£ æ³¨1ï¼š æš´éœ²ç«¯å£åï¼Œå¯ä»¥é€šè¿‡ å‰é¢è¯´çš„ docker run -P æ¥åšè‡ªåŠ¨ç«¯å£æ˜ å°„ æ³¨2ï¼š æˆ–è€…ä¸æš´éœ²ç«¯å£ï¼Œç›´æ¥ä½¿ç”¨æ‰‹åŠ¨æ˜ å°„-pï¼Œéƒ½æ˜¯å¯ä»¥çš„ã€‚ å®˜æ–¹æ¨¡æ¿å‚è€ƒç½‘å€ å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.docker.com/engine/reference/builder/ å„ç§å¼€æºDockerfileæ¨¡æ¿ï¼šhttps://github.com/docker-library/docs/tree/master/ Docker Compose Docker-Composeè®¤çŸ¥ ä¸€ã€Dockerfile å¯ä»¥çœ‹ä½œæ˜¯ Dockerå‘½ä»¤çš„ç»„åˆ äºŒã€Docker-Compose å¯ä»¥çœ‹ä½œæ˜¯ Dockerfileçš„ç»„åˆï¼ˆä¹Ÿç§°ä½œ å®¹å™¨ç¼–æ’å·¥å…·ï¼‰ ä¸‰ã€Docker-Compose æ–‡ä»¶é»˜è®¤åä¸º docoker-compose.yaml å››ã€docoker-compose.yaml æ–‡ä»¶æŒ‡ä»¤ä¸­é—´éƒ½æœ‰ç©ºæ ¼ eg: version: 3.7ï¼ˆ3.7ä¹‹å‰æ˜¯æœ‰ç©ºæ ¼çš„ï¼‰ äº”ã€docoker-compose.yaml é‡‡ç”¨ç¼©è¿›å¯¹æ ¼å¼è¯­æ³•è¿›è¡ŒåŒºåˆ† Docker-Composeå®‰è£… å®˜æ–¹å®‰è£…æ•™ç¨‹ï¼šhttps://docs.docker.com/compose/install/ ä»ä¸Šå¾€ä¸‹ï¼Œå‘½ä»¤å¤åˆ¶-ç²˜è´´-è¿è¡Œã€‚ã€‚ã€‚Easyç•¥ Docker-Composeæ–‡ä»¶æŒ‡ä»¤ version: &quot;3.7&quot; # å¿…æœ‰ # æ­¤ç‰ˆæœ¬å·ä¸dockerç‰ˆæœ¬å¯¹åº”åœ°å€ï¼š https://docs.docker.com/compose/compose-file/ services: # serviceså…³é”®å­—ï¼Œå†™ä¸Šå°±è¡Œï¼Œ å¿…æœ‰ mypython: # mypythonæ˜¯æˆ‘éšä¾¿èµ·ä¸ªå build: . # Dockerfileçš„è·¯å¾„ä½ç½®ï¼Œ buildæ˜¯æ„å»ºDockerfileæ–‡ä»¶çš„ ports: -&quot;6006:3003&quot; # æ³¨æ„-åé¢æ˜¯æœ‰ç©ºæ ¼çš„ï¼Œmarkdownè¯­æ³•å……å†²çªï¼Œæˆ‘å°±æ²¡å†™ç©ºæ ¼ command: xxxx # è¦†ç›–Dockerfileä¸­çš„ CMD depends_on: # ä¾èµ–çš„æœåŠ¡ï¼Œ ï¼ˆè¢«ä¾èµ–çš„å…ˆæ‰§è¡Œï¼Œä¹Ÿå°±æ˜¯myrediså…ˆæ‰§è¡Œï¼‰ -myredis # -åæœ‰ç©ºæ ¼ myredis: # åŒç† myredis ä¹Ÿæ˜¯æˆ‘éšä¾¿èµ·çš„å image: redis # æŒ‡å®šä¸€ä¸ªæˆå“é•œåƒ ç±»ä¼¼DockerfilEçš„ FROMæŒ‡ä»¤ container_name: myredis # æŒ‡å®šå®¹å™¨å networks: # ä½¿ç”¨ä¸‹é¢åˆ›å»ºçš„mynetç½‘ç»œ -mynet # (åŒ-åæœ‰ç©ºæ ¼ï¼Œé¿å…markdownè¯­æ³•å†²çª) volumes: # ä½¿ç”¨ä¸‹é¢åˆ›å»ºçš„myvolumeæ•°æ®å·,å¹¶æ˜ å°„åˆ°å®¹å™¨çš„/rootç›®å½• -myvolume:/root # -åæœ‰ç©ºæ ¼ï¼Œï¼ˆç‰¹åˆ«æ³¨æ„ :åé¢ä¸å…è®¸æœ‰ç©ºæ ¼ï¼‰ hostname: myredis # å› ä¸ºå®¹å™¨åˆ›å»ºæ—¶IPå¯èƒ½åŠ¨æ€æ”¹å˜ï¼ŒæŒ‡å®šåç§°ï¼Œåˆ™å¯é€šè¿‡åç§°æ¥ä»£æ›¿IP # è‹¥ä¸æŒ‡å®š hostnameï¼Œ åˆ™é»˜è®¤ä¸ºæœåŠ¡åï¼Œ å³ myredis networks: # åˆ›å»ºç½‘ç»œ mynet: # ç»™ç½‘ç»œèµ·åä¸º mynet driver: &quot;bridge&quot; # æŒ‡å®šä¸ºæ¡¥æ¥æ¨¡å¼ volumes: # åˆ›å»ºæ•°æ®å· myvolume: # ç»™æ•°æ®å·èµ·åä¸º myvolume driver: &quot;local&quot; # é»˜è®¤å°±æ˜¯localï¼Œå³æ•°æ®å·å­˜å‚¨åœ¨å®¿ä¸»æœºçš„ç›®å½•ä¸‹ é¢„æ£€æŸ¥docker-compose.ymlæ–‡ä»¶è¯­æ³•æ ¼å¼æ˜¯å¦æœ‰è¯¯ docker-compose config æ³¨ï¼šéœ€è¦åœ¨ docker-compose.yml æ‰€åœ¨ç›®å½•ä¸‹æ‰§è¡Œ å¯åŠ¨/åœæ­¢ docker comopse docker-compose up # å‰å°ç»ˆç«¯é˜»å¡æ‰§è¡Œï¼ˆå°±æ˜¯æ‰§è¡Œä¹‹åï¼Œä½ ä¸èƒ½åœ¨ç»ˆç«¯è¾“å…¥ä¸œè¥¿äº†ï¼‰ docker-compose up -d # åå°ç»ˆç«¯éé˜»å¡æ‰§è¡Œ ï¼ˆä½œä¸ºæœåŠ¡ä¸€æ ·åå°æ‰§è¡Œï¼‰ docker-compose stop # åœæ­¢ç¼–æ’ï¼ˆå³åœæ­¢ æ‰€æœ‰ ç¼–æ’è¿è¡Œçš„å®¹å™¨ï¼‰ END ","link":"https://cythonlin.github.io/post/py-greater-docker-yu-fa-quan-mian-hui-yi/"},{"title":"PY => Redisä¸Pythonæ“ä½œRedisè¯­æ³•å¯¹æ¯”è§£æ","content":"å‰è¨€ R: ä»£è¡¨ redis-cli P: ä»£è¡¨ pythonçš„redis å‡†å¤‡ pip install redis pool = redis.ConnectionPool(host='39.107.86.223', port=6379, db=1) redis = redis.Redis(connection_pool=pool) redis.æ‰€æœ‰å‘½ä»¤ ä¸‹é¢å‘½ä»¤æ‰€æœ‰å‘½ä»¤æˆ‘éƒ½çœç•¥äº†ï¼Œ æœ‰å’ŒPythonå†…ç½®å‡½æ•°å†²çªçš„æˆ‘ä¼šåŠ ä¸Š redis. å…¨å±€å‘½ä»¤ dbsizeï¼ˆè¿”å›keyçš„æ•°é‡ï¼‰ R: dbsize P: print(redis.dbsize()) existsï¼ˆæ˜¯å¦å­˜åœ¨æŸkeyï¼‰ R: exists name P: exists('name') keysï¼ˆåˆ—å‡ºæ‰€æœ‰key,å¯ä½¿ç”¨é€šé…ç¬¦ï¼‰ R: keys na* P: keys('na*') æ³¨ï¼šæ—¶é—´å¤æ‚åº¦ä¸º O(n) scan (å¯¹åº”keysï¼Œè¿­ä»£å–å‡ºæ‰€æœ‰keys) R: scan 0 match '*' count 4 P: keys_iter = redis.scan_iter(match='*', count=4) æ³¨ï¼šè¿™ç§scanï¼ŒAPIåé¢ä¹Ÿä¼šæœ‰ï¼Œ æ‰€ä»¥æˆ‘å…¨éƒ¨æ”¾åœ¨æœ€åçš„ç»“æŸè¯­ä¸­è®² info (æŸ¥çœ‹èµ„æºä¿¡æ¯) R: info # ä¹Ÿå¯ä»¥å¡«å‚æ•° info memory info cpu ç­‰ P: redis.info() # redis.info('CPU') redis.info('MEMORY') type (åˆ—å‡ºç±»å‹) R: type name P: redis.type('name') # typeå’Œpythonçš„å†²çªäº†ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘å†™å…¨äº† redisä¸­ç±»å‹æœ‰ï¼š none string list set zset hash è¿‡æœŸæ—¶é—´ expire(è®¾ç½®) R: expire name ç§’æ•° P: expire('name', ç§’æ•°) ttl(æŸ¥è¯¢) R: ttl name P: ttl('name') # è¿”å›å‰©ä½™è¿‡æœŸæ—¶é—´å€¼ # è¿”å›å€¼ä¸º -2 åˆ™ä»£è¡¨ æ— æ­¤ key # è¿”å›å€¼ä¸º -1 åˆ™ä»£è¡¨ æœ‰æ­¤ key ï¼Œ ä½†æœªè®¾ç½®è¿‡æœŸæ—¶é—´ persist(åˆ é™¤) R: persist name P: persist('name') è‡ªå¢ï¼Œè‡ªå‡ incr incrby åŠ ä¸Šä¸€ä¸ªæ•´æ•° R: incr age æˆ– incrby age 1 P: incr age 1 æˆ– incrby age 1 # pythonå®ç° çš„ incr è¢« é‡å®šå‘ä¸º incrbyï¼Œæ‰€ä»¥ç”¨å“ªä¸ªéƒ½è¡Œ decr decrby å‡å»ä¸€ä¸ªæ•´æ•° åŒä¸Š incrbyfloat åŠ å‡ä¸€ä¸ªæµ®ç‚¹æ•° åŒä¸Š å­—ç¬¦ä¸²ç›¸å…³æ“ä½œ set è®¾ç½®å€¼ R: set name lin P: redis.set('name', 'lin') seté€‰é¡¹ï¼ˆåŸå­æ“ä½œï¼‰ nxï¼ˆè®¾ç½®é»˜è®¤å€¼ï¼‰ R: set name lin nx P: redis.set('name', 'lin', nx=True) æ³¨ï¼š nx ä»£è¡¨keyä¸å­˜åœ¨æ‰ä¼šå°†å€¼è®¾ç½®æˆåŠŸï¼Œ ç±»ä¼¼python dictçš„ setdefaultï¼Œå³ç»™keyè®¾ç½®é»˜è®¤å€¼ xxï¼ˆæ›´æ–°å€¼ï¼‰ R: set name Tom xx P: redis.set('name', 'lin', xx=True) æ³¨ï¼š xx ä»£è¡¨keyå­˜åœ¨æ‰ä¼šå°†å€¼æ›´æ–°æˆåŠŸã€‚ å¦‚æœkeyä¸å­˜åœ¨ï¼Œ åˆ™æ›´æ–°å¤±è´¥ã€‚ get è·å–å€¼ R: get name P: redis.get('name') æ³¨ï¼šé€šè¿‡py rediså®¢æˆ·ç«¯çš„ getå–å‡ºçš„éƒ½æ˜¯ å­—èŠ‚äºŒè¿›åˆ¶ç±»å‹ï¼Œ æ‰€ä»¥éœ€è¦æ‰‹åŠ¨è½¬ä¸ºå¯¹åº”ç±»å‹ å‰é¢æåˆ°çš„ incr decr ç­‰ï¼Œ æ“ä½œè¿”å›ç»“æœç›´æ¥å°±æ˜¯ intï¼Œ è€Œé å­—èŠ‚ç±»å‹ mset æ‰¹é‡è®¾ç½® R: mset name lin age 18 p: redis.mset( {'name': 'lin', 'age': 18} ) mget æ‰¹é‡è·å– R: mget name age p: redis.mget('name', 'age') # è¿”å›å€¼ä¸º å­—èŠ‚ç±»å‹çš„ åˆ—è¡¨ getset è®¾ç½®æ–°å€¼å¹¶è¿”å›æ—§å€¼ R: getset name zhang P: print( redis.getset('name', 'zhang') ) append å­—ç¬¦ä¸²è¿½åŠ æ‹¼æ¥ R: append name abc P: redis.append('name', 'abc') strlen è·å–å­—ç¬¦ä¸²é•¿åº¦ R: strlen name P: print( redis.strlen('name') ) æ³¨ï¼š ä¸ç¼–ç¨‹è¯­è¨€çš„æ™®éAPIä¸åŒçš„æ˜¯ï¼Œ strlenè¿”å›çš„å­—ç¬¦ä¸² é•¿åº¦æ˜¯ å­—ç¬¦å¯¹åº”ç¼–ç çš„é•¿åº¦ã€‚ã€‚ã€‚ã€‚ ä¸­æ–‡ utf-8 å  3ä¸ªå­—èŠ‚ getrange å­—ç¬¦ä¸²åˆ‡ç‰‡ ï¼ˆä»0å¼€å§‹ï¼Œå‰é—­åé—­ï¼‰ R: getrange name 1 2 P: redis.getrange('name', 1, 2) setrange å­—ç¬¦ä¸²æŒ‰ç´¢å¼•èµ‹å€¼ï¼ˆè¦†ç›–ï¼‰ R: setrange name 0 abc # æŠŠç¬¬0ä¸ªä½ç½®å¼€å§‹ï¼Œ é€ä¸ªè¦†ç›–èµ‹å€¼ä¸º abcï¼Œ å¤šä½™çš„ä¸å˜ P: redis.setrange('name', 0, 'abc') del åˆ é™¤é”®å€¼ R: del k1 k2 P: redis.delete(k1, k2) Hashç›¸å…³æ“ä½œ(å¯å¯¹åº”ä¸º æ–‡æ¡£-å±æ€§-å€¼) hset è®¾ç½® 1æ¡æ–‡æ¡£ï¼Œ1ä¸ªå±æ€§-å€¼ R: hset user name lin P: redis.hset('user', 'name', 'lin') hget è·å– 1æ¡æ–‡æ¡£ï¼Œ1ä¸ªå±æ€§ R: hget user name P: print(redis.hget('user', 'name')) hmset è®¾ç½® 1æ¡æ–‡æ¡£ï¼Œ å¤šä¸ªå±æ€§-å€¼ R: hmset user name lin age 18 P: redis.hmset('user', {'user': 'lin', 'age': 18}) hmget è·å– 1æ¡æ–‡æ¡£ï¼Œ å¤šä¸ªå±æ€§-å€¼ R: hmget user name age P: print(redis.hmget('user', 'name', 'age')) hkeys è·å–æ‰€æœ‰ key R: hkeys user P: print(redis.hkeys('user')) hvals è·å–æ‰€æœ‰ values R: hvals user P: print(redis.hvals('user')) hgetall è·å– ä¸€æ¡æ–‡æ¡£ï¼Œæ‰€æœ‰å±æ€§å€¼ï¼ˆæ…ç”¨ï¼Œè§ä¸‹ä¸€æ¡APIï¼‰ R: hgetall user # è¿”å›ä¸ºåˆ—è¡¨ï¼Œ å¶æ•°ç´¢å¼•ä¸ºkeyï¼Œå¥‡æ•°ç´¢å¼•ä¸ºvaLue(ä»0å¼€å§‹) P: print(redis.hgetall('user')) # è¿”å›ä¸º dictæ ¼å¼ æ³¨ï¼š hgetall ä¼šå°†æ‰€æœ‰key-valueå–å‡ºæ¥ï¼Œæ‰€ä»¥æ•°æ®é‡åºå¤§å¯èƒ½ä¼šé€ æˆæ€§èƒ½å½±å“ã€‚ å¤§æ‰¹é‡æ•°æ®åœ¨pythonæ˜¯æ€ä¹ˆå¤„ç†æ¥ç€ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ æ²¡é”™ï¼Œå°±æ˜¯è¿­ä»£å™¨ï¼Œå½“ç„¶pythonçš„redisæ¨¡å—å·²ä¸ºæˆ‘ä»¬å°è£…å¥½ä¸€ä¸ªAPIï¼Œhscan_iter, è§ä¸€æ¡API hscan ï¼ˆhashè¿­ä»£ï¼Œå¤§ä½“ä¸Šå¯ä»£æ›¿ hgetallä½¿ç”¨ï¼‰ R: hscan user 0 match * count 200 # æŒ‰æ¸¸æ ‡ï¼ŒæŒ‰æ•°é‡å– # 0ä»£è¡¨æ¸¸æ ‡ä»å¤´å¼€å§‹ # matchæ˜¯å…³é”®å­— # * æ˜¯keyçš„é€šé…ç¬¦ # count æ˜¯ä¸€æ¬¡æ¥å¾…çš„æ¡æ•° P: result_iter = redis.hscan_iter('user', match= 'na*', count=2) # pythonçš„ cursorå‚æ•°æ²¡æœ‰ï¼Œæ˜¯å› ä¸ºæºç ä¸­è¢«å›ºå®šè®¾ç½®ä¸º 0äº†ï¼Œ å…¶ä»–å‚æ•°è§£é‡ŠåŒä¸Š # è¿”å›ç»“æœä¸ºå¯è¿­ä»£å¯¹è±¡ï¼Œå¯éå†å–å‡ºã€‚ hexists æ£€æµ‹æ˜¯å¦å­˜åœ¨æŸkey R: hexists user name1 # å­˜åœ¨è¿”å› 1ï¼Œä¸å­˜åœ¨è¿”å› 0 P: print(redis.hexists('user', 'name')) # å­˜åœ¨è¿”å›True hlen ç»Ÿè®¡è·å–ä¸€ä¸ªæ–‡æ¡£ï¼Œæ‰€æœ‰å±æ€§çš„ æ€»æ•° R: hlen user P: print(redis.hlen('user')) hdel åˆ é™¤æŒ‡å®šå­—æ®µ R: hdel key field P: redis.hdel('key', 'field') Listç›¸å…³æ“ä½œ lpush (å·¦å‹æ ˆ) R: lpush list1 1 2 3 P: redis.lpush('list1', 1,2,3) rpush (å³å‹æ ˆï¼ŒåŒå·¦å‹æ ˆï¼Œç•¥) lpop (å·¦å¼¹æ ˆ) R: lpop list2 P: print(redis.lpop('list2')) rpop (å³å¼¹æ ˆï¼ŒåŒå·¦å¼¹æ ˆï¼Œç•¥) blpop (å·¦é˜»å¡å¼¹æ ˆï¼Œåˆ—è¡¨ä¸ºç©ºæ—¶ï¼Œå°±é˜»å¡äº†) R: blpop list2 1000 # 1000ä¸ºè¿‡æœŸæ—¶é—´ä¸º1000ç§’ï¼Œ1000ç§’åè‡ªåŠ¨è§£é™¤é˜»å¡ï¼Œæœ‰å€¼åŠ å…¥ä¹Ÿä¼šè§£é™¤é˜»å¡ P: redis.blpop('list2', timeout=1000) brpop (å³é˜»å¡å¼¹æ ˆï¼ŒåŒå·¦é˜»å¡å¼¹æ ˆï¼Œç•¥) linsert ( åœ¨æŒ‡å®š å€¼ çš„ å‰å æ’å…¥å€¼) R: linsert list2 before Tom jerry # åœ¨Tomå‰æ’å…¥ jerry, beforeä»£è¡¨ä¹‹å‰ P: redis.linsert('list2', 'after', 'b', 'Tom') # åœ¨bçš„åé¢æ’å…¥Tom, afterä»£è¡¨ä¹‹å lset (æŒ‰ç´¢å¼•èµ‹å€¼, æ³¨æ„ç´¢å¼•ä¸è¦è¶Šç•Œ) Rï¼šlset list2 4 zhang P: redis.lset('list2', 4, 'zhang') lindex (æŒ‰ç´¢å¼•å–å€¼, ç´¢å¼•å¯æ­£å¯è´Ÿ) R: lindex list2 -3 P: print(redis.lindex('list2', 3)) llen ï¼ˆè·å–åˆ—è¡¨å…ƒç´ ä¸ªæ•°ï¼‰ R: llen list2 P: print(redis.llen('list2')) ltrim (æ³¨æ„ï¼šåœ¨åŸæ•°æ®ä¸Šåˆ‡ç‰‡ï¼Œä¸è¿”å›å€¼ã€‚) R: ltrim list2 3 10 # ä¿ç•™ ç´¢å¼• 3-10 çš„åˆ—è¡¨æ•°æ®ï¼Œå…¶ä»–éƒ½åˆ é™¤ P: print(redis.ltrim('list2', 2, -1)) # ç´¢å¼•å‰é—­åé—­ï¼Œå¯æ­£å¯è´Ÿ lrem (åˆ é™¤æŒ‡å®šå€¼) R: lrem list2 0 Tom # 0 è¿™ä¸ªä½ç½®çš„å‚æ•°ä»£è¡¨åˆ é™¤å€¼çš„ä¸ªæ•° # 0 ä»£è¡¨å…¨éƒ¨åˆ é™¤ï¼Œ åˆ é™¤å…¨éƒ¨Tomå€¼ # æ­£æ•°ä»£è¡¨ ä»å·¦åˆ°å³ åˆ é™¤nä¸ªã€‚ eg: lrem list2 5 Tom å³ä¸º ä»å·¦åˆ°å³ åˆ é™¤5ä¸ªTomå€¼ # è´Ÿæ•°ä»£è¡¨ ä»å³åˆ°å·¦ åˆ é™¤nä¸ªã€‚ eg: lrem list2 -5 Tom å³ä¸º ä»å³åˆ°å·¦ åˆ é™¤5ä¸ªTomå€¼ P: print(redis.lrem('list2', -5, 1)) # è§£é‡ŠåŒä¸Š lrange(éå†ï¼Œæ­£è´Ÿç´¢å¼•éƒ½å¯ï¼Œå‰é—­åé—­) R: lrange list1 0 -1 P: print(redis.lrange('list2', 0, -1)) Setç›¸å…³æ“ä½œ sadd ï¼ˆæ’å…¥å…ƒç´ ï¼‰ R: sadd set1 1 2 3 P: redis.sadd('set1', *[1,2,3]) srem ï¼ˆåˆ é™¤æŒ‡å®šå€¼çš„å…ƒç´ ï¼‰ R: srem set1 Tom P: redis.srem('set1', 'Tom') scard ï¼ˆè·å–é›†åˆä¸­å…ƒç´ ä¸ªæ•°ï¼‰ R: scard set1 P: redis.scard('set1') sismember (åˆ¤æ–­æŸå…ƒç´ æ˜¯å¦åœ¨é›†åˆ) R: sismember set1 Tom P: redis.sismember('set1', 'Tom') srandmember (éšæœºå–å‡ºé›†åˆæŒ‡å®šä¸ªæ•°å…ƒç´ ) â€œâ€â€œç±»ä¼¼pyçš„ random.choicesï¼Œæ³¨æ„æœ‰sâ€â€œ R: srandmember set1 2 # ä»é›†åˆéšæœºä¸­å–å‡º2ä¸ªå…ƒç´  P: redis.srandmember('set1', 2) smembers (å–å‡ºé›†åˆä¸­æ‰€æœ‰å…ƒç´ ) R: smembers set1 P: redis.smembers('set1') æ³¨ï¼š åŒ hgetallï¼Œ å¦‚æœä¸€æ¬¡æ€§å–å‡ºï¼Œå¯èƒ½ä¼šå‡ºé—®é¢˜ï¼Œæ‰€ä»¥éœ€è¦è¿­ä»£è·å–ï¼Œè§ä¸‹ sscan sscan (æ¸¸æ ‡/è¿­ä»£å–å‡ºé›†åˆæ‰€æœ‰å…ƒç´ ) R: sscan set1 0 match * count 200 P: result_iter = redis.sscan_iter('set1', match='*', count=200) # éå†è¿­ä»£ sdiff (å·®é›†) R: sdiff sset1 sset2 P: print(redis.sdiff('sset1', 'sset2')) sinterï¼ˆäº¤é›†ï¼‰ R: sinter sset1 sset2 P: print(redis.sinter('sset1', 'sset2')) sunion (å¹¶é›†) R: sunion sset1 sset2 P: print(redis.sunion('sset1', 'sset2')) zset æœ‰åºé›†åˆç›¸å…³æ“ä½œ zadd (æœ‰åºæ’å…¥) R: zadd zset 100 Tom 90 Jerry # 100æ˜¯æƒé‡ï¼ŒTomæ˜¯æ•°æ®å€¼ï¼Œ æ³¨æ„redis-cli æƒé‡åœ¨å‰ï¼Œå€¼åœ¨å P: redis.zadd('zset', {'Tom': 100, 'Jerry': 90}) # æ³¨æ„ï¼Œpyè¯­æ³•ï¼Œæƒé‡ä½œä¸ºå­—å…¸çš„value æ³¨ç‰¹åˆ«æ³¨æ„ï¼š zaddçš„é»˜è®¤æœºåˆ¶æ˜¯åŒå€¼ï¼Œä¸åŒæƒé‡æ—¶ï¼Œä¼šæ›´æ–°å€¼çš„æƒé‡ eg: ä¸Šé¢å†æ’å…¥ä¸€æ¡ Tom, ä¸è¿‡è¿™æ¬¡çš„æƒé‡æ˜¯ 50 ï¼ˆ zadd zset 50 Tomï¼‰ï¼Œåˆ™Tomçš„æƒé‡ä¼šæ›´æ–°ä¸º50 è¿™æ—¶å°±å»¶ç”³å‡º2ä¸ªå‚æ•°ï¼Œï¼ˆåº”è¯¥è¿˜è®°å¾—å‰é¢è®²çš„ setçš„ nx å’Œ xxå‚æ•°å§ï¼Œæ²¡é”™ zaddä¹Ÿæœ‰ï¼‰ nx: ï¼ˆä¸å­˜åœ¨æ‰æ›´æ–°ï¼ˆæ·»åŠ ï¼‰ï¼Œ å­˜åœ¨åˆ™æ›´æ–°ï¼ˆæ·»åŠ ï¼‰ å¤±è´¥ï¼‰ R: zadd zset nx 1000 Tom P: redis.zadd('zset',{'Tom': 1000}, nx=True) æ³¨ï¼š å¦‚æœTomè¿™ä¸ªå€¼ä¹‹å‰å­˜åœ¨ï¼Œåˆ™è¿™ä¸ª1000å°±ä¸ä¼šè¢«æ›´æ–°äº† è‹¥ä¸å­˜åœ¨ï¼Œåˆ™å°±ä¼šæ–°åˆ›å»ºï¼Œå¹¶æŠŠè¿™ä¸ª1000è®¾ç½®æˆåŠŸ nxï¼šï¼ˆå­˜åœ¨æ‰æ›´æ–°ï¼ˆæ·»åŠ ï¼‰ï¼Œ ä¸å­˜åœ¨åˆ™æ›´æ–°ï¼ˆæ·»åŠ ï¼‰ å¤±è´¥ï¼‰ R: zadd zset xx 1000 Tom Pï¼šredis.zadd('zset',{'Tom': 1000}, xx=True) æ³¨ï¼š å¦‚æœTomè¿™ä¸ªå€¼ä¹‹å‰å­˜åœ¨ï¼Œåˆ™1000æ‰ä¼šæ›´æ–°æˆåŠŸ å¦‚æœä¸å­˜åœ¨ï¼Œæ¯”å¦‚ {'å¼ ä¸‰':500}, å¼ ä¸‰æœ¬æ¥å°±ä¸å­˜åœ¨ï¼Œç”¨äº†xx, ä»–ä¸ä¼šè¢«æ·»åŠ è¿›æ¥ï¼Œæ›´ä½•è°ˆæ›´æ–° zrange (éå†) R: zrange zset 0 -1 P: print(redis.zrange('zset', 0, -1)) # è¿”å›å€¼ä¸ºåˆ—è¡¨ withscores å‚æ•°ï¼ˆæŠŠæƒé‡ä¹Ÿå¸¦å‡ºæ¥è¿”å›ï¼‰ï¼š R: zrange zset 0 -1 withscores # æ³¨æ„ï¼Œ è¿”å›æ—¶ å¥‡æ•°ä½ æ˜¯å€¼ï¼Œ å¶æ•°ä½æ˜¯æƒé‡ P: print(redis.zrange('zset', 0, -1, withscores=True)) # è¿”å›åˆ—è¡¨åµŒå¥—å…ƒç»„ï¼Œ[(å€¼ï¼Œæƒé‡)] zrevrange (é€†åº-é™åºï¼Œéå†) è¿™æ¡APIå°±æ˜¯å¤šäº† &quot;rev&quot; ä¸‰ä¸ªå­—æ¯, reversedå•è¯ ç†Ÿæ‚‰æŠŠï¼Œ pythonå†…ç½®é€†åºé«˜é˜¶å‡½æ•°ã€‚ã€‚å°±æ˜¯é‚£ä¸ªæ„æ€ æ“ä½œåŒzrangeï¼Œç•¥ zrangebyscore (æ ¹æ®æƒé‡æ¥éå†) R: zrangebyscore zset 40 99 limit 1 3 # æŸ¥å‡ºæƒé‡åœ¨40-99ä¹‹å†…çš„æ•°æ®ï¼Œå¹¶ä»ç¬¬1æ¡å¼€å§‹ï¼Œè¿”å›3æ¡ # 40-99éƒ½æ˜¯é—­åŒºé—´ï¼Œ è¦æƒ³å˜æˆå¼€åŒºé—´è¿™æ ·å†™å³å¯ (40 (99 P: print(redis.zrangebyscore('zset', 40, 99, start=1, num=3)) zrevrangebyscore (æ ¹æ®æƒé‡æ¥ é€†åºéå†) æ“ä½œåŒ zrangebyscoreï¼Œ ç•¥ è¿™APIè®¾è®¡çš„ï¼Œè¿˜ä¸å¦‚ï¼Œç›´æ¥å¼„æˆä¸€æ¡å‘½ä»¤ï¼Œç„¶ååŠ ä¸€ä¸ªé€†åºå‚æ•°ï¼Œåæ§½ï¼ï¼ï¼ï¼ zrem (åˆ é™¤æŸå€¼) R: zrem zset Tom # åˆ é™¤Tomè¿™ä¸ªå€¼ P: print(redis.zrem('zset','Tom')) zremrangebyscore (åˆ é™¤ æƒé‡ èŒƒå›´å†…çš„å€¼) R: zremrangebyscore zset 70 90 # æŠŠæƒé‡åœ¨70-90åˆ†çš„æ‰€æœ‰æ•°æ®åˆ é™¤ P: redis.zremrangebyscore('zset', 70, 90) zremrangebyrank (åˆ é™¤ ç´¢å¼• èŒƒå›´å†…çš„å€¼) R: zremrangebyrank zset 0 -1 # åˆ é™¤æ‰€æœ‰å€¼ ï¼ˆ 0åˆ°-1çš„ç´¢å¼•å°±ä»£è¡¨æ‰€æœ‰å€¼å•¦ï¼ï¼‰ P: redis.zremrangebyrank('zset', 0, -1) # redisçš„APIé£æ ¼çœŸçš„ã€‚ã€‚ã€‚æ²¡åŠæ³•pythonä¹Ÿæ— å¥ˆåŒå zcard (è·å–æœ‰åºé›†åˆçš„ æ‰€æœ‰ å…ƒç´ ä¸ªæ•°) R: zcard zset P: print(redis.zcard('zset')) zcount (ç»Ÿè®¡æœ‰åºé›†åˆçš„ æŸæƒé‡èŒƒå›´çš„ å…ƒç´ ä¸ªæ•°) R: zcount zset 10 69 # åŒæ ·é»˜è®¤é—­åŒºé—´ï¼Œ ( å¯æ”¹ä¸ºå¼€åŒºé—´ P: print(redis.zcount('zset',50, 69)) zrank (è·å–æŸå…ƒç´ çš„ç´¢å¼•) R: zrank zset Jerry # ä¸ç”¨çŒœï¼Œç´¢å¼•è‚¯å®šä»0å¼€å§‹ P: print(redis.zrank('zset', 'Jerry')) zrevrank (é€†åº è·å–æŸå…ƒç´ çš„ç´¢å¼•) é€†åºè·å–ç´¢å¼•ï¼Œæ¯”å¦‚æœ€åä¸€ä¸ªï¼Œç´¢å¼•å°±æ˜¯0 å…·ä½“æ“ä½œï¼ŒåŒ zrankï¼Œ ç•¥ zscore (è·å–æŸå…ƒç´ å¯¹åº”çš„æƒé‡) R: zscore zset Jerry P: print(redis.zscore('zset', 'Jerry')) zscan (è¿­ä»£æ–¹å¼å’Œè¿”å› æ‰€æœ‰å…ƒç´ åŠå…¶æƒé‡) &quot;&quot;&quot; å—¯?ä¼¼æ›¾ç›¸è¯†ç‡•å½’æ¥ï¼Ÿ å‰é¢è¯´è¿‡çš„ scan hsacn sscan è¿˜æœ‰æ¥ä¸‹æ¥è¦è¯´çš„ zscan éƒ½æ˜¯ä¸€ä¸ªæ ·å­çš„ï¼Œéƒ½æ˜¯ä¸ºäº†åº”å¯¹å¤§æ•°æ®æ¥è¿­ä»£å¤„ç† pythonç‰ˆçš„redisç»™äº†æˆ‘ä»¬ä¸€ä¸ªç®€åŒ–å‡½æ•°,é‚£å°±æ˜¯ _iterç»“å°¾çš„ï¼Œ eg: hscan_iter() è¿™ç§ _iterç»“å°¾çš„å‡½æ•°ï¼Œä¸ç”¨æˆ‘ä»¬æ¥ä¼ æ¸¸æ ‡cursorå‚æ•°ï¼Œ ä¸ºå•¥å‘¢?? ä¸€. å› ä¸ºpythonæœ‰ç”Ÿæˆå™¨-è¿­ä»£å™¨æœºåˆ¶é˜¿ï¼ï¼ˆå½“ç„¶ _iterç­‰å‡½æ•°çš„æºç å°±æ˜¯ç”¨yieldä¸ºæˆ‘ä»¬å®ç°çš„ï¼‰ äºŒ. cursoræ¸¸æ ‡ä¸æ˜“äºç®¡ç† &quot;&quot;&quot; R: zscan zset 0 match * count 5 P: zset_iter = redis.zscan_iter('zset', match='*', count=5) # åŒç†è¿”å›å¯è¿­ä»£å¯¹è±¡ æ³¨ï¼šè¿˜è¦è¯´æ˜ä¸€ä¸‹ï¼š matchå‚æ•°: è¿‡æ»¤æŸ¥è¯¢æ•°æ®ï¼ˆå…¶å®è¿‡æ»¤å®Œäº†ï¼Œæ•°æ®é‡å°äº†ä¹Ÿæ²¡å¿…è¦ç”¨scanäº†ï¼Œæ­¤å‚æ•°ä¸»è¦ç”¨åœ¨&quot;hscan&quot;ä¹‹ç±»çš„ï¼‰ &quot;å› æ­¤matchå‚æ•°å¯ä¸å†™&quot;, &quot;match='*' å’Œ ä¸ä¼ æ˜¯ä¸€ä¸ªæ•ˆæœçš„ã€‚&quot; countå‚æ•°ï¼š Pyæºç è§£é‡Š ``count`` allows for hint the minimum number of returns æ„æ€å°±æ˜¯ï¼š è¿™ä¸ªå‚æ•°æ˜¯ä¸€æ¬¡è¿­ä»£&quot;æœ€å°‘&quot;å–5ä¸ª&quot;ï¼Œä½†ä¸ç®¡æ€ä¹ˆè¯´ï¼Œæœ€ç»ˆè¿˜æ˜¯ä¼šå–å‡ºå…¨éƒ¨æ•°æ®ï¼ï¼ zpopmax (å¼¹å‡ºæœ€å¤§ä¼˜å…ˆçº§æ•°æ®å¯¹ï¼Œredis5.+æ–°å¢) R: zpopmax zset1 2 # 2ä»£è¡¨å¼¹å‡ºæœ€å¤§çš„2å¯¹key:score,ä¸å†™ï¼Œé»˜è®¤åªå¼¹ä¸€å¯¹key:score P: data = redis.zpopmax(zset1, count=None) # åŸç†åŒä¸Š zpopmaxå¯ç­‰ä»·äºä¸‹é¢ä¸¤æ¡å‘½ä»¤çš„åŠ èµ·æ¥çš„æ•ˆæœï¼š data = redis.zrange(zset1, -1, -1) zrem(zset1, data) æ³¨ï¼šæ— è®ºcountæŒ‡å®šå‡ ä¸ªæˆ–ä¸æŒ‡å®šï¼Œpyè¿”å›å€¼ä¸º [(key, score)] åˆ—è¡¨åµŒå…ƒç»„è¿™ç§æ ¼å¼ã€‚ zpopmin (å¼¹å‡ºæœ€å°ä¼˜å…ˆçº§æ•°æ®å¯¹ï¼Œredis5.+æ–°å¢) ç”¨æ³•åŒzpopmax zpopmaxå¯ç­‰ä»·äºä¸‹é¢ä¸¤æ¡å‘½ä»¤çš„åŠ èµ·æ¥çš„æ•ˆæœï¼š data = redis.zrange(zset1, 0, 0) # å°±è¿™é‡Œå˜äº†ï¼Œé»˜è®¤å‡åºï¼Œæ•…æœ€å°å€¼éœ€è¦ä»ç¬¬0æ¡å¼€å§‹å¼¹ zrem(zset1, data) æ³¨ï¼š zpopmax å’Œ zpopmin è¿™ä¸¤ä¸ªæ–¹æ³•æ˜¯ redis5.+æ‰æœ‰çš„ã€‚ å‰é¢ä¹Ÿè¯´äº†è¿™ç§æ–¹æ³• = zrange + zrem å¾ˆæ˜æ˜¾ï¼Œç”±åŸæ¥çš„å¤šè¡Œæ“ä½œã€‚å˜æˆäº†åŸå­æ“ä½œã€‚ æˆ‘æƒ³ï¼Œredisæ–°å¢è¿™ä¸¤æ¡å‘½ä»¤ï¼Œåº”è¯¥æ­£æ˜¯è§£å†³èµ„æºç«äº‰çš„è¿™ä¸€é—®é¢˜ï¼ï¼ï¼ï¼ï¼ï¼ Redisä¸¤ç§æŒä¹…åŒ–çš„æ–¹å¼ ç”ŸæˆRDBæ–‡ä»¶ ï¼ˆä¸‰ç§æ–¹æ³•ï¼‰ &quot;&quot;&quot;RDBæœºåˆ¶å°±æ˜¯ è§¦å‘ç”ŸæˆRDBæ–‡ä»¶ï¼Œå°†Redisæ•°æ®ä»¥äºŒè¿›åˆ¶å½¢å¼å†™å…¥å…¶ä¸­ï¼Œ è§¦å‘æ–¹å¼æœ‰å¦‚ä¸‹ä¸‰ç§&quot;&quot;&quot; RDBåŸºæœ¬é…ç½®ï¼š vi /etc/redis/redis.conf dbfilename dump.rdb # é…ç½®RDBæ–‡ä»¶å dir /var/lib/redis # é…ç½®RDBæ–‡ä»¶å­˜æ”¾ç›®å½• ï¼ˆll å‘½ä»¤æŸ¥çœ‹ dump.rdbæ˜¯å¦ä¸ºæœ€æ–°æ—¶é—´ï¼‰ appendonly no # è‹¥ä¸ºyes, ä¼šä¼˜å…ˆæŒ‰ç…§aofæ–‡ä»¶æ¥æ¢å¤ï¼Œæˆ–ä¸æ¢å¤ ä¸Šè¿°é…ç½®ï¼Œå¯åœ¨ä¸‹é¢ä¸‰ç§æ–¹æ³•å®ç°çš„æ—¶å€™ï¼Œè‡ªåŠ¨è§¦å‘ç”ŸæˆRDBæ–‡ä»¶ã€‚å¹¶åœ¨rediså¯åŠ¨æ—¶æ¢å¤RDBæ–‡ä»¶ è§¦å‘æ–¹å¼1ï¼šsave ï¼ˆé˜»å¡ï¼‰ R: save P: redis.save() è§¦å‘æ–¹å¼2ï¼šbgsave ï¼ˆå¼€forkè¿›ç¨‹ï¼Œå¼‚æ­¥,éé˜»å¡ï¼‰ R: bgsave P: redis.bgsave() è§¦å‘æ–¹å¼3ï¼šè‡ªåŠ¨åŠ¨æ€ç”ŸæˆRDBæ–‡ä»¶ï¼ˆé…ç½®æ–‡ä»¶ï¼‰ åœ¨ä¸Šé¢RDBåŸºæœ¬é…ç½®åŸºç¡€ä¸Šï¼Œè¿½åŠ å¦‚ä¸‹é…ç½® vi /etc/redis/redis.conf save 100 10 # 100ç§’é’Ÿæ”¹å˜10æ¡æ•°æ®å°±ä¼šï¼Œè‡ªåŠ¨ç”ŸæˆRDBæ–‡ä»¶ RDBç¼ºç‚¹ å¤§æ•°æ®è€—æ—¶ï¼ŒRDBæ–‡ä»¶å†™å…¥å½±å“IOæ€§èƒ½ã€‚å®•æœºæ•°æ®ä¸å¯æ§ ç”ŸæˆAOFæ–‡ä»¶ï¼ˆä¸‰ç§æ–¹æ³•ï¼‰ &quot;&quot;&quot;AOFæœºåˆ¶å°±æ˜¯ æ¯æ‰§è¡Œä¸€æ¡å‘½ä»¤ï¼Œéƒ½ä¼šè®°å½•åˆ°ç¼“å†²åŒºï¼Œåœ¨æ ¹æ®æŸç§ç­–ç•¥åˆ·æ–°åˆ°AOFæ–‡ä»¶ä¸­ï¼Œç­–ç•¥æœ‰å¦‚ä¸‹ä¸‰ç§&quot;&quot;&quot; AOFåŸºæœ¬é…ç½®ï¼š vi /etc/redis/redis.conf appendonly yes # å¼€å…³ï¼Œå…ˆè¦æ‰“å¼€ appendfilename &quot;appendonly.aof&quot; # AOFæ–‡ä»¶å dir /var/lib/redis # AOFæ–‡ä»¶ç›®å½•ï¼ˆå’ŒRDBæ˜¯ä¸€æ ·çš„ï¼‰ åˆ·æ–°ç­–ç•¥1ï¼šalways always å³ç¼“å†²åŒºæœ‰ä¸€æ¡å‘½ä»¤ï¼Œå°±ä¼šåˆ·æ–°è¿½åŠ åˆ°AOFæ–‡ä»¶ä¸­ ï¼ˆå®‰å…¨å¯é ï¼Œè€—IOï¼‰ åˆ·æ–°ç­–ç•¥2ï¼ševerysec ï¼ˆé»˜è®¤ï¼‰ everysec å³æ¯è¿‡1ç§’ å°±ä¼šæŠŠç¼“å†²åŒºçš„å‘½ä»¤ åˆ·æ–°è¿½åŠ åˆ°AOFæ–‡ä»¶ä¸­ å¦‚æœå°±åœ¨è¿™ä¸€ç§’é’Ÿå®•æœºï¼Œé‚£ä¹ˆæ•°æ®å°±ä¸¢å¤±äº†ã€‚ã€‚ã€‚ï¼ˆ1ç§’ä¸å¯æ§ï¼‰ åˆ·æ–°ç­–ç•¥3ï¼šno no å³ ä»€ä¹ˆæ—¶å€™åˆ·æ–°ï¼Œå…¨å¬æ“ä½œç³»ç»Ÿè‡ªå·±çš„ ï¼ˆå®Œå…¨ä¸å¯æ§ï¼‰ AOFé‡å†™æœºåˆ¶ ï¼ˆä¸¤ç§æ–¹æ³•,å¼‚æ­¥ï¼‰ é‡å†™æ¸…æ´è¿‡ç¨‹ï¼š å¦‚ä¸Šå¯çŸ¥ï¼Œè¶Šæ¥è¶Šå¤šçš„å‘½ä»¤ä¼šè¿½åŠ åˆ°AOFä¸­ï¼Œå…¶ä¸­å¯èƒ½ä¼šæœ‰ä¸€äº›ç±»ä¼¼ ä¸€ã€é”®å€¼è¦†ç›–ï¼š set name tom set name jerry äºŒã€è¶…æ—¶æ—¶é—´è¿‡æœŸ ä¸‰ã€å¤šæ¡æ’å…¥ï¼ˆå¯ç”¨ä¸€æ¡å‘½ä»¤ä»£æ›¿ï¼‰ å¦‚ä¸Šæ— ç”¨å‘½ä»¤ï¼Œä¼šè®©AOFæ–‡ä»¶å˜å¾—ç¹æ‚ã€‚ å¯é€šè¿‡ AOFé‡å†™ç­–ç•¥ä¼˜åŒ–æ¥è¾¾åˆ°åŒ–ç®€ï¼Œæé«˜æ¢å¤é€Ÿåº¦ç­‰ã€‚ é‡å†™åŸç†ï¼ˆæŸ¥æ‰¾èµ„æ–™ + ä¸ªäººç†è§£ï¼‰ï¼š ä¸€ã€ å¼€forkå­è¿›ç¨‹ æ–°å¼„ä¸€ä»½AOFæ–‡ä»¶ï¼Œå®ƒçš„ä»»åŠ¡å°±æ˜¯æŠŠå½“å‰redisä¸­çš„æ•°æ®é‡æ–°æŒ‰ç…§ä¸Šé¢çš„ â€é‡å†™æ¸…æ´è¿‡ç¨‹â€œ æ‹ä¸€éï¼Œå¹¶è®°å½•åˆ°è¿™ä¸ªæ–°AOFæ–‡ä»¶ä¸­ äºŒã€ æ­¤æ—¶ä¸»è¿›ç¨‹å¯ä»¥æ­£å¸¸æ¥å—ç”¨æˆ·çš„è¯·æ±‚åŠä¿®æ”¹ï¼Œï¼ˆè¿™æ—¶å¯èƒ½å­è¿›ç¨‹AOFï¼Œå’Œæ•°æ®åº“å†…å®¹ä¸ä¸€è‡´,å¾€ä¸‹çœ‹ï¼‰ ä¸‰ã€ å…¶å®---ç¬¬ä¸€æ¡å¼€forkçš„æ—¶å€™ï¼Œé¡ºä¾¿ä¹Ÿå¼€äº†ä¸€ä»½å†…å­˜ç©ºé—´Aï¼ˆåä¸ºé‡å†™ç¼“å†²åŒºï¼‰ ç”¨æ¥å¹³è¡Œè®°å½• ç”¨æˆ·æ–°è¯·æ±‚çš„å‘½ä»¤ å››ã€ å½“å­è¿›ç¨‹AOFé‡å†™å®Œäº‹åï¼Œ ä¼šæŠŠä¸Šé¢ ç©ºé—´Aä¸­ ä¸­çš„æ•°æ®å‘½ä»¤è¿½åŠ åˆ° AOFä¸­ï¼ˆç±»ä¼¼æ–­ç‚¹å¤åˆ¶ï¼‰ äº”ã€ æ–°AOFæ›¿ä»£ æ—§çš„AOF æ‰“ä¸ªæ¯”æ–¹ï¼ˆé’ˆå¯¹äº äºŒã€ä¸‰ã€å››ï¼‰ï¼š å°±æ˜¯ï¼Œä½ ç»™æˆ‘ä¸€ä¸ªä»»åŠ¡ï¼Œæˆ‘æ­£åšç€ï¼Œä½ åˆç»™æˆ‘å¾ˆå¤šä»»åŠ¡ï¼Œæˆ‘å½“ç„¶å¿™ä¸è¿‡æ¥ é‚£è¿™æ ·ï¼Œä½ å…ˆæ‹¿ä¸ªæ¸…å•è®°å½•ä¸‹æ¥ï¼Œä¸€ä¼šç­‰æˆ‘å¿™å®Œäº†ï¼Œå’±ä»¬å¯¹æ¥ä¸€ä¸‹å°±å¥½äº†ï¼‰ é‡å†™æ–¹å¼1ï¼šbgrewriteaof R: bgrewriteaof P: redis.bgrewriteaof() é‡å†™æ–¹å¼2ï¼šé…ç½®æ–‡ä»¶å®ç°è‡ªåŠ¨é‡å†™ åœ¨ä¸Šé¢AOFåŸºæœ¬é…ç½®çš„åŸºç¡€ä¸Šï¼Œè¿½åŠ å¦‚ä¸‹é…ç½® vi /etc/redis/redis.conf appendfsync everysec # å°±æ˜¯ä¸Šé¢è¯´çš„ä¸‰ç§ç­–ç•¥ï¼Œé€‰ä¸€ç§ always no auto-aof-rewrite-min-size 64mb # å½“AOFæ–‡ä»¶è¶…è¿‡64mbå°±ä¼šè‡ªåŠ¨é‡å†™ auto-aof-rewrite-percentage 100 # 100ä¸ºå¢é•¿ç‡ï¼Œ æ¯ä¸€æ¬¡çš„é™åˆ¶å¤§å°æ˜¯ä¹‹å‰çš„100%,ä¹Ÿå°±æ˜¯äºŒå€ no-appendfsync-on-rewrite yes # yes å°±æ˜¯ä¸æŠŠ â€œé‡å†™ç¼“å†²åŒºâ€ çš„å†…å®¹ åˆ·æ–°åˆ° ç£ç›˜ æ³¨æ„è¿™ä¸ªå‚æ•°: è¿™å°±æ˜¯é’ˆå¯¹ä¸Šé¢ â€™é‡å†™åŸç†â€˜ ä¸­çš„ç¬¬ä¸‰æ¡ ä¸­çš„ å†…å­˜ç©ºé—´Aï¼ˆé‡å†™ç¼“å†²åŒºï¼‰ å¦‚æœè¿™ä¸ª é‡å†™ç¼“å†²åŒº ä¸åˆ·æ–°æŒä¹…åŒ–åˆ°ç£ç›˜ä¸­ï¼Œ è¦æ˜¯å®•æœºäº†ï¼Œé‚£ä¹ˆè¿™ä¸ªç¼“å†²åŒºçš„æ•°æ®å°±ä¼šä¸¢å¤±ã€‚ ä¸¢å¤±å¤šå°‘å‘¢ï¼Ÿ æ®æ‚‰ï¼ˆlinuxä¸­ æœ€å¤šæœ€å¤š ä¼šä¸¢å¤± 30ç§’çš„æ•°æ®ï¼‰ å¦‚æœä½ å°†å…¶ è®¾ç½®ä¸º noï¼Œé‚£ä¹ˆ é‡å†™ç¼“å†²åŒº å°±ä¼šåƒ å‰é¢è®²çš„ åŸå§‹AOFä¸€æ ·åœ° åˆ·æ–°æŒä¹…åŒ–åˆ°ç¡¬ç›˜ä¸­ã€‚ ä½†æ˜¯ä½ æƒ³æƒ³ï¼Œ å¦‚æœ é‡å†™ç¼“å†²åŒº å’Œ åŸå§‹AOF éƒ½åšæŒä¹…åŒ–åˆ·æ–° é‚£ä¹ˆ å®ƒä»¬å°±ä¼š ç«äº‰ IOï¼Œæ€§èƒ½å¿…å®šå¤§æ‰“æŠ˜æ‰£ï¼Œç‰¹æ®Šæƒ…å†µä¸‹ï¼Œè¿˜å¯èƒ½ å µå¡ã€‚ so, è¦æ€§èƒ½ï¼ˆè®¾ä¸ºyesï¼‰ï¼Œ è¦æ•°æ®å®Œæ•´å®‰å…¨(è®¾ä¸ºno)ï¼Œ è‡ªå·±é€‰.... ç»“æŸè¯­ æœ¬æ–‡ä¸»è¦å†™äº†å…³äº redis ä»¥åŠ pythonæ“ä½œredisçš„è¯­æ³•å¯¹æ¯”è¯¦ç»†è§£é‡Šï¼ï¼ pythonçš„redis API ä¹Ÿæ˜¯éå¸¸å¤Ÿæ„æ€äº†ï¼Œå‡½æ•°åå‡ ä¹å®Œå…¨è¿˜åŸ åŸç”ŸRedisï¼ï¼ è¯­æ³•éƒ¨åˆ†å°è±¡æ¯”è¾ƒæ·±åˆ»çš„å°±æ˜¯ &quot;redisçš„ scanå®¶æ—å‡½æ•°&quot; ä»¥åŠ &quot;pythonçš„ scan_iter&quot;å®¶æ—å‡½æ•°ï¼š ä¸Šé¢é™†é™†ç»­ç»­è®²äº†é‚£ä¹ˆå¤šæ•°æ®ç»“æ„ï¼Œéƒ½æœ‰å®ƒä»¬å„è‡ªçš„&quot;éå†æ‰€æœ‰æ•°æ®çš„æ“ä½œ&quot; ä½†å¯¹äºå¤§é‡æ•°æ®çš„æƒ…å†µä¸‹ï¼Œ è¿™äº›éå†å‡½æ•°å°±éƒ½å˜æˆæ¸£æ¸£äº†ï¼Œ å¯èƒ½ä¼šé€ æˆ&quot;OOMï¼ˆå†…å­˜æº¢å‡ºï¼‰ç­‰æƒ…å†µ&quot; è¿™æ—¶ redis æœºæ™ºçš„ä¸ºæˆ‘ä»¬ æä¾›äº†ä¸€äº›åˆ— &quot;scanå®¶æ—å‡½æ•°&quot; , å½“ç„¶è¿™äº›å‡½æ•°æ˜¯éƒ½éœ€è¦æ¸¸æ ‡æ§åˆ¶çš„ã€‚ &quot;æ¸¸æ ‡cursor&quot;æ˜¯æ¯”è¾ƒå¤´ç–¼çš„ä¸œè¥¿ï¼Œ å› æ­¤ pythonæœ¬ç€ äººæ€§åŒ–çš„æ€æƒ³ï¼š å°† &quot;scanå®¶æ—å‡½æ•°&quot; å°è£…ä¸º &quot;scan_iterå®¶æ—å‡½æ•°&quot;ï¼Œ è®©æˆ‘ä»¬çœå»äº†æ¸¸æ ‡çš„æ“ä½œï¼Œå¯ä»¥æ„‰å¿«ç¼–ç¨‹ï¼ é‚£æˆ‘å°±åˆ—å‡ºå…¨éƒ¨å¤§å®¶æ— ä»¥åŠ å¯¹åº” åŸå§‹éå†å‡½æ•°ï¼š åŸå§‹éå† redis python keys scan scan_iter hgetall hscan hscan_iter smembers sscan sscan_iter zrange zscan zscan_iter æ²¿ç€è¿™ä¸ªå¯¹åº”è§„å¾‹ï¼Œä¹‹å‰æˆ‘å‘ç°ä¸€ä»¶äº‹æƒ…ï¼š ä¸ºä»€ä¹ˆ &quot;list çš„ lrange æ²¡æœ‰å¯¹åº”çš„ lscanï¼Ÿ&quot; æˆ‘åƒzzä¸€æ ·è¿˜å»ovæŸ¥äº†ä¸€éï¼Œ å±…ç„¶è¿˜çœ‹åˆ°ä¸€ä½å¤–å›½æœ‹å‹å’Œæˆ‘æœ‰ä¸€æ ·çš„ç–‘é—®ã€‚ã€‚ã€‚ è§£ç­”è€…çš„ä¸€å¥è¯ï¼Œæˆ‘ç›´æ¥å°±æ¸…é†’äº†ï¼Œ &quot;Instead, you should use LRANGE to iterate the list&quot; ç”±äºé¡ºç€è§„å¾‹ï¼Œæ€ç»´å®šåŠ¿ï¼Œå´å¿˜è®°äº† &quot;lrangeæœ¬èº«å°±å¯ä»¥å¸¦ç´¢å¼•æ¥è¿­ä»£ &quot; lrange list1 0 n è¿™æ—¶æˆ‘çªç„¶åˆæƒ³èµ· zrangeä¸ä¹Ÿæ˜¯å’Œ lrangeè¯­æ³•ä¸€æ ·ä¹ˆï¼Ÿï¼Ÿï¼Ÿ ä¸ºä½• zrangeå•ç‹¬è®¾ç«‹äº†ä¸€ä¸ª zscanï¼Œ è€Œ listå´æ²¡ï¼Ÿï¼Ÿï¼Ÿ (æŸ¥äº†ä¸€ä¸‹å¥½åƒæ˜¯liståº•å±‚æ€§èƒ½ä¹‹ç±»çš„åŸå› ï¼Œæˆ‘ä¹Ÿæ²¡æ„¿æ„ç»§ç»­çœ‹äº†ã€‚ã€‚ã€‚) scan ä¸ iterå®¶æ—å‡½æ•°ï¼Œå„è‡ªçš„æ•°æ®ç»“æ„ç« èŠ‚éƒ½æœ‰å†™ï¼Œ å¹¶ä¸”åœ¨&quot;zset&quot;é‚£èŠ‚çš„ &quot;zscan&quot;é‚£é‡Œåšå‡ºäº†è¯¦ç»†çš„åˆ†æ END ","link":"https://cythonlin.github.io/post/py-greater-redis-yu-python-cao-zuo-redis-yu-fa-dui-bi-jie-xi/"},{"title":"PY => MongoDBä¸PyMongoè¯­æ³•å¯¹æ¯”è§£æ","content":"é˜…è¯»é¡»çŸ¥ ç”±äºæ˜¯å¯¹æ¯”ä¹¦å†™: M: ä»£è¡¨ MongoåŸç”Ÿè¯­æ³• P: ä»£è¡¨ PyMongoä¹¦å†™æ–¹æ³• åé¢æåˆ°ï¼šâ€åŒä¸Šâ€œ å­—çœ¼ï¼š æ„æ€å°±æ˜¯ Mongo å’Œ PyMongo è¯­å¥æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œ ä¸€ä¸ªå­—éƒ½ä¸å·®ï¼Œå¤åˆ¶ä¸Šå»ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ ï¼ˆä¹Ÿè®¸ä½ å¾ˆå¥½å¥‡ï¼Œä¸ºä»€ä¹ˆ ä¸€ä¸ªæ˜¯Pythonè¯­è¨€é‡Œçš„PyMongoï¼Œä¸€ä¸ªæ˜¯Mongoï¼‰ ä»–ä»¬çš„è¯­å¥ä¸ºä»€ä¹ˆå¯ä»¥åšåˆ°ä¸€æ¨¡ä¸€æ · ï¼Ÿï¼Ÿ ç­”ï¼šå› ä¸º Mongoå’ŒPythonéƒ½å¯ä»¥ ç»™å˜é‡èµ‹å€¼ï¼Œ PyMongoçš„è¯­æ³•è®¾è®¡ä¹Ÿæ˜¯æ¨¡ä»¿Mongoçš„ã€‚ æ‰€ä»¥ï¼šæˆ‘å·§å¦™çš„ æŠŠäºŒè€…çš„å˜é‡è®¾ä¸ºåŒä¸€ä¸ªï¼Œå‡½æ•°90%éƒ½ä¸€è‡´ï¼Œ æ‰€ä»¥æ•´æ¡è¯­å¥å°±ä¸€æ¨¡ä¸€æ ·äº†ï¼ ä¸»è¦è¯­æ³•åŒºåˆ«ï¼š 1. å‡½æ•°å‘½å Mongo æ–¹æ³•å‡½æ•°å¤§éƒ½ä»¥ é©¼å³°å‘½å PyMongoæ–¹æ³•å‡½æ•°å¤§éƒ½ä»¥ _ ä¸‹åˆ’çº¿åˆ†å‰²å‘½å 2. å‡½æ•°å‚æ•° Mongo : åŸºæœ¬éƒ½æ˜¯ {} + [] å„ç»„ç»„åˆæ ¼å¼ PyMongoï¼šåŒä¸Šï¼Œ ä½†{}çš„ keyéœ€è¦ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼ï¼Œ æœ‰äº›æƒ…å†µï¼Œè¿˜éœ€è¦ä½¿ç”¨å‘½åå‚æ•°ä»£æ›¿ {} 3. ç©ºå€¼ ä¸ Bool Mongo: null true false PyMongo: None True False å‰ç½®å®‰è£…é…ç½®ç¯å¢ƒ å®¢æˆ·ç«¯è¿æ¥ï¼š pip install pymongo import pymongo M: Mongo P: cursor = pymongo.MongoClient('ip',port=27017) é€‰æ‹©æ•°æ®åº“ï¼š M: use test P: db = cursor['test'] # è®°ä½è¿™ä¸ªdbï¼Œ ä¸‹é¢å¤ç”¨è¿™ä¸ªå‚æ•° é€‰æ‹©é›†åˆï¼š (è®°ä½tableå˜é‡åï¼Œä¸‹é¢å°±ç›´æ¥ç”¨ä»–ä»¬äº†) æ³¨æ„ï¼Œæ³¨æ„ï¼Œæ³¨æ„ M: table = db.zhang P: table = db['zhang'] æ³¨ï¼šé€‰æ‹©åº“ï¼Œé€‰æ‹©é›†åˆçš„æ—¶å€™ æ³¨æ„äº‹é¡¹ï¼š Mongoä¸­ï¼š xx.xx ç”¨ . çš„è¯­æ³• PyMongoä¸­ï¼šä¹Ÿå¯ä»¥ ç”¨ xx.xx è¿™æ ·, ä½†æ˜¯è¿™æ ·ç”¨åœ¨PyCharmä¸­æ²¡æœ‰è¯­æ³•æç¤º æ‰€ä»¥æå€¡ xx['xx'] ç”¨ç´¢å¼•çš„æ–¹å¼ä½¿ç”¨ Mongo ä¸ PyMongo è¿”å›ç»“æœçš„æ¸¸æ ‡æ¯”è¾ƒ Mongoä¸­ï¼š å¤§å¤šæ•°æŸ¥è¯¢ç­‰ç»“æœè¿”å›éƒ½æ˜¯æ¸¸æ ‡å¯¹è±¡ å¦‚æœä¸å¯¹æ¸¸æ ‡éå†ï¼Œé‚£ä¹ˆMongoçš„æ¸¸æ ‡ä¼šé»˜è®¤ä¸ºä½ å–å‡º å‰ 20 ä¸ª å€¼ å½“ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥ç´¢å¼•å–å€¼ å…³é—­æ“ä½œï¼š .close() PyMongoä¸­ï¼š åŒæ ·ï¼Œå¤§å¤šæ•°æŸ¥è¯¢ç­‰ç»“æœè¿”å›éƒ½æ˜¯æ¸¸æ ‡å¯¹è±¡ï¼ˆå¦‚æœä½ å­¦è¿‡ORMï¼Œå¯ä»¥ç†è§£æ¸¸æ ‡å°±åƒ ORMçš„æŸ¥è¯¢é›†ï¼‰ æ‰€ä»¥å¿…é¡»é€šè¿‡ list() æˆ– éå† æˆ– ç´¢å¼• ç­‰æ“ä½œæ‰èƒ½çœŸæ­£å–å‡ºå€¼ å…³é—­æ“ä½œï¼š .close() æˆ–è€… ç”¨ Python çš„ with ä¸Šä¸‹æ–‡åè®® å¢ save() M: table.save({}) # ä¼°è®¡è¦åºŸå¼ƒäº† P: å°†è¦è¢«åºŸå¼ƒ ç”¨insert_oneä»£æ›¿å®ƒ insert() M: table.insert() # åŒ…æ‹¬ä¸Šé¢ä¸¤ç§ï¼Œå¯ä»¥ä¸€ä¸ª {}ï¼Œå¯ä»¥å¤šä¸ª [{},{}] P: PyMongoæºç æ˜ç¡®è¯´æ˜ï¼Œinsert()è¯­æ³•å°†è¢«åºŸå¼ƒï¼Œè¯·ç”¨ insert_one({}) å’Œ insert_many([])ä»£æ›¿ insert_one() å’Œ insert_many() M: table.insertOne( {} ) # é©¼å³° table.insertMany([ {},{} ]) # é©¼å³° P: table.insert_one( {} ) # ä¸‹åˆ’çº¿ table.insert_many([ {},{} ]) # ä¸‹åˆ’çº¿ åˆ  remove() å‚æ•°1ï¼šåˆ é™¤æŸ¥è¯¢æ¡ä»¶ å‚æ•°2ï¼šåˆ é™¤é€‰é¡¹ M: table.remove({'name':'zhangsan'}, {'justOne': true}) # æˆ‘æ›´å–œæ¬¢ç”¨deleteçš„ P: PyMongoä¸­,æ­¤æ–¹æ³•å°†è¢«åºŸå¼ƒã€‚ å°†ä¼šè¢« delete_one() å’Œ delete_many() ä»£æ›¿ deleteOne() # åªåˆ é™¤ä¸€æ¡ M: table.deleteOne({'name': 'lin3'}) P: table.delete_one({'name': 'lin3'}) # deleteMany() # åˆ é™¤å¤šæ¡ M: table.deleteMany({'name': 'lin3'}) P: table.delete_many({'name': 'lin3'}) æ³¨æ„ï¼š ä¸çŸ¥é“è¿™ä¸¤ä¸ªå‡½æ•°æ˜¯å¦è®©ä½ æƒ³èµ·äº†å‰é¢è®²çš„ insertOne å’Œ insertManyï¼Œä»–ä»¬çœ‹èµ·æ¥å¾ˆåƒï¼Œè¯­æ³•ä¸åŒï¼š insertMany([]) # å‚æ•°éœ€è¦ç”¨ [] åŒ…èµ·æ¥ deleteMany({}) # å‚æ•°ä¸éœ€è¦ æ³¨æ„2ï¼š table.deleteMany({}) # ç©º {}ï¼Œ ä»£è¡¨åˆ é™¤æ‰€æœ‰æ–‡æ¡£ ï¼ˆæ…è¡Œï¼Œæ…è¡Œï¼Œæ…è¡Œï¼‰ åˆ é™¤æ•´ä¸ªé›†åˆï¼š table.drop() # åˆ é™¤é›†åˆï¼ˆè¿åŒ æ‰€æœ‰æ–‡æ¡£ï¼Œ è¿åŒ ç´¢å¼•ï¼Œå…¨éƒ¨åˆ é™¤ï¼‰ æ”¹ &quot;&quot;&quot; æ–‡æ¡£ä¿®æ”¹, æ³¨æ„ï¼š _id ä¸å¯ä¿®æ”¹ &quot;&quot;&quot; ä¸‰ç§æ›´æ–°æ–¹æ³•ï¼š update(å°†è¦åºŸå¼ƒï¼Œå¯è·³è¿‡ï¼Œç›´æ¥çœ‹2ï¼Œ3ç‚¹çš„æ–¹æ³•) update({æŸ¥è¯¢æ¡ä»¶}, {æ›´æ–°æ“ä½œç¬¦} , {æ›´æ–°é€‰é¡¹}) M: table.update({'name': {'regex&#039;:&#039;li&#039;}},{&#039;set':{'name':'lin2'}}, {multi: true}) P: table.update({'name': {'regex&#039;: &#039;li&#039;}}, {&#039;set': {'name': 'lin3'}},multi=True) æ³¨æ„1: ç¬¬ä¸‰ä¸ªå‚æ•° multiå¦‚æœä¸è®¾ç½®ï¼Œé»˜è®¤åªæ›´æ–°ä¸€æ¡æ–‡æ¡£ï¼Œè®¾ç½®ä¸º true ï¼Œå°±ä¼šæ›´æ–°å¤šæ¡æ–‡æ¡£ æ³¨æ„2ï¼š Mongoå†™æ³•ï¼š {multi: true} # Mongo å’Œå¾€å¸¸ä¸€æ ·ï¼Œé‡‡ç”¨jsonæ ¼å¼ï¼Œ trueå°å†™ Pythonå†™æ³•ï¼š multi = True # pythonæ˜¯é‡‡ç”¨å‘½åå‚æ•°æ¥ä¼ é€’ï¼Œ Trueå¤§å†™ updateOne(æ›´æ–°ä¸€æ¡) M: updateOne( {æŸ¥è¯¢æ¡ä»¶}, {æ›´æ–°æ“ä½œç¬¦} ) P: update_one updateMany(æ›´æ–°å¤šæ¡) M: updateMany( {æŸ¥è¯¢æ¡ä»¶}, {æ›´æ–°æ“ä½œç¬¦} ) å…¶å®å‚æ•°æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œåªä¸è¿‡æ–¹æ³•ååŒºåˆ† P: update_many æ³¨ï¼š è¿™ä¸‰ä¸ªæ–¹æ³•çš„å‚æ•° æ˜¯åŸºæœ¬ä¸€æ¨¡ä¸€æ ·çš„ æ‰€ä»¥ä¸‹é¢è®²å…·ä½“ {æŸ¥è¯¢æ¡ä»¶}, {æ›´æ–°æ“ä½œç¬¦} æ—¶ å°±ç»Ÿä¸€ç”¨ update()æ¥å†™äº† æ™®é€šæ›´æ–°æ“ä½œç¬¦ï¼š $set(æ›´æ–°) æ³¨ï¼šè§„åˆ™å°±æ˜¯ï¼š&quot;æœ‰åˆ™æ”¹ä¹‹ï¼Œ æ— åˆ™æ·»åŠ &quot; M: table.update({'5':5},{'$set': {'lin': [5,6,7,8]} }) P: åŒä¸Š å¾®æ‰©å±•(å…³äºå†…åµŒæ•°ç»„)ï¼š table.update({'5':5},{'$set': {'lin.0': 'å‘µå‘µ' }) # lin.0ä»£è¡¨æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´  å½“æ•°ç»„çš„ç´¢å¼•è¶Šç•Œï¼Œè¿™ä¸ªæ—¶å€™å°±è§†ä¸ºæ•°ç»„çš„æ·»åŠ æ“ä½œã€‚ eg: å‡å®šæˆ‘ä»¬ç»™ lin.10 ä¸€ä¸ªå€¼ï¼Œé‚£ä¹ˆ ä¸­é—´ç©ºå‡ºçš„é‚£ä¹ˆå¤šç´¢å¼•ï¼Œä¼šè‡ªåŠ¨å¡«å…… null $unset(åˆ é™¤) æ³¨ï¼šåˆ é™¤çš„é”®å¯¹åº”çš„valueå¯ä»¥éšä¾¿å†™ï¼Œå†™å•¥éƒ½ä¼šåˆ é™¤ï¼Œ å†™ '' åªæ˜¯ä¸ºäº†è¯­ä¹‰æ˜ç¡®ï¼ˆè§„èŒƒï¼‰ M: table.update({'6':6}, {'$unset': {'6':''}}) # æŠŠæ­¤æ¡è®°å½•çš„ '6' å­—æ®µåˆ é™¤ P: åŒä¸Š å¾®æ‰©å±•(å…³äºåµŒå¥—æ•°ç»„)ï¼š table.update({'5':5}, {'$unset': {'lin.0':''}}) # lin.0åŒæ ·ä»£è¡¨æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´  æ³¨ï¼šæ•°ç»„çš„åˆ é™¤ å¹¶ä¸æ˜¯çœŸæ­£çš„åˆ é™¤ï¼Œ è€Œæ˜¯æŠŠå€¼ ç”¨ null æ›¿æ¢ $rename(æ”¹åï¼Œæ›¿æ¢) M: table.update({'name':'lin'}, {'rename&#039;:{&#039;name&#039;:&#039;nick&#039;}}) # nameå˜æˆäº†nick P: åŒä¸Š å¾®æ‰©å±•ï¼ˆæ–‡æ¡£åµŒå¥—ï¼‰ï¼š å¦‚æœæ–‡æ¡£æ˜¯åµŒå¥—çš„ eg: { a: {b:c} } M: table.update({&#039;lin&#039;:&#039;lin&#039;}, {&#039;rename': {'a.b':'d'}}) P: åŒä¸Š ç»“æœ =&gt; {&quot;a&quot; : { }, &quot;d&quot; : &quot;c&quot; } è§£æï¼š b å±äº å­æ–‡æ¡£ a.b è¡¨ç¤º é€šè¿‡çˆ¶æ–‡æ¡£çš„a æ¥å–å‡º å­æ–‡æ¡£çš„b å¦‚æœæ•´ä½“a.bè¢« renameä¸º dï¼Œé‚£ä¹ˆ dä¼šè¢«å®‰æ’åˆ°çˆ¶æ–‡æ¡£çš„å±‚çº§é‡Œï¼Œè€Œaè®¾ä¸ºç©ºã€‚ ä¸¾ä¸ªæ —å­ï¼š ä½ æœ‰ä¸€ä¸ªç®±å­ï¼Œé‡Œé¢ æœ‰ä¸€ä¸ª å„¿å­çº§åˆ« å’Œ å­™å­çº§åˆ« çš„ç®±å­ ï¼ˆå…±3å±‚ï¼‰ ç°åœ¨ä½ æŠŠ å­™å­çº§åˆ«çš„ç®±å­ å•ç‹¬æ‹¿å‡ºæ¥ï¼Œ æŠŠæ•´ä¸ªç®±å­æ›¿æ¢æ‰ å°±æ˜¯è¿™ç§æ€æƒ³ã€‚ã€‚ã€‚è‡ªå·±ä½“ä¼šå§ ï¼ˆè¿™ç§è¯­æ³•ï¼Œå¥½åƒPythonåˆ—è¡¨çš„åˆ‡ç‰‡èµ‹å€¼ã€‚ã€‚å½¢å®¹å¯èƒ½ä¸å¤ªæ°å½“ï¼‰ $incï¼š {$inc: { 'age': -2}} # å‡å°‘ä¸¤å²ï¼Œæ­£æ•°è¡¨ç¤ºåŠ æ³•ï¼Œè´Ÿæ•°è¡¨ç¤ºå‡æ³•ï¼Œç®€å•ï¼Œä¸ä¸¾ä¾‹äº† ç‰¹ä¾‹ï¼šå¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œé‚£ä¹ˆï¼Œæ­¤å­—æ®µä¼šè¢«æ·»åŠ ï¼Œ å¹¶ä¸”å€¼å°±æ˜¯ä½ è®¾å®šçš„å€¼(0+n=n) $mul: {$mul: { 'age': 0.5}} # å¹´é¾„é™¤ä»¥2ï¼Œæ•´æ•°è¡¨ç¤ºä¹˜æ³•ï¼Œå°æ•°è¡¨ç¤ºé™¤æ³•ï¼Œç®€å•ï¼Œä¸ä¸¾ä¾‹äº† ç‰¹ä¾‹ï¼šå¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œé‚£ä¹ˆï¼Œæ­¤å­—æ®µä¼šè¢«æ·»åŠ ï¼Œ å¹¶ä¸”å€¼ä¸º0 (0*n=0) $min {$min: { 'age': 30}} # 30æ¯”åŸæœ‰å€¼å°ï¼šå°±æ›¿æ¢ï¼Œ 30æ¯”åŸæœ‰å€¼å¤§ï¼Œåˆ™ä¸åšä»»ä½•æ“ä½œ $max {$max: { 'age': 30}} # 30æ¯”åŸæœ‰å€¼å¤§ï¼šå°±æ›¿æ¢ï¼Œ 30æ¯”åŸæœ‰å€¼å°ï¼Œåˆ™ä¸åšä»»ä½•æ“ä½œ ç‰¹ä¾‹ï¼šminå’Œmaxç‰¹ä¾‹ç›¸åŒï¼Œå³å¦‚æœå­—æ®µä¸å­˜åœ¨ï¼Œé‚£ä¹ˆï¼Œæ­¤å­—æ®µä¼šè¢«æ·»åŠ ï¼Œ å¹¶ä¸”å€¼å°±æ˜¯ä½ è®¾å®šçš„å€¼ æ•°ç»„æ›´æ–°æ“ä½œç¬¦ï¼š &quot;&quot;&quot; å•æ•°ç»„: xx å†…åµŒæ•°ç»„: xx.ç´¢å¼• &quot;&quot;&quot; $addToSetï¼ˆæœ‰åºï¼Œæ— é‡å¤ï¼Œå°¾éƒ¨æ·»åŠ ï¼‰ åŸå§‹æ•°æ®ï¼š {'1':1} M: table.update({'1':1}, {'$addToSet':{'lin':[7,8]}}) P: åŒä¸Š ç»“æœ =&gt; {&quot;1&quot;: 1,&quot;lin&quot;: [ [7, 8 ] ]} # [7,8] æ•´ä½“æ’å…¥è¿›æ¥ï¼Œ ç‰¹åˆ«æ³¨æ„è¿™æ˜¯äºŒçº§åˆ—è¡¨ $each ( ç»™[7,8]åŠ ä¸ª $eachï¼Œæ³¨æ„çœ‹ç»“æœå˜åŒ– ) M: table.update({'1': 1}, {'addToSet&#039;: {&#039;lin&#039;: {&#039;each':[7, 8]} }}) P: åŒä¸Š ç»“æœ =&gt; {&quot;1&quot;: 1, &quot;lin&quot;: [7,8]} # 7,8å•ç‹¬æ’å…¥è¿›æ¥ï¼Œå‚è€ƒpythonçš„ * è§£æ„ push(æ•°æ®æ·»åŠ ï¼Œæ¯”push(æ•°æ®æ·»åŠ ï¼Œ æ¯”push(æ•°æ®æ·»åŠ ï¼Œæ¯”addToSetå¼ºå¤§ï¼Œå¯ä»»æ„ä½ç½®,å¯é‡å¤) &quot;&quot;&quot; è¡¥å……è¯´æ˜: $addToSet:æ·»åŠ æ•°æ®æœ‰é‡å¤ï¼Œä¼šè‡ªåŠ¨å»é‡ $push :æ·»åŠ æ•°æ®æœ‰é‡å¤ï¼Œä¸ä¼šå»é‡ï¼Œè€Œæ˜¯ç›´æ¥è¿½åŠ  &quot;&quot;&quot; åŸå§‹æ•°æ®: {'1':1} M: table.update( { '1': 1 }, { 'push&#039;: { &#039;lin&#039;: { &#039;each': [ {'a': 5, 'b': 8 }, { 'a': 6, 'b': 7 }, {'a': 7, 'b': 6 } ], 'sortâ€²:â€²aâ€²:âˆ’1,â€²sort&#x27;: { &#x27;a&#x27;: -1 }, &#x27;sortâ€²:â€²aâ€²:âˆ’1,â€²position': 0, '$slice': 2 }}}) # è¿™é‡Œä¸ºäº†æ¸…æ™°ç‚¹ï¼Œæˆ‘å°±æŠŠæ‰€æœ‰æ‹¬å·æŠ˜å èµ·æ¥äº† P: åŒä¸Š ç»“æœ =&gt; {&quot;1&quot; : 1, &quot;lin&quot; : [ { &quot;a&quot; : 7, &quot;b&quot; : 6 }, { &quot;a&quot; : 6, &quot;b&quot; : 7 } ] } ç»ˆæè§£æï¼š 1. æ·»åŠ æ•°ç»„ï¼š å…ˆèµ° $sort =&gt; æ ¹æ®a é€†åºæ’åˆ— 2. å†èµ° $position, 0è¡¨ç¤ºï¼šç´¢å¼•å®šä½ä»0å¼€å§‹ 3. å†èµ° $slice, 2è¡¨ç¤ºï¼š å–2ä¸ª 4. æœ€åèµ° $each,æŠŠæ•°ç»„å…ƒç´ é€ä¸ªæ”¾è¿›å¦ä¸€ä¸ªæ•°ç»„ï¼Œè¯´è¿‡çš„ï¼Œç›¸å½“äºpythonçš„ * è§£æ„æ“ä½œï¼Œ $popï¼ˆåªèƒ½ åˆ é™¤ å¤´æˆ–å°¾ å…ƒç´ ï¼‰ M: table.update({'a': a}, {'$pop': {'lin': 1}}) # åˆ é™¤æœ€åä¸€ä¸ª P: åŒä¸Š æ³¨1ï¼š$popå‚æ•°ï¼Œ 1ä»£è¡¨æœ€åä¸€ä¸ªï¼Œ -1ä»£è¡¨ç¬¬ä¸€ä¸ªã€‚ è¿™ä¸ªæ˜¯å€¼å¾—æ³¨æ„ä¸€ä¸‹çš„ï¼Œå®¹æ˜“è®°å æ³¨2ï¼šå¦‚æœå…¨éƒ¨åˆ æ²¡äº†ï¼Œé‚£ä¹ˆä¼šå‰©ä¸‹ç©º[]ï¼Œ è€Œä¸æ˜¯å½»åº•åˆ é™¤å­—æ®µ $pull (åˆ é™¤ ä»»ä½•ä½ç½® çš„ æŒ‡å®šçš„å…ƒç´ ) M: table.update({'1': 1},{'$pull':{ 'lin':[7,8]}}) # åˆ é™¤æ•°ç»„ä¸­[7,8]è¿™ä¸ªå†…åµŒæ•°ç»„ P: åŒä¸Š $pullAll(åŸºæœ¬å’Œ $pull ä¸€è‡´) M: table.update({'1': 1},{'pullAll&#039;:{ &#039;lin&#039;:[ [7,8] ]}}) # åŒpullï¼Œä½†å¤šäº†ä¸ª [] P: åŒä¸Š æ³¨ï¼š $pull å’Œ $pullAll é’ˆå¯¹äº å†…åµŒæ–‡æ¡£ å’Œ å†…åµŒæ•°ç»„ æœ‰ç»†å°å·®åˆ«ï¼Œ å·®åˆ«å¦‚ä¸‹ï¼š å†…åµŒæ•°ç»„ï¼š $pull å’Œ $pullAll éƒ½ä¸¥æ ¼è¦æ±‚å†…åµŒæ•°ç»„çš„ æ’åˆ—é¡ºåºï¼Œé¡ºåºä¸ä¸€è‡´ï¼Œåˆ™ä¸è¿”å› å†…åµŒæ–‡æ¡£: $pullAll : ä¸¥æ ¼è¦æ±‚å†…åµŒæ–‡æ¡£çš„é¡ºåºï¼Œ é¡ºåºä¸ä¸€è‡´ï¼Œåˆ™ ä¸è¿”å› $pull : ä¸è¦æ±‚å†…åµŒæ–‡æ¡£çš„å¾ªåºï¼Œ é¡ºåºä¸ä¸€è‡´ï¼Œä¸€æ ·å¯ä»¥è¿”å› æŸ¥ &quot;&quot;&quot; ç¬¬ä¸€ä¸ªå‚æ•°çš„æ¡ä»¶æ˜¯ ç­›é€‰å‡º æ•°æ®çš„è®°å½•ï¼ˆæ–‡æ¡£ï¼‰ ç¬¬äºŒä¸ªå‚æ•°çš„æ¡ä»¶æ˜¯ ç­›é€‰å‡º æ•°æ®çš„è®°å½•ä¸­çš„ å±æ€§ï¼ˆå­—æ®µï¼‰ï¼Œä¸é…ç½® å°±æ˜¯ é»˜è®¤ å–å‡ºæ‰€æœ‰å­—æ®µ find({æŸ¥è¯¢æ¡ä»¶}, {æŠ•å½±è®¾ç½®}) &quot;&quot;&quot; æŠ•å½±è§£é‡Š å“ªä¸ªå­—æ®µ è®¾ç½®ä¸º 0ï¼Œ æ­¤å­—æ®µå°±ä¸ä¼šè¢«æŠ•å½±ï¼Œ è€Œå…¶ä»–å­—æ®µå…¨éƒ¨è¢«æŠ•å½± å“ªä¸ªå­—æ®µ è®¾ç½®ä¸º 1ï¼Œ æ­¤å­—æ®µå°±ä¼šè¢«å•ç‹¬æŠ•å½±ï¼Œ å…¶ä»–å­—æ®µä¸æŠ•å½± {'name': 0, 'age': 0} # é™¤äº† name å’Œ age ï¼Œå…¶ä»–å­—æ®µ éƒ½ æŠ•å½± {'name': 1, 'age': 1} # åªæŠ•å½± name å’Œ age, å…¶ä»–å­—æ®µ ä¸ æŠ•å½±ï¼Œï¼ˆ_idé™¤å¤–ï¼‰ æ³¨æ„:æ‰€æœ‰å­—æ®µå¿…é¡»æ»¡è¶³å¦‚ä¸‹è¦æ±‚ï¼š ä¸€ï¼š ä½ å¯ä»¥ä¸è®¾ç½®ï¼Œé»˜è®¤éƒ½ä¼šè¢«æŠ•å½± äºŒï¼š å¦‚æœä½ è®¾ç½®äº†ï¼Œå°±å¿…é¡»åŒä¸º0ï¼Œæˆ–è€…åŒä¸º1,ä¸å…è®¸0ï¼Œ1 æ··åˆè®¾ç½®(_idé™¤å¤–) ä¸‰ï¼š _idè™½ç„¶å¯ä»¥å‚ä¸æ··åˆè®¾ç½®ï¼Œä½†æ˜¯å®ƒåªå¯ä»¥è®¾ä¸º0ï¼Œ ä¸å¯ä»¥è®¾ä¸º1ï¼Œå› ä¸º1æ˜¯å®ƒé»˜è®¤çš„ é€šä¿—ç†è§£ï¼ˆ0å’Œ1çš„è®¾å®šï¼‰ï¼šå¦ä¸€ç§ç†è§£æ€æƒ³ ====&gt; è®¾ç½®ä¸º1ï¼š å°±æ˜¯ åŠ å…¥ ç™½åå• æœºåˆ¶ è®¾ç½®ä¸º0ï¼Œ å°±æ˜¯ åŠ å…¥ é»‘åå• æœºåˆ¶ æ³¨ï¼š _idå­—æ®µæ˜¯ MongoDBçš„é»˜è®¤å­—æ®µï¼Œå®ƒæ˜¯ä¼šä¸€ç›´è¢«æŠ•å½±çš„(é»˜è®¤ç™½åå•) ä½†æ˜¯ï¼Œå½“ä½ å¼ºåˆ¶æŒ‡å®š {'_id': 0} ï¼Œå¼ºåˆ¶æŠŠ _idæŒ‡å®šä¸º0ï¼Œä»–å°±ä¸ä¼šè¢«æŠ•å½±äº†ï¼ˆå˜ä¸ºé»‘åå•ï¼‰ è¯­æ³•ï¼š M: queryset = table.find({}, {'name': 0}) P: åŒä¸Š æŠ•å½±-æ•°ç»„åˆ‡ç‰‡($slice) &quot;&quot;&quot;é’ˆå¯¹æŠ•å½±æ—¶çš„valueä¸ºæ•°ç»„çš„æƒ…å†µä¸‹ï¼Œå¯¹æ­¤æ•°ç»„åˆ‡ç‰‡ï¼Œç„¶åå†æŠ•å½±&quot;&quot;&quot; æ•°æ®æ¡ä»¶ï¼š {'arr1': [5,6,7,8,9] } æ•´å½¢å‚æ•°ï¼š M: queryset = table.find({},{'arr1':{'$slice': 2}}) # 2è¡¨ç¤ºå‰2ä¸ª, -2è¡¨ç¤ºåä¸¤ä¸ª P: åŒä¸Šï¼Œä¸€æ¨¡ä¸€æ ·ï¼Œä¸€å­—ä¸å·® ç»“æœ: { 'arr1': [5,6] } æ•°ç»„å‚æ•°ï¼š [skip, limit] M: queryset = table.find({},{'arr1':{'$slice': [2,3]}}) # è·³è¿‡å‰2ä¸ªï¼Œå–3ä¸ª P: åŒä¸Šï¼Œä¸€æ¨¡ä¸€æ ·ï¼Œä¸€å­—ä¸å·® è¾“å‡ºç»“æœ =&gt; { 'arr1': {7,8,9] } æ³¨ï¼š è¿™ç§æ•°ç»„å‚æ•°ï¼Œä½ å¯ä»¥ç”¨ skip+limit æ–¹å¼ç†è§£ ä¹Ÿå¯ä»¥ç”¨, pythonçš„ç´¢å¼•+åˆ‡ç‰‡æ–¹å¼ç†è§£ ï¼ˆskipå¼€å§‹æŸ¥ç´¢å¼•ï¼ˆ0å¼€å§‹æ•°ï¼‰, ç„¶åå–limitä¸ªï¼‰ æŠ•å½±-æ•°ç»„è¿‡æ»¤($elemMatch) &quot;&quot;&quot; é’ˆå¯¹æŠ•å½±æ—¶ çš„valueä¸ºæ•°ç»„çš„æƒ…å†µä¸‹ï¼Œæ ¹æ®æŒ‡å®šæ¡ä»¶ å¯¹ æ•°ç»„ è¿‡æ»¤ï¼Œç„¶åå†æŠ•å½± æ³¨æ„è¿™ä¸ªè¿‡æ»¤æœºåˆ¶ï¼š ä»å‰å‘åæ‰¾ï¼Œé‡åˆ°ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„å°±ç«‹åˆ»æŠ•å½±(ç±»ä¼¼ pythonæ­£åˆ™çš„ search) &quot;&quot;&quot; æ•°æ®æ¡ä»¶: {'arr1': [6,7,8,9]} M: queryset = table.find({}, {'arr1': {'$elemMatch': {'$gt':5}} }) P: åŒä¸Š è¾“å‡ºç»“æœ =&gt; &quot;arr1&quot; : [ 6 ] è§£æï¼šï¼ˆæˆ‘è‡ªå·±æ€»ç»“çš„ä¼ªæµç¨‹ï¼Œå¯å‚è€ƒç†è§£ï¼‰ 1. å‡†å¤‡æŠ•å½± 2. å‘ç°æ•°ç»„ï¼Œå…ˆå¤„ç†æ•°ç»„ï¼Œå¯çœ‹åˆ°æ•°ç»„ä¸­æœ‰ elemMatchæ¡ä»¶ elemMatchåœ¨æŠ•å½±ä¸­å®šä¹‰ä¸ºï¼š â€ä½ ç»™æˆ‘ä¸€ä¸ªæ¡ä»¶ï¼Œæˆ‘æŠŠç¬¦åˆæ¡ä»¶çš„ æ•°ç»„æ¯ä¸ªå…ƒç´ ä»å‰å‘åç­›é€‰ é‡åˆ°ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„å°±è¿”å›, å‰©ä¸‹çš„éƒ½æ‰”æ‰ ï¼ˆè¿™é‡Œçš„è¿”å›ä½ å¯ä»¥ç†è§£ä¸º returnï¼‰ â€œ 3. æŠŠ 2 æ­¥éª¤ è¿”å›çš„æ•°æ® æŠ•å½± limit() limit: ï¼ˆåªå–å‰næ¡ï¼‰ M: queryset = table.find({'name':'lin'}).limit(n) # nå°±æ˜¯å–çš„æ¡æ•° P: åŒä¸Š skip() skip: ï¼ˆè·³è¿‡næ¡ï¼Œä»ç¬¬n+1æ¡å¼€å§‹å–ï¼‰ M: queryset = table.find({'name':'lin'}).skip(n) # ä»0å¼€å§‹æ•° P: åŒä¸Š è§£é‡Šä¸€ä¸‹skipè¿™ä¸ªå‚æ•°nï¼š å‡å¦‚nç­‰äº2 ï¼Œå°±æ˜¯ä»ç¬¬ä¸‰ä¸ªï¼ˆçœŸå®ä¸ªæ•°ï¼‰å¼€å§‹å– =&gt; ä½ å¯ä»¥å€Ÿé‰´æ•°ç»„ç´¢å¼•çš„æ€æƒ³ a[2] count() count: ï¼ˆç»Ÿè®¡è®°å½•æ•°ï¼‰ M: count_num = table.find({'name':'lin'}).skip(1).limit(1).count() P: count_num = table.count_documents(filter={'name':'lin'}, skip=1, limit=1) åˆ†æï¼š find() -&gt; æŸ¥å‡º 3 æ¡æ•°æ® skip(1) -&gt; è·³è¿‡ä¸€æ¡ï¼Œå°±æ˜¯ä»ç¬¬äºŒæ¡å¼€å§‹å– limit(1) -&gt; æ¥ç€ä¸Šé¢çš„æ¥ï¼Œä»ç¬¬äºŒæ¡å¼€å§‹å–ï¼ˆç®—æœ¬èº«å“¦ï¼‰ï¼Œå–ä¸€ä¸ªï¼Œå®é™…ä¸Šå–çš„å°±æ˜¯ç¬¬äºŒæ¡ count() -&gt; 3 # ä¹Ÿè®¸ä½ å¾ˆæƒŠè®¶ï¼ŒæŒ‰å¸¸ç†æ¥è¯´ï¼Œç»“æœåº”è¯¥ä¸º 1(çœ‹ä¸‹é¢) count(applySkipLimit=false) # è¿™æ˜¯ APIåŸå‹ï¼Œè¿™ä¸ªå‚æ•°é»˜è®¤ä¸ºFalse applySkipLimit: çœ‹åå­—ä½ å°±çŸ¥é“è¿™å‡½æ•°ä½œç”¨äº†å§ é»˜è®¤ä¸å†™ä¸º False: ä¸åº”ç”¨(å¿½ç•¥) skip(), limit() æ¥ç»Ÿè®¡ç»“æœ ==&gt; ä¸Šä¾‹ç»“æœä¸º 3 è®¾ä¸º Trueï¼š ç»“åˆ skip(), limit() æ¥ç»Ÿè®¡æœ€ç»ˆç»“æœ ==&gt; ä¸Šä¾‹ç»“æœä¸º 1 æ³¨ï¼š å¯¹äº count() ï¼ŒMongo å’Œ PyMongoéƒ½æœ‰æ­¤æ–¹æ³•ï¼Œä¸”ç”¨æ³•æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚ é‚£ä¸ºä»€ä¹ˆä¸Šé¢PyMongoä¸­æˆ‘å´ç”¨äº† count_documents() è€Œä¸æ˜¯ count() ????? ç­”ï¼š å› ä¸º è¿è¡Œ æˆ–è€…å æˆ³è¿›PyMongoæºç å¯æ¸…æ™°çœ‹è§ï¼Œæœªæ¥ç‰ˆæœ¬ count() APIå°†è¦åºŸé™¤ã€‚ å®˜æ–¹å»ºè®®æˆ‘ä»¬ç”¨ count_documents() å®ƒçš„å¥½å¤„æ˜¯æŠŠ skip() å’Œ limit() ç”±ä¸¤ä¸ªå‡½æ•°è°ƒç”¨ å˜ä¸º 2ä¸ªå‚æ•°ä¼ è¿›å»äº†ã€‚ sort() sort: æ’åº M: queryset = table.find({'name':'lin'}).sort({'_id': -1}) # æ³¨æ„ï¼Œå‚æ•°æ˜¯{} å¯¹è±¡ P: queryset = table.find({'name':'lin'}).sort( '_id', -1 ) # æ³¨æ„ï¼Œè¿™æ˜¯2ä¸ªå‚æ•° ç¬¬ä¸€ä¸ªå‚æ•°ï¼Œä»£è¡¨ æ’åºä¾æ®çš„å­—æ®µå±æ€§ ç¬¬äºŒä¸ªå‚æ•°ï¼Œä»£è¡¨ å‡/é™ 1 : å‡åº eg: 456 -1: é™åº eg: 654 ç‰¹åˆ«æ³¨æ„ï¼š 3è¿æ‹›é¡ºåºï¼ˆä¼˜å…ˆçº§è¦ç‰¢è®°ï¼‰ () sort -&gt; skip -&gt; limit ï¼ˆæ’åº - å®šä½ - æŒ‘é€‰ï¼‰ æ— è®ºä½ ä»£ç ä»€ä¹ˆé¡ºåºï¼Œå®ƒéƒ½ä¼šè¿™ä¸ªé¡ºåºæ‰§è¡Œ eg: queryset = table.find({'name': 'lin'}).sort('_id', -1).skip(1).limit(1) ä¹Ÿè®¸ä½ ä¼šæœ‰è¿™æ ·ä¸€ä¸ªç–‘æƒ‘ï¼š ä¸ºä»€ä¹ˆ count_documents æ²¡æœ‰æ”¾è¿›è¿æ‹›é‡Œé¢ï¼Ÿ ç­”ï¼š ä½ ä»”ç»†æƒ³æƒ³ï¼Œ ç»Ÿè®¡ä¸ªæ•°ï¼Œå’Œä½ æ’ä¸æ’åºæœ‰å…³ç³»å—ï¼Ÿ æ²¡é”™ï¼Œä¸€ç‚¹å…³ç³»éƒ½æ²¡æœ‰ã€‚ã€‚ã€‚ sort() å’Œ count() æ²¡æœ‰è”ç³» æ•°ç»„æ“ä½œç¬¦ å·²æœ‰æ•°æ®æ¡ä»¶ï¼š { name: ['å¼ ','æ','ç‹'] } $all: M: queryset = table.find({'name': {'$all': ['å¼ ','æ']}}) # æ•°ç»„å€¼é‡Œå¿…é¡»åŒ…å« å¼ å’Œæ Pï¼šåŒä¸Šï¼Œä¸€æ¨¡ä¸€æ ·ï¼Œä¸€å­—ä¸å·® $elemMatchï¼š M: queryset = table.find({'name': {'$elemMatch': {'$eq':'å¼ '} }}) # æ•°ç»„å€¼æœ‰å¼  å°±è¡Œ P: åŒä¸Šï¼Œä¸€æ¨¡ä¸€æ ·ï¼Œä¸€å­—ä¸å·® æ­£åˆ™ M: db.xx.find( {name: { $regex: /^a/, $options:'i' }} ) P: queryset = db.xx.find({'name': {'$regex': 'LIN', '$options': 'i'}}) PyMongoç‰ˆçš„æˆ–è€…è¿™æ ·å†™-&gt; import re e1 = re.compile(r'LIN', re.I) # æŠŠPythonçš„æ­£åˆ™å¯¹è±¡ ä»£æ›¿ Mongoè¯­å¥ queryset = db.xx.find({'name': {'$regex': re1 }}) èšåˆ èšåˆè¡¨è¾¾å¼ å­—æ®µè·¯å¾„è¡¨è¾¾å¼ï¼š $name # å…·ä½“å­—æ®µ ç³»ç»Ÿå˜é‡è¡¨è¾¾å¼ï¼š $$CURRENT # è¡¨ç¤ºç®¡é“ä¸­ï¼Œå½“å‰æ“ä½œçš„æ–‡æ¡£ åè½¬ä¹‰è¡¨è¾¾å¼ï¼š $literal: '$name' # æ­¤å¤„ $name åŸè¯­æ³•è¢«ç ´åï¼Œç°åœ¨å®ƒåªæ˜¯å•çº¯çš„å­—ç¬¦ä¸² èšåˆç®¡é“ &quot;&quot;&quot; å•ä¸ªç®¡é“ï¼Œå°±åƒ Pythonä¸­çš„ mapç­‰é«˜é˜¶å‡½æ•°åŸç†ï¼Œ åˆ†è€Œæ²»ä¹‹ã€‚ åªä¸è¿‡ï¼ŒMongoDBå–„äºå°†ç®¡é“ä¸²è”è€Œå·²ã€‚ .aggregate([ é‡Œé¢å†™ç®¡é“å„ç§æ“ä½œ ]) &quot;&quot;&quot; $matchï¼ˆç®¡é“æŸ¥è¯¢ï¼‰ M: queryset = table.aggregate([{'$match': {'name': 'zhangsan'}}]) P: åŒä¸Š $project(ç®¡é“æŠ•å½±) æ•°æ®æ¡ä»¶ =&gt; [ {&quot;id&quot;:'xxx', &quot;name&quot; : &quot;zhangsan&quot;, &quot;age&quot; : 15 }, {&quot;id&quot;:'xxx', &quot;name&quot; : &quot;lisi&quot;, &quot;age&quot; : 18 }, {&quot;id&quot;:'xxx', &quot;name&quot; : &quot;wangwu&quot;, &quot;age&quot; : 16 } ] M: queryset = table.aggregate([{'$project': {'_id': 0,'new':'5'}}]) P: åŒä¸Š ç»“æœ =&gt; [{'new': '5'}, {'new': '5'}, {'new': '5'}] æ³¨ï¼š'new'æ˜¯åœ¨æŠ•å½±çš„æ—¶å€™æ–°åŠ çš„ï¼Œä¼šè¢«æŠ•å½±ã€‚ä½†æ˜¯åŠ äº†æ­¤æ–°å€¼ï¼Œé™¤äº†_idï¼Œå…¶ä»–å±æ€§é»˜è®¤éƒ½ä¸ä¼šè¢«æŠ•å½±äº† $skip (ç®¡é“è·³è¿‡ï¼ŒåŸç†åŒå‰é¢è®²è¿‡skip() ç•¥) $limitï¼ˆç®¡é“æˆªå–ï¼ŒåŸç†åŒå‰é¢è®²è¿‡çš„limit() ï¼‰ M: queryset = table.aggregate([{'$skip': 1},{'$limit':1}]) P: åŒä¸Š è§£é‡Šï¼š ä¸€å…±ä¸‰æ¡æ–‡æ¡£ï¼Œ skipè·³è¿‡äº†ç¬¬ä¸€æ¡ï¼Œä»ç¬¬äºŒæ¡å¼€å§‹å–ï¼Œlimitå–ä¸€æ¡ï¼Œæ‰€ä»¥æœ€ç»ˆå–çš„æ˜¯ç¬¬äºŒæ¡ $sort (ç®¡é“æ’åºï¼ŒåŒä¸Š,ä¸è§£é‡Š) M: queryset = table.aggregate([{'$sort':{'age':1}}]) P: åŒä¸Š $unwindï¼ˆç®¡é“å±•å¼€æ•°ç»„ï¼Œ ç›¸å½“äº æ•°å­¦çš„ åˆ†é…å¾‹ï¼‰ æ•°æ®æ¡ä»¶ =&gt; {&quot;name&quot; : &quot;Tom&quot;, &quot;hobby&quot; : [ &quot;sing&quot;, &quot;dance&quot; ]} pathå°å‚æ•°: M: table.aggregate([{'$unwind':{'path': '$hobby'}}]) # æ³¨æ„ pathæ˜¯è¯­æ³•å…³é”®è¯ P: åŒä¸Š ç»“æœ =&gt; { &quot;_id&quot; : xx, &quot;name&quot; : &quot;Tom&quot;, &quot;hobby&quot; : &quot;sing&quot; } { &quot;_id&quot; : xx, &quot;name&quot; : &quot;Tom&quot;, &quot;hobby&quot; : &quot;dance&quot; } å½¢è±¡ä¾‹å­ï¼š a * [b+c] =&gt; a*b + a*c includeArrayIndexå°å‚æ•°ï¼š M: queryset = table.aggregate([{'$unwind': { 'path':'$hobby', 'includeArrayIndex':'index' # å±•å¼€çš„åŒæ—¶ä¼šæ–°å¢indexå­—æ®µè®°å½•åŸç´¢å¼• }}]) P: åŒä¸Š ç»“æœ =&gt; {&quot;name&quot; : &quot;Tom&quot;, &quot;hobby&quot; : &quot;sing&quot;, &quot;index&quot; : NumberLong(0) } {&quot;name&quot; : &quot;Tom&quot;, &quot;hobby&quot; : &quot;dance&quot;, &quot;index&quot; : NumberLong(1) } æ³¨æ„ï¼š $unwind ä¸Šé¢æœ‰ä¸¤ç§ç‰¹æ®Šæƒ…å†µï¼š æƒ…å†µä¸€ï¼š æ–‡æ¡£ä¸­æ—  hobbyå­—æ®µ æˆ– hobbyå­—æ®µä¸º ç©ºæ•°ç»„[] é‚£ä¹ˆè¯¥æ–‡æ¡£ä¸å‚ä¸unwindå±•å¼€æ“ä½œï¼Œ è‡ªç„¶å°±ä¸ä¼šæ˜¾ç¤ºç»“æœã€‚ è‹¥æƒ³è®©è¿™ç§æ–‡æ¡£ä¹Ÿå‚ä¸ unwindå±•å¼€æ“ä½œ,é‚£ä¹ˆéœ€è¦è¿½åŠ å°å‚æ•° 'preserveNullAndEmptyArrays':true # ä¸ pathåŒçº§ä¹¦å†™ æœ€ç»ˆç»“æœï¼Œè¿™ç§å­—æ®µçš„æ–‡æ¡£ä¹Ÿä¼šè¢«å±•ç¤ºå‡ºæ¥ï¼Œå¹¶ä¸” indexä¼šè¢«èµ‹äºˆä¸€ä¸ª nullå€¼ æƒ…å†µäºŒï¼š æ–‡æ¡£ä¸­æœ‰ hobbyå­—æ®µï¼Œä½†æ˜¯è¯¥å­—æ®µçš„å€¼å¹¶ä¸æ˜¯æ•°ç»„ é‚£ä¹ˆè¯¥æ–‡æ¡£ ä¼š å‚ä¸ unwindå±•å¼€æ“ä½œï¼Œå¹¶ä¸”ä¼šæ˜¾ç¤ºå‡ºæ¥ï¼Œ åŒæ · index ä¼šè¢«èµ‹äºˆä¸€ä¸ª nullå€¼ $lookupï¼ˆä½¿ç”¨æ–¹å¼ä¸€ï¼‰ ä½¿ç”¨æ–¹å¼ï¼ˆä¸€ï¼‰ï¼šé›†åˆå…³è” ===&gt; æˆ‘çš„ç†è§£æ˜¯ï¼Œç›¸å½“äºå…³ç³»å‹æ•°æ®åº“çš„ å¤šè¡¨æŸ¥è¯¢æœºåˆ¶ é›†åˆ &lt;=&gt; è¡¨ ï¼Œ å¤šè¡¨æŸ¥è¯¢ &lt;=&gt; å¤šé›†åˆæŸ¥è¯¢ è‡ªèº«é›†åˆ ä¸ å¤–é›†åˆ æ ¹æ®æˆ‘ä»¬æŒ‡å®šçš„ å…³è”å­—æ®µ å…³è”åï¼Œ å¦‚æœ‰å…³è”ï¼Œ åˆ™æ–°å­—æ®µçš„å€¼ä¸º [å¤–é›†åˆçš„å…³è”æ–‡æ¡£ï¼Œ ã€‚ã€‚ã€‚]ï¼Œ æœ‰å‡ æ¡æ–‡æ¡£å…³è”ï¼Œè¿™ä¸ªæ•°ç»„å°±ä¼šæœ‰å‡ æ¡ åºŸè¯ä¸å¤šè¯´ï¼Œå…ˆé‡æ–°åˆ›å»ºä¸¤ä¸ªé›†åˆï¼š db.user.insertOne({'name':'çŒ«', 'country': ['China','USA']}) # ä¸€æ¡ db.country.insertMany([{'name':'China'}, {'name':'USA'}]) # ä¸¤æ¡ table = db.user # çœ‹å¥½ï¼Œæˆ‘èµ‹å€¼äº†ä¸€ä¸‹ï¼Œä¸‹é¢ç›´æ¥å†™tableå°±è¡Œäº† M: queryset = table.aggregate([{ '$lookup': { 'from': 'country', # éœ€è¦è¿æ¥çš„å¦å¤–ä¸€ä¸ªé›†åˆçš„åç§°ï¼ˆå¤–é›†åˆï¼‰ 'localField': 'country', # ï¼ˆä¸»é›†åˆï¼‰è¿æ¥çš„ ä¾æ® å­—æ®µ 'foreignField': 'name', # ï¼ˆå¤–é›†åˆï¼‰è¿æ¥çš„ ä¾æ® å­—æ®µ 'as': 'new_field' # æœ€ç»ˆå…³è”åæŸ¥è¯¢å‡ºæ¥çš„æ•°æ®ï¼Œç”Ÿæˆæ–°å­—æ®µï¼Œasç”¨æ¥èµ·å } }]) P: åŒä¸Š ç»“æœ =&gt; { &quot;_id&quot; : ObjectId(&quot;5d2a6f4dee909cc7dc316bf1&quot;), &quot;name&quot; : &quot;çŒ«&quot;, &quot;country&quot; : [ &quot;China&quot;, &quot;USA&quot; ], # è¿™è¡Œä¹‹å‰åº”è¯¥ä¸ç”¨è§£é‡Šï¼Œè¿™å°±æ˜¯ useré›†åˆæœ¬èº«çš„æ•°æ®ï¼Œæ²¡å˜ &quot;new_field&quot; : [ # è¿™è¡Œæ˜¯æ–°åŠ çš„å­—æ®µï¼Œåé¢è§£é‡Š { &quot;_id&quot; : ObjectId(&quot;5d2a6fcbee909cc7dc316bf2&quot;), &quot;name&quot; : &quot;China&quot; }, { &quot;_id&quot; : ObjectId(&quot;5d2a6fcbee909cc7dc316bf3&quot;), &quot;name&quot; : &quot;USA&quot; } ] } è§£é‡Šï¼š 1. new_fieldæ˜¯æˆ‘ä»¬æ–°æ·»åŠ çš„å­—æ®µ 2. å› ä¸ºuseré›†åˆå’Œcountryé›†åˆ æˆ‘ä»¬ç»™å‡ºäº†2ä¸ªä¾æ®å…³è”å­—æ®µ å¹¶ä¸”è¿™ä¸¤ä¸ªå…³è”å­—æ®µ 'China' å’Œ 'USA' çš„å€¼éƒ½ç›¸ç­‰ æ‰€ä»¥æœ€ç»ˆ useré›†åˆçš„new_fieldå­—æ®µä¸­ ä¼šæ·»åŠ  ä¸¤æ¡ countryé›†åˆçš„æ–‡æ¡£ åˆ° [] ä¸­ 3. å¦‚æœæ— å…³è”, é‚£ä¹ˆ new_fieldå­—æ®µä¸­çš„å€¼ ä¸º ç©º[] $lookupï¼ˆä½¿ç”¨æ–¹å¼äºŒï¼‰: ä½¿ç”¨æ–¹å¼äºŒï¼šä¸åšé›†åˆçš„å…³è”ï¼Œè€Œæ˜¯ç›´æ¥æŠŠï¼ˆå¤–é›†åˆï¼‰ç»è¿‡æ¡ä»¶ç­›é€‰ï¼Œä½œä¸ºæ–°å­—æ®µæ”¾åˆ°ï¼ˆä¸»é›†åˆï¼‰ä¸­ã€‚ M: queryset = table.aggregate([{ '$lookup': { 'from': 'country', # å¤–é›†åˆ 'let': {'coun': '$country'}, # ä½¿ï¼ˆä¸»é›†åˆï¼‰çš„å˜é‡ å¯ä»¥æ”¾åœ¨ï¼ˆå¤–é›†åˆï¼‰ä½¿ç”¨ 'pipeline': [{ # å¤–é›†åˆçš„ä¸“å±ç®¡é“ï¼Œé‡Œé¢åªå¯ä»¥ç”¨å¤–é›†åˆçš„å±æ€§ '$match': { # å› ä¸ºè®¾ç½®äº† letï¼Œæ‰€ä»¥è¿™é‡Œé¢å¯ä»¥ç”¨ä¸»é›†åˆå˜é‡ '$expr': { # $exprä½¿å¾—$matché‡Œé¢å¯ä»¥ä½¿ç”¨ èšåˆæ“ä½œ '$and': [ {'$eq': ['$name', 'China']}, # æ³¨æ„ï¼Œè¿™æ˜¯èšåˆçš„ $eqç”¨æ³• {'$eq': ['$$coun',['China', 'USA']]} ] } } }], 'as': 'new_field' } }]) P: åŒä¸Š è§£é‡Šï¼š æŠŠï¼ˆå¤–é›†åˆï¼‰ pipelineé‡Œé¢æŒ‰å„ç§æ¡ä»¶ æŸ¥åˆ°çš„æ–‡æ¡£ï¼Œ ä½œä¸ºï¼ˆä¸»é›†åˆï¼‰new_field çš„å€¼ã€‚ å½“ç„¶ï¼Œå¦‚æœä¸éœ€è¦ä¸»é›†åˆä¸­çš„å±æ€§ï¼Œå¯ä»¥èˆå¼ƒ let å­—æ®µ $group ï¼ˆåˆ†ç»„--ç»Ÿè®¡ç§ç±»ï¼‰ ç”¨æ³•1ï¼ˆåˆ†ç»„--ç»Ÿè®¡å­—æ®µç§ç±»ï¼‰ M: queryset = table.aggregate([{'$group': {'_id': '$name'}}]) # _idæ˜¯å›ºå®šå†™æ³• P: åŒä¸Š ç»“æœ =&gt; [{'_id': 'è€é¼ '}, {'_id': 'ç‹—'}, {'_id': 'çŒ«'}] ç”¨æ³•2ï¼ˆåˆ†ç»„--èšåˆï¼‰ æ•°æ®æ¡ä»¶ï¼š { &quot;name&quot; : &quot;çŒ«&quot;, &quot;country&quot; : [ &quot;China&quot;, &quot;USA&quot; ], &quot;age&quot; : 18 } { &quot;name&quot; : &quot;ç‹—&quot;, &quot;country&quot; : &quot;Japna&quot; } { &quot;name&quot; : &quot;è€é¼ &quot;, &quot;country&quot; : &quot;Korea&quot;, &quot;age&quot; : 12 } { &quot;name&quot; : &quot;çŒ«&quot;, &quot;country&quot; : &quot;Japna&quot; } M: queryset = table.aggregate([{ '$group': { '_id': '$name', # æ ¹æ®nameå­—æ®µåˆ†ç»„ 'type_count': {'$sum': 1}, # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„ ä¸ªæ•° 'ageCount': {'$sum': '$age'}, # ç»Ÿè®¡ageå­—æ®µçš„ æ•°å­—å’Œ 'ageAvg': {'$avg': '$age'}, # ç»Ÿè®¡ageå­—æ®µçš„ å¹³å‡å€¼ 'ageMin': {'$min': '$age'}, # ç»Ÿè®¡ageå­—æ®µçš„ æœ€å°å€¼ 'ageMax': {'$max': '$age'}, # ç»Ÿè®¡ageå­—æ®µçš„ æœ€å¤§å€¼ } }]) p: åŒä¸Š ç»“æœ: { &quot;_id&quot; : &quot;è€é¼ &quot;, &quot;type_count&quot; : 1, &quot;ageCount&quot; : 12, &quot;ageAvg&quot; : 12, &quot;ageMin&quot; : 12, &quot;ageMax&quot; : 12 } { &quot;_id&quot; : &quot;ç‹—&quot;, &quot;type_count&quot; : 1, &quot;ageCount&quot; : 0, &quot;ageAvg&quot; : null, &quot;ageMin&quot; : null, &quot;ageMax&quot; : null } { &quot;_id&quot; : &quot;çŒ«&quot;, &quot;type_count&quot; : 2, &quot;ageCount&quot; : 18, &quot;ageAvg&quot; : 18, &quot;ageMin&quot; : 18, &quot;ageMax&quot; : 18 } æ³¨æ„ï¼š è‹¥æƒ³ç›´æ¥å¯¹æ•´ä¸ªé›†åˆçš„ åšç»Ÿè®¡ï¼Œè€Œä¸æ˜¯åˆ†ç»„å†ç»Ÿè®¡ æŠŠ _idæ”¹ä¸º nullå³å¯ { _id: 'null' } # (æˆ–è€…éšä¾¿å†™ä¸€ä¸ªåŒ¹é…ä¸åˆ°çš„ å­—ç¬¦ä¸²æˆ–æ•°å­—éƒ½è¡Œï¼Œåˆ†ä¸äº†ç»„ï¼Œå°±è‡ªåŠ¨ç»™ä½ ç»Ÿè®¡æ•´ä¸ªé›†åˆäº†) $out (èšåˆæ“ä½œåï¼Œå°†ç»“æœå†™å…¥æ–°é›†åˆ) &quot;&quot;&quot; æˆ‘çš„ç†è§£æ˜¯é‡å®šå‘ æ“ä½œï¼Œ æˆ–è€…ç†è§£ä¸º è§†å›¾ æ“ä½œ å†™å…¥çš„é›†åˆå¦‚æœå­˜åœ¨ï¼Œé‚£ä¹ˆä¼šå…¨éƒ¨è¦†ç›–ï¼ˆä½†ä¿ç•™ç´¢å¼•ï¼‰ èšåˆè¿‡ç¨‹é‡åˆ°é”™è¯¯ï¼Œé‚£ä¹ˆä¼šè‡ªåŠ¨æ‰§è¡Œ â€™å›æ»šâ€™æ“ä½œ &quot;&quot;&quot; M: table.aggregate([ { '$group': {'_id': '$name'} }, { '$out': 'newCollection' } ]) P: åŒä¸Š æœ€åéªŒè¯ï¼š db.newCollection.find() ï¼Œä½ å°±ä¼šçœ‹åˆ°æ–°é›†åˆ åŠå…¶ é‡Œé¢çš„å†…å®¹ èšåˆç®¡é“ ==&gt; ç¬¬äºŒä¸ªå‚æ•° table.aggregate([ä¹‹å‰è¯´çš„éƒ½æ˜¯è¿™é‡Œé¢çš„å‚æ•°], ä¸‹é¢è¯´è¿™ä¸ªå‚æ•°) allowDiskUse: true æ¯ä¸ªèšåˆç®¡é“å ç”¨å†…å­˜éœ€ &lt; 16Mï¼Œ è¿‡å¤§å°±ä¼šå‡ºé—®é¢˜ allowDiskUseè®¾ç½®ä¸ºtrueï¼Œ ä¼šå°†å†…å­˜çš„ å†™å…¥åˆ°ä¸´æ—¶æ–‡ä»¶ä¸­ï¼Œå‡ç¼“å†…å­˜å‹åŠ›ã€‚ å®˜æ–¹æ–‡æ¡£ï¼šwrite data to the _tmp subdirectory in the dbPath directory Default: /data/db on Linux and macOS, \\data\\db on Windows å®ƒè¯´ï¼š é»˜è®¤åœ¨ dbPathé…ç½®å˜é‡ä¸‹çš„ å­ç›®å½•_tmpä¸‹ï¼Œ dbPathé»˜è®¤ä¸º : /data/db M: queryset = table.aggregate([{ '$group': {'_id': '$name'}}], {'allowDiskUse': true} ) P: queryset = table.aggregate([{ '$group': {'_id': '$name'}}], allowDiskUse=True, # æ³¨æ„ï¼Œè¿™é‡Œè¯­æ³•ç¨æœ‰ä¸ä¸€æ · ) ç´¢å¼• åˆ›å»ºç´¢å¼•ï¼š å•é”®ç´¢å¼• M: table.createIndex({'name':1}) P: table.create_index([('name',-1)]) # -1ä»£è¡¨é€†åºç´¢å¼•ï¼Œæ³¨æ„æ˜¯å…ƒç»„ è”åˆç´¢å¼• ç´¢å¼•å‘½ä¸­ï¼šæœ€å·¦åŒ¹é…åŸåˆ™ eg 1,2ï¼Œ3 è¿™ä¸‰ä¸ªåˆ›å»ºè”åˆç´¢å¼•ï¼Œ å¯å‘½ä¸­ç´¢å¼•ä¸ºï¼šã€1,12,123ã€‘ M: table.createIndex( {'name':1}, {}, {} ) # å¤šä¸ª{} P: table.create_index([ ('name',-1), (), () ]) # å¤šä¸ªå…ƒç»„ å¤šé”®ç´¢å¼• å¤šé”®æ˜¯é’ˆå¯¹äºæ•°ç»„æ¥è®²çš„ï¼Œåˆ›å»ºå•é”®çš„å­—æ®µ æŒ‡å®šä¸º æ•°ç»„å­—æ®µï¼Œ é»˜è®¤å°±ä¼šè®¾ç½®ä¸ºå¤šé”®ç´¢å¼• å”¯ä¸€ç´¢å¼• ï¼ˆuniqueï¼‰ '''æ³¨æ„ï¼š å¦‚æœé›†åˆä¸­ï¼Œä¸åŒæ–‡æ¡£çš„å­—æ®µæœ‰é‡å¤ï¼Œåˆ›å»ºå”¯ä¸€ç´¢å¼•çš„æ—¶å€™ä¼šæŠ¥é”™''' M: table.createIndex({'name':1}, {'unique':true}) P: table.create_index([('name', 1),('counrty',1)], unique=True) ç¨€ç–ç´¢å¼• (sparse) eg: ä¸€ä¸ªé›†åˆä¸­ï¼š ç»™ nameåˆ›å»º å”¯ä¸€ç´¢å¼• æ’å…¥æ–‡æ¡£1: æœ‰ nameå­—æ®µ æ’å…¥æ–‡æ¡£2: æ—  nameå­—æ®µ ï¼ˆMongoDBä¼šåœ¨ç´¢å¼•åº“ä¸­ï¼ŒæŠŠæ²¡æœ‰çš„å­—æ®µçš„ ç´¢å¼•è®¾ä¸º {å­—æ®µ:null} ï¼‰ å†æ’å…¥æ–‡æ¡£3, æ— nameå­—æ®µ --&gt; åŒæ ·ä¹Ÿä¼šæŠŠç´¢å¼•åº“ä¸­ nameè®¾ä¸º null ä½†æ˜¯å°±åœ¨è¿™ä¸ªæ—¶å€™ï¼Œåˆšè¦æŠŠç´¢å¼•åº“ä¸­çš„ nameå­—æ®µè®¾ä¸º nullçš„æ—¶å€™ã€‚ã€‚ã€‚ å”¯ä¸€ç´¢å¼•å‘Šè¯‰ä½ ï¼šâ€ æˆ‘è¿™é‡Œå·²ç»æœ‰äº†ä¸€ä¸ªï¼Œ{ name:null }ï¼Œè¯·ä½ æ»š â€ ç„¶åå°±æ— æƒ…çš„ç»™ä½ æŠ¥é”™äº†ï¼ˆé‡å¤ç´¢å¼•å­—æ®µï¼‰ é‚£å’‹æ•´å•Šï¼Œ åˆ«æ€¥ï¼Œç¨€ç–ç´¢å¼•å°±æ˜¯ç»™ä½ åŠè¿™äº‹çš„ è®¾ç½®ç¨€ç–ç´¢å¼•ã€‚ MongoDBå°±ä¸ä¼šæŠŠ æ²¡æœ‰çš„å­—æ®µ åŠ å…¥åˆ°ç´¢å¼•åº“äº† æ‰€ä»¥ï¼Œç´¢å¼•åº“é‡Œé¢å°±ä¸ä¼šè‡ªåŠ¨æ·»åŠ  {å­—æ®µ: null} é‡æ–°å†æ¬¡æ’å…¥æ–‡æ¡£3ï¼Œ æ— nameå­—æ®µï¼Œ å¯æˆåŠŸæ’å…¥ï¼Œä¸å­˜åœ¨nullçš„é‡å¤é—®é¢˜äº† M: table.createIndex({'name':1}, {'unique':true, 'sparse':true}) P: table.create_index([('name', 1),('counrty',1)], unique=True, sparse=True) æŸ¥è¯¢ç´¢å¼• Mï¼šqueryset = table.getIndexes() P: queryset = table.list_indexes() åˆ é™¤ç´¢å¼• æ–¹å¼1ï¼š M: table.dropIndex('ç´¢å¼•å') # ç´¢å¼•åå¯é€šè¿‡ ä¸Šé¢æŸ¥è¯¢ç´¢å¼•çš„æŒ‡ä»¤æŸ¥ P: table.drop_index('ç´¢å¼•å') æ–¹å¼2ï¼š M: table.dropIndexes() # åˆ é™¤å…¨éƒ¨ï¼Œ_idé™¤å¤–ï¼Œ æƒ³æŒ‡å®šåˆ é™¤å¤šä¸ªï¼Œå¯ç”¨åˆ—è¡¨åˆ—å‡º P: table.drop_indexes() æŸ¥çœ‹ç´¢å¼•æ€§èƒ½(æ˜¯å¦æœ‰æ•ˆ) table.ä¸Šé¢è¯´è¿‡çš„ä»»ä¸€å‡½æ•°().explain() # é“¾å¼è°ƒç”¨ explainï¼Œè¡¨ç¤ºåˆ—å‡ºæ­¤æ“ä½œçš„æ€§èƒ½ eg: M: queryset = table.explain().find({'name':'çŒ«'}) P: åŒä¸Š ç»“æœä¸­æ‰¾åˆ°ï¼š queryPlanner -&gt; winningPlan -&gt; inputStage -&gt; stage # stageç»“æœå¯¹åº”è¯´æ˜å¦‚ä¸‹ COLLSCAN # æœªä¼˜åŒ–ï¼Œè¿˜æ˜¯æœçš„æ•´ä¸ªé›†åˆ IXSCAN # ç´¢å¼•èµ·åˆ°ä½œç”¨ ç´¢å¼•å¯¹æŠ•å½±çš„ä¼˜åŒ–ï¼š queryPlanner -&gt; winningPlan -&gt; stage # stageç»“æœå¯¹åº”è¯´æ˜å¦‚ä¸‹ FETCH # ç´¢å¼• å¯¹æŠ•å½± æœªä¼˜åŒ– PROJECTION # ç´¢å¼• å¯¹æŠ•å½± èµ·åˆ°ä¼˜åŒ–ä½œç”¨ ç´¢å¼•å¯¹æ’åºçš„ä¼˜åŒ–ï¼š åŒä¸Š stage æœ€å¥½ ä¸æ˜¯ sort æŒ‰ç´¢å¼• æ­£åºï¼ˆé€†åºï¼‰ å–æ•°æ®ï¼Œ è¿™æ ·å°±æœ‰æ•ˆé¿å…äº†æœºæ¢°æ’åºçš„è¿‡ç¨‹ ","link":"https://cythonlin.github.io/post/py-greater-mongodb-yu-pymongo-yu-fa-dui-bi-jie-xi/"},{"title":"PY => Linuxå®ç”¨å·¥å…·å‘½ä»¤","content":"Ubuntu16å‡çº§åˆ°18.04 â€œâ€â€œ æœ‰ç‰¹æ®Šæ–°é¢–å¼ºè¿«ç—‡ç™–å¥½å¯ä»¥å‡ä¸‹ï¼Œå¦‚æœä½ è§‰å¾—16.04å¥½ç”¨ï¼Œå°±æ ¹æœ¬æ²¡å¿…è¦å‡äº† â€â€œâ€ æˆ‘å½“æ—¶ç§Ÿçš„ äº‘æœåŠ¡å™¨é€šå¸¸éƒ½æ˜¯16.04ï¼Œç°åœ¨ä¼°è®¡ä¹Ÿæ˜¯16.04è¾ƒå¤š æˆ‘æ˜¯ä¸ªPython3çš„ç©å®¶ï¼Œ æˆ‘åªæƒ³ç”¨Pythonçš„æœ€æ–°ç‰ˆï¼Œæˆ–æœ€æ–°æ ‡å‡†ç‰ˆ3.6-3.7 é“ç†å¾ˆç®€å•ï¼Œæˆ‘è¿½æ±‚æ–°é¢–ï¼Œè™½ç„¶æ–°ç‰ˆä¸ç¨³å®šï¼Œä½†æ˜¯ä½ å¯ä»¥å°é²œå¹¶é¢†å…ˆäºåˆ«äººã€‚ã€‚ã€‚ åºŸè¯ä¸å¤šè¯´ï¼š Ubuntu16.04: é»˜è®¤è£…çš„æ˜¯Python2.7 + Python3.4 æˆ–3.5 Ubuntu18.04: é»˜è®¤è£…çš„æ˜¯Python2.7 + Python3.6.+ æˆ‘å–œæ¬¢å‡çº§ç³»ç»Ÿç‰ˆæœ¬æ¥ç›´æ¥è®©å¯¹åº”è½¯ä»¶å‡çº§ï¼š lsb_release -a # æŸ¥çœ‹ç³»ç»Ÿç‰ˆæœ¬ apt update # ä¸€è·¯é€‰Y apt dist-upgrade apt autoremove # ä¸€è·¯é€‰Y apt install update-manager-core # æ¯”è¾ƒé‡è¦ do-release-upgrade -d # å®Œäº‹ æ³¨ï¼š å¦‚æœå…¶ä¸­æŸä¸ªå‘½ä»¤è¿‡ç¨‹å¼¹å‡ºä¸€ä¸ªé»‘çª—å£è®©ä½ é€‰æ‹©ï¼Œ æˆ‘è®°å¾—æœ‰ä¸ª core-new-update å­—çœ¼çš„ï¼Œé€‰è¿™ä¸ªå³å¯ # é€‰æ‹© æ–° æ ¸å¿ƒ vimå¤šè¡Œæ³¨é‡Šï¼ˆPythonä¸ºä¾‹ï¼‰ Ubuntuæ˜¯è‚¯å®šå¯ä»¥ç”¨ï¼Œ CentOSæˆ‘è®°å¾—å¥½åƒç”¨ä¸äº† ç›´æ¥ä¸€å¥—è¿æ‹›ï¼š æ³¨é‡Šï¼š 1. ctrl + v 2. æŒ‰ ä¸‹ ç®­å¤´æ–¹å‘é”®ï¼Œé€‰ä¸­å¤šè¡Œ 3. shift + i 4. è¾“å…¥ # 5. æŒ‰ä¸¤ä¸‹ ESCé”® å–æ¶ˆæ³¨é‡Šï¼š 1. ctrl + v 2. æŒ‰ ä¸‹ ç®­å¤´æ–¹å‘é”®ï¼Œé€‰ä¸­å¤šè¡Œ 3. æŒ‰ x é”® æ³¨ï¼š æ­¤å¥—è¿æ‹›ï¼Œéœ€è¦ç†Ÿç»ƒåº¦ï¼Œ å¦‚æœä¸è¡Œå°±å¤šç»ƒç»ƒã€‚ æ‰‹ä¸å¥½ä½¿ï¼Œå°±ä¸è¦æ€ªæˆ‘äº†~~~~ vimrcç®€å•é…ç½®ï¼š â€œâ€â€œ tab = 4ç¼©è¿›, è®¾ç½®è¡Œå· åŸºäºæ–‡ä»¶åçš„ç®€å•è¯­æ³•é«˜äº® ä¸è¦æƒ³ç€åˆ ä¸€è¡Œï¼Œç›´æ¥æ‰“å¼€vimrc å…¨éƒ¨å¤åˆ¶ä¸Šå»ï¼Œä¿å­˜é€€å‡ºå°±å¯ä»¥ç”¨äº† â€â€œâ€ vi ~/.vimrc syntax on set nu set expandtab set tabstop=4 set shiftwidth=4 set softtabstop=4 locateæŸ¥è¯¢åº“ locate xxx # è™½ç„¶å¾ˆç®€å•çš„å‘½ä»¤ï¼Œä½†æ˜¯å¦‚æœï¼Œä¸€ç›´ä¸ºä¸‹çº¿ï¼Œå¹¶ä¸”è¿˜æƒ³æŸ¥æ‰¾æ–°ä¸œè¥¿ï¼Œé‚£ä¹ˆéœ€è¦æ›´æ–°åº“ updatedb # æ›´æ–°æœç´¢åº“ï¼Œ å®Œäº‹ å¦‚æœ updatedbå‘½ä»¤å‡ºé”™ï¼Œé‚£å°±å®‰è£…ä¸€ä¸‹ mlocateå°±å¥½äº†ï¼š yum/apt-get install mlocate htopæŸ¥çœ‹æœåŠ¡å™¨è´Ÿè½½ ubuntu/centosä¸­æœ‰ top ï¼š æ­¤å‘½ä»¤å¯ä»¥è¯¦ç»†æŸ¥çœ‹æœåŠ¡å™¨å„ç§è´Ÿè½½ï¼Œèµ„æºçŠ¶å†µï¼Œä½†æ˜¯çœ‹ç€ä¸æ–¹ä¾¿ï¼Œéå¸¸è´¹åŠ² htop ï¼š topçš„å‡çº§ç‰ˆï¼Œ å®¹æ˜“çœ‹å‡ºèµ„æºæ¶ˆè€—æƒ…å†µ å¦‚æœæœªå®‰è£…ï¼Œå¯é€šè¿‡ apt-get/yum install htop å®‰è£… htop -d 0.1 # 0.1ç§’åŠ¨æ€æ›´æ–°ä¸€æ¬¡èµ„æºæ•°æ®ã€‚ çœ‹èµ·æ¥æœ‰ä¸€ç‚¹ç‚«ã€‚ pkill ps -el æŸ¥çœ‹ PId + kill -9 PID # è¿™å¥—è¿æ‹›å¯å¼ºåˆ¶æ€æ­»ä¸€ä¸ªè¿›ç¨‹ ä½†å‡å¦‚ä½ æœ‰ä¸€è¿ä¸²çš„pythonè¿›ç¨‹ æƒ³è¦ å…¨éƒ¨KILL pkill python # å®Œäº‹ï¼Œå’Œpythonæœ‰å…³çš„å…¨KILLæ‰äº†ï¼Œä¹Ÿå¯ä»¥é€šè¿‡é€šé…ç¬¦* çš„æ–¹å¼æ¥ç®€å†™ patreeåˆ—å‡ºè¿›ç¨‹ tree: æ­¤å‘½ä»¤ç”¨æ¥åˆ—å‡ºç›®å½•å±‚çº§ç»“æ„ pstree: ç”¨æ¥åˆ—å‡º æ­£åœ¨è¿è¡Œçš„ ç¨‹åºï¼ˆæ‰€æœ‰è¿›ç¨‹çš„å±‚çº§ç»“æ„ï¼Œè¿›ç¨‹åï¼‰ pstree -p: ä»¥å±‚çº§çš„æ–¹å¼ï¼Œä¸ä»…åˆ—å‡ºè¿›ç¨‹åï¼Œ è¿˜åˆ—å‡ºæ‰€æœ‰è¿›ç¨‹çš„(PID) aliasæ”¹å vi /etc/profile alias python='python3' # è¿™é‡Œæ˜¯ä¸¾ä¸ªä¾‹å­ï¼Œé…å®Œï¼Œpythonå‘½ä»¤å°±ç­‰ä»·äº python3å‘½ä»¤ alias pip='pip3' source /etc/profile # ä¸è¦å¿˜è®°ï¼Œè¿™æ¡å‘½ä»¤ æ›´æ–°ä¸€ä¸‹é…ç½®æ–‡ä»¶ é‡å®šå‘ç®¡é“ ( &gt; ä¸ tee ) date &gt; date.txt # æˆªæµï¼Œ å±å¹•ä¸Šä¸æ˜¾ç¤º date | tee date.txt # ä¸æˆªæµï¼Œ å±å¹•ä¸Šæ˜¾ç¤ºï¼Œ å¹¶ä¸”è¿˜èƒ½è¾“å…¥åˆ°æ–‡ä»¶ ! å¹å·å‘½ä»¤ â€â€œ !å‘½ä»¤å‰ç¼€ : è¿è¡Œæœ€åä¸€æ¡ä»¥è¿™ä¸ªå‰ç¼€å¼€å¤´çš„å‘½ä»¤ â€â€œ å‡å¦‚ä¸‹é¢æ˜¯ä½ æœ€åæŒ‰é¡ºåºå†commandç»ˆç«¯ è¾“å…¥çš„å››æ¡å‘½ä»¤ï¼š python aaa.py python bbb.py npm run dev pip install ccc éœ€æ±‚ï¼šä½ æƒ³è¿…é€Ÿè¿è¡Œ python bbb.pyè¿™æ¡å‘½ä»¤ ä½ åªéœ€ !py # å³å¯ï¼Œ æ„£ç€å¹²å•¥å‘¢ï¼Œ å·²ç»å®Œäº‹äº†ï¼Œè¿™æ¡å‘½ä»¤å°±ç­‰äºä½ ä¸Šé¢é‚£ä¸€å¤§ä¸² è§£æƒ‘ï¼š 1. !py -&gt; pyå¼€å¤´çš„æœ‰ä¸¤æ¡ï¼Œä¸ºå•¥ä¸æ‰§è¡Œç¬¬ä¸€æ¡ python aaa.py å› ä¸º ! å¹å· çš„è¯­æ³•æ„æ€å°±æ˜¯é€‰æ‹© æœ€åå‡ºç°ä»¥pyå¼€å¤´çš„æ‰§è¡Œã€‚ 2. ä¸ºå•¥ç›´æ¥ !p ä¸è¡Œå‘¢ï¼Ÿ å› ä¸ºä»¥på¼€å¤´çš„æœ€åä¸€æ¡å‘½ä»¤æ˜¯ pip install cccã€‚ è¿™ä¹Ÿä¸æ˜¯ä½ æƒ³è¦çš„å•Šã€‚ ctrl+z å’Œ &amp; å’Œ nohup å’Œ screen ctrl+cï¼š å¼ºåˆ¶ç»ˆæ­¢ï¼ˆæœ€å¸¸ç”¨çš„ï¼Œå…ˆæå‡ºæ¥ã€‚ã€‚ã€‚ã€‚ åº”è¯¥éƒ½çŸ¥é“çš„ã€‚ã€‚ï¼‰ ctrl+zï¼š å¯ä»¥æŠŠæ­£åœ¨è¿è¡Œä¸­çš„ç¨‹åºæŒ‚èµ·åˆ°åå°ï¼ˆæ³¨æ„è¿™æ—¶å€™ç¨‹åºå°±æš‚åœäº†ï¼‰ jobs: ç²—ç•¥åˆ—å‡º åå°æŒ‚èµ·çš„ç¨‹åº jobs -l: è¯¦ç»†åˆ—å‡º åå°æŒ‚èµ·çš„ç¨‹åº ï¼ˆå…¶å®å°±æ˜¯å¤šåˆ—å‡ºäº†ä¸ªPIDï¼‰ kill -9 PID # é¡ºæ°´æ¨èˆŸåœ°ä½¿ç”¨æ­¤å‘½ä»¤æ¥é€šè¿‡ PID å¹²æ‰åå°æŒ‚èµ·çš„ç¨‹åº fg: æŠŠæŒ‚èµ·çš„åå°çš„ç¨‹åº æ‹¿å›æ¥ç»§ç»­æ‰§è¡Œ fg ç¨‹åºç¼–å·: å¦‚æœæœ‰å¤šä¸ªåå°æŒ‚èµ·çš„ç¨‹åºï¼Œé€‰æ‹©ä¸€ä¸ªç»§ç»­æ‰§è¡Œï¼Œç¼–å·å¯é€šè¿‡ jobs æŸ¥çœ‹ã€‚ ä½¿ç”¨åœºæ™¯ï¼š åŠ å…¥æ­£åœ¨ vim ç¼–è¾‘ä¸œè¥¿ï¼Œæƒ³è·³å‡ºç¼–è¾‘å™¨ï¼Œå†™ç‚¹åˆ«çš„ï¼Œé‚£ä¹ˆå¯ä»¥ è¿›è¡Œä¸‹é¢æ“ä½œï¼š ä¸è¦ä¿å­˜ï¼Œ ç›´æ¥ ctrl+z ç„¶åå» åšåˆ«çš„äº‹ åšå®Œäº†æƒ³å›åˆ° vimç»§ç»­ç¼–è¾‘å‰©ä¸‹çš„å†…å®¹, ç›´æ¥ fg &amp;ï¼š è¿è¡Œ çš„ æ—¶åˆ» å°±ç›´æ¥ æ”¾åˆ°åå° (ä¸å®ç”¨) eg: (é€šå¸¸æ˜¯è´¹æ—¶çš„æ“ä½œï¼Œæˆ–è€…é•¿æ—¶é—´å ç”¨ commandå‘½ä»¤è¡Œï¼‰ sleep 100 &amp; # è¿™æ ·è´¹æ—¶100ç§’çš„æ“ä½œï¼Œç›´æ¥è®©å®ƒæ»šå»åå°æ‰§è¡Œï¼Œåˆ«å æˆ‘åœ°æ–¹ å±€é™ï¼š å‡å¦‚ä½ ç”¨ python xxxx.py &amp; è¿è¡Œä¸€ä¸ªwebæœåŠ¡å™¨ï¼Œè™½ç„¶å®ƒä¼šæ»šå»åå°ä¸€ç›´è¿è¡Œã€‚ å‰å°commandç•Œé¢çœ‹èµ·æ¥å¾ˆå¹²å‡€äº†ã€‚ ä½†æ˜¯ï¼Œå¦‚æœæœ‰ç”¨æˆ·è¯·æ±‚è¿‡æ¥ï¼Œ ä½ æœåŠ¡å™¨æ”¶åˆ°æ‰“å°åœ¨ç»ˆç«¯çš„ä¿¡æ¯ å¯ä¸ä¼šä¹–ä¹–æ‰“å°åœ¨åå°ã€‚ æ‰“å°ä¿¡æ¯ä¼šé’»å‡ºæ¥åˆ°å‰å°commandç•Œé¢æ¥æ¶å¿ƒä½ ã€‚ã€‚ã€‚ã€‚ã€‚ ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œ è¯·ç§»æ­¥ ä¸‹é¢ ... nohup: (é€šå¸¸å’Œ ä¸Šé¢çš„ &amp; è”åˆä½¿ç”¨) ï¼ˆå®ç”¨æ€§ä¸€èˆ¬ï¼‰ eg: åŒæ ·è¿è¡Œä¸€ä¸ªæœåŠ¡å™¨ nohup python xxx.py &amp; # å®ƒä¼šä¹–ä¹–çš„æ»šå»åå°æ‰§è¡Œï¼Œå¹¶ä¸”å°†è¦æ‰“å°çš„æ¶ˆæ¯ ä¹Ÿä¸ä¼šæ‰“å°åˆ°å‰å°ï¼Œä¹Ÿä¸ä¼šæ‰“å°åˆ°åå°ã€‚ é‚£æ‰“å°çš„å†…å®¹å»å“ªäº†å‘¢ï¼Ÿï¼Ÿ nohupä¼šè‡ªåŠ¨ç»™ä½  æŠŠæ‰“å°çš„ä¸œè¥¿é‡å®šå‘ åˆ°ä¸€ä¸ª nohup.outæ–‡ä»¶ï¼Œé€šå¸¸åœ¨å½“å‰ç›®å½•ä¸‹ # è¿™æ—¶ä½ çš„å‰å°command å°±ä¸ä¼šå—åˆ° éªšæ‰°äº†ã€‚ã€‚ã€‚ã€‚ ä¹Ÿè®¸ä½ ä»¥ä¸ºå®ƒå¾ˆå¥½ç”¨äº†ï¼Œå¯ä»¥å®Œç¾çš„å†³ç»è¿è¡Œä¸€ä¸ªè´¹æ—¶çš„è¿›ç¨‹ã€‚ä½†æ˜¯ å®ƒä¾ç„¶æ˜¯ä¸ª loserã€‚ã€‚. å±€é™ï¼š å½“æˆ‘ä¸€ç›´ç”¨ nohup.out éƒ¨ç½²ä¸€äº›æœåŠ¡ç¨‹åºçš„æ—¶å€™ï¼Œä¸€éƒ¨ç½²å°±æ˜¯å¾ˆå¤šå¤©ã€‚ å½“æ—¶å­¦æ ¡æ–­ç”µï¼ˆæˆ‘ç§Ÿçš„é˜¿é‡Œäº‘ECSæœåŠ¡å™¨ï¼‰. è™½ç„¶æœåŠ¡å™¨å¯ä»¥ä¸é—´æ–­çš„æ‰§è¡Œã€‚ ä½†æ˜¯ æˆ‘éœ€è¦ ç”¨ xshell ä¸€ç›´å»è¿œç¨‹ æŸ¥çœ‹æˆ‘çš„ ç¨‹åºè¿è¡Œçš„æ€ä¹ˆæ ·äº†å•Šï¼Œ æ˜¯å¦å´©äº†ï¼Ÿ å¯æƒœçš„æ˜¯ï¼Œæ¯æ¬¡xshellå…³é—­äº†ï¼Œä½ å†ä¸Šå»ï¼Œ æƒ³æ‰¾ é€šè¿‡ nohup &amp; è¿æ‹› æ”¾åˆ°åå°ç¨‹åºçš„æ—¶å€™ï¼Œ ä½ ä¼šç—›è‹¦æ— æ¯”ã€‚ã€‚ã€‚éå¸¸æƒ¨ åæ¥ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ screen: ï¼ˆä¼šè¯æœºåˆ¶ï¼‰ æ²¡é”™ï¼Œåæ¥æˆ‘å°±å‘ç°äº† è¿™ä¸ª screenå·¥å…· å¦‚æœä½ é‚£é‡Œæ²¡æœ‰ï¼Œå°±å®‰è£…ä¸€ä¸‹å–½ï¼š apt-get / yum install screen ç„¶åéœ€è¦é…ç½®ä¸€ä¸‹ï¼š vi ~/.screenrc # åˆ›å»ºæ–‡ä»¶ shell -$SHELL # è¾“å…¥æ­¤è¡Œå†…å®¹ï¼Œä¿å­˜é€€å‡º è‡³äºä¸ºä½•é…ç½®è¿™ä¸ªï¼š è¯´å®è¯æˆ‘æœ‰ç‚¹å¿˜äº† è²Œä¼¼ä¸åŒscreenä¼šè¯å¯¹äºä¸åŒçš„shell æƒé™æœ‰é™åˆ¶ï¼Œå¯¼è‡´å¾ˆå¤šä¸œè¥¿ç”¨ä¸äº†ï¼Œso do it ç›´æ¥è¯´ä¸€å¥—æˆ‘å¸¸ç”¨ä¸”è¶…çº§å®ç”¨è¿æ‹›æŠŠï¼š eg: screen -S ä¼šè¯å # åˆ›å»º å¹¶ è¿›å…¥è¿™ä¸ªä¼šè¯ï¼ˆå°±åƒè¿›å…¥å¦ä¸€ä¸ªä¸–ç•Œï¼Œä½†èµ„æºå…±äº«ï¼‰ python xxx.py # ä¸¾ä¾‹å­ï¼Œè¿™æ˜¯æˆ‘çš„çˆ¬è™«ç¨‹åºï¼Œéœ€è¦è¿è¡Œ ä¸‰å¤© ctrl + a + d # è·³å‡ºä¼šè¯ï¼Œå›åˆ°æ­£å¸¸å‘½ä»¤è¡Œï¼Œä½†æ˜¯è¿™ä¸ªä¼šè¯ä»¥åŠä½ çš„ç¨‹åºä¾ç„¶åœ¨è¿è¡Œï¼Œ ....... è¿™æ®µæ—¶é—´ï¼ˆé™¤äº†å…³é—­æœåŠ¡å™¨ï¼‰ä½ åšä»€ä¹ˆéƒ½è¡Œï¼Œå…³é—­ shellä¹Ÿå¯ä»¥çš„ã€‚ screen -r ä¸Šé¢çš„ä¼šè¯å # æ¢å¤åˆ°ä¼šè¯ä¸­ï¼Œ ä½ ä¼šå‘ç°ï¼Œçˆ¬è™«ç¨‹åºè¿˜åœ¨é‚£é‡Œå¥½å¥½çš„è¿è¡Œå‘¢ã€‚ å¦‚æœä½ å¿˜è®°ä¼šè¯åäº†ï¼Œä¸è¦ç´§ï¼š screen -ls # è¿™æ¡å‘½ä»¤ä¼šåˆ—å‡ºæ‰€æœ‰ ä½ åˆ›å»ºè¿‡çš„ä¼šè¯ï¼Œä½ ä¹Ÿå¯ä»¥çœ‹åˆ°ä¼šè¯å æ€»ç»“ï¼š æ‰€ä»¥ï¼Œæˆ‘ä¸çŸ¥é“é˜ä¸‹èƒ½ä¸èƒ½æ„Ÿå—åˆ° screençš„é­…åŠ›ã€‚ æˆ‘ä»¬å¯ä»¥ é€šè¿‡ screen -r è¿™ä¸€æ¡å‘½ä»¤æ¥ è¿…é€Ÿå›åˆ°ç¨‹åºè¿è¡Œçš„ç¯å¢ƒã€‚ nohup &amp;ï¼š ä½ ç”¨è¿™ä¸ªæ‰§è¡Œçš„ç¨‹åºï¼Œå…³äº† xshell, ä½ å†è¿ï¼Œä½ å°±ä¸å¥½æ‰¾è¿™ä¸ªè¿è¡Œçš„ç¨‹åºäº† screen æœ‰ä¸€å¥—å®Œå¥½çš„ç³»ç»Ÿï¼ˆå°±åƒæœ‰å¼€å…³ä¸€æ ·ï¼‰æ¥æ§åˆ¶ä¼šè¯ ä½ è¿›å…¥screenä¼šè¯ä¸­å†™ç¨‹åºï¼Œscreen è‡ªç„¶å°±èƒ½æœ‰æ¡ä¸ç´Šçš„ç®¡ç†å¥½ ä½ ç¨‹åºçš„è¿è¡ŒçŠ¶æ€ ä¸¾ä¸ªç™½è¯ä¾‹å­ï¼š ä½ æ­£é›äºŒå“ˆå‘¢ï¼Œçªç„¶æœ‰æ€¥äº‹ï¼š nohup &amp; : ä½ è¯´ï¼šâ€˜äºŒå“ˆï¼Œç­‰æˆ‘å›æ¥ï¼Œè‡ªå·±ç©æŠŠâ€™ ä½ å›æ¥æ—¶ï¼Œ äºŒå“ˆè·‘ä¸¢äº†ã€‚ ï¼ˆä¸å—æ§åˆ¶ï¼Œç¨‹åºæ‰¾ä¸åˆ°äº†ï¼Œè™½ç„¶å¯ä»¥èŠ±åŠ›æ°”æ‰¾åˆ°ï¼‰ screen : ä½ è¯´ï¼šâ€˜äºŒå“ˆï¼Œç­‰æˆ‘å›æ¥ï¼Œè‡ªå·±ç©å§ï¼Œä½†æˆ‘è¦æŠŠä½ æ‹´èµ·æ¥â€™ ä½ å›æ¥æ—¶ï¼Œ äºŒå“ˆè¿˜åœ¨é‚£é‡Œä¹–ä¹–çš„ç©ã€‚ï¼ˆç¨‹åºæœ‰æ•ˆçš„å—åˆ°æ§åˆ¶ï¼Œä½ å¯ä»¥è½»æ¾å®šä½ï¼‰ sudo suç­‰æ“ä½œ ä¸å¥½æ„æ€ï¼Œç”¨äº†å¥½å‡ å¹´linuxï¼š ä»€ä¹ˆ su- su ä¹‹ç±»çš„ï¼Œ æˆ‘è‡³ä»Šéƒ½æ²¡æå¤ªæ˜ç™½ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ ä½†æ˜¯ï¼Œæˆ‘åªç”¨ä¸‹é¢è¿™ä¸€æ¡å‘½ä»¤ï¼Œè¿™äº›å¹´å°±æ²¡é‡åˆ°è¿‡é—®é¢˜ï¼š sudo -s # å˜ä¸ºroot, å¦‚æœä½ ä¹‹å‰è¾“å…¥è¿‡å¯†ç ï¼Œ è¿™æ¡å‘½ä»¤è¿˜ä¼šå…å»è®©ä½ è¾“å…¥å¯†ç çš„ç¯èŠ‚ ç¯å¢ƒå˜é‡ æŠŠæŸè·¯å¾„åŠ å…¥åˆ°ç¯å¢ƒå˜é‡ä¸­ï¼š vi /etc/profile export PATH=$PATH:/XXX/XX åšä¸€äº›é…ç½®ï¼š vi /etc/profile vi ~/.bashrc ç­‰ä¿®æ”¹å®Œå source /etc/profile # ç”¨ä¸€ä¸ª source å‘½ä»¤æ‰§è¡Œä¸€ä¸‹ä½¿é…ç½®æ›´æ–°ç”Ÿæ•ˆ æ³¨ï¼š Linux-shellæˆ‘ç ”ç©¶çš„ä¸æ·±,æ‰€ä»¥è¿™é‡Œå¯èƒ½æœ‰äº›è¯´çš„ä¸æ˜¯ç‰¹åˆ«æ˜æœ—ã€‚ å…¶å® è¿™äº›é…ç½®æ–‡ä»¶ ä»¥åŠ source . sh bash è¿™äº›å‘½ä»¤ å’Œ ç”¨æˆ· ä»¥åŠæƒé™ç­‰éƒ½æ˜¯æœ‰å¾ˆå¤§å…³ç³»çš„ã€‚ æœ‰å…´è¶£å¯è‡ªè¡Œæ·±å…¥äº†è§£ æ¿€æ´»Ubuntuçš„rootç”¨æˆ· ä¹Ÿè®¸ä½ ubuntuåªèƒ½ç”¨rootæƒé™ ä½†ä½ ä¸èƒ½ä½¿ç”¨rootç”¨æˆ·ç™»å½•ï¼Œæˆ–ä¸èƒ½ä½¿ç”¨rootç”¨æˆ·è¿›è¡Œsshè¿æ¥ ubuntuå…¶å®æ˜¯å­˜åœ¨ root ç”¨æˆ·çš„, ä¸ç”¨åˆ›å»ºï¼Œç»™ä¸ªå¯†ç å°±èƒ½ç›´æ¥ä½¿ç”¨ sudo passwd root rootç”¨æˆ·è¿œç¨‹SSHè¿æ¥ å‡å¦‚ä½ çš„ xshell è¿æ¥ä¸ä¸Šè¿œç¨‹æœåŠ¡å™¨ï¼Œ å¯èƒ½æœªå¼€å¯ æˆ– æœªå®‰è£… sshdæœåŠ¡ å¦‚ä¸‹å‘½ä»¤å³å¯ï¼š sudo apt-get install ssh systemctl start ssh å¦‚æœä½ æƒ³è¦ç”¨rootç”¨æˆ·ç›´æ¥sshè¿æ¥, å¯ä½œå¦‚ä¸‹é…ç½®ï¼š sudo vim /etc/ssh/sshd_config PermitRootLogin yes systemctl restart ssh MySQL5.7+/MariaDBä¿®æ”¹å¯†ç å°å‘ å½“é˜ä¸‹è¿˜åœ¨åœç•™åœ¨Mysql5.7ç‰ˆæœ¬ä¹‹å‰ï¼Œä¿®æ”¹å¯†ç å¯ä»¥ç”¨ä¸‹é¢è¿™ä¸¤ç§æ–¹å¼ï¼š mysqladmin -uroot password -p æˆ–å†…éƒ¨è®¾ç½®ï¼š update user set password=password('root') where user='root' ä½†æ˜¯ MySQL5.7 ä¹‹å æˆ–è€… MariaDB ,ä¸Šé¢è¿™ä¿©æ–¹æ³• éƒ½ä¸èƒ½ ä¿®æ”¹å¯†ç äº†ã€‚ æ­£ç¡®ä¿®æ”¹æ–¹å¼ï¼š å…ˆè¿›å…¥MySQLäº¤äº’å¼ï¼š MySQL -uroot -p update mysql.user set authentication_string=password(&quot;å¯†ç &quot;) where user=&quot;ç”¨æˆ·å&quot; update user set plugin=&quot;mysql_native_password&quot;; flush privileges æœ€åé‡å¯æœåŠ¡ï¼Œ å®Œäº‹ å¦å¤–ï¼Œå€¼å¾—æé†’çš„ä¸€ç‚¹å®¹æ˜“å‡ºç°çš„é—®é¢˜ï¼š æ— è®ºä½ è¿æ¥çš„æ˜¯ä»€ä¹ˆæ•°æ®åº“ï¼Œå¦‚æœä½ è¿ä¸ä¸Š é¦–å…ˆä½ åº”è¯¥æƒ³åˆ°çš„æ˜¯ï¼Œæ•°æ®åº“é…ç½®æ–‡ä»¶ï¼š bind 0.0.0.0 # æ¯ç§æ•°æ®åº“å‡ ä¹éƒ½éœ€è¦å…ˆæ”¹æˆè¿™æ ·ï¼Œæ‰èƒ½è¢«å¤–ç•Œè®¿é—® å…¶æ¬¡ï¼Œä½ ç”¨çš„æ˜¯äº‘æœåŠ¡å™¨çš„è¯ çœ‹çœ‹æ˜¯å¦æ”¾é€šäº† å¯¹åº”æ•°æ®åº“çš„å®½å£ æœ€åï¼Œæ˜¯å¦å¼€äº†é˜²ç«å¢™ï¼š æ²¡è®°é”™çš„è¯ï¼ŒCentos å’Œ Ubuntu é˜²ç«å¢™ä¸æ˜¯åŒä¸€ç§ï¼ŒçœŸæ­£éœ€è¦å…³é—­å¯è‡ªè¡Œç™¾åº¦ å…¶ä»–å‘½ä»¤ &quot;&quot;&quot; ä¸€æ—¶é—´ä¹Ÿè®°ä¸èµ·æ¥è¿˜ç”¨è¿‡å“ªäº›äº† &quot;&quot;&quot; wc : ç»Ÿè®¡å­—,è¯ï¼Œè¡Œï¼ˆè‡ªå·±é€‰å‚æ•°ï¼‰ curl : å¯ä»¥è¯·æ±‚ urlï¼Œå¹¶è¿”å›æ•°æ®ï¼ˆç›¸å½“äºä¸€ä¸ªå°å°çˆ¬è™«ï¼‰ï¼Œä¹Ÿå¯ä»¥å‘æŸä¸ªæ¥å£å‘é€è¯·æ±‚ ssh-keygen ï¼šç”Ÿæˆå…¬ç§å¯†é’¥ cd - : è·³å›åˆ°ä¸Šä¸€æ¬¡çš„è·¯å¾„ lsb_release -a : æŸ¥çœ‹Linuxå‘è¡Œç‰ˆä¿¡æ¯ grep : è¿‡æ»¤å­—ç¬¦ tar : å‹ç¼©/è§£å‹ netstat : æŸ¥ç«¯å£ ç­‰ ","link":"https://cythonlin.github.io/post/py-greater-linux-shi-yong-gong-ju-ming-ling/"},{"title":"PY => Pythonæ­£åˆ™å…¨è§£è¯¦è§£","content":"é¢„ç¼–è¯‘ import re re1 = re.compile(r'å…ƒå­—ç¬¦ ç»„æˆçš„æ­£åˆ™è§„åˆ™') # å…ƒå­—ç¬¦ä¸‹é¢ä¼šè¯´ re1.æ–¹æ³•() # æ–¹æ³•ä¸‹è¾¹ä¹Ÿä¼šè¯´ å…ƒå­—ç¬¦ï¼š è¡¨ç¤ºæ™®é€šå­—ç¬¦ï¼š . # é™¤äº†\\nå¤– éƒ½å¯ä»¥åŒ¹é…çš„åˆ° \\d # åªåŒ¹é… çº¯æ•°å­— 0-9 \\D # å’Œ \\dç›¸åï¼Œ é™¤äº†æ•°å­—å…¨éƒ½åŒ¹é… \\s # åªåŒ¹é…ç©ºæ ¼ \\S # å’Œ \\sç›¸åï¼Œé™¤äº†ç©ºæ ¼ï¼Œå…¨éƒ½åŒ¹é… # æˆ‘å–œæ¬¢ç”¨ [\\s\\S]*? åŒ¹é…æ‰€æœ‰ \\w # åªåŒ¹é… çº¯æ•°å­— æˆ– å¤§å°å†™å­—æ¯ æˆ– ä¸‹åˆ’çº¿ \\W # ä¸ \\w æ°å¥½ç›¸åï¼Œ é™¤äº† çº¯æ•°å­—ã€å¤§å°å†™å­—æ¯ã€ä¸‹åˆ’çº¿ å…¨éƒ½åŒ¹é… [] # [abcde] åªè¦åŒ…å«è¿™ä¸ªåˆ—è¡¨çš„å­—ç¬¦ï¼Œéƒ½å¯ä»¥åŒ¹é…çš„åˆ°ã€‚ä½†é»˜è®¤åªå–ä¸€ä¸ªï¼Œ ç®€å†™ [a-e] eg: re.compile(r'[e-h]').match('hello python ').group(0) &gt;&gt;&gt; h æ­¤å¤–: [^abcde] æˆ– [^a-e] è¡¨ç¤º 'æ’é™¤'ï¼Œæ„æ€å°±æ˜¯ é™¤äº†abcdeå…¨åŒ¹é… åŒ¹é…è¡¨ç¤ºè¾¹ç•Œçš„ï¼š ^ # åŒ¹é… èµ·å§‹ ä½ç½®ï¼Œå— re.M å½±å“ #æ³¨æ„ï¼šä¸è¦å’Œ [^123] é™¤123ä¹‹å¤–ææ·· eg: import re r1 = re.compile(r'^\\d+') print(r1.search('456hello123').group()) &gt;&gt;&gt; 456 $ # åŒ¹é… ç»“å°¾ ä½ç½®ï¼Œå— re.M å½±å“ eg: import re s = &quot;&quot;&quot; 123abc456 678abc789 &quot;&quot;&quot; r1 = re.compile(r'\\d+$',re.M) # æ³¨æ„è¿™é‡ŒåŠ å…¥äº†re.M print(r1.findall(s)) &gt;&gt;&gt; ['456', '789'] # è¿™æ˜¯å†™äº†re.Mï¼Œå°±æ„å‘³ç€ æ¯ä¸€è¡Œéƒ½ç»™ä½ å•ç‹¬æŒ‰ç…§è§„åˆ™å¤„ç† &gt;&gt;&gt; ['789'] # å¦‚æœæ²¡å†™re.M, é‚£ä¹ˆå°±æŒ‰ç…§æ•´ä½“ï¼Œå»æœ€åä¸€è¡Œçš„å°¾éƒ¨ æ³¨ï¼š å…¶å®re.Mçš„æœ¬è´¨æ˜¯ æ˜¯æ ¹æ®\\nï¼Œè¿›è¡Œ æ–­è¡Œï¼Œæ–­è¡Œåå¯¹æ¯ä¸€è¡ŒæŒ‰ç…§è§„åˆ™å•ç‹¬å¤„ç† \\bï¼š # åŒ¹é… å•è¯çš„ è¾¹ç•Œï¼ˆé™¤äº† æ•°å­—ã€ä¸­è‹±å­—æ¯ã€ä¸‹åˆ’çº¿ çš„ æ‰€æœ‰ç¬¦å·ï¼‰ eg: import re s = 'ä½ å¥½å•Š----å¥½ä¸ªP' r1 = re.compile(r'\\bå¥½') print(r1.findall(s)) &gt;&gt;&gt; å¥½ # è§£é‡Šï¼šè¿™ä¸ªâ€˜å¥½â€™æ˜¯ï¼Œåé¢ çš„é‚£ä¸ªã€‚å› ä¸ºåé¢çš„ â€™å¥½â€˜ å­— å·¦è¾¹æ˜¯ç¬¦å·ï¼Œè€Œéå•è¯å­—ç¬¦ \\Bï¼š # åŒ¹é… å•è¯ é è¾¹ç•Œï¼ˆåŒ…æ‹¬ æ•°å­—ã€ä¸­è‹±å­—æ¯ã€ä¸‹åˆ’çº¿ï¼‰ eg: import re s = 'ä½ å¥½å•Š----å¥½ä¸ªP' r1 = re.compile(r'\\bå¥½') print(r1.findall(s)) &gt;&gt;&gt; å¥½ # è§£é‡Šï¼šè¿™ä¸ªâ€˜å¥½â€™æ˜¯ï¼Œå‰é¢ çš„é‚£ä¸ªã€‚å› ä¸ºå‰é¢çš„ â€™å¥½â€˜ å­— å·¦è¾¹æ˜¯ä¸­æ–‡å­—ç¬¦ã€‚å±äºéè¾¹ç•Œ # æ‰€ä»¥å°±åŒ¹é…ä¸Šäº† å†æ¬¡æ€»ç»“ï¼š \\b ä¸ \\Bï¼š \\bï¼š åŒ¹é…è¾¹ç•Œå­—ç¬¦ã€‚è¾¹ç•Œå­—ç¬¦ï¼šï¼ˆé™¤äº† æ•°å­—ã€å­—æ¯ã€æ±‰å­—ã€ä¸‹åˆ’çº¿çš„æ‰€æœ‰ç¬¦å·ï¼‰ \\Bï¼š åŒ¹é…éè¾¹ç•Œå­—ç¬¦ã€‚éè¾¹ç•Œå­—ç¬¦ï¼šï¼ˆæ•°å­—ã€å­—æ¯ã€æ±‰å­—ã€ä¸‹åˆ’çº¿ï¼‰ åŒ¹é…è¡¨ç¤ºæ•°é‡çš„ï¼š * ï¼š 0æ¬¡ æˆ– å¤šæ¬¡ egï¼š ä½ * + ï¼š 1æ¬¡ æˆ– å¤šæ¬¡ eg: ä½ + ? ï¼š 0æ¬¡ æˆ– ä¸€æ¬¡ eg: ä½ ? {m} : å‡ºç°mæ¬¡ eg: ä½ {3} {m,} : è‡³å°‘ å‡ºç°mæ¬¡ eg: ä½ {3,} # æ¶‰åŠåˆ°è´ªå©ªæ¨¡å¼ï¼Œä¸æ·±çš„ä¸è¦ç”¨ {m,n}: mæ¬¡ åˆ° næ¬¡ ä¹‹é—´ä»»æ„ä¸€æ¬¡å°±è¡Œ eg: ä½ {3,6} è¡¨ç¤ºåˆ†ç»„ï¼š | ï¼š ç›¸å½“äºæˆ–è¿ç®—ç¬¦ï¼Œ ä¸¤è¾¹å†™çš„æ˜¯ æ­£åˆ™è¡¨è¾¾å¼ï¼Œ ä¼˜å…ˆé€‰æ‹©å·¦è¾¹çš„ () : æ‹¬èµ·æ¥é‡Œé¢çš„å†…å®¹ï¼Œå°±å˜æˆäº†åˆ†ç»„ã€‚ å¯ä»¥ç”¨ .group(1)æå–ï¼Œå¦‚æœæœ‰æ›´å¤šé‚£å°± group(2).. (?P&lt;name&gt;) ï¼š åœ¨ä¸Šé¢åˆ†ç»„çš„åŸºç¡€ä¸Š èµ·åˆ«å (?P=name) : æ ¹æ®åˆ†ç»„çš„åˆ«åæ¥ä½¿ç”¨åˆ†ç»„ eg: s = '&lt;h1&gt;ä½ å¥½&lt;/h1&gt;' r1 = re.compile(r'&lt;(?P&lt;name1&gt;\\w+)&gt;(\\w+)&lt;/(?P=name1)&gt;').match(s).group(2) print(r1) &gt;&gt;&gt; ä½ å¥½ \\æ•°å­— ï¼šæå–çš„åˆ†ç»„å¯ä»¥åœ¨ åŒä¸€ä¸ªæ­£åˆ™ä¸­ å¤ç”¨ eg: s = '&lt;h1&gt;ä½ å¥½&lt;/h1&gt;' r1 = re.compile(r'&lt;(\\w+)&gt;(\\w+)&lt;/\\1&gt;') # \\1 ä»£è¡¨å¤ç”¨ç¬¬ä¸€ä¸ªåˆ†ç»„ print(r1.match(s).group(2)) # 2ä»£è¡¨æå–ç¬¬äºŒä¸ªåˆ†ç»„ &gt;&gt;&gt; ä½ å¥½ åŒ¹é…æ¨¡å¼ re.M # å¤šè¡ŒåŒ¹é…ï¼Œ å½±å“ ^ å’Œ $ï¼Œä¸Šé¢è®² ^ ä¸ $å·²ç»è¯¦è§£äº†ã€‚ re.I # å¿½ç•¥å¤§å°å†™ eg: s = 'aAbB' r1 = re.compile(r'aabb', re.I).match(s).group() print(r1) &gt;&gt;&gt; aAbB re.S # æå‡ . çš„æƒé™ï¼Œ è®© . å¯ä»¥ åŒ¹é…åˆ°æ¢è¡Œç¬¦ s = &quot;&quot;&quot; hello python &quot;&quot;&quot; r1 = re.compile(r'.*', re.S).match(s).group() # æ³¨æ„è¿™é‡Œ re.S print(r1) &gt;&gt;&gt; hello python æ³¨æ„ï¼šå¦‚æœä¸å†™ re.S é‚£ä¹ˆ .* åªèƒ½åŒ¹é…åˆ°ç¬¬ä¸€è¡Œçš„ç©ºå­—ç¬¦ä¸²ï¼Œå› ä¸ºé‡åˆ°ç¬¬ä¸€ä¸ªç©ºè¡Œçš„\\nå°±åœæ­¢äº† re.X # å¯ä»¥ç»™æ­£åˆ™åˆ†è¡Œå†™ï¼Œå¹¶å¯ä»¥åŠ æ³¨é‡Šï¼Œ eg: import re title = '1å¥½2ä½ 3' r1 = re.compile(r&quot;&quot;&quot; 1 # æ³¨é‡Š1 çœ‹è¿™ä¸¤è¡Œ å¥½ # æ³¨é‡Š2 çœ‹è¿™ä¸¤è¡Œï¼Œ1 å’Œ å¥½ æ²¡æœ‰åŠ é€—å·ã€‚ä½†æ˜¯ä»–ä»¬å±äºæ•´ä½“çš„è§„åˆ™ï¼Œä½ å¯ä»¥åŠ æ³¨é‡Š &quot;&quot;&quot;, re.X) # æŠŠæ­£åˆ™å¯ä»¥åˆ†è¡Œå†™, ç”¨äº†re.Xåï¼Œåˆ†è¡Œçš„æ­£åˆ™ä¼šè¢«çœ‹ä½œä¸ºä¸€è¡Œ result = r1.match(title).group() print(result) # è¾“å‡ºç»“æœï¼š 1å¥½ è´ªå©ªæ¨¡å¼ ä¸ éè´ªå©ªæ¨¡å¼ ä¸ªäººç†è§£ï¼š è´ªå©ªæ¨¡å¼ï¼š(Pythoné»˜è®¤ä½¿ç”¨çš„å°±æ˜¯ è´ªå©ªæ¨¡å¼) ä½ æƒ³åŒ¹é… ä¸€ä¸ªå¥å­ä¸­çš„ ä¸€ä¸ªå•è¯ï¼Œ ä½†æ˜¯ä½ å†™çš„è§„åˆ™æ°å¥½å¯ä»¥ æ»¡è¶³ åŒ¹é…æ‰€æœ‰å•è¯ã€‚ é‚£ä¹ˆå®ƒå°±ä¼š è´ªå©ªçš„ æŠŠæ‰€æœ‰å•è¯ å…¨éƒ¨ éƒ½ç»™ä½ åŒ¹é…å‡ºæ¥ã€‚ (è´ª) ä½¿ç”¨æ–¹æ³•ï¼š * æˆ– + éè´ªå©ªæ¨¡å¼ï¼š å³ä½¿ä½ æŠŠè§„åˆ™å†™çš„å¾ˆå¥½ï¼Œå¹¶ä¸”èƒ½æŠŠæ‰€æœ‰å­—ç¬¦ä¸²éƒ½åŒ¹é…åˆ°ï¼Œ ä½†æ˜¯å¦‚æœä½ åŠ ä¸Šäº† éè´ªå©ªæ¨¡å¼ã€‚ åœ¨æ»¡è¶³è§„åˆ™æ¡ä»¶çš„å‰æä¸‹ï¼ŒåªåŒ¹é…ä¸€ä¸ª. ä½¿ç”¨æ–¹æ³•ï¼š *? æˆ– +? eg1ï¼šåŸºäºsearchçš„è´ªå©ªæ¨¡å¼ï¼ˆmatchåŒæ­¤ï¼‰ æˆ‘ä»¬å…ˆå›å¿†ä¸€ä¸‹ï¼šsearch()æ–¹æ³•çš„ æœ€æ ¸å¿ƒæ€æƒ³å°±æ˜¯ï¼šä»å‰å¾€åæœï¼Œæœåˆ°ä¸€ä¸ªæ»¡è¶³çš„å°±ç›´æ¥è¿”å›ã€‚ OKï¼Œç»§ç»­ã€‚ è´ªå©ªï¼šï¼ˆé»˜è®¤ï¼‰ï¼š import re r1 = re.compile(r'\\d+') print(r1.search('ä½ å¥½333ä½ å¥½333ä½ å¥½').group()) &gt;&gt;&gt; 333 # æ»¡è¶³è§„åˆ™å å°½å¯èƒ½è´ªï¼Œ æ‰€ä»¥ç¬¬ä¸€ä¸²è¿ç€çš„ '333' æœåˆ°äº†å°±ç›´æ¥è¿”å›äº† éè´ªå©ªï¼ˆå°±å¤šäº†ä¸ªé—®å· ? ï¼‰ï¼š import re r1 = re.compile(r'\\d+?') print(r1.search('ä½ å¥½333ä½ å¥½333ä½ å¥½').group()) &gt;&gt;&gt; 3 # å—¯ï¼Œä½ çš„è§„åˆ™å°±æ˜¯ è‡³å°‘ä¸€ä¸ªæ•°å­—ï¼Œæœåˆ°äº†ä¸€ä¸ªå°±å¯ä»¥è¿”å›äº†ï¼Œå¹²å¾—æ¼‚äº®ã€‚ eg2: åŸºäºfindallçš„è´ªå©ªæ¨¡å¼ï¼ˆå¦‚æœä½ findallä¸è§„åˆ™ï¼Œç†è§£çš„ä¸é€å½»ï¼Œè¿™ä¸ªä¼šæœ‰ç‚¹ç»•çš„ï¼Œå‰æ–¹é«˜èƒ½ï¼‰ å…ˆå›å¿†ä¸€ä¸‹ï¼šfindall()æ–¹æ³•çš„ æœ€æ ¸å¿ƒæ€æƒ³å°±æ˜¯ï¼šæ‹¿ç€ å®šæ­»çš„ è§„åˆ™ï¼ŒæŠŠæ‰€æœ‰æ»¡è¶³è§„åˆ™çš„éƒ½æå‡ºæ¥ OKï¼Œç»§ç»­ã€‚ è´ªå©ªï¼ˆé»˜è®¤ï¼‰ï¼š import re r1 = re.compile(r'\\d+') print(r1.findall('ä½ å¥½333ä½ å¥½333ä½ å¥½')) &gt;&gt;&gt; ['333', '333'] è§£é‡Šï¼š è§„åˆ™æ˜¯åŒ¹é…è‡³å°‘ä¸€ä½æ•°å­—ã€‚ ä½†æ˜¯ è´ªå©ªæ¨¡å¼ æé†’äº† è§„åˆ™ï¼šâ€œä½ çš„ä»»åŠ¡æ˜¯ç»™æˆ‘å°½å¯èƒ½çš„ å¤šåŒ¹é…æ•°å­—â€ findall æ‹¿ç€ è¢«è´ªå©ªåŒ–çš„ è§„åˆ™ å»åŒ¹é…åŸå§‹å­—ç¬¦ä¸² è¢«è´ªå©ªæ¨¡å¼ æé†’è¿‡çš„è§„åˆ™æœç„¶ä¸è´Ÿä¼—æœ›ï¼Œ ä¸€æ¬¡æä¸€ä¸²è¿ç€çš„ â€˜333â€˜ findall æ‹¿ç€å®ƒ æå–äº† ä¸¤æ¬¡ ,å°±æŠŠæ‰€æœ‰æ•°å­—æå–å‡ºæ¥äº† ç»“æœå°±æ˜¯ ['333', '333'] éè´ªå©ªï¼š import re r1 = re.compile(r'\\d+?') print(r1.findall('ä½ å¥½333ä½ å¥½333ä½ å¥½')) &gt;&gt;&gt; ['3', '3', '3', '3', '3', '3'] è§£é‡Šï¼š è§„åˆ™ åŒæ ·æ˜¯ åŒ¹é…è‡³å°‘ä¸€ä½æ•°å­—ã€‚ ä½†æ˜¯ é è´ªå©ªæ¨¡å¼ æé†’äº† è§„åˆ™ï¼šâ€œä½ çš„ä»»åŠ¡æ˜¯ç»™æˆ‘å°½å¯èƒ½çš„ å°‘ åŒ¹é…æ•°å­—â€ findall æ‹¿ç€ è¢«è´ªå©ªåŒ–çš„ è§„åˆ™ å»åŒ¹é…åŸå§‹å­—ç¬¦ä¸² è¢«è´ªå©ªæ¨¡å¼ æé†’è¿‡çš„è§„åˆ™æœç„¶ä¸è´Ÿä¼—æœ›ï¼Œ ä¸€æ¬¡åªæå–ä¸€ä¸ª â€˜3â€˜ findall æ‹¿ç€å®ƒ æå–äº† å…­æ¬¡ ,æ‰æŠŠæ‰€æœ‰æ•°å­—æå–å‡ºæ¥äº† ç»“æœå°±æ˜¯ ['3', '3', '3', '3', '3', '3'] åŒ¹é…æ–¹æ³• match(): ''' match()æ–¹æ³•æ˜¯ æ ¹æ®è§„åˆ™ä»ç¬¬ä¸€ä¸ªå¼€å§‹ï¼Œå‘åé€ä¸ªåŒ¹é…ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå­—ç¬¦åŒ¹é…ä¸ä¸Šï¼Œå°±è¿”å›None ''' s = 'hello python' re1 = re.compile(r'he') re1.match('') result = re1.match(s).group() if re1.match(s) else None # æ³¨æ„ï¼šéNoneæ‰æœ‰groupæ–¹æ³• print(result) # é€šè¿‡ group()æ–¹æ³•è·å¾—çš„æ‰æ˜¯æœ€ç»ˆ æ­£åˆ™åŒ¹é…çš„å­—ç¬¦ä¸² &gt;&gt;&gt; he ç®€å•åˆ†ç»„æå–ï¼š s = 'hello python' re1 = re.compile(r'h(e)llo') # ç»™eåŠ ä¸ªä¸€ä¸ª(),å°±ä»£è¡¨æ·»åŠ äº†åˆ†ç»„ï¼Œä¸€ä¼šè¦æŠŠä»–æå‡ºæ¥ result = re1.match(s).group(1) if re1.match(s) else None # æ³¨æ„ä¸Šæ–¹çš„ group(1) è¿™ä¸ªå‚æ•°æ˜¯1ï¼Œä»£è¡¨ åª æå– åˆ†ç»„ é‡Œé¢çš„å†…å®¹ &gt;&gt;&gt; e # å¦‚æœæ˜¯ group() æˆ– group(0) ä»£è¡¨æå– æ•´ä¸ªæ­£åˆ™è§„åˆ™ çš„å†…å®¹ &gt;&gt;&gt; hello print(result) &gt;&gt;&gt; e åµŒå¥—-å¹³è¡Œï¼ˆæ·±åº¦-å¹¿åº¦ï¼‰åˆ†ç»„æå–ï¼š åŸç†ï¼šåˆ†ç»„æå–å…ˆæå–åµŒå¥—çš„ï¼Œåæå–å¹³è¡Œçš„ (ä¸“ä¸šç‚¹å°±æ˜¯å…ˆæ·±åº¦ï¼Œåå¹¿åº¦) egï¼š a = '123-%%%-dd' result = re.compile(r'123(-(%%%)-)d(d)').match(a).groups() # æˆ–è€…ç”¨ group(1), group(2), group(3) ä»£æ›¿groups() å•ä¸ªçœ‹ä¹Ÿè¡Œ print(result) &gt;&gt;&gt; ('-%%%-', '%%%', 'd') search(): &quot;&quot;&quot; search() æ–¹æ³•æ˜¯ï¼š ä»å‰å‘åæŒ‰è§„åˆ™â€˜æœç´¢â€™, ç›´åˆ°æœåˆ°ä½ç½®ï¼Œæœä¸åˆ°å°±è¿”å›None &quot;&quot;&quot; s = &quot;aaa123aaa&quot; r1 = re.compile(r'\\d+').search(s).group() print(r1) &gt;&gt;&gt; 123 findall(): &quot;&quot;&quot; findall() æ–¹æ³•æ˜¯ï¼š æŒ‰ç…§æ­£åˆ™è§„åˆ™ï¼Œæœç´¢æ‰€æœ‰ç¬¦åˆè§„åˆ™çš„å­—ç¬¦ä¸²ï¼Œä»¥åˆ—è¡¨çš„å½¢å¼ä½œä¸ºç»“æœè¿”å› &quot;&quot;&quot; s = &quot;aaa---123---bbb&quot; r1 = re.compile(r'\\w+').findall(s) print(r1) &gt;&gt;&gt; ['aaa', '123', 'bbb'] å¾®ä¸è¶³é“çš„æ‰©å±•ï¼š a = '123-%%%-dd' result = re.compile(r'-(.*?)-').findall(a) print(result) &gt;&gt;&gt; %%% # è§£é‡Šï¼š findall() æ–¹æ³•ä¸­ å¦‚æœè§„åˆ™ä¸­å«æœ‰åˆ†ç»„ï¼Œé‚£ä¹ˆå°±ä¼šåªè¿”å›åˆ†ç»„ä¸­æå–çš„çš„å†…å®¹ finditer(): &quot;&quot;&quot; finditer() å’Œ findall() ä½¿ç”¨æ–¹å¼ä¸€æ ·ï¼Œåªä¸è¿‡è¿”å›ç»“æœæ˜¯ å¯è¿­ä»£å¯¹è±¡ï¼Œeasy,æ­¤å¤„ä¸åœ¨å¤šè¯´ &quot;&quot;&quot; split(): &quot;&quot;&quot; split()æ–¹æ³•æ˜¯ï¼šæŒ‰ç…§è§„åˆ™å»åˆ‡å‰²ï¼Œåˆ‡å‰²ç»“æœä»¥åˆ—è¡¨çš„æ–¹å¼è¿”å› &quot;&quot;&quot; è¯­æ³•å…³è”ï¼š æˆ‘ä»¬çŸ¥é“å­—ç¬¦ä¸² æœ‰ split() æ–¹æ³•ï¼Œå¯ä»¥æŒ‰ç…§ä¸€ä¸ªå‚æ•°æŸè€—æ¥åˆ‡å‰²ï¼Œä½†æ˜¯è¿™ä¸ªå‚æ•°åªèƒ½æŒ‡å®šä¸€ä¸ª å¦‚æœè®©ä½ åœ¨å¤šç§è§„åˆ™çš„å‰æä¸‹åˆ‡å‰²ï¼Œéœ€è¦æ€ä¹ˆåŠã€‚ å·§äº†ï¼Œæ­£åˆ™åˆ‡å‰²split() æ–¹æ³•å°±æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„ï¼Œ å®ä¾‹å¦‚ä¸‹ï¼š s = &quot;aaa%%123@@bbb&quot; # å¯ä»¥çœ‹è§ï¼Œ%å’Œ@ç¬¦å·æŠŠå­—ç¬¦åˆ†å¼€äº†ï¼Œç°åœ¨æˆ‘ä»¬åªæƒ³è¦å­—ç¬¦ r1 = re.compile(r'\\W+').split(s) # \\W å¤§å†™ï¼š ä»¥éå•è¯æ€§å­—ç¬¦ä½œä¸ºæŸè€—è§„åˆ™ï¼Œæ¥åˆ‡å‰² print(r1) &gt;&gt;&gt; ['aaa', '123', 'bbb'] sub(): &quot;&quot;&quot; sub()æ–¹æ³•æ˜¯ï¼š æŒ‰ç…§è§„åˆ™åŒ¹é…é€‰å‡ºä»£æ›¿æ¢çš„å­—ç¬¦ï¼Œç„¶åè‡ªå·± ç»™å®šå­—ç¬¦å»æ›¿æ¢ &quot;&quot;&quot; åœºæ™¯1ï¼šå¸¸ç”¨æ–¹å¼ï¼Œè‡ªå·±ç»™å®šç›®æ ‡å­—ç¬¦ä¸²ï¼ŒæŒ‰è§„åˆ™åŒ¹é…å¹¶ç›´æ¥æ›¿æ¢åŸå§‹å­—ç¬¦ä¸² eg: s = &quot;aaa%%123@@bbb&quot; r1 = re.compile(r'\\W+').sub('ä½ å¥½',s) print(r1) &gt;&gt;&gt; aaaä½ å¥½123ä½ å¥½bbb åœºæ™¯2ï¼šæ­£åˆ™åŒ¹é…åçš„ç»“æœ ç»è¿‡å‡½æ•°æ“ä½œï¼Œå‡½æ•°çš„è¿”å›å€¼ä½œä¸º æ›¿æ¢çš„æœ€ç»ˆç»“æœ eg: s = &quot;aaa%%123@@bbb&quot; r1 = re.compile(r'\\W+').sub(lambda a:a.group()*2, s) print(r1) &gt;&gt;&gt; aaa%%%%123@@@@bbb è§£é‡Šï¼š æŒ‰ç…§è§„åˆ™åŒ¹é…åˆ°çš„å­—ç¬¦æ˜¯ %%å’Œ@@ï¼Œç»è¿‡å‡½æ•° ä¹˜ä»¥2åï¼Œ å°±æ›¿æ¢æˆäº† %%%%å’Œ@@@@ subn(): &quot;&quot;&quot; subn() å’Œ sub()è¯­æ³•å‡ ä¹ä¸€æ ·ï¼Œå”¯ä¸€çš„æ‰©å±•åŠŸèƒ½å°±æ˜¯ è¿”å›ç»“æœæ˜¯å…ƒç»„ï¼Œ(å­—ç¬¦ä¸², æ¬¡æ•°) &quot;&quot;&quot; s = &quot;aaa%%123@@bbb&quot; r1 = re.compile(r'\\W+').subn('ä½ å¥½',s) print(r1) &gt;&gt;&gt; ('aaaä½ å¥½123ä½ å¥½bbb', 2) ","link":"https://cythonlin.github.io/post/py-greater-python-zheng-ze-quan-jie-xiang-jie/"},{"title":"PY => Pythonå¥½ç”¨æ·±åº¦æŠ€èƒ½å·¥å…·ä»‹ç»","content":"å•å…ƒç´ å…ƒç¥–ï¼š a = (1) # è¿™æ˜¯æ•´æ•°1 a = (1,) # è¿™æ‰æ˜¯å…ƒç¥– ä¹Ÿè®¸è¿™ä¸¤è¡Œï¼Œä½ ä»¬å½“æ—¶ç–‘æƒ‘è¿‡ï¼Œå¹¶ä¸”ç°åœ¨ä¹Ÿéƒ½çŸ¥é“äº†ï¼Œå½“ç„¶é‡ç‚¹å¹¶ä¸åœ¨è¿™é‡Œã€‚ã€‚ æˆ‘æ— èŠçš„æ—¶å€™æƒ³è¿‡ï¼Œä¸ºä»€ä¹ˆå•å…ƒç´ å…ƒç¥–è¦è¿™æ ·è®¾è®¡ -&gt; (1,)? ä¸å¤šåºŸè¯ï¼Œçœ‹ä¸‹é¢ä»£ç ï¼Œè‡ªå·±ç†è§£ï¼š a = (3,) a = (3) a = (1+2) a = (1+2,) a = (1+2) + (3+4) a = (1+2,) + (3+4,) æ³¨ï¼š è¿™æ˜¯æˆ‘ä¸ªäººåŸåˆ›ç†è§£çš„ä¸€ä¸ªå¾®ä¸è¶³é“çš„çŸ¥è¯†ç‚¹ï¼Œä½†æ˜¯å°è±¡å´ç‰¹åˆ«æ·±åˆ»ã€‚ å› ä¸ºæˆ‘åå‘æ¨æµ‹å‡º è®¾è®¡è€…ä¸ºä»€ä¹ˆä¼šè®¾è®¡å‡ºè¿™ç§è¯­æ³•ã€‚ ï¼ˆå½“ç„¶ï¼Œä¹Ÿè®¸æˆ‘çš„æ¨æµ‹å’Œè®¾è®¡è€…å½“æ—¶çš„æƒ³æ³•çš„å¹¶ä¸ä¸€æ ·~~~æ‰‹åŠ¨æ»‘ç¨½ï¼‰ æ·±/æµ…æ‹·è´-copy/deepcopyï¼ˆçš®/è‚‰ï¼‰ &quot;&quot;&quot; æœ€å¼€å§‹æ¥è§¦æ·±æµ…æ‹·è´çš„æ—¶å€™æ²¡å¤ªå¤§æ„Ÿè§‰ï¼Œåªæ˜¯æ™®é€šçš„è§‰å¾—é¿å…æ•°æ®æ±¡æŸ“å°±å¤Ÿäº† åæ¥æœ‰ä¸€æ¬¡ç”¨scrapyå†™çˆ¬è™«çš„æ—¶å€™ï¼Œå±‚æ¬¡å¤ªå¤šå¯¼è‡´å†…å­˜æœ‰äº›é¡¶ä¸ä½ã€‚ åæ¥ç”¨çš„ deepcopy() æ¥ ä¼˜åŒ– scrapy çš„ metaï¼Œ è™½ç„¶æ•ˆæœä¸æ˜¯ç‰¹åˆ«æ˜æ˜¾ï¼Œä½†æ˜¯æ„Ÿè§‰æ·±æµ…æ‹·è´å¾ˆæœ‰ç”¨ &quot;&quot;&quot; ä¸€ã€ =å·ï¼Œä¸æ‹·è´ =å·å°±æ„å‘³ç€ï¼Œå¼•ç”¨æŒ‡å‘åŒä¸€ä¸ªåœ°å€ç©ºé—´ï¼Œâ€˜æ•ŒåŠ¨æˆ‘åŠ¨ï¼Œæ•Œä¸åŠ¨æˆ‘ä¸æ‡‚â€™ çš„æ„Ÿè§‰ã€‚ LOLä¸€å¥è¯:&quot;è¿ä½“å©´å„¿&quot;~~ äºŒã€ copyï¼šä¹Ÿç§°æµ…æ‹·è´ æˆ‘ç”¨æœ€ç®€å•çš„è¯è§£é‡Šä¸€ä¸‹ï¼šæµ…æ‹·è´å°±æ˜¯åªèƒ½æ‹·è´æœ€å¤–é¢çš„ä¸€å±‚çš®ï¼Œæ¥ç‹¬ç«‹å¼€è¾Ÿç©ºé—´ä½¿ç”¨ï¼Œå†æ·±è¿˜æ˜¯å…±ç”¨çš„ from copy import copy from copy import deepcopy a = [[1,2,3],[4,5,6]] b = deepcopy(a) b[0] = 0 # è¿™å°±æ˜¯æœ€å¤–é¢çš„ä¸€å±‚çš® print(b) print(a) ä¸‰ã€ deepcopyï¼šé¡¾åæ€ä¹‰äº†ï¼Œæ·±æ‹·è´ å¦‚æœä½ å¬æ‡‚æˆ‘ä¸Šé¢çš„è¯ï¼Œæˆ‘æ„Ÿè§‰è¿™ä¸ªå°±æ›´å¥½ç†è§£äº†ï¼Œ æµ…æ‹·è´æ˜¯çš®ï¼Œæ·±æ‹·è´é‚£å°±æ˜¯è‚‰äº†å‘—ã€‚ æ²¡é”™ï¼Œæ— è®ºå¥—äº†å‡ å±‚çš„åºåˆ—ç»“æ„ï¼Œæ¯ä¸€å±‚éƒ½æ˜¯ç‹¬ç«‹å¼€è¾Ÿç©ºé—´ï¼Œç‹¬ç«‹æŒ‡å‘ã€‚ from copy import copy from copy import deepcopy a = [[1,2,3],[4,5,6]] b = deepcopy(a) b[0][1] = 0 # çœ‹æ¸…æ¥šï¼Œè¿™å›å°±æ˜¯é‡Œé¢çš„è‚‰äº†ï¼Œ æ·±æ‹·è´ï¼šä½ æ”¹å“ªé‡Œéƒ½è¡Œï¼Œå“ªé‡Œéƒ½ä¸æˆ‘æ— å…³ print(b) print(a) lambdaé»‘ç§‘æŠ€ &quot;&quot;&quot;lambdaç›¸å½“äºåŒ¿åå‡½æ•°ï¼Œå¯ä»¥ä½¿ä»£ç ç®€ä»‹ï¼Œä½†æœ‰æ—¶ä¹Ÿä¼šè¢«äººå”¾å¼ƒï¼Œä½†æˆ‘ä»ç„¶å–œæ¬¢ç”¨lambda&quot;&quot;&quot; 1. è¯•æƒ³ï¼šå¦‚æœä½ æƒ³åœ¨lambdaè°ƒç”¨å¤šä¸ªå‡½æ•°ï¼Œè¯¥å¦‚ä½•å†™ï¼Ÿ lambda: (print(1),print(2)) # æœ€å¤–å±‚åŠ ä¸ªæ‹¬å·å³å¯ 2. å¦‚æœä½ æƒ³è®©è¿™ä¸ª lambdaå‡½æ•°ç›´æ¥è‡ªæ‰§è¡Œï¼Œè€Œä¸æ˜¯é€šè¿‡èµ‹äºˆä¸€ä¸ªå‡½æ•°å¼•ç”¨å†æ‰§è¡Œï¼Ÿ 1. è¿™ä¸ªä¹Ÿæ˜¯æˆ‘è‡ªå·±çé¼“æ£å‡ºæ¥çš„ã€‚ 2. è™½ç„¶æˆ‘JSæ°´å¹³å¾ˆåƒåœ¾ï¼Œä½†æ˜¯æˆ‘çŸ¥é“JSåŒ¿åå‡½æ•°æœ‰ä¸€ç§æ‰§è¡Œæ–¹å¼å«åš â€˜è‡ªæ‰§è¡Œâ€™ã€‚ 3. æŠŠä¸Šé¢ç±»æ¯”ä¸€ä¸‹ã€‚ çœ‹å§ï¼Œè¿™å°±æ˜¯Pythonç‰ˆçš„åŒ¿åå‡½æ•°è‡ªæ‰§è¡Œæ–¹æ³•ã€‚ Pythonç‰ˆæœ¬ï¼š (lambda a:print(a))(1) JSç‰ˆï¼š (function(){})() lambdaçš„è™šä¼ªæ›¿ä»£å“-operator &quot;&quot;&quot; æ®è¯´è¿™ä¸ªæ¨¡å—å¯ä»¥æ›¿ä»£lambdaï¼Œ ä¸ªäººç†è§£æ­¤æ¨¡å—å¹¶ä¸é‚£ä¹ˆå¤ªæœ‰å®ç”¨ä»·å€¼ï¼Œç†è§£æˆæœ¬ä¹Ÿåé«˜ï¼Œ å»ºè®®ï¼šå¦‚æœä¸å–œæ¬¢lambdaæˆ–è€…lambdaç”¨çš„å¾ˆå°‘çš„äººï¼Œå¯ä»¥ç ”ç©¶ä¸€ä¸‹æ­¤æ¨¡å—ã€‚æ­¤æ¨¡å—çš„æ„å›¾è¿˜æ˜¯å¯ä»¥çš„ã€‚ æˆ‘è¿˜æ˜¯å–œæ¬¢ä½¿ç”¨ lambda &quot;&quot;&quot; ç›´æ¥ä¸Šä¸ªä¾‹å­ï¼šï¼ˆå­—å…¸åŸºäºValueæ¥æ’åºï¼‰ ä¼ ç»Ÿlambdaå†™æ³•ï¼š In [27]: a = {'1':6, '2':5, '3':4} In [28]: sorted(a.items(), key=lambda a:a[1]) # çœ‹key= è¿™é‡Œ Out[28]: [('3', 4), ('2', 5), ('1', 6)] operatorå†™æ³•ï¼š from operator import itemgetter In [25]: a = {'1':6, '2':5, '3':4} In [26]: sorted(a.items(), key=itemgetter(1)) # å°±æ˜¯key= è¿™é‡Œæœ‰åŒºåˆ« Out[26]: [('3', 4), ('2', 5), ('1', 6)] å¦‚æœä¸Šé¢ä¸¤ç§æ–°æ—§æ–¹æ³•éƒ½å¾ˆæ¨¡ç³Šï¼Œé‚£ä¹ˆæˆ‘å†è§£é‡Šä¸€ä¸‹ï¼š æˆ‘è®¤ä¸ºä¸Šé¢èƒ½è®©äººå¤´ç–¼çš„ä¹Ÿå°±æ˜¯ ç´¢å¼• 1 äº†ï¼ï¼ï¼ï¼ sorted, mapè¿™ç§é«˜é˜¶å‡½æ•°ï¼Œæˆ‘ä¹‹å‰ä¹Ÿå•ç‹¬è®²è¿‡ï¼Œå®ƒä¼šæŠŠ ä¸€ä¸ªåºåˆ—çš„æ¯ä¸€ä¸ªå…ƒç´ ç”¨ç®¡é“å‡½æ•°è¿›è¡Œæ˜ å°„ã€‚ sortedç¨å¾®ç‰¹æ®Šä¸€ç‚¹ï¼Œå®ƒçš„ç®¡é“å‡½æ•°æ–¹æ³•å˜æˆäº†key=è¿™é‡Œï¼š (å˜ç›¸ç†è§£ä¸º æŒ‡å®šæ’åºçš„åŸºå‡†/å‚è€ƒ) 1. key=lambda a:a[1] æŒ‡å®šåŸºå‡†ï¼šåºåˆ—açš„ æ¯å­å…ƒç´  çš„ ç¬¬1å·ç´¢å¼•å­å…ƒç´  # egï¼š [[1,2],[3,4],[5,6]] å°±æ˜¯2,4,6 2. key=itemgetter(1) æŒ‡å®šåŸºå‡†ï¼šåŒä¸Šä¸€æ¨¡ä¸€æ ·ï¼Œåªä¸è¿‡å†™æ³•ä¸ä¸€æ ·ï¼Œé€»è¾‘æ­¥éª¤å°±æ˜¯ åŸåŸæœ¬æœ¬ä» lambdaé‚£é‡Œæ¼”å˜è¿‡æ¥çš„ã€‚ æ€»ç»“ä¸ä¸ªäººè§‚ç‚¹ï¼š 1. operator æ¨¡å—åªæ˜¯ lambda ä½¿ç”¨æ€æƒ³ çš„ é«˜ä¸€å±‚çš„å°è£… 2. è®©ä½¿ç”¨è€…å¯ä»¥å¿½ç•¥lambdaæ ¼å¼ç»†èŠ‚ 3. ä½†æ˜¯æˆ‘è®¤ä¸º å¦‚æœlambdaéƒ½ç”¨ä¸å¥½ï¼Œ é‚£ä¹ˆ è¿™ä¸ª itemgetter(1) è¿™ç§å­å…ƒç´  ç´¢å¼•çš„æŒ‡å®š ä¹Ÿä¼šå¾ˆå›°éš¾ 4. æ‰€ä»¥æˆ‘è¿˜æ˜¯å»ºè®®ç”¨ lambda, å½“ä½  lambdaæ€æƒ³ç»ƒç†Ÿäº†ä¹‹åï¼Œ ç”¨ operatorçœ‹çœ‹å®˜æ–¹æ–‡æ¡£å°±æ˜¯å¾ˆå¿«çš„äº‹æƒ… å°åŒ…/æ‹†åŒ…(è§£æ„èµ‹å€¼)/å‡½æ•°å ä½å‚æ•°éªšæ“ä½œ &quot;&quot;&quot; å†æ¬¡è¯´æ˜ä¸€ä¸‹ï¼šæˆ‘å†™çš„æ‰€æœ‰çš„éƒ½æ˜¯Py3çš„/ Py2çš„è§£æ„èµ‹å€¼å¯èƒ½æœ‰äº›å‡ºå…¥ï¼Œæ­¤å¤„æˆ‘åªè¯´Py3 &quot;&quot;&quot; å°åŒ…ï¼š 1ï¼‰ def f(a,*b): print(a) # 1 print(b) # (2,3,4) f(1,2,3,4) 2ï¼‰ def f(**kwargs): print(kwargs) # {'a': 3, 'b': 4} f(**dict(a=3,b=4)) æ‹†åŒ…ï¼ˆè§£æ„èµ‹å€¼ï¼‰ï¼š &quot;&quot;&quot; æˆ‘è¯´è¿‡å¤ªå¤šæ¬¡äº†ï¼Œ ES6çš„è¯­æ³•å’ŒPythonå¾ˆåƒã€‚è§£æ„èµ‹å€¼è¿™ä¸ªè¯ä¹Ÿæ˜¯ä»ES6å¬åˆ°çš„ã€‚ ä¸è¿‡ES6çš„è§£æ„ï¼Œè¿˜å¯ä»¥è§£æ„ {} å’Œ è§£æ„ç©ºå€¼ å’Œ è§£æ„é»˜è®¤å€¼, è€ŒPythonä¸å¯ä»¥ &quot;&quot;&quot; 1) åªè¦ç¬¬ä¸€ä¸ª a, *_ = range(5) print(a, _) # 0 [1, 2, 3, 4] 2) åªè¦ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ª a, *_, c = range(5) print(a, _, c) # 0 [1, 2, 3] 4 3) åªè¦æœ€åä¸€ä¸ª *_, b = range(5) print(_, b) # [0, 1, 2, 3] 4 å‡½æ•°å ä½å‚æ•°éªšæ“ä½œï¼š &quot;&quot;&quot; è¿™æ˜¯æˆ‘åœ¨æºç ä¸­çœ‹åˆ°çš„ï¼Œå½“æ—¶è§‰å¾—å¾ˆæƒŠè®¶ï¼Œè‡ªå·±è¯•äº†ä¸€ä¸‹ï¼Œä¸‹é¢è¯´ä¸‹è‡ªå·±çš„ç†è§£: è¿™ä¸ª*çš„ä½œç”¨å°±æ˜¯ï¼š ï¼ˆ*åé¢çš„å‚æ•°æ˜¯ è°ƒç”¨æ—¶ å¿…é¡»å‘½å ä¸” å¿…é¡»ä¼ é€’ çš„å‚æ•°ï¼‰ aä½ å¿…é¡»ç»™æˆ‘ä¼ è¿‡æ¥ï¼Œä½†æ˜¯ä½ ä¸å†™ a= bä½ å¿…é¡»ç»™æˆ‘ä¼ è¿‡æ¥ï¼Œä½†æ˜¯ä½ å¿…é¡»å†™ b= &quot;&quot;&quot; def f(a,*,b): print(a) print(b) f(1,b=3) # f(a=1,b=3) # åªèƒ½é€šè¿‡è¿™ä¸¤ç§æ–¹å¼è°ƒç”¨ åå°„-getattr &amp; setattr &amp; hasattr &amp; delattr &amp; import_module ç»¼åˆä¾‹å­: from importlib import import_module random = import_module('random') # åŠ¨æ€åå°„å¯¼å…¥æ¨¡å— # æˆ– random = __import__('random') if hasattr(random, 'randint'): # æ£€æµ‹æ¨¡å—ä¸­æ˜¯å¦æœ‰å‡½æ•° randint = getattr(random,'randint') # åŠ¨æ€åå°„å¯¼å…¥å‡½æ•° print(eval('randint(0,1)')) # å­—ç¬¦ä¸²è½¬è¯­å¥æ‰§è¡Œï¼ˆç±»ä¼¼åå°„ï¼‰ getattr &amp; setattr &amp; hasattr &amp; delattr è®²è§£ï¼š hasattr &amp; getattr random = __import__('random') if hasattr(random,'randint'): # æ£€æµ‹ random æ¨¡å—ä¸­æ˜¯å¦æœ‰ randint å‡½æ•° randint = getattr(random,'randint') print(randint(0,1)) delattr &amp; hasattr delattr(random, 'randint') # åŠ¨æ€åˆ é™¤æ¨¡å—ä¸­çš„ randintå‡½æ•° if not hasattr(random,'randint'): print('æ²¡æœ‰æ­¤å‡½æ•°äº†ï¼Œè®©delattråˆ é™¤äº†') setattr &amp; getattr # åŠ¨æ€é‡æ–°è®¾ç½®æ¨¡å—çš„ randintå‡½æ•°ï¼Œå¹¶ç»™ä¸ªå‡½æ•°ä½“ setattr(random, 'randint', lambda:print('è®¾ç½®è¿™ä¸ªæ–¹æ³•å‡‘åˆç”¨æŠŠã€‚')) randint = getattr(random, 'randint') randint() æ¨¡å—é‡æ–°å¯¼å…¥åˆ°å†…å­˜-reload from imp import reload import time reload(time) print(time.time()) è¿›åº¦æ¡-tqdm for x in tqdm(range(100)): import time time.sleep(1) print(x) tqdmåŒ…è£…ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œ åªæ˜¯è£…é¥°äº†ä¸€ä¸‹ï¼Œä½¿ç”¨æ–¹æ³•è¿˜æ˜¯åƒåŸæ¥ä¸€æ ·ä½¿ç”¨ã€‚ ç¥¨æ•°ç»Ÿè®¡-Counter In [2]: from collections import Counter In [3]: Counter([1,2,3,4]) Out[3]: Counter({1: 1, 2: 1, 3: 1, 4: 1}) In [4]: Counter([1,1,1,2,2,3]) # ç»Ÿè®¡é¢‘æ¬¡ Out[4]: Counter({1: 3, 2: 2, 3: 1}) In [5]: Counter([1,1,1,2,2,3]).most_common(1) # é¢‘æ¬¡æœ€å¤šçš„å‰1ä¸ª Out[5]: [(1, 3)] æ–‡ä»¶ å¤åˆ¶/ç§»åŠ¨-shutil import shutil shutil.copy(æºï¼Œç›®æ ‡) # å¤åˆ¶ shutil.move(æºï¼Œç›®æ ‡) # ç§»åŠ¨ï¼Œæ”¹å shutil.rmtree(r'ç›®å½•å') # åˆ é™¤ç›®å½•ï¼ˆçº§è”åˆ é™¤ï¼‰ # å‚æ•°åªèƒ½æ˜¯ç›®å½• æ–‡ä»¶éå†-os.walk &quot;&quot;&quot; os.walk() æ˜¯ä¸€ä¸ªæ·±åº¦éå†æ¨¡å¼çš„æ–‡ä»¶éå†å‡½æ•° è¿”å›å€¼æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œéå†è¿™ä¸ªè¿­ä»£å™¨åï¼Œæ¯ä¸€æ¬¡çš„è¿”å›å€¼éƒ½æ˜¯å¦‚ä¸‹é¡ºåºä¸‰ç§æ„æˆ 1. current_path: å½“å‰è·¯å¾„ 2. dir_list: å…¶ä¸‹ç›®å½•åˆ—è¡¨ 3. file_list: å…¶ä¸‹æ–‡ä»¶åˆ—è¡¨ &quot;&quot;&quot; import os file_generator = os.walk('D:/è™šæ‹ŸEç›˜-ä»£ç ç©ºé—´/TF2') for current_dir, dir_list, file_list in file_generator: print(current_dir, dir_list, file_list) éé˜»å¡æ‰§è¡Œcmd/shell-subprocess &quot;&quot;&quot; ä¸»è¦ä»£æ›¿os.system &quot;&quot;&quot; import subprocess res = subprocess.run('dir', shell=True, stdout=subprocess.PIPE) # ç»“æœè¾“å…¥åˆ°resç®¡é“ä¸­å» print(res.stdout.decode('gbk')) # resç®¡é“ä¸­æœ‰è¾“å‡ºæ—¥å¿—ï¼Œå¦‚æœåœ¨winä¸‹ï¼Œéœ€è¦ decode æ’åˆ—ç»„åˆ-itertoolsæ¨¡å— import itertools list(itertools.product([1,2,3],repeat=3)) # å¤åˆ¶3ä»½æœ‰åºå…¨æ’åˆ—ï¼Œ repeat=3 list(itertools.permutations([1,2,3], 3)) # å†…éƒ¨æœ‰åºæ’åˆ—ï¼Œ 3è¡¨ç¤ºæœ€åæ’åˆ—ä¸ºå‡ ä½ list(itertools.permutations([1,2,3,4],3)) # æ— åºç»„åˆï¼Œ 3è¡¨ç¤º3ä½ æšä¸¾-emunerate In [100]: list(enumerate(list('abcde'),start=1)) # é»˜è®¤ä»0ï¼Œå¼€å§‹æ ‡å·ï¼Œ start=1å°±ä»1å¼€å§‹ Out[100]: [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e')] In [108]: list(enumerate(((1,2),(3,4)))) Out[108]: [(0, (1, 2)), (1, (3, 4))] In [106]: list(enumerate({&quot;a&quot;:'c','b':'d'})) Out[106]: [(0, 'a'), (1, 'b')] global &amp; nonlocal &amp; globals() &amp; locals() global: å‡½æ•°å¤–çš„å˜é‡åªèƒ½åœ¨å‡½æ•°å†…éƒ¨å–å€¼ï¼Œè€Œä¸èƒ½ä¿®æ”¹ï¼Œ å¦‚æœæƒ³è¦åœ¨å‡½æ•°å†…éƒ¨ä¿®æ”¹å¤–éƒ¨å˜é‡, â€˜global å˜é‡åâ€™ å³å¯ a = 1 def f(): global a a += 1 print(a) f() nonlocal: åŸç†åŒä¸Šä¸€æ¨¡ä¸€æ ·ï¼Œåªä¸è¿‡åº”ç”¨åœºæ™¯æ˜¯é—­åŒ…äº†ï¼Œä»£ç å¦‚ä¸‹ï¼š def f(): a = 1 def f1(): nonlocal a a = a+1 print(a) f1() f() æ—¥å†-calendar import calendar calendar.calendar(2019) # è¿”å›2019å¹´çš„æ—¥å† calendar.month(2919,5) # è¿”å›2019å¹´5æœˆçš„æ—¥å† calendar.isleap(2000) # åˆ¤æ–­2000å¹´æ˜¯å¦ä¸ºé—°å¹´ æ—¶é—´/æ—¥æœŸ-time/datetime import time 1. æ—¶é—´æˆ³ï¼š time.time() 2. å­—ç¬¦ä¸²è½¬æ—¶é—´(p-passæ–¹ä¾¿è®°å¿†) from datetime import datetime fordate = datetime.strptime('2019-5-25 9:30:30', '%Y-%m-%d %H:%M:%S') print(fordate) 3. æ—¶é—´è½¬å­—ç¬¦ä¸²(f-fromæ–¹ä¾¿è®°å¿†) from datetime import datetime strdate = datetime.strftime(fordate, '%Y-%m-%d %H:%M:%S') print(strdate) 4. åˆå§‹åŒ–æ—¶é—´ from datetime import datetime dt1 = datetime(2019,5,25,9,37) # åˆå§‹åŒ–æ—¶é—´ä¸º datetimeæ ¼å¼ dt1 = datetime.now() # è·å–å½“å‰æ—¶é—´ä¸º datetimeæ ¼å¼ print(dt1.year) print(dt1.month) print(dt1.day) print(dt1.hour) print(dt1.minute) print(dt1.second) retryingæ¨¡å— &quot;&quot;&quot; retryingæ¨¡å—çš„retryæ˜¯ä¸ªè£…é¥°å™¨ è¢«è£…é¥°çš„å‡½æ•°ä¼šæ‰§è¡Œå¦‚ä¸‹åŸºæœ¬æ“ä½œï¼š å¦‚æœæ­¤å‡½æ•°å†…éƒ¨ä»£ç  æ— å¼‚å¸¸ï¼Œ é‚£ä¹ˆ retryè£…é¥°å™¨ ä¸èµ·åˆ°ä»»ä½•ä½œç”¨ å¦‚æœæ­¤å‡½æ•°å†…éƒ¨ä»£ç  æ— å¼‚å¸¸ï¼Œ é‚£ä¹ˆ retryè£…é¥°å™¨ ä¼šä¸€ç›´åå¤æ‰§è¡Œè¿™ä¸ªå‡½æ•° ç›´åˆ°æ— å¼‚å¸¸ï¼Œæ‰æ‰§è¡Œä¸‹é¢çš„ä»£ç ï¼ˆæ‰æ”¾ä½ èµ°ï¼‰ å¦‚æœä½ è¿™ä¸ªç¨‹åºå‹æ ¹å°±æ˜¯ä¸ªé”™è¯¯ç¨‹åºï¼Œé‚£ä¹ˆä¸å¥½æ„æ€ï¼Œæ…¢æ…¢ç­‰ï¼Œç­‰åˆ°æ­»å§ã€‚ã€‚ã€‚ã€‚ã€‚ æ‰€ä»¥è¯´åˆ°åº•ï¼Œretryè£…é¥°å™¨ çš„è®¾è®¡ç›®çš„å°±æ˜¯ï¼ˆç±»ä¼¼ è½®è¯¢/å›è°ƒé‚£ç§æ€æƒ³ï¼‰ï¼š å¸Œæœ›ä½ è¿™ä¸ªå‡½æ•°æ‰§è¡Œ å‡ºç°å¼‚å¸¸ï¼Œä½†æ­¤å¼‚å¸¸ä¼šé€šè¿‡ç¨‹åºä¹‹å¤–çš„å› ç´ æ¥æ§åˆ¶ï¼Œè‡³æ— å¼‚å¸¸ä¸ºæ­¢ å½“ç„¶è®¾è®¡è€…å¹¶ä¸ä¼šè‹¦è‹¦ç›¸é€¼çš„ã€‚ã€‚ ä»–ä¸ä¼šè®©ä½ ç­‰åˆ°æ­»ï¼Œ ä½ ä¹Ÿå¯ä»¥é€šè¿‡æ‰‹åŠ¨è®¾ç½®å‚æ•°æ¥è‡ªå·±æ§åˆ¶å¼‚å¸¸ è¿™é‡Œæˆ‘å°±è¯´2ä¸ªå¸¸ç”¨çš„å‚æ•°ï¼š stop_max_attempt_number = 10000 # æ­¤å‚æ•°å°±æ˜¯ä¼š è‡ªåŠ¨æ‰§è¡Œè¿™ä¸ªå‡½æ•° 10000æ¬¡ 10000æ¬¡ä¹‹å†…ï¼Œå¦‚æœæœ‰æœ‰ä¸€æ¬¡ï¼Œå‡½æ•°é¡ºåˆ©æ‰§è¡Œï¼Œæ— å¼‚å¸¸ï¼Œé‚£ä¹ˆç»§ç»­æ‰§è¡Œä¸‹é¢çš„ä»£ç (æ”¾è¡Œ) 10000æ¬¡ä¹‹å†…ï¼Œå…¨éƒ¨éƒ½æ˜¯å¼‚å¸¸ï¼Œä¸å¥½æ„æ€ï¼Œ æˆ‘ä¹Ÿä¸ç­‰ä½ äº†ï¼Œç›´æ¥æŠ›å‡ºä¸€ä¸ªå¼‚å¸¸ï¼Œç¨‹åºç»ˆæ­¢ stop_max_delay = 20*1000, # æ­¤å‚æ•°å°±æ˜¯ä¼š ç­‰ä½  20*1000 æ¯«ç§’ ==== 20ç§’ 20ç§’ä¹‹å†…ï¼Œ å¦‚æœèƒ½é¡ºåˆ©æ‰§è¡Œæ­¤å‡½æ•°ï¼Œ ç»§ç»­æ‰§è¡Œä¸‹é¢ç¨‹åºï¼ˆæ”¾è¡Œï¼‰ 20ç§’ä¹‹å†…ï¼Œ å…¨éƒ½æ˜¯å¼‚å¸¸ï¼Œ æŠ›å‡ºå¼‚å¸¸ï¼Œç¨‹åºç»ˆæ­¢ è¿™ä¸¤ä¸ªå‚æ•°ä¹Ÿå¯ä»¥è”ç”¨ å…·ä½“è¯­æ³•è§ä¸‹æ–¹ä»£ç  &quot;&quot;&quot; pip install retrying from retrying import retry # æœ€å¤šç­‰ä½ æ‰§è¡Œ 10000æ¬¡ï¼Œ æœ€å¤šç­‰ä½ æ‰§è¡Œ 20ç§’ï¼Œ è¿˜è¿ä¸ä¸Šï¼Œå°±æ»šè›‹ï¼Œç¨‹åºæŠ›å¼‚å¸¸ç»ˆæ­¢ã€‚ @retry( stop_max_attempt_number = 10000, stop_max_delay = 20*1000, ) def verify_request(): response = requests.get(&quot;http://selenium:4444&quot;, timeout=0.5) print(response) verify_request() æ³¨ï¼šæ—¶é—´ å’Œ æ¬¡æ•°è¿™ä¸¤ä¸ªå‚æ•°è”åˆç”¨ï¼Œå“ªä¸ªå‚æ•°å…ˆè¾¾åˆ°è®¾å®šå€¼ï¼Œ å°±æŒ‰å“ªä¸ªä¼˜å…ˆåœæ­¢ç¨‹åºã€‚ å¦‚æœå¯¹è¿ä¸ªè”åˆå‚æ•° æœ‰æ¬¡åºç–‘é—®ï¼Œå¯ç”¨å¦‚ä¸‹ä»£ç è‡ªå·±è°ƒèŠ‚æµ‹è¯•ï¼š from retrying import retry a = 1 @retry( stop_max_attempt_number = 10000000, stop_max_delay = 3*1000 ) def f(): global a print(a) a+=1 1/0 f() å…¶å®è¿˜æœ‰å¾ˆå¤šå‚æ•°ï¼Œä¸ç®—å¤ªå¸¸ç”¨ï¼Œæ„Ÿå…´è¶£å¯ä»¥çœ‹çœ‹ï¼š https://github.com/rholder/retrying ","link":"https://cythonlin.github.io/post/py-greater-python-hao-yong-shen-du-ji-neng-gong-ju-jie-shao/"},{"title":"PY => Python__é»‘é­”æ³•__","content":"ç±»çš„ç»§æ‰¿ ç±»ç»§æ‰¿æœ‰ä¸‰ç§è°ƒç”¨æ–¹å¼ï¼Œå…¶å®æ˜¯ æœ‰åŒºåˆ« çš„ï¼Œå¬æˆ‘æ…¢æ…¢é“æ¥ class A: def say(self, name): print(f'Im {name}') class B(A): def say(self, name): # ç¬¬ä¸€ç§ï¼šçˆ¶ç±».æ–¹æ³•(self, å‚æ•°) ç›´æ¥è°ƒç”¨ A.say(self, name) def say(self, name): # ç¬¬äºŒç§ï¼šsuper().æ–¹æ³•(å‚æ•°) ç›´æ¥è°ƒç”¨ # åœ¨è°çš„ç±»ä¸‹è°ƒç”¨superï¼Œå°±æ‰¾æ­¤ç±»å¯¹åº” mro()çš„ä¸‹ä¸€ä¸ª,å°±æ˜¯è¦ç»§æ‰¿çš„ super().say(name) def say(self, name): # ç¬¬ä¸‰ç§ï¼šsuper(B, self).æ–¹æ³•(å‚æ•°) # æ‰¾ç±»å å¯¹åº”çš„ mro()çš„ä¸‹ä¸€ä¸ªï¼Œå°±æ˜¯ ç»§æ‰¿çš„ï¼Œä¸€èˆ¬å†™æœ¬èº«çš„ç±»å super(B, self).say(name) B().say('Tom') ä¸Šä¸‹æ–‡ç®¡ç†å™¨ &quot;&quot;&quot; ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯ä»¥ç”¨ä¸¤ç§æ–¹å¼å®ç°ï¼š &quot;&quot;&quot; æ–¹å¼1ï¼šé€šè¿‡ç±»æ¥å®ç° ä¸»è¦å®ç°ä¸¤ç§åè®® 1. __enter__(self) 2. __exit__(self, *args, **kwargs) class A(): def __init__(self, name): self.name = name def __enter__(self): print('è¿›å…¥') return self def __exit__(self, *args, **kwargs): print('é€€å‡º') return True with A('Tom') as a: print(a.name) æ–¹å¼2ï¼šé€šè¿‡å‡½æ•°æ¥å®ç° from contextlib import contextmanager @contextmanager def f(): print('å¼€å§‹') # yield ä¹‹å‰ å¯¹åº” with f() yield 'ä¸­é—´' # yield çš„å€¼ å°±æ˜¯ as ä¹‹åçš„å€¼ print('ç»“æŸ') # yield ä¹‹å å¯¹åº” print(str1) è¿™ä¸ªè¯­å¥ä½“ with f() as str1: print(str1) ------------------Output---------------------- å¼€å§‹ ä¸­é—´ ç»“æŸ å±æ€§æè¿°ç¬¦-property-setter class A: @property def name(self): return '123' @name.setter def name(self, value): self.age=value a = A() print(a.name) a.name = '456' print(a.age) init() å®ä¾‹åŒ–å¯¹è±¡æ—¶è‡ªåŠ¨è°ƒç”¨ï¼Œè¿™é‡Œå…ˆå–ä¸ªå…³å­ï¼Œè§ä¸‹é¢ __new__() call() &quot;&quot;&quot; å¯¹è±¡å½“åšå‡½æ•°æ‰§è¡Œçš„æ—¶å€™ä¼šè‡ªåŠ¨è°ƒç”¨ __call__() &quot;&quot;&quot; class A(): pass a = A() # æ­¤å¤„è‡ªåŠ¨è°ƒç”¨äº† __init__() a() # æ­¤å¤„è‡ªåŠ¨è°ƒç”¨äº† __call__() str() &quot;&quot;&quot; å¯¹å¯¹è±¡è¿›è¡Œprintæ“ä½œçš„æ—¶å€™ ä¼šè‡ªåŠ¨è°ƒç”¨ __str__() &quot;&quot;&quot; class A: def __str__(self): return '5' a = A() print(a) # æ­¤å¤„è‡ªåŠ¨è°ƒç”¨äº† __str__() new() &quot;&quot;&quot; ä¸Šé¢è¯´è¿‡ __init__()æ˜¯å®ä¾‹åŒ–å¯¹è±¡çš„æ—¶å€™è‡ªåŠ¨è°ƒç”¨ï¼Œåœ¨å®ƒä¹‹å‰è¿˜éšå¼è°ƒç”¨äº† __new__() __new__è¿”å›çš„æ˜¯ä»€ä¹ˆï¼Œå¯¹è±¡å°±æ˜¯ä»€ä¹ˆ &quot;&quot;&quot; In [2]: class A: ...: def __new__(self): ...: print('__new__') # åˆå§‹åŒ–å¯¹è±¡åªè°ƒç”¨ __new__ è€Œä¸è°ƒç”¨ __init__ ...: return 1 ...: def __init__(self): ...: print(2) ...: print(A()) __new__ 1 setattr() å’Œ getattr() å’Œ delattr() &quot;&quot;&quot; __setattr__()ï¼š=å· å±æ€§èµ‹å€¼ ä¼šè‡ªåŠ¨è°ƒç”¨æ­¤æ–¹æ³• __getattr__()ï¼š.å· å±æ€§å–å€¼ ä¼šè‡ªåŠ¨è°ƒç”¨æ­¤æ–¹æ³• # æ³¨ï¼šæ‰¾ä¸åˆ°å±æ€§æ‰ä¼šè°ƒç”¨æ­¤æ–¹æ³• __delattr__()ï¼šdel å±æ€§åˆ é™¤ ä¼šè‡ªåŠ¨è°ƒç”¨æ­¤æ–¹æ³• &quot;&quot;&quot; class A: def __init__(self, name): self.name = name # èµ‹å€¼æ“ä½œå°±ä¼šè°ƒç”¨ __setattr__() def __setattr__(self, name, value): print(f'{name}:{value}') def __getattr__(self, name): print(name) def __delattr__(self,name): print('deläº†') a = A('Jack') # è°ƒç”¨äº† __init__ a.name = 'Tom' # èµ‹å€¼æ“ä½œå†æ¬¡è°ƒç”¨ __setattr__() a.name # å–å€¼æ“ä½œè°ƒç”¨ __getattr__() ---------------------output--------------------- name:Jack name:Tom name deläº† getattribute() &quot;&quot;&quot; å’Œ __getattr__() ä¸€æ ·ï¼Œåªä¸è¿‡ __getattribute__æœ€å…ˆè°ƒç”¨ï¼Œå¹¶æ‹¦æˆªäº† __getattr__() &quot;&quot;&quot; class A: def __init__(self): self.name = 1 def __getattr__(self,x,*args, **kwargs): print(456) def __getattribute__(self, x): print(123) a = A() a.aaaaaa -----------output--------------- 123 getitem() &quot;&quot;&quot; å¯¹å¯¹è±¡è¿›è¡Œ åˆ‡ç‰‡ã€ç´¢å¼•ã€éå† ç­‰ ä¼šè‡ªåŠ¨è°ƒç”¨æ­¤æ–¹æ³• &quot;&quot;&quot; class A: def __getitem__(self,x,*args, **kwargs): return x a = A() è§¦å‘æ–¹å¼1ï¼š å¦‚æœç›´æ¥ç´¢å¼•æ­¤å¯¹è±¡ï¼Œé‚£ä¹ˆç´¢å¼•å€¼å°±ä¼šä¼ é€’åˆ°ä¸Šé¢ x å½“ä½œå‚æ•° print(a[5]) &gt;&gt; 5 è§¦å‘æ–¹å¼2ï¼š å¦‚æœç›´æ¥åˆ‡ç‰‡æ­¤å¯¹è±¡ï¼Œé‚£ä¹ˆsliceå¯¹è±¡ å°±ä¼šä¼ é€’åˆ°ä¸Šé¢ x å½“ä½œå‚æ•° print(a[1:5]) &gt;&gt; slice(1, 5, None) è§¦å‘æ–¹å¼3ï¼š å¦‚æœforå¾ªç¯è¿­ä»£æ­¤å¯¹è±¡ï¼Œé‚£ä¹ˆ ä¸Šé¢çš„ x æ¯æ¬¡å°†ä¼šè¢«èµ‹äºˆä»é›¶å¼€å§‹ è‡ªå¢1çš„è‡ªç„¶æ•´æ•° for x in a: print(x) &gt;&gt; 0,1,2,3,4.................... init_subclassï¼ˆï¼‰ &quot;&quot;&quot; è¢«ç»§æ‰¿çš„ç±» ä¼šè‡ªåŠ¨è°ƒç”¨__init_subclass__ &quot;&quot;&quot; class A: def __init_subclass__(self): print('æˆ‘è¢«ç»§æ‰¿äº†') class B(A): pass baseï¼ˆï¼‰ &quot;&quot;&quot; æŸ¥çœ‹åŸºç±» &quot;&quot;&quot; class A: pass class B(A): pass print(B.__base__) -----------output--------------- &lt;class '__main__.A'&gt; contains() &quot;&quot;&quot; xx in xx å°±ä¼šè‡ªåŠ¨è°ƒç”¨ __contains__() &quot;&quot;&quot; ","link":"https://cythonlin.github.io/post/py-greater-python__-hei-mo-fa-__/"},{"title":"PY => Pythonä¸‰ç¨‹","content":"GILçš„ç†è§£ GILè¿™ä¸ªè¯é¢˜è‡³ä»Šä¹Ÿæ˜¯ä¸ªäº‰è®®è¾ƒå¤šçš„ï¼Œå¯¹äºä¸ç”¨åº”ç”¨åœºæ™¯å¯¹çº¿ç¨‹çš„éœ€æ±‚ä¹Ÿå°±ä¸åŒï¼Œè¯´ä¸‹æˆ‘å¬è¿‡çš„ä¼˜ç‚¹ï¼š 1. æˆ‘æ²¡æœ‰ç”¨è¿‡å…¶ä»–è¯­è¨€çš„å¤šçº¿ç¨‹ï¼Œæ‰€ä»¥æ— æ³•æ¯”è¾ƒä»€ä¹ˆï¼Œä½†æ˜¯å¯¹äºI/Oè€Œè¨€ï¼ŒPythonçš„çº¿ç¨‹è¿˜æ˜¯æ¯”è¾ƒé«˜æ•ˆçš„ã€‚ 2. æœ‰äº›ç¬¬ä¸‰æ–¹åŸºäºPythonçš„æ¡†æ¶å’Œåº“ï¼Œæ¯”å¦‚Tensorflowç­‰åŸºäºC/C plus plusé‡å†™çš„Pythonçº¿ç¨‹æœºåˆ¶ã€‚ 3. è‡³äºæ¢æˆCythonç¼–è¯‘å™¨è§£å†³GILï¼Œè¿™ä¸ªåªæ˜¯å¬è¿‡ï¼Œæ²¡ç”¨è¿‡ã€‚ 4. Pythonå¤šçº¿ç¨‹å¯¹äºwebã€çˆ¬è™«æ–¹é¢ä¹Ÿå¯ä»¥è¡¨ç°å‡ºè¾ƒå¥½çš„æ€§èƒ½ã€‚ 5. Pythonå¤šè¿›ç¨‹æ˜¯å®Œå¥½çš„ï¼Œå¯ä»¥æŠŠèµ„æºæ¶ˆè€—è¾ƒå°‘çš„éå¿…è¦çº¿ç¨‹å·¥ä½œè½¬ä¸ºå¤šè¿›ç¨‹æ¥å·¥ä½œã€‚ 6. è®¡ç®—å¯†é›†å‹å°±åˆ«æƒ³å¤šçº¿ç¨‹äº†ï¼Œä¸€å¾‹å¤šè¿›ç¨‹ã€‚ 7. Pythonè¿˜æœ‰ç»†ç²’åº¦ä¸”é«˜æ•ˆçš„åç¨‹ã€‚ 8. å¦‚æœæœ‰Næ ¸CPUï¼Œé‚£ä¹ˆåŒæ—¶å¹¶è¡Œçš„è¿›ç¨‹æ•°å°±æ˜¯Nï¼Œæ¯ä¸ªè¿›ç¨‹é‡Œé¢åªæœ‰ä¸€ä¸ªçº¿ç¨‹èƒ½æŠ¢åˆ°å·¥ä½œæƒé™ã€‚ æ‰€ä»¥åŒä¸€æ—¶åˆ»æœ€å¤§çš„å¹¶è¡Œçº¿ç¨‹æ•°=è¿›ç¨‹æ•°=CPUçš„æ ¸æ•°ï¼ˆè¿™æ¡æˆ‘çš„ä¸ªäººç†è§£å¾ˆæ¨¡ç³Šï¼Œå‚è€ƒå§ï¼‰ å¤šçº¿ç¨‹ å¤šçº¿ç¨‹æœ‰2ç§é€šè¿‡startçš„é‚£ç§æ–¹å¼ï¼Œéå¸¸æ™®éï¼Œæ­¤å¤„å°±ä¸å†™äº†ã€‚ æ–°ç‰ˆçº¿ç¨‹æ±  futureåº“ æ˜¯python3.2æ–°å‡ºçš„åŠŸèƒ½ï¼ˆè®°ä½è¿™ä¸ªfutureï¼‰ æ–¹å¼1ï¼šï¼ˆsublimeè¿è¡Œåç›´æ¥è´´ä¸Šæ¥äº†ï¼‰ from time import sleep from concurrent.futures import ThreadPoolExecutor,as_completed,ALL_COMPLETED,wait executor = ThreadPoolExecutor(max_workers=10) # åˆå§‹åŒ–çº¿ç¨‹æ± 10ä¸ªå‘ def f(): sleep(15) return 100 all_tasks = [executor.submit(f) for _ in range(10)] # æäº¤10ä¸ªçº¿ç¨‹ï¼Œå…¨æ”¾æ± é‡Œæ‰§è¡Œ # for per_thread in as_completed(all_tasks): # print(per_thread.result()) ---------# æ³¨æ„ä¸Šé¢ï¼Œas_completed(all_tasks) æ˜¯ç­‰å¾…futureå¯¹è±¡å®Œæˆåæ‰æ‰§è¡Œä¸»çº¿ç¨‹ ---------# æ³¨æ„ä¸‹é¢ï¼Œwaitå’Œ as_completed() çš„ ä½œç”¨ä¸€æ ·ï¼Œå°±å’Œæ™®é€šç‰ˆçš„join() ç›¸ä¼¼ for per_thread in all_tasks: print(per_thread.result()) wait(all_tasks, return_when=ALL_COMPLETED) # è¿˜å¯ä»¥é€‰FIRST_COMPLETEDï¼Œå¾…ç¬¬ä¸€ä¸ªå®Œæˆå print('ä¸»çº¿ç¨‹') æ–¹å¼2ï¼š mapå¤šçº¿ç¨‹ç‰ˆ value_list = executor.map(func, list(range(10))) # è¿”å›çš„ç›´æ¥æ˜¯mapåçš„åºåˆ— for value in value_list: print(value) æ³¨æ„ï¼š è¿™ä¸ªmapæ–¹å¼ï¼Œå¦‚æœè¦ä¼ å¤šä¸ªå‚æ•°å°±æ¶‰åŠåˆ°é«˜é˜¶å‡½æ•°é‚£èŠ‚è®²çš„åå‡½æ•°äº†ã€‚ å¤šè¿›ç¨‹ å¤šè¿›ç¨‹æœ‰2ç§é€šè¿‡startçš„é‚£ç§æ–¹å¼+æ™®é€šè¿›ç¨‹æ± ï¼ŒåŒæ ·éå¸¸æ™®éï¼Œæ­¤å¤„å°±ä¸å†™äº†ï¼Œè‡ªå·±ç™¾åº¦ä¸€ä¸‹ã€‚ æ–°ç‰ˆè¿›ç¨‹æ±  åŒæ ·æ˜¯å’Œä¸Šé¢ç”¨ä¸€æ ·çš„futureåº“ï¼ŒæƒŠä¸æƒŠå–œã€‚ï¼ˆå¯ä»¥çœ‹å‡ºå¥½çš„ç¨‹åºè¦å‘ç€ç»Ÿä¸€å°è£…çš„æ–¹å‘ä¼˜åŒ–ï¼‰ ä¹Ÿè®¸ä½ ä¼šæƒŠè®¶ï¼Œå› ä¸ºåªæŠŠthreadå•è¯æ”¹ä¸ºprocessingå°±æ˜¯è¿›ç¨‹æ± ç‰ˆæœ¬äº†ï¼Œå°±æ˜¯è¿™ä¹ˆç®€å•ï¼ï¼ï¼ï¼ï¼ from time import sleep import multiprocessing from concurrent.futures import ProcessPoolExecutor,as_completed,ALL_COMPLETED,wait executor = ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()) def f(): sleep(15) return 100 if __name__ == '__main__': # è¿™å¥è¦åŠ  all_tasks = [executor.submit(f) for _ in range(multiprocessing.cpu_count())] for per_thread in as_completed(all_tasks): print(per_thread.result()) # for per_thread in all_tasks: # print(per_thread.result()) # wait(all_tasks, return_when=ALL_COMPLETED) print('ä¸»è¿›ç¨‹') # è¿™å°±æ˜¯ futures æ¨¡å— è®¾è®¡æ€æƒ³çš„é­…åŠ› å¤šåç¨‹ å‰è¨€ï¼š ä¹Ÿè®¸ä½ è®°å¾—ï¼Œå‡½æ•°ç”¨åˆ° yield æ¥ä»£æ›¿ return å°±å˜æˆäº† ç”Ÿæˆå™¨ã€‚å…¶ç‰¹ç‚¹æ˜¯ä»£ç ç‰‡æ®µæ–­ç‚¹å¼æ‰§è¡Œã€‚ å¦‚æœæœ‰å¤šä¸ªyieldï¼Œ å°±å¯ä»¥è‡ªå·±ç”¨ç¨‹åºæ¥åˆ‡æ¢æ‰§è¡Œç¨‹åºã€‚ï¼ˆè¿™å°±æ˜¯åç¨‹çš„ç‰¹ç‚¹ï¼‰ æ¨èï¼šï¼ˆå­¦ä¹ ä¸­ã€‚ã€‚ã€‚ï¼‰ æ­¤ç¬”è€…å†™çš„å¾ˆå¥½ï¼š https://juejin.im/post/5ccf0d18e51d453b557dc340 ","link":"https://cythonlin.github.io/post/py-greater-python-san-cheng/"},{"title":"PY => Pythonä¸‰å™¨","content":"å¯è¿­ä»£å¯¹è±¡ã€ç”Ÿæˆå™¨ã€è¿­ä»£å™¨ä¸‰è€…çš„å…³ç³» 1. è¿­ä»£å™¨ä¸€å®šæ˜¯å¯è¿­ä»£å¯¹è±¡ 2. ç”Ÿæˆå™¨æ˜¯è¿­ä»£å™¨çš„ä¸€ç§ 3. å¯è¿­ä»£å¯¹è±¡ï¼šå¿…é¡»å®ç° __iter__æ–¹æ³• 4. è¿­ä»£å™¨ï¼šå¿…é¡»å®ç° __iter__æ–¹æ³• å’Œ __next__ æ–¹æ³• 5. ç”Ÿæˆå™¨ï¼šå¿…é¡»å®ç° __iter__æ–¹æ³• å’Œ __next__ æ–¹æ³•ï¼Œyield ä»£æ›¿äº†è¿™ä¸¤ä¸ªæ–¹æ³• 6. å·¥å…·åŒ…ï¼š from collections import Iterable,Iterator 7. æŸ¥çœ‹æŠ½è±¡æ¥å£ï¼š In [265]: Iterable.__abstractmethods__ Out[265]: frozenset({'__iter__'}) In [266]: Iterator.__abstractmethods__ Out[266]: frozenset({'__next__'}) 8. å¯è¿­ä»£å¯¹è±¡éƒ½å¯ä»¥è¢« forå¾ªç¯ æ‰€éå†ï¼Œ å¦å¤– å®ç°äº† __getitem__çš„ç±» å…¶å¯¹è±¡ä¹Ÿå¯foréå† å…³äº __getitem__ç­‰é­”æ³•æ–¹æ³•ï¼Œä»¥åä¼šå•ç‹¬å†™ä¸€ç¯‡æ–‡ç« ã€‚ ç”Ÿæˆå™¨ ç”Ÿæˆå™¨æœ‰ä¸¤ç§å†™æ³•ï¼š å½¢å¼ä¸€ï¼š In [230]: def f(): ...: for x in range(10): ...: yield x In [231]: y = f() å½¢å¼äºŒ: In [239]: y = ( x for x in range(10) ) In [240]: y Out[240]: &lt;generator object &lt;genexpr&gt; at 0x0000024A4D3AFB48&gt; 'æ¨åŠ¨ç”Ÿæˆå™¨' è¿­ä»£æœ‰ä¸‰ç§æ–¹å¼ï¼š æ–¹å¼1ï¼š In [232]: next(y) Out[232]: 0 æ–¹å¼2ï¼š In [233]: y.__next__() Out[233]: 1 æ–¹å¼3ï¼š In [236]: y.send(None) Out[236]: 2 å‰ä¸¤ç§æ–¹å¼æ˜¯ç­‰ä»·çš„ï¼Œç¬¬ä¸‰ç§æ–¹å¼æœ‰äº›å·®åˆ«ï¼Œä¸”å¬æˆ‘è¯´ï¼š In [248]: def f(): ...: print(1) ...: a = yield 2 ...: print(a) In [249]: y = f() In [250]: y.send(None) 1 # è¿™é‡Œæ˜¯ print(1)çš„ç»“æœ Out[250]: 2 In [251]: y.send(100) 100 # è¿™é‡Œæ˜¯print(a)çš„ç»“æœ ä¸çŸ¥é“é˜ä¸‹èƒ½å¦çœ‹å‡ºå’Œä¸¤ç§çš„å·®åˆ«ï¼š 1. yield 2 # è¿™è¡Œå¤šäº†ä¸ªèµ‹å€¼æ“ä½œ 2. send(100) # send() å‡½æ•°é‡Œé¢æ”¾äº†ä¸ªï¼Œç„¶åprint(a) æ‰“å°çš„å°±æ˜¯100 ä¸¾ä¸ªä¾‹å­ï¼š 1. a = yield 2 # ç›¸å½“äºä¸€ä¸ªå£«å…µç­‰å¾…æŒ‡ä»¤ï¼Œç­‰å·å·¦è¾¹è¿˜æœªæ‰§è¡Œï¼Œç¨‹åºå°±è¢«å°é”äº† 2. send(100) # é•¿å®˜è¾“å…¥äº†ä¸€ä¸ª100ï¼Œå£«å…µæ”¶åˆ°åå°±æŠŠç¨‹åºè§£å°ï¼Œå¹¶æ‰§è¡Œç­‰å·å·¦è¾¹ 3. äºæ˜¯ å°±ç›¸å½“äº a è¢«èµ‹å€¼ä¸º 100 è¿­ä»£å™¨ å…ˆçœ‹ä¸¤ä¸ªç®€å•çš„å‡½æ•°ï¼š In [294]: iter([1,2,3]) Out[294]: &lt;list_iterator at 0x24a4e7f5780&gt; In [295]: reversed([1,2,3]) Out[295]: &lt;list_reverseiterator at 0x24a4d38a6a0&gt; è‡ªå®šä¹‰è¿­ä»£å™¨ï¼š In [283]: class A(Iterator): # æ³¨æ„è¿™é‡Œï¼šç»§æ‰¿äº†Iteratorå°±ä¸ç”¨å®ç° __iter__æ¥å£äº† ...: def __init__(self, value): ...: self.value = value ...: self.index = -1 ...: def __next__(self): # æ³¨æ„è¿™é‡Œï¼š__next__æ˜¯å†™é€»è¾‘çš„ä¸»è¦æ¥å£ï¼Œæ¯æ¬¡è¿”å›å•ä¸ªå€¼ ...: self.index += 1 ...: return self.value[self.index] In [284]: a = A(['Tom', 'Jerry']) In [285]: next(a) Out[285]: 'Tom' In [286]: next(a) Out[286]: 'Jerry' ä¸²è”åˆå¹¶è¿­ä»£å™¨ï¼š 1. æ™®é€šåºåˆ—è¿­ä»£å™¨ä¸²è” In [287]: from itertools import chain In [289]: chain(range(1),range(2),range(3)) Out[289]: &lt;itertools.chain at 0x24a4d2c77f0&gt; In [290]: list(chain(range(1),range(2),range(3))) Out[290]: [0, 0, 1, 0, 1, 2] 2. å­—å…¸åºåˆ—è¿­ä»£å™¨ä¸²è” In [288]: from collections import ChainMap In [291]: ChainMap({1:1},{2:2,3:3}) Out[291]: ChainMap({1: 1}, {2: 2, 3: 3}) In [292]: dict(ChainMap({1:1},{2:2,3:3})) Out[292]: {1: 1, 2: 2, 3: 3} è£…é¥°å™¨ è£…é¥°å™¨å¦‚æœæŒ‰é’»ç‰›è§’å°–çš„æ–¹å¼æ¥ç†è§£çš„ç¡®æ˜¯å¾ˆå¤´ç–¼çš„äº‹æƒ…ã€‚å…ˆè¯´ä¸ªä¾‹å­å§ï¼š In [296]: def f(func): ...: def f1(): ...: print('åŸå‡½æ•°ä¹‹å‰åŠ ç‚¹åŠŸèƒ½') ...: func() # è¿™å°±æ˜¯åŸå‡½æ•° ...: print('åŸå‡½æ•°ä¹‹ååŠ ç‚¹åŠŸèƒ½') ...: return f1 In [299]: @f #è¿™å¥ç­‰ä»·äº=&gt; func = f(func) ...: def func(): ...: print('æˆ‘æ˜¯åŸå‡½æ•°å“¦') In [300]: func() &gt;&gt; åŸå‡½æ•°ä¹‹å‰åŠ ç‚¹åŠŸèƒ½ &gt;&gt; æˆ‘æ˜¯åŸå‡½æ•°å“¦ &gt;&gt; åŸå‡½æ•°ä¹‹ååŠ ç‚¹åŠŸèƒ½ è§£é‡Š ç”¨å¤§ç™½è¯æ¥è®²ï¼Œè£…é¥°å™¨å°±æ˜¯åœ¨åŸå‡½æ•°çš„å‰ååŠ åŠŸèƒ½ã€‚ä¹Ÿå°±æ˜¯ç»™åŸå‡½æ•°åŠ ä¸ªå¤–å£³ã€‚çœ‹ä¸Šå»æ˜¯è°ƒç”¨çš„åŸå‡½æ•°ï¼Œ å®åˆ™è°ƒç”¨çš„æ˜¯å¤–å£³å‡½æ•°ï¼Œå¤–å£³å‡½æ•°é‡Œé¢åŒ…æ‹¬åŸå‡½æ•°å’Œ ä¸€äº›å…¶ä»–çš„è‡ªå®šä¹‰åŠŸèƒ½ ä¾‹å­ï¼š é¢åŒ…ä¸å¥½åƒå•Šï¼Œä½†æ˜¯ä½ è¿˜æƒ³åƒè¿™ä¸ªé¢åŒ…ï¼Œå’‹æ•´ï¼Ÿ ä¸Šä¸‹æŠ¹ç‚¹å¥¶æ²¹ï¼Œå°±å˜æˆäº†ä¸‰æ˜æ²»ï¼ˆæˆ‘æ²¡åƒè¿‡ã€‚ã€‚ï¼‰ åƒå…¶ä»–é¢åŒ…çš„æ—¶å€™ç»§ç»­æŠ¹ä¸Šå¥¶æ²¹å°±è¡Œäº†ï¼ˆå°è£…æ€§ï¼‰ é¢åŒ…-åŸå‡½æ•° ä¸‰æ˜æ²»-è¢«è£…é¥°å™¨è£…é¥°åçš„å‡½æ•° å„ç§åŠŸèƒ½ï¼ˆåƒæ³•ï¼‰å¿«é€Ÿæ‹¼æ¥ï¼š @å¥¶æ²¹ def é¢åŒ…1(): pass @å¥¶æ²¹ def é¢åŒ…2(): pass @æ²™æ‹‰ def é¢åŒ…1(): pass @æ²™æ‹‰ def é¢åŒ…2(): pass å­˜åœ¨é—®é¢˜ï¼š @f #è¿™å¥ç­‰ä»·äº=&gt; func = f(func) è¿™æ˜¯æˆ‘ä¸Šé¢è¯´è¿‡çš„ä¸€å¥è¯ï¼Œä½ ä»”ç»†çœ‹çœ‹ï¼š funcä¹‹å‰æŒ‡å‘çš„æ˜¯ï¼ˆåŸå‡½æ•°ï¼‰é¢åŒ…çš„ç©ºé—´ï¼Œæ©ï¼Œfuncå‡½æ•°å ä¹Ÿå°±æ˜¯(__name__) æ˜¯funcï¼ˆé¢åŒ…ï¼‰ ç°åœ¨ä»–æŒ‡å‘çš„æ˜¯ï¼ˆæ–°å‡½æ•°ï¼‰ä¸‰æ˜æ²»çš„ç©ºé—´ï¼Œæ©ï¼Œå®ƒçš„å‡½æ•°åæ˜¯f1(ä¸‰æ˜æ²») å‡½æ•°åå˜äº†ï¼Œæœ‰äº›å¼ å† ææˆ´çš„æ„Ÿè§‰ï¼Œå¦‚æœä¸æƒ³è®©å®ƒå˜ï¼Œå¹¶ä¿æŒæœ¬èº«çš„å‡½æ•°åï¼Œçœ‹æˆ‘æ“ä½œï¼š In [301]: from functools import wraps In [316]: def f(func): ...: @wraps(func) ### æ²¡é”™ è¿™é‡Œæ˜¯æœ€ä¸»è¦çš„ï¼ŒåŸºæœ¬æ ¼å¼å›ºå®šå†™æ³•ï¼Œç…§ç€å†™å³å¯ ...: def f1(): ...: print(func.__name__) ...: print('åŸå‡½æ•°ä¹‹å‰åŠ ç‚¹åŠŸèƒ½') ...: func() ...: print('åŸå‡½æ•°ä¹‹ååŠ ç‚¹åŠŸèƒ½') ...: return f1 æ ‡å‡†è£…é¥°å™¨ä½¿ç”¨ï¼ˆåŸå‡½æ•°å¸¦æœ‰è¿”å›å€¼ å’Œ å‚æ•°ï¼‰ï¼š In [323]: def f(func): ...: @wraps(func) ...: def f1(*args, **kwargs): ...: print('æŠ¥å¹´é¾„å’Œæ€§åˆ«~~~') ...: return func(*args, **kwargs) ...: return f1 In [324]: @f #æ¯æ¬¡éƒ½è¦è®°ä½ test=f(test) è¿™ä¸ªéšå«çš„å˜å½¢ï¼Œç†Ÿäº†å°±å¥½äº† ...: def test(name,age): ...: print(name, age) In [325]: test('Tom',18) -------------------------------ä¸‹é¢æ˜¯æ‰“å°éƒ¨åˆ† æŠ¥å¹´é¾„å’Œæ€§åˆ«~~~ Tom 18 å¸¦å‚æ•°çš„è£…é¥°å™¨ï¼š æ„é€ å¦‚ä¸‹ï¼š def foo(arg): # å…¶å®å°±æ˜¯åœ¨åŸæ¥çš„åŸºç¡€ä¸Šå†å†å†æ¬¡åŒ…è£…ä¸ªå¤–å£³ï¼Œä»…æ­¤è€Œå·² # ä¹‹å‰è®²çš„è£…é¥°å™¨få®ç°ä»£ç åŸå°ä¸åŠ¨å…¨æ”¾åœ¨è¿™é‡Œé¢ï¼Œçœ‹ä¸‹é¢å¸®ä½ å†™å¥½äº†ã€‚ def f(func): @wraps(func) def f1(*args, **kwargs): return func(*args, **kwargs) return f1 return f è°ƒç”¨å½¢å¦‚ï¼š @foo('123') #å¤šäº†ä¸ªå‚æ•°ï¼Œå¯åˆ†è§£ä¸ºfooçš„è¿”å›å€¼f æ”¾åœ¨ @ çš„åé¢ï¼Œæ˜¯ä¸æ˜¯ä¸€åˆ‡åˆå›åˆ°äº†ä»å‰ï¼Ÿ def func(): pass è£…é¥°ç±»ï¼š åº”ç”¨åœºæ™¯ï¼š Python WEBæ¡†æ¶ Flask/Djangoéƒ½æœ‰ FBVå’ŒCBVæ¨¡å¼ (ä»¥åæˆ‘ä¹Ÿä¼šå†™è¿™æ–¹é¢çš„æ–‡ç« ) FBV: Function Based View ç®€å•æ¥è¯´ï¼Œé€»è¾‘è§†å›¾ç”¨å‡½æ•°æ¥å†™ ----é‚£ä¹ˆéœ€è¦è£…é¥°å™¨çš„æ—¶å€™ï¼Œç›´æ¥ç”¨æ™®é€šå‡½æ•°è£…é¥°å™¨è£…é¥°åˆ°å‡½æ•°ä¸Šå³å¯ CBV: Class Based View ç®€å•æ¥è¯´ï¼Œé€»è¾‘è§†å›¾ç”¨ç±»æ¥å†™ ----è¿™ç§æ²¡æœ‰å‡½æ•°ï¼Œæ˜¯ç”¨ç±»å†™çš„ï¼Œé‚£ä¹ˆè¿™æ—¶å€™å°±éœ€è¦å¯¹ç±»è¿›è¡Œè£…é¥°äº† æ ¸å¿ƒæ€æƒ³ï¼š è¿˜æ˜¯è®°ä½ä¸Šé¢è®²çš„éšå¼å˜å½¢ï¼Œåªä¸è¿‡è¿™æ¬¡ä¼ ç»™è£…é¥°å™¨çš„æ˜¯ç±»ï¼Œå¯¹ç±»çš„æ“ä½œå¯å°±å¤ªå¤šäº†ã€‚ é‡Œé¢ä¸€å¤§å †é»‘é­”æ³•ï¼Œä¸‹é¢æˆ‘å°±æ¥å†™ä¸€ä¸‹ç±»åˆå§‹åŒ–åŠŸèƒ½æ€§è£…é¥°å™¨ã€‚ï¼ˆä»¥åä¹Ÿä¼šå•ç‹¬å†™é»‘é­”æ³•çš„æ–‡ç« ï¼‰ In [1]: def f(c): def f1(*args, **kwargs): return c(*args,**kwargs) return f1 In [2]: @f ...: class A: ...: def __init__(self,name): ...: print(name) In [3]: A('Tom') Tom # è¿™æ˜¯printæ‰“å°çš„è¾“å‡º Out[3]: &lt;__main__.A at 0x2948e8fb828&gt; ç±»è£…é¥°å™¨ï¼š è¿™ä¸ªåœºæ™¯çœŸæ²¡é‡åˆ°è¿‡ï¼Œä¸è¿‡å®ç°ä¹Ÿå¾ˆå®¹æ˜“çš„ã€‚ In [8]: class A: ...: def __init__(self,func): ...: self.func = func ...: def __call__(self,*args,**kwargs): ...: print('ç±»è£…é¥°å¡«å……äº†å•Š') ...: self.func(*args, **kwargs) ...: In [9]: @A ...: def test(): ...: print('æˆ‘æ˜¯åŸå‡½æ•°') ...: In [10]: test() ç±»è£…é¥°å¡«å……äº†å•Š æˆ‘æ˜¯åŸå‡½æ•° è¯´æ˜ï¼šåé¢å…³äºç±»çš„è£…é¥°å™¨å¦‚æœç†è§£å›°éš¾å½“åšäº†è§£å³å¯ï¼Œç”¨çš„ä¹Ÿå°‘ã€‚ ","link":"https://cythonlin.github.io/post/py-greater-python-san-qi/"},{"title":"PY => Pythoné«˜é˜¶å‡½æ•°æ“ä½œ","content":"map In [25]: list(map(lambda a:a**2, [1,2,3,4])) Out[25]: [1, 4, 9, 16] è§£é‡Šï¼šmapå°±ç›¸å½“äº æŠŠæ¯ä¸ªåºåˆ—å…ƒç´  çš„æ¯ä¸€ä¸ª å•ç‹¬ç”¨ä¸€ä¸ªç®¡é“å‡½æ•°å¤„ç†ï¼Œ å†æŠŠä»–ä»¬æŒ‰é¡ºåºç»„åˆæˆä¸€ä¸ªæ–°å¯è¿­ä»£å¯¹è±¡ æ³¨æ„ï¼šè¿™ä¸ªç®¡é“å‡½æ•° åªèƒ½æ˜¯å•å‚æ•°å‡½æ•°ï¼Œå¦‚æœæƒ³ä¼ é€’å¤šä¸ªå‚æ•°æ€ä¹ˆåŠï¼Ÿï¼Ÿï¼Ÿ 1. ä½¿ç”¨åå‡½æ•° paitial (æ€•æœ‰äº›äººçœ‹ä¸æ‡‚ï¼Œè¿™é‡Œå°±ä¸ç”¨lambdaäº†ï¼Œè€Œæ˜¯ç”¨æ™®é€šå‡½æ•°å®šä¹‰æ–¹å¼) In [58]: def f(a,b): ...: return a**2,b In [59]: f = partial(f,b='å›ºå®šå€¼') In [60]: list(map(f,[1,2,3,4])) Out[60]: [(1, 'å›ºå®šå€¼'), (4, 'å›ºå®šå€¼'), (9, 'å›ºå®šå€¼'), (16, 'å›ºå®šå€¼')] å½“ç„¶è¿˜æ˜¯æä¾›ä¸€ä¸‹lambdaçš„æ–¹å¼å§ï¼Œçœ‹çœ‹æœ‰å¤šç®€æ´ã€‚ In [64]: list(map(partial(lambda a,b:(a**2,b),b='å›ºå®šå€¼') ,[1,2,3,4])) Out[64]: [(1, 'å›ºå®šå€¼'), (4, 'å›ºå®šå€¼'), (9, 'å›ºå®šå€¼'), (16, 'å›ºå®šå€¼')] 2. å¦‚æœæƒ³å¯¹mapä¼ é€’å¤šä¸ªå‚æ•°ï¼Œé™¤äº†ä¸Šé¢ç”¨åå‡½æ•°ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ä¸‹é¢ä»‹ç»çš„starmap mapå¤šå‚åº”ç”¨åœºæ™¯ï¼šè¿›ç¨‹æ± çš„imap ï¼ˆä»¥åæˆ‘ä¹Ÿä¼šå†™Pythonä¸‰å™¨ä¸‰ç¨‹çš„æ–‡ç« ï¼‰ starmap In [30]: list(starmap(lambda a,b:a+b,( (1,2),(3,4)))) Out[30]: [3, 7] è§£é‡Šä¸€ä¸‹ï¼š starmap å’Œ partialè™½ç„¶éƒ½å¯ä»¥è§£å†³ mapä¼ å¤šå‚ï¼Œä½†è¿˜æ˜¯æœ‰ä¸€äº›åŒºåˆ«çš„ starmapçš„ æ¯ä¸€å¯¹çš„å¤šä¸ªå‚æ•° éƒ½æ˜¯å¯†åˆ‡ç›¸å…³çš„ partialçš„ åå‚æ•° æ˜¯å’Œæ‰€æœ‰ ä¸»å‚æ•° å…¨éƒ¨ç›¸å…³çš„ reduce In [87]: from functools import reduce In [88]: reduce(lambda a,b:a*b, [1,2,3,4]) Out[88]: 24 è§£é‡Šä¸€ä¸‹ï¼šreduce ç›¸å½“äºå¯¹ä¸€ä¸ªåºåˆ—'ç´¯'çš„æ“ä½œ ï¼ˆç´¯åŠ ã€ç´¯ä¹˜ç­‰ï¼‰ï¼Œè¿”å›ç»“æœå°±æ˜¯ç´¯å€¼ filter In [100]: list(filter(lambda a:a if a&gt;2 else None, [1,2,3,4])) Out[100]: [3, 4] è§£é‡Šä¸€ä¸‹ï¼šå’Œmapæ€æƒ³ä¸€æ ·ï¼Œæ ¹æ®æ¡ä»¶è¿‡æ»¤åºåˆ—ã€‚ sorted In [128]: dict1 = {'å­¦å·2':'1','å­¦å·1':'2'} In [129]: sorted(dict1.items(),key=lambda x:x[1]) Out[129]: [('å­¦å·2', '1'), ('å­¦å·1', '2')] è§£é‡Šä¸€ä¸‹ï¼šå’Œlistçš„sortå‡½æ•°ç±»ä¼¼ï¼Œ ä½†è¿™ä¸ªsortedçš„ä¼˜ç‚¹æ˜¯é’ˆå¯ä»¥å¯¹æ‰€æœ‰åºåˆ—æ’åº zip In [132]: list(zip((1,2),(3,4,5))) Out[132]: [(1, 3), (2, 4)] è§£é‡Šä¸€ä¸‹ï¼šæ¯ä¸ªå­åºåˆ—å¯¹åº”ä½ç½®è¿›è¡Œç»„åˆï¼Œ å¦‚æœæ ¼å¼ä¸åŒ¹é…ï¼Œåˆ™ä¼šèˆå¼ƒä¸åŒ¹é…çš„é‚£ä¸€é¡¹ ä¸‰ç›®è¿ç®— ä¸‰ç›®è¿ç®—ç¬¦å¯ä»¥ä½¿ä»£ç ç®€ä»‹é€»è¾‘æ¸…æ™°ï¼ˆè™½ç„¶ or and ä¹Ÿæ˜¯å¯ä»¥ä½¿ä»£ç é€»è¾‘ç®€æ´ï¼Œä½†æœ‰äº›çƒ§è„‘ï¼Œæˆ‘å‡ ä¹ä¸ç”¨~~ï¼‰ In [78]: print(1 if 0==0 else 2) Out[78]: 1 æ¨å¯¼å¼ å…¶å®æœ‰æ—¶ç”¨æ¨å¯¼å¼ä¹Ÿå¯ä»¥ä»£æ›¿éƒ¨åˆ†é«˜é˜¶æ“ä½œï¼Œå¹¶ä¸”æ¨å¯¼å¼çš„æ•ˆç‡ä¹Ÿé«˜ 1. åˆ—è¡¨æ¨å¯¼å¼ In [77]: [1 for _ in range(5) if 1==1] Out[77]: [1, 1, 1, 1, 1] 2. é›†åˆæ¨å¯¼å¼ In [6]: {x for x in [1,2,1,2]} Out[6]: {1, 2} 3. å­—å…¸æ¨å¯¼å¼ In [18]: {value:key for key,value in {'name':'tom'}.items()} Out[18]: {'tom': 'name'} 4. ç”Ÿæˆå™¨ ï¼ˆç”Ÿæˆå™¨è¿˜æœ‰å¦å¤–çš„æ–¹å¼ï¼Œåé¢è¿˜ä¼šä¸‰ç¨‹ä¸‰å™¨ï¼‰ In [23]: (x for x in range(10)) Out[23]: &lt;generator object &lt;genexpr&gt; at 0x0000024A4CFA8BA0&gt; ","link":"https://cythonlin.github.io/post/py-greater-python-gao-jie-han-shu-cao-zuo/"},{"title":"PY => PythonåŸºæœ¬æ•°æ®ç±»å‹","content":"æ•°æ®ç»“æ„ å¯å˜ç±»å‹ä¸ä¸å¯å˜ç±»å‹ï¼ˆé‡å¤´æˆï¼‰ åŸºæ“ï¼š å¯å˜ç±»å‹ï¼š[], {} # å¯å¢åˆ æ”¹ æŸ¥ ä¸å¯å˜ç±»å‹: int float str () # æ— æ³•å¢åˆ æ”¹ï¼Œ åªå¯æŸ¥ å‡æ“ï¼š + ä¸ += çš„åŒºåˆ«ï¼š ä¹Ÿè®¸å¾ˆå¤šäººä¼šè¯´ + å’Œ += æ˜¯å®Œå…¨ç­‰ä»·çš„ï¼Œæˆ–è€…çŸ¥é“åŒºåˆ«ï¼Œä½†ä¹Ÿè¯´ä¸å‡ºä¸ªæ‰€ä»¥ç„¶ çœ‹æˆ‘æ“ä½œï¼šï¼ˆå¿½ç•¥Pythonå°æ•´æ•°æ± çš„å†…å­˜å›ºå®šåˆ†é…é—®é¢˜ï¼‰ +: æ— è®ºæ˜¯å¯å˜ç±»å‹ è¿˜æ˜¯ ä¸å¯å˜ç±»å‹ï¼Œ éƒ½æ˜¯æ–°æŒ‡å‘çš„ç©ºé—´ +=: å¯¹äºå¯å˜ç±»å‹ï¼šåŸåœ°æ“ä½œï¼ŒåŸæŒ‡å‘ï¼ŒåŸç©ºé—´ å¯¹äºä¸å¯å˜ç±»å‹ï¼šå¼‚åœ°æ“ä½œï¼Œæ–°æŒ‡å‘ï¼Œæ–°ç©ºé—´ æˆ‘è¿™é‡Œæ•…æ„æä½ ä¸€ä¸‹æ€ç»ªï¼šè§è¿‡ a=+1 ä¹ˆï¼Œå¯ä»¥è¿è¡Œè¯•è¯•ã€‚ ä¸è¦ç–‘æƒ‘ï¼Œå‘Šè¯‰ä½ ç­”æ¡ˆï¼šè¿™ä¸ª+1 ä»£è¡¨ æ­£è´Ÿå·çš„ æ­£1ã€‚ è™½ç„¶ä¸€ç‚¹æŠ€æœ¯å«é‡æ²¡æœ‰ï¼Œä½†æ˜¯ä½ è¦æ‡‚ åºåˆ— ä¹Ÿè®¸å«å¯è¿­ä»£å¯¹è±¡æ›´ä¸ºåˆé€‚ï¼Œä½†æ˜¯æˆ‘å–œæ¬¢å«åºåˆ—ã€‚ æˆ‘è®¤çŸ¥çš„åºåˆ—åŒ…æ‹¬ [], {}, () # è¯·è®°ä½è¿™ä¸ªåºåˆ—ï¼Œæ•°æ®å¤„ç†æœ€ä¸ºé‡è¦ æ­¤å¤–è¯´æ˜ä¸€ä¸‹ï¼š 1. æˆ‘çš„ä»£ç å¤§å¤šéƒ½æ˜¯Ipythonè¿è¡Œå®Œè´´ä¸Šå»çš„ï¼Œ æ‰€ä»¥ä½ çœ‹è§çš„outæ ¼å¼å°±ä»£è¡¨printäº†ï¼Œè¦æ‡‚~ 2. æ‰€å†™çš„å¤§å¤šéƒ½æ˜¯å®é™…ç»éªŒä¸­å¸¸ç”¨çš„ æˆ–è€… å†·é—¨ä½†æ˜¯å¥½ç”¨çš„ 3. åˆ—å‡ºçš„å‡½æ•°APIæœ‰çš„å«Œå¼ƒéº»çƒ¦æ²¡æœ‰å†™å‚æ•°ï¼Œä½ è¦æ‡‚ï¼Œï¼ˆæˆ‘è¿™é‡Œæ²¡æœ‰é¡¾åŠ0å…¥é—¨çš„å°ç™½ï¼Œè°…è§£ï¼‰ å…ƒç¥– åŸºæ“ï¼š å…ƒç¥–å±äºä¸å¯å˜ç±»å‹ï¼Œä¸èƒ½å¢åˆ æ”¹ï¼Œæ‰€ä»¥å‡½æ•°å°‘çš„å¯æ€œ æˆ‘ç”¨helpæŸ¥äº†ä¸€ä¸‹ï¼Œåªæœ‰ä¸‹é¢è¿™2ä¸ªå‡½æ•°ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ a = (1,2,3) count() # ç»Ÿè®¡å…ƒç´ ä¸ªæ•° index() # æŸ¥æ‰¾å…ƒç´ ï¼Œå¹¶è¿”å›ä½ç½® å‡æ“ï¼š a = (1) # å“¥ä»¬æ³¨æ„ï¼Œè¿™ä¸æ˜¯å…ƒç¥–ï¼Œè¿™æ˜¯ æ•´å½¢1 ..... a = (1,) # è¿™æ‰æ˜¯å…ƒç¥–ï¼Œå•å…ƒç´ å…ƒç¥–éœ€è¦åŠ é€—å·ï¼Œè®°ä½å³å¯ï¼Œä¸å¿…çº ç»“ å¸¸ç”¨å­—ç¬¦ä¸²æ“ä½œ: åŸºæ“ï¼š a = ' ä½ 2å¥½ ' a.find('ä½ ') # æœç´¢ç›®æ ‡å­—ç¬¦ä¸²ï¼Œæ‰¾åˆ° åˆ™ è¿”å›ç´¢å¼•ï¼Œæ‰¾ä¸åˆ° åˆ™ è¿”å›-1 ï¼ˆæ¨èä½¿ç”¨ï¼‰ a.split(2) # æ³¨æ„ï¼šä¸ç»™å‚æ•°ï¼Œé»˜è®¤æŒ‰æ‰€æœ‰ ç©ºç™½ç¬¦ åˆ‡å‰² a.strip() å‡æ“ï¼š 1. stringåº“çš„çµæ´»ä½¿ç”¨ In [1]: import string In [2]: string.digits Out[2]: '0123456789' In [8]: string.ascii_letters Out[8]: 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' In [9]: string.ascii_lowercase Out[9]: 'abcdefghijklmnopqrstuvwxyz' In [10]: string.ascii_uppercase Out[10]: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' In [12]: string.punctuation Out[12]: '!&quot;#$%&amp;\\'()*+,-./:;&lt;=&gt;?@[\\\\]^_`{|}~' 2. python3.6 - fæ¨¡æ¿å­—ç¬¦ä¸² æ–°è¯­æ³•å¼•å‡ºæ¥ï¼Œåªä¸ºåˆ·ä¸‰è§‚ï¼Œå…·ä½“è‡ªå·±å»å­¦ å­¦è¿‡ES6å¯èƒ½ä¼šå¾ˆç†Ÿæ‚‰ -&gt; å…¶å®å°±æ˜¯æ¨¡æ¿å­—ç¬¦ä¸² (ES6å’Œpythonè¯­æ³•çœŸçš„å¾ˆåƒ) In [15]: name = 'å¼ ä¸‰' In [16]: f'åå­—:{name}' Out[16]: 'åå­—:å¼ ä¸‰' å¦‚æœä½ æƒ³å­¦ä¹ æ›´å¤šfåŸè¯­ï¼Œè¯·å‚è€ƒè¿™ä½è€å“¥-&gt; https://blog.csdn.net/sunxb10/article/details/81036693 å¸¸ç”¨åˆ—è¡¨æ“ä½œ: a = [4,3,2,1] åŸºæ“ï¼š a.extend() # å‚æ•°å¦‚æœæ˜¯åºåˆ—ï¼Œåˆ™æŠŠè¿™ä¸ªåºåˆ—è§£å¼€ï¼Œä¸€ä¸ªä¸€ä¸ªæ’å…¥ a.append() # å‚æ•°å†™ä»€ä¹ˆ,æ’å…¥çš„å°±æ˜¯ä»€ä¹ˆ å‡æ“ï¼š a[::] # å¼€è¾Ÿç©ºé—´ å¤åˆ¶åˆ—è¡¨ a.sort(key=) # è®°ä½è¿™ä¸ªkey,å¯ä»¥å†™å‡½æ•°å ï¼ˆåé¢ä¹Ÿä¼šå†™é«˜é˜¶å‡½æ•°çš„æ–‡ç« ï¼‰ å¸¸ç”¨å­—å…¸æ“ä½œ: åŸºæ“ï¼š a = {1:2} a.update({key:value}) # æœ‰åˆ™æ›´æ–°ï¼Œæ— åˆ™æ·»åŠ (Key-Valueç®—ä¸€ä¸ªæ•´ä½“) a.setdefault(key, value) # æœ‰æ­¤Keyåˆ™ä¸å˜ å¹¶è¿”å›valueï¼Œæ— åˆ™æ’å…¥key,valueå¹¶è¿”å›None a.keys() # è¿”å›æ‰€æœ‰ key ï¼ˆæ³¨æ„ï¼šè¿”å›å€¼å¯ä»¥ç†è§£ä¸º é›†åˆå¯¹è±¡ï¼‰ a.values() # è¿”å›æ‰€æœ‰ value (åŒä¸Šï¼Œè¿”å›å€¼å¯ç†è§£ä¸º é›†åˆå¯¹è±¡) a.items() # è¿”å›æ‰€æœ‰ é”®å€¼å¯¹ ï¼ˆåŒä¸Šï¼Œè¿”å›å€¼å¯ç†è§£ä¸º é›†åˆå¯¹è±¡ï¼‰ å‡æ“ï¼š 1. Keyæ˜¯å­—å…¸ä½œä¸ºåºåˆ—çš„é»˜è®¤é¦–é€‰é¡¹ è§£é‡Šå¯¹åˆ—è¡¨ã€å…ƒç¥–ç­‰åºåˆ—ç­‰ä¸€ç³»åˆ—æ“ä½œå¦‚æœåº”ç”¨åœ¨ å­—å…¸ä¸Š å°±ä¼šåªæ“ä½œ Key 2. åŒå±‚åºåˆ— å’Œ å­—å…¸ è½¬æ¢ï¼š seq2dict: dict( ((1,2),(3,4)) ) dict2seq: tuple( {1:2,3:4}.items() ) å¸¸ç”¨é›†åˆæ“ä½œï¼š å¤§å‰æï¼š é›†åˆ=æ— åº=å»é‡ åŸºæ“ï¼šadd | pop | remove | update å’Œ &amp; | - ^ å‡æ“ï¼š(é›†åˆçš„åˆå§‹åŒ–æ–¹å¼çš„å·®å¼‚) In [57]: s1 = set('abcd') # ç†è§£æ–¹å¼ï¼š æ­¤åˆå§‹åŒ–æ–¹å¼ ä¼šå…ˆéå† æ•´ä¸ª å­—ç¬¦ä¸² In [58]: s1 Out[58]: {'a', 'b', 'c', 'd'} In [59]: s2 = {'abcd'} # ç†è§£æ–¹å¼ï¼š æ­¤åˆå§‹åŒ–æ–¹æ³•æŠŠ æ•´ä¸ª å­—ç¬¦ä¸²å½“åšé›†åˆçš„ ä¸€ä¸ª å…ƒç´  In [60]: s2 Out[60]: {'abcd'} ","link":"https://cythonlin.github.io/post/py-greater-python-ji-ben-shu-ju-lei-xing/"}]}